{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22da9b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2021-08-23 00:00:00', '2021-08-23 00:01:00',\n",
       "               '2021-08-23 00:02:00', '2021-08-23 00:03:00',\n",
       "               '2021-08-23 00:04:00', '2021-08-23 00:05:00',\n",
       "               '2021-08-23 00:06:00', '2021-08-23 00:07:00',\n",
       "               '2021-08-23 00:08:00', '2021-08-23 00:09:00',\n",
       "               ...\n",
       "               '2021-08-23 23:50:00', '2021-08-23 23:51:00',\n",
       "               '2021-08-23 23:52:00', '2021-08-23 23:53:00',\n",
       "               '2021-08-23 23:54:00', '2021-08-23 23:55:00',\n",
       "               '2021-08-23 23:56:00', '2021-08-23 23:57:00',\n",
       "               '2021-08-23 23:58:00', '2021-08-23 23:59:00'],\n",
       "              dtype='datetime64[ns]', length=1440, freq='T')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from datetime import datetime, timedelta\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import altair as alt\n",
    "#from neuralprophet import NeuralProphet\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from orbit.utils.simulation import make_trend, make_seasonality, make_regression\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = [8, 8]\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "random.seed()\n",
    "\n",
    "myfreq = \"1MIN\" # \"D\" or \"1MIN\"\n",
    "if myfreq == \"1MIN\":\n",
    "    xs = pd.date_range(\"00:00\", \"23:59\", freq=myfreq)\n",
    "elif myfreq == \"D\":\n",
    "    xs = pd.date_range(start='1/1/2018', end='1/1/2022', freq=myfreq)\n",
    "else:\n",
    "    xs = pd.date_range(start='1/1/1818', end='1/1/2122', freq=myfreq)\n",
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ff4e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies(forecast):\n",
    "    forecasted = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper', 'fact']].copy()\n",
    "    #forecast['fact'] = df['y']\n",
    "    forecasted['anomaly'] = 0\n",
    "    forecasted.loc[forecasted['fact'] > forecasted['yhat_upper'], 'anomaly'] = 1\n",
    "    forecasted.loc[forecasted['fact'] < forecasted['yhat_lower'], 'anomaly'] = 1\n",
    "\n",
    "    #anomaly importances\n",
    "    '''\n",
    "    forecasted['importance'] = 0\n",
    "    forecasted.loc[forecasted['anomaly'] ==1, 'importance'] = \\\n",
    "        (forecasted['fact'] - forecasted['yhat_upper'])/forecast['fact']\n",
    "    forecasted.loc[forecasted['anomaly'] == 1, 'importance'] = \\\n",
    "        (forecasted['yhat_lower'] - forecasted['fact'])/forecast['fact']\n",
    "    '''\n",
    "    \n",
    "    return forecasted\n",
    "def plot_anomalies(forecasted, mytitle='Anomaly Detection'):\n",
    "    interval = alt.Chart(forecasted).mark_area(interpolate=\"basis\", color = '#7FC97F').encode(\n",
    "    x=alt.X('ds:T', axis=alt.Axis(format='%H:%M'), title ='date'),\n",
    "    y='yhat_upper',\n",
    "    y2='yhat_lower',\n",
    "    tooltip=['ds', 'fact', 'yhat_lower', 'yhat_upper']\n",
    "    ).interactive().properties(\n",
    "        title=mytitle\n",
    "    )\n",
    "\n",
    "    fact = alt.Chart(forecasted[forecasted.anomaly==0]).mark_circle(size=15, opacity=0.7, color = 'Black').encode(\n",
    "        x='ds:T',\n",
    "        y=alt.Y('fact', title='CPU Utilization Percentage'),    \n",
    "        tooltip=['ds', 'fact', 'yhat_lower', 'yhat_upper']\n",
    "    ).interactive()\n",
    "\n",
    "    anomalies = alt.Chart(forecasted[forecasted.anomaly!=0]).mark_circle(size=30, color = 'Red').encode(\n",
    "        x='ds:T',\n",
    "        y=alt.Y('fact', title='CPU Utilization Percentage'),    \n",
    "        tooltip=['ds', 'fact', 'yhat_lower', 'yhat_upper']\n",
    "    ).interactive()\n",
    "\n",
    "    return alt.layer(interval, fact, anomalies)\\\n",
    "              .properties(width=870, height=450)\\\n",
    "              .configure_title(fontSize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2d2f12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-08-23 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-08-23 00:01:00</td>\n",
       "      <td>1.082844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-08-23 00:02:00</td>\n",
       "      <td>1.167463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-08-23 00:03:00</td>\n",
       "      <td>1.200064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-08-23 00:04:00</td>\n",
       "      <td>1.281451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2021-08-23 23:55:00</td>\n",
       "      <td>7.643661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2021-08-23 23:56:00</td>\n",
       "      <td>7.740793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2021-08-23 23:57:00</td>\n",
       "      <td>7.729485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2021-08-23 23:58:00</td>\n",
       "      <td>7.809879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2021-08-23 23:59:00</td>\n",
       "      <td>7.870194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ds         y\n",
       "0    2021-08-23 00:00:00       NaN\n",
       "1    2021-08-23 00:01:00  1.082844\n",
       "2    2021-08-23 00:02:00  1.167463\n",
       "3    2021-08-23 00:03:00  1.200064\n",
       "4    2021-08-23 00:04:00  1.281451\n",
       "...                  ...       ...\n",
       "1435 2021-08-23 23:55:00  7.643661\n",
       "1436 2021-08-23 23:56:00  7.740793\n",
       "1437 2021-08-23 23:57:00  7.729485\n",
       "1438 2021-08-23 23:58:00  7.809879\n",
       "1439 2021-08-23 23:59:00  7.870194\n",
       "\n",
       "[1440 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## generate random data\n",
    "\n",
    "multiplier = 10\n",
    "\n",
    "# random walk\n",
    "rw = make_trend(len(xs), rw_loc=0.01, rw_scale=1, seed=random.randint(1, 2000))\n",
    "# normalize [0, 1.5]\n",
    "y= 1 + (multiplier*(rw - np.min(rw))/np.ptp(rw))\n",
    "_ = plt.plot(xs, y)\n",
    "\n",
    "for i in range(len(y)):\n",
    "    if i % 50 == 0 :#and i > 100:\n",
    "        y[i] = np.NaN\n",
    "# # fourier\n",
    "# fs = make_seasonality(len(xs), seasonality=random.randint(100, 1000), method='fourier', order=random.randint(4, 10), seed=random.randint(1, 2000))\n",
    "# y = 1 + (multiplier*(fs - np.min(fs))/np.ptp(fs))\n",
    "# _ = plt.plot(y)\n",
    "\n",
    "# # arma\n",
    "# arma_trend =  make_trend(len(xs), method='arma', arma=[.8, -.1], seed=random.randint(1, 2000))\n",
    "# # normalize [0, 1.5]\n",
    "# y = (multiplier*(arma_trend - np.min(arma_trend))/np.ptp(arma_trend))\n",
    "# _ = plt.plot(xs, y)\n",
    "\n",
    "# # discrete\n",
    "# ds = make_seasonality(len(xs), seasonality=random.randint(20, 50), duration=random.randint(2, 50), method='discrete', seed=random.randint(1, 2000))\n",
    "# y = (multiplier*(ds - np.min(ds))/np.ptp(ds))\n",
    "# _ = plt.plot(xs, y)\n",
    "\n",
    "df = pd.DataFrame({\"ds\" : xs, \"y\" : y})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c83e251e-465c-404b-a62a-0d5e3b1fb297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "\n",
    "%matplotlib inline\n",
    "mydf = pd.Series(y, xs)\n",
    "\n",
    "## shared parameters among different models\n",
    "\n",
    "max_interval = 1440 # max training time interval\n",
    "one_step_len = 5 ## re-fit model every five steps\n",
    "n_loops = (len(mydf) // one_step_len) - 1\n",
    "confidence_interval_level = 2.57 ## 1 for 68%, 2 for 95% and 3 standard deviation for 99.7%. use 3 or 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "45d82bf3-22b7-406e-a5e5-0a3e73b67a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021-08-23 00:00:00         NaN\n",
       "2021-08-23 00:01:00    1.082844\n",
       "2021-08-23 00:02:00    1.167463\n",
       "2021-08-23 00:03:00    1.200064\n",
       "2021-08-23 00:04:00    1.281451\n",
       "                         ...   \n",
       "2021-08-23 23:55:00    7.643661\n",
       "2021-08-23 23:56:00    7.740793\n",
       "2021-08-23 23:57:00    7.729485\n",
       "2021-08-23 23:58:00    7.809879\n",
       "2021-08-23 23:59:00    7.870194\n",
       "Freq: T, Length: 1440, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "55dbecc5-1917-455a-bf4d-9230c03ba4b7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "## SARIMAX model fit\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import statsmodels as sm\n",
    "# mydf2, mytest = mydf[:1000], mydf[1000:1010]\n",
    "# model = SARIMAX(mydf2, order=(1,1,1))\n",
    "# model_fit = model.fit(disp=0)\n",
    "# res = model_fit.get_forecast(10, alpha=0.05)\n",
    "# res.conf_int()\n",
    "# res1 = model_fit.forecast(10, alpha=0.05)\n",
    "# res1\n",
    "# fc_series = pd.Series(fc, index=mytest.index)\n",
    "# lower_series = pd.Series(conf[:, 0], index=mytest.index)\n",
    "# upper_series = pd.Series(conf[:, 1], index=mytest.index)\n",
    "\n",
    "print(n_loops)\n",
    "fcall = None\n",
    "lowerall = None\n",
    "upperall = None\n",
    "\n",
    "for i1 in range(10, n_loops): # 39 for normal period and 59 for all\n",
    "    i = i1 * one_step_len\n",
    "    mydf1, mytest = mydf[0:i+one_step_len].copy(), mydf[i+one_step_len: i + one_step_len*2].copy() # no max interval\n",
    "    order = (1,1,1)\n",
    "    seasonal_order= (0,0,0,0)\n",
    "    enforce_stationarity = True\n",
    "    myfit = SARIMAX(mydf1,enforce_stationarity=enforce_stationarity, order=order, seasonal_order=seasonal_order).fit(disp=False)\n",
    "\n",
    "    #alpha = 0.003 if confidence_interval_level == 3 else 0.05 if confidence_interval_level == 2 else 0.32\n",
    "    alpha = 0.01\n",
    "    fc_series = myfit.forecast(one_step_len)\n",
    "    intervals = myfit.get_forecast(one_step_len).conf_int(alpha=alpha)\n",
    "    lower_series, upper_series = intervals[\"lower y\"], intervals[\"upper y\"]\n",
    "    \n",
    "    if fcall is None:\n",
    "        fcall = fc_series.copy()\n",
    "        lowerall = lower_series.copy()\n",
    "        upperall = upper_series.copy()\n",
    "    else:\n",
    "        fcall = pd.concat([fcall, fc_series.copy()])\n",
    "        lowerall = pd.concat([lowerall, lower_series.copy()])\n",
    "        upperall = pd.concat([upperall, upper_series.copy()])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "53a80fc4-a5b7-4501-9f2a-7f93e70b2bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-ba79105e726d4edea33747e712caa881\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-ba79105e726d4edea33747e712caa881\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-ba79105e726d4edea33747e712caa881\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"title\": {\"fontSize\": 20}}, \"layer\": [{\"data\": {\"name\": \"data-117cd9359370c6ea9344baafbe26ab87\"}, \"mark\": {\"type\": \"area\", \"color\": \"#7FC97F\", \"interpolate\": \"basis\"}, \"encoding\": {\"tooltip\": [{\"type\": \"temporal\", \"field\": \"ds\"}, {\"type\": \"quantitative\", \"field\": \"fact\"}, {\"type\": \"quantitative\", \"field\": \"yhat_lower\"}, {\"type\": \"quantitative\", \"field\": \"yhat_upper\"}], \"x\": {\"type\": \"temporal\", \"axis\": {\"format\": \"%H:%M\"}, \"field\": \"ds\", \"title\": \"date\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"yhat_upper\"}, \"y2\": {\"field\": \"yhat_lower\"}}, \"selection\": {\"selector019\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"title\": \"SARIMAX Anomaly Detection\"}, {\"data\": {\"name\": \"data-a4cdb69cb061d4522db309b74e93ce10\"}, \"mark\": {\"type\": \"circle\", \"color\": \"Black\", \"opacity\": 0.7, \"size\": 15}, \"encoding\": {\"tooltip\": [{\"type\": \"temporal\", \"field\": \"ds\"}, {\"type\": \"quantitative\", \"field\": \"fact\"}, {\"type\": \"quantitative\", \"field\": \"yhat_lower\"}, {\"type\": \"quantitative\", \"field\": \"yhat_upper\"}], \"x\": {\"type\": \"temporal\", \"field\": \"ds\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"fact\", \"title\": \"CPU Utilization Percentage\"}}, \"selection\": {\"selector020\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}}, {\"data\": {\"name\": \"data-6901ae1c11c8ca95bc6f676e09993d85\"}, \"mark\": {\"type\": \"circle\", \"color\": \"Red\", \"size\": 30}, \"encoding\": {\"tooltip\": [{\"type\": \"temporal\", \"field\": \"ds\"}, {\"type\": \"quantitative\", \"field\": \"fact\"}, {\"type\": \"quantitative\", \"field\": \"yhat_lower\"}, {\"type\": \"quantitative\", \"field\": \"yhat_upper\"}], \"x\": {\"type\": \"temporal\", \"field\": \"ds\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"fact\", \"title\": \"CPU Utilization Percentage\"}}, \"selection\": {\"selector021\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}}], \"height\": 450, \"width\": 870, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-117cd9359370c6ea9344baafbe26ab87\": [{\"ds\": \"2021-08-23T00:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.082844108170518, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.1674626685853957, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.2000638083637936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.2814511443512329, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.3429855599321083, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.2755731156274361, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.3259830242634005, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.4015225334641455, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.4579557754303325, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.4239244375389235, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.4248304660409077, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5154668939682374, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5347447133251277, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5788794305034655, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5726670357289692, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6529094883797053, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5430597588849078, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7045537848463952, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.725605597123208, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8969706823799903, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8337969714925286, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6294768866812936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.567784829262433, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5549744824391043, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.4655315966944646, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5393699211046206, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5668600641982584, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6655541826966052, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7580343014578879, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7003402751751524, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7381733427541626, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8166089669392944, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8202484912521655, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7872173390481985, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7582781883694865, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6414662620123128, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.570877626485185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6024371681340028, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7349602229944048, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7985687642651969, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8061596609015358, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6931954985336808, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.760725739200367, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7189225397241747, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7880738117048671, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8704947902250355, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.967249743848884, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8691529633007926, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8629364499573176, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7756583985416396, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7897277717701854, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6222619168405523, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7314104084301887, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:55:00\", \"yhat\": 1.7324618046870077, \"yhat_lower\": 1.5209716187737432, \"yhat_upper\": 1.9439519906002722, \"fact\": 1.9129068757687002, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:56:00\", \"yhat\": 1.7326506211511794, \"yhat_lower\": 1.431620296009358, \"yhat_upper\": 2.033680946293001, \"fact\": 1.8975244367609747, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:57:00\", \"yhat\": 1.7326845300194211, \"yhat_lower\": 1.362926683150179, \"yhat_upper\": 2.1024423768886633, \"fact\": 1.7613237273260038, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:58:00\", \"yhat\": 1.7326906195908496, \"yhat_lower\": 1.3050689186996047, \"yhat_upper\": 2.1603123204820944, \"fact\": 1.7500453495271577, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:59:00\", \"yhat\": 1.7326917131950335, \"yhat_lower\": 1.2541454030724348, \"yhat_upper\": 2.211238023317632, \"fact\": 1.762571819220517, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:00:00\", \"yhat\": 1.7648229574886871, \"yhat_lower\": 1.5493576659277932, \"yhat_upper\": 1.980288249049581, \"fact\": 1.6311805915464404, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:01:00\", \"yhat\": 1.7664662837660827, \"yhat_lower\": 1.4726893242716057, \"yhat_upper\": 2.0602432432605595, \"fact\": 1.6367814595846615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:02:00\", \"yhat\": 1.767665908547982, \"yhat_lower\": 1.4187819220893685, \"yhat_upper\": 2.1165498950065955, \"fact\": 1.4275645069609109, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:03:00\", \"yhat\": 1.7685416321563379, \"yhat_lower\": 1.3760580453223883, \"yhat_upper\": 2.161025218990287, \"fact\": 1.5905556060578103, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:04:00\", \"yhat\": 1.7691809085782686, \"yhat_lower\": 1.339997015098217, \"yhat_upper\": 2.1983648020583204, \"fact\": 1.6655632693644886, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:05:00\", \"yhat\": 1.6650696741336137, \"yhat_lower\": 1.4346867846187878, \"yhat_upper\": 1.8954525636484396, \"fact\": 1.546791983263702, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:06:00\", \"yhat\": 1.665071234912231, \"yhat_lower\": 1.3403231365488284, \"yhat_upper\": 1.9898193332756335, \"fact\": 1.8056647493831086, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:07:00\", \"yhat\": 1.6650712299769526, \"yhat_lower\": 1.2677696347707297, \"yhat_upper\": 2.0623728251831754, \"fact\": 1.7934579666991242, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:08:00\", \"yhat\": 1.6650712299925583, \"yhat_lower\": 1.206556474693036, \"yhat_upper\": 2.1235859852920806, \"fact\": 1.705101463531864, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:09:00\", \"yhat\": 1.665071229992509, \"yhat_lower\": 1.1526036660207635, \"yhat_upper\": 2.1775387939642545, \"fact\": 1.7224407924287297, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:10:00\", \"yhat\": 1.7189795020452858, \"yhat_lower\": 1.4816164433267345, \"yhat_upper\": 1.9563425607638372, \"fact\": 1.6633223909604884, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:11:00\", \"yhat\": 1.716666315528499, \"yhat_lower\": 1.4023946846380166, \"yhat_upper\": 2.030937946418981, \"fact\": 1.6588597657693875, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:12:00\", \"yhat\": 1.7151204088669143, \"yhat_lower\": 1.3504416032894788, \"yhat_upper\": 2.07979921444435, \"fact\": 1.5859053445587559, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:13:00\", \"yhat\": 1.7140872766966424, \"yhat_lower\": 1.3113166674310557, \"yhat_upper\": 2.1168578859622293, \"fact\": 1.8477342784230981, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:14:00\", \"yhat\": 1.7133968326305327, \"yhat_lower\": 1.27941331200412, \"yhat_upper\": 2.147380353256945, \"fact\": 1.892257718603778, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:15:00\", \"yhat\": 1.8651646014999852, \"yhat_lower\": 1.6214768656830687, \"yhat_upper\": 2.1088523373169017, \"fact\": 2.065957311209133, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:16:00\", \"yhat\": 1.8472379362629077, \"yhat_lower\": 1.5262788041101425, \"yhat_upper\": 2.168197068415673, \"fact\": 2.0592974557159858, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:17:00\", \"yhat\": 1.8353764245257713, \"yhat_lower\": 1.4644925665765978, \"yhat_upper\": 2.206260282474945, \"fact\": 2.060554824830489, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:18:00\", \"yhat\": 1.827528034497311, \"yhat_lower\": 1.4192843883193276, \"yhat_upper\": 2.2357716806752945, \"fact\": 2.1274093355782053, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:19:00\", \"yhat\": 1.8223350011467658, \"yhat_lower\": 1.3836642496281624, \"yhat_upper\": 2.261005752665369, \"fact\": 2.033973783734165, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:20:00\", \"yhat\": 2.0245629353826717, \"yhat_lower\": 1.7794560356883378, \"yhat_upper\": 2.2696698350770057, \"fact\": 2.039052392155165, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:21:00\", \"yhat\": 2.017743654668316, \"yhat_lower\": 1.6864678094347605, \"yhat_upper\": 2.349019499901871, \"fact\": 2.2018149811854757, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:22:00\", \"yhat\": 2.012802273432074, \"yhat_lower\": 1.622309720619191, \"yhat_upper\": 2.403294826244957, \"fact\": 2.1549872175178706, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:23:00\", \"yhat\": 2.0092216540757715, \"yhat_lower\": 1.572722426065072, \"yhat_upper\": 2.4457208820864706, \"fact\": 2.1714092548496255, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:24:00\", \"yhat\": 2.0066270688046135, \"yhat_lower\": 1.5319185550130399, \"yhat_upper\": 2.4813355825961874, \"fact\": 2.392593747792554, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:25:00\", \"yhat\": 2.3707718252337275, \"yhat_lower\": 2.119680407639439, \"yhat_upper\": 2.621863242828016, \"fact\": 2.369397260991428, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:26:00\", \"yhat\": 2.357869432886782, \"yhat_lower\": 2.017166375244786, \"yhat_upper\": 2.698572490528778, \"fact\": 2.553716627751497, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:27:00\", \"yhat\": 2.3502407866102795, \"yhat_lower\": 1.9457708659393564, \"yhat_upper\": 2.7547107072812027, \"fact\": 2.48438777779565, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:28:00\", \"yhat\": 2.3457302863521026, \"yhat_lower\": 1.889665337625986, \"yhat_upper\": 2.801795235078219, \"fact\": 2.523275431247673, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:29:00\", \"yhat\": 2.343063415738154, \"yhat_lower\": 1.8424630037446055, \"yhat_upper\": 2.8436638277317026, \"fact\": 2.541655645961276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:30:00\", \"yhat\": 2.540459285803163, \"yhat_lower\": 2.2904929282539914, \"yhat_upper\": 2.790425643352335, \"fact\": 2.5946662175765676, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:31:00\", \"yhat\": 2.540728141477548, \"yhat_lower\": 2.2043266949890357, \"yhat_upper\": 2.8771295879660603, \"fact\": 2.6388582691705813, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:32:00\", \"yhat\": 2.5406677220685943, \"yhat_lower\": 2.132754632171186, \"yhat_upper\": 2.9485808119660026, \"fact\": 2.6823768968397044, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:33:00\", \"yhat\": 2.540681300003993, \"yhat_lower\": 2.07266098228124, \"yhat_upper\": 3.008701617726746, \"fact\": 2.9349245206759322, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:34:00\", \"yhat\": 2.540678248661173, \"yhat_lower\": 2.019312358327148, \"yhat_upper\": 3.0620441389951982, \"fact\": 2.9313232387612618, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:35:00\", \"yhat\": 2.9352974198285415, \"yhat_lower\": 2.6816005813336723, \"yhat_upper\": 3.1889942583234108, \"fact\": 2.7479986630107325, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:36:00\", \"yhat\": 2.9342174141414032, \"yhat_lower\": 2.5890632851659965, \"yhat_upper\": 3.27937154311681, \"fact\": 2.890996166493898, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:37:00\", \"yhat\": 2.9345109116606416, \"yhat_lower\": 2.5144740120737152, \"yhat_upper\": 3.354547811247568, \"fact\": 3.102050247761979, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:38:00\", \"yhat\": 2.9344311520863866, \"yhat_lower\": 2.4516917460375955, \"yhat_upper\": 3.4171705581351777, \"fact\": 3.2153245723915553, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:39:00\", \"yhat\": 2.934452827191859, \"yhat_lower\": 2.3960926704643537, \"yhat_upper\": 3.472812983919364, \"fact\": 3.351469110459854, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:40:00\", \"yhat\": 3.3483772476226807, \"yhat_lower\": 3.083307441915901, \"yhat_upper\": 3.6134470533294607, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:41:00\", \"yhat\": 3.348686154560237, \"yhat_lower\": 2.978296467387896, \"yhat_upper\": 3.7190758417325775, \"fact\": 3.263568933965749, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:42:00\", \"yhat\": 3.348655291775859, \"yhat_lower\": 2.8964997444716976, \"yhat_upper\": 3.8008108390800204, \"fact\": 3.1765726494156343, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:43:00\", \"yhat\": 3.3486583752658805, \"yhat_lower\": 2.8274407710776805, \"yhat_upper\": 3.8698759794540805, \"fact\": 3.03359878070924, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:44:00\", \"yhat\": 3.348658067195468, \"yhat_lower\": 2.766511834539758, \"yhat_upper\": 3.9308042998511783, \"fact\": 3.0229695218101025, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:45:00\", \"yhat\": 3.0229229335265977, \"yhat_lower\": 2.759094916532928, \"yhat_upper\": 3.2867509505202674, \"fact\": 3.1900447587564402, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:46:00\", \"yhat\": 3.0229424054328, \"yhat_lower\": 2.6500866843814497, \"yhat_upper\": 3.39579812648415, \"fact\": 3.124001365720735, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:47:00\", \"yhat\": 3.0229342670103767, \"yhat_lower\": 2.566298152340734, \"yhat_upper\": 3.4795703816800194, \"fact\": 3.0901049942288012, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:48:00\", \"yhat\": 3.022937668522219, \"yhat_lower\": 2.495700838075068, \"yhat_upper\": 3.5501744989693704, \"fact\": 3.008162397059522, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:49:00\", \"yhat\": 3.0229362468360232, \"yhat_lower\": 2.4334834422446194, \"yhat_upper\": 3.612389051427427, \"fact\": 3.0342427632947664, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:50:00\", \"yhat\": 3.033979243535028, \"yhat_lower\": 2.7715624774369862, \"yhat_upper\": 3.29639600963307, \"fact\": 2.9627319946168917, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:51:00\", \"yhat\": 3.033939399271535, \"yhat_lower\": 2.6675269272207265, \"yhat_upper\": 3.4003518713223437, \"fact\": 2.9569461503037706, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:52:00\", \"yhat\": 3.033933374807431, \"yhat_lower\": 2.5876854401735248, \"yhat_upper\": 3.4801813094413374, \"fact\": 3.0267749492582157, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:53:00\", \"yhat\": 3.033932463906725, \"yhat_lower\": 2.5201830757737165, \"yhat_upper\": 3.5476818520397337, \"fact\": 3.07180359176354, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:54:00\", \"yhat\": 3.0339323261782765, \"yhat_lower\": 2.460584374854987, \"yhat_upper\": 3.607280277501566, \"fact\": 3.1560782394784286, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:55:00\", \"yhat\": 3.15436640658461, \"yhat_lower\": 2.8956863064015694, \"yhat_upper\": 3.4130465067676505, \"fact\": 2.997043850204673, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:56:00\", \"yhat\": 3.154227147361811, \"yhat_lower\": 2.7918802326113314, \"yhat_upper\": 3.5165740621122903, \"fact\": 3.009950987266252, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:57:00\", \"yhat\": 3.154215818492501, \"yhat_lower\": 2.7120947181902997, \"yhat_upper\": 3.5963369187947025, \"fact\": 3.0938716467439757, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:58:00\", \"yhat\": 3.1542148968782824, \"yhat_lower\": 2.6446756367519493, \"yhat_upper\": 3.6637541570046155, \"fact\": 3.0880073603636, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:59:00\", \"yhat\": 3.154214821904095, \"yhat_lower\": 2.585191010156913, \"yhat_upper\": 3.723238633651277, \"fact\": 3.11206377340535, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:00:00\", \"yhat\": 3.1106639702154433, \"yhat_lower\": 2.8540462339565362, \"yhat_upper\": 3.3672817064743503, \"fact\": 3.071783339491452, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:01:00\", \"yhat\": 3.1099779656333957, \"yhat_lower\": 2.753563425940895, \"yhat_upper\": 3.466392505325896, \"fact\": 2.9694802366080912, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:02:00\", \"yhat\": 3.1096417738815956, \"yhat_lower\": 2.678385237243149, \"yhat_upper\": 3.540898310520042, \"fact\": 3.1296100628743804, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:03:00\", \"yhat\": 3.109477015661408, \"yhat_lower\": 2.6156588437861275, \"yhat_upper\": 3.603295187536689, \"fact\": 3.002978165799547, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:04:00\", \"yhat\": 3.109396272243481, \"yhat_lower\": 2.5605734039148578, \"yhat_upper\": 3.658219140572104, \"fact\": 2.961692345489058, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:05:00\", \"yhat\": 2.965787033189844, \"yhat_lower\": 2.7087503222310163, \"yhat_upper\": 3.2228237441486716, \"fact\": 2.988327400999106, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:06:00\", \"yhat\": 2.967019660899941, \"yhat_lower\": 2.613799246425694, \"yhat_upper\": 3.3202400753741883, \"fact\": 2.817236951076069, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:07:00\", \"yhat\": 2.967390719984962, \"yhat_lower\": 2.5415646043468643, \"yhat_upper\": 3.3932168356230594, \"fact\": 2.7591756473744242, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:08:00\", \"yhat\": 2.967502420252162, \"yhat_lower\": 2.4804125270406647, \"yhat_upper\": 3.4545923134636594, \"fact\": 2.7415743889488313, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:09:00\", \"yhat\": 2.96753604548921, \"yhat_lower\": 2.4262459816248163, \"yhat_upper\": 3.508826109353604, \"fact\": 2.634959930239999, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:10:00\", \"yhat\": 2.6400907570695664, \"yhat_lower\": 2.383394752666771, \"yhat_upper\": 2.8967867614723617, \"fact\": 2.684944460100623, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:11:00\", \"yhat\": 2.6404810586106437, \"yhat_lower\": 2.285826349232641, \"yhat_upper\": 2.9951357679886463, \"fact\": 2.7044345238588345, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:12:00\", \"yhat\": 2.6405107488141972, \"yhat_lower\": 2.2101365207535446, \"yhat_upper\": 3.07088497687485, \"fact\": 2.6484580732244156, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:13:00\", \"yhat\": 2.6405130073453438, \"yhat_lower\": 2.1459119581350796, \"yhat_upper\": 3.135114056555608, \"fact\": 2.7494103531133773, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:14:00\", \"yhat\": 2.640513179151607, \"yhat_lower\": 2.089118720120073, \"yhat_upper\": 3.1919076381831415, \"fact\": 2.8828342883822207, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:15:00\", \"yhat\": 2.875977278267513, \"yhat_lower\": 2.620809859683987, \"yhat_upper\": 3.1311446968510386, \"fact\": 2.8354131880299063, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:16:00\", \"yhat\": 2.874651973186076, \"yhat_lower\": 2.5217034282116035, \"yhat_upper\": 3.227600518160548, \"fact\": 2.8000865445536682, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:17:00\", \"yhat\": 2.874395821666755, \"yhat_lower\": 2.4466425909828837, \"yhat_upper\": 3.302149052350626, \"fact\": 2.7125150434931227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:18:00\", \"yhat\": 2.8743463133672926, \"yhat_lower\": 2.3832569135284105, \"yhat_upper\": 3.3654357132061747, \"fact\": 2.5930717283678337, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:19:00\", \"yhat\": 2.8743367445319326, \"yhat_lower\": 2.3272304029369106, \"yhat_upper\": 3.4214430861269545, \"fact\": 2.608611290894402, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:20:00\", \"yhat\": 2.6112004733309084, \"yhat_lower\": 2.3582774225825283, \"yhat_upper\": 2.8641235240792886, \"fact\": 2.630785813099688, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:21:00\", \"yhat\": 2.6124367826371135, \"yhat_lower\": 2.2612149951181593, \"yhat_upper\": 2.963658570156068, \"fact\": 2.4460733245935717, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:22:00\", \"yhat\": 2.613027108246873, \"yhat_lower\": 2.188038891790566, \"yhat_upper\": 3.03801532470318, \"fact\": 2.3347403540561436, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:23:00\", \"yhat\": 2.6133089829555636, \"yhat_lower\": 2.126615425937818, \"yhat_upper\": 3.100002539973309, \"fact\": 2.262071173411276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:24:00\", \"yhat\": 2.6134435753738594, \"yhat_lower\": 2.0724716333673605, \"yhat_upper\": 3.1544155173803583, \"fact\": 2.298347870588908, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:25:00\", \"yhat\": 2.3092081841918843, \"yhat_lower\": 2.058868967907293, \"yhat_upper\": 2.5595474004764758, \"fact\": 2.3476057569157662, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:26:00\", \"yhat\": 2.299015257587928, \"yhat_lower\": 1.9355471426844162, \"yhat_upper\": 2.6624833724914403, \"fact\": 2.135029126951106, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:27:00\", \"yhat\": 2.308581809397736, \"yhat_lower\": 1.86678428208665, \"yhat_upper\": 2.7503793367088223, \"fact\": 2.1239990673356894, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:28:00\", \"yhat\": 2.2996031404554693, \"yhat_lower\": 1.7855751474070074, \"yhat_upper\": 2.8136311335039315, \"fact\": 2.0556779001073835, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:29:00\", \"yhat\": 2.308030053054445, \"yhat_lower\": 1.7356143965229234, \"yhat_upper\": 2.8804457095859664, \"fact\": 2.0694340149175385, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:30:00\", \"yhat\": 2.076690472981364, \"yhat_lower\": 1.8263758664441987, \"yhat_upper\": 2.3270050795185293, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:31:00\", \"yhat\": 2.069933752324449, \"yhat_lower\": 1.705201603615039, \"yhat_upper\": 2.4346659010338594, \"fact\": 2.162436461794182, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:32:00\", \"yhat\": 2.076225151466293, \"yhat_lower\": 1.6332757248949223, \"yhat_upper\": 2.5191745780376635, \"fact\": 2.2670705003332525, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:33:00\", \"yhat\": 2.0703670280996733, \"yhat_lower\": 1.5545487669724989, \"yhat_upper\": 2.5861852892268478, \"fact\": 2.29288072551883, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:34:00\", \"yhat\": 2.075821714506436, \"yhat_lower\": 1.5016324814606539, \"yhat_upper\": 2.6500109475522184, \"fact\": 2.3569619929709806, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:35:00\", \"yhat\": 2.3584429606971, \"yhat_lower\": 2.1091499730761765, \"yhat_upper\": 2.607735948318023, \"fact\": 2.410609579163354, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:36:00\", \"yhat\": 2.3570643927267643, \"yhat_lower\": 1.9948346923113647, \"yhat_upper\": 2.719294093142164, \"fact\": 2.3144117890462743, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:37:00\", \"yhat\": 2.3583476412509, \"yhat_lower\": 1.9180924075693333, \"yhat_upper\": 2.7986028749324667, \"fact\": 2.4445136543567934, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:38:00\", \"yhat\": 2.357153121422983, \"yhat_lower\": 1.8448712907803038, \"yhat_upper\": 2.8694349520656623, \"fact\": 2.465681531052395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:39:00\", \"yhat\": 2.358265047595076, \"yhat_lower\": 1.7877799650393729, \"yhat_upper\": 2.9287501301507795, \"fact\": 2.534376307983406, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:40:00\", \"yhat\": 2.5500422667291547, \"yhat_lower\": 2.3016771259640856, \"yhat_upper\": 2.798407407494224, \"fact\": 2.6272076036465988, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:41:00\", \"yhat\": 2.5354335488837045, \"yhat_lower\": 2.1745973053645384, \"yhat_upper\": 2.8962697924028706, \"fact\": 2.5816446195896057, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:42:00\", \"yhat\": 2.549056375328712, \"yhat_lower\": 2.110492233972347, \"yhat_upper\": 2.9876205166850767, \"fact\": 2.6662380206684615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:43:00\", \"yhat\": 2.5363529059131134, \"yhat_lower\": 2.02604306455059, \"yhat_upper\": 3.046662747275637, \"fact\": 2.7168521403799497, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:44:00\", \"yhat\": 2.548199062497762, \"yhat_lower\": 1.9799167259335855, \"yhat_upper\": 3.1164813990619384, \"fact\": 2.8538032872934025, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:45:00\", \"yhat\": 2.8516004686382512, \"yhat_lower\": 2.6011644707240524, \"yhat_upper\": 3.10203646655245, \"fact\": 2.854838809029115, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:46:00\", \"yhat\": 2.851618103341481, \"yhat_lower\": 2.500276460585571, \"yhat_upper\": 3.202959746097391, \"fact\": 2.8618450419844574, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:47:00\", \"yhat\": 2.8516179621665563, \"yhat_lower\": 2.4224565040084793, \"yhat_upper\": 3.280779420324633, \"fact\": 2.9749993982224634, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:48:00\", \"yhat\": 2.8516179632967344, \"yhat_lower\": 2.356726017983553, \"yhat_upper\": 3.346509908609916, \"fact\": 2.9242167077789762, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:49:00\", \"yhat\": 2.8516179632876866, \"yhat_lower\": 2.298755847639495, \"yhat_upper\": 3.4044800789358782, \"fact\": 3.046298158099033, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:50:00\", \"yhat\": 3.0606560956161064, \"yhat_lower\": 2.8147741278439877, \"yhat_upper\": 3.306538063388225, \"fact\": 3.2619941973050857, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:51:00\", \"yhat\": 3.0473316848125234, \"yhat_lower\": 2.689148068143719, \"yhat_upper\": 3.4055153014813278, \"fact\": 3.2881410304426844, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:52:00\", \"yhat\": 3.0596969652054433, \"yhat_lower\": 2.6246440140291227, \"yhat_upper\": 3.494749916381764, \"fact\": 3.17823623114512, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:53:00\", \"yhat\": 3.0482217741857833, \"yhat_lower\": 2.541661819102959, \"yhat_upper\": 3.5547817292686075, \"fact\": 3.2035656084512185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:54:00\", \"yhat\": 3.0588709470919695, \"yhat_lower\": 2.4949329801448945, \"yhat_upper\": 3.6228089140390445, \"fact\": 3.2670646744239535, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:55:00\", \"yhat\": 3.266783828640226, \"yhat_lower\": 3.01636407595188, \"yhat_upper\": 3.517203581328572, \"fact\": 3.141727652556658, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:56:00\", \"yhat\": 3.266784448415951, \"yhat_lower\": 2.9134190542736205, \"yhat_upper\": 3.6201498425582814, \"fact\": 2.9955668695370674, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:57:00\", \"yhat\": 3.2667844470482184, \"yhat_lower\": 2.8343201494468584, \"yhat_upper\": 3.6992487446495783, \"fact\": 2.9382006257672204, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:58:00\", \"yhat\": 3.266784447051237, \"yhat_lower\": 2.7676014816616963, \"yhat_upper\": 3.7659674124407774, \"fact\": 3.1072176080352674, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:59:00\", \"yhat\": 3.26678444705123, \"yhat_lower\": 2.70880425280032, \"yhat_upper\": 3.8247646413021403, \"fact\": 3.2265123861605005, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:00:00\", \"yhat\": 3.228122278641863, \"yhat_lower\": 2.9750583920217446, \"yhat_upper\": 3.481186165261981, \"fact\": 3.193007278757366, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:01:00\", \"yhat\": 3.228133265781497, \"yhat_lower\": 2.8678002303031285, \"yhat_upper\": 3.5884663012598654, \"fact\": 2.9939694331844597, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:02:00\", \"yhat\": 3.228133340766155, \"yhat_lower\": 2.785809323070364, \"yhat_upper\": 3.6704573584619458, \"fact\": 3.0510071595638975, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:03:00\", \"yhat\": 3.228133341277908, \"yhat_lower\": 2.7168005150160024, \"yhat_upper\": 3.7394661675398133, \"fact\": 3.0843334587124414, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:04:00\", \"yhat\": 3.2281333412814006, \"yhat_lower\": 2.6560564387955092, \"yhat_upper\": 3.800210243767292, \"fact\": 3.017355148653572, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:05:00\", \"yhat\": 3.0245044986582035, \"yhat_lower\": 2.775543924190105, \"yhat_upper\": 3.2734650731263017, \"fact\": 3.0840789077005564, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:06:00\", \"yhat\": 3.017949854162934, \"yhat_lower\": 2.6531159030056024, \"yhat_upper\": 3.3827838053202655, \"fact\": 3.2646089479518845, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:07:00\", \"yhat\": 3.0239592626310507, \"yhat_lower\": 2.5814412147665555, \"yhat_upper\": 3.466477310495546, \"fact\": 3.165542668097864, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:08:00\", \"yhat\": 3.01844973573562, \"yhat_lower\": 2.502478831521387, \"yhat_upper\": 3.534420639949853, \"fact\": 3.0844463441003063, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:09:00\", \"yhat\": 3.0235009627860903, \"yhat_lower\": 2.4494215389146623, \"yhat_upper\": 3.5975803866575182, \"fact\": 3.1069823468616202, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:10:00\", \"yhat\": 3.093201140076813, \"yhat_lower\": 2.8438174806726204, \"yhat_upper\": 3.3425847994810054, \"fact\": 3.219189334092936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:11:00\", \"yhat\": 3.1058632318437795, \"yhat_lower\": 2.740609649126394, \"yhat_upper\": 3.471116814561165, \"fact\": 3.253827606819794, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:12:00\", \"yhat\": 3.094229376375343, \"yhat_lower\": 2.6511570835315688, \"yhat_upper\": 3.537301669219117, \"fact\": 3.2185308345572, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:13:00\", \"yhat\": 3.1049184943782286, \"yhat_lower\": 2.588355830076726, \"yhat_upper\": 3.6214811586797313, \"fact\": 3.155315043321703, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:14:00\", \"yhat\": 3.095097395604086, \"yhat_lower\": 2.520342785746619, \"yhat_upper\": 3.6698520054615527, \"fact\": 3.3632975565070162, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:15:00\", \"yhat\": 3.3912968472352842, \"yhat_lower\": 3.140001588056288, \"yhat_upper\": 3.6425921064142806, \"fact\": 3.343103013230474, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:16:00\", \"yhat\": 3.3651657474822896, \"yhat_lower\": 2.9994015459983867, \"yhat_upper\": 3.7309299489661925, \"fact\": 3.2149037491158556, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:17:00\", \"yhat\": 3.3895533071861346, \"yhat_lower\": 2.945234248726223, \"yhat_upper\": 3.8338723656460463, \"fact\": 3.3955861520011412, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:18:00\", \"yhat\": 3.366792953663683, \"yhat_lower\": 2.8495159158670127, \"yhat_upper\": 3.884069991460353, \"fact\": 3.198464588834615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:19:00\", \"yhat\": 3.388034672751522, \"yhat_lower\": 2.8121554464046383, \"yhat_upper\": 3.9639138990984053, \"fact\": 3.1356264595407213, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:20:00\", \"yhat\": 3.13185700637819, \"yhat_lower\": 2.8789454186077554, \"yhat_upper\": 3.3847685941486247, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:21:00\", \"yhat\": 3.1353194920197893, \"yhat_lower\": 2.764655736458891, \"yhat_upper\": 3.5059832475806876, \"fact\": 3.216974287061278, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:22:00\", \"yhat\": 3.132138975827825, \"yhat_lower\": 2.6825807948955758, \"yhat_upper\": 3.5816971567600744, \"fact\": 3.265503557337653, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:23:00\", \"yhat\": 3.135060484909571, \"yhat_lower\": 2.610846920573899, \"yhat_upper\": 3.659274049245243, \"fact\": 3.282716546203024, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:24:00\", \"yhat\": 3.132376890549546, \"yhat_lower\": 2.5491581384326105, \"yhat_upper\": 3.7155956426664813, \"fact\": 3.2557944933176817, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:25:00\", \"yhat\": 3.258884125032105, \"yhat_lower\": 3.00710323375902, \"yhat_upper\": 3.5106650163051896, \"fact\": 3.253280546730072, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:26:00\", \"yhat\": 3.256043948178181, \"yhat_lower\": 2.8886241249718436, \"yhat_upper\": 3.623463771384518, \"fact\": 3.2468023667661132, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:27:00\", \"yhat\": 3.258654810995231, \"yhat_lower\": 2.812519542212457, \"yhat_upper\": 3.7047900797780047, \"fact\": 3.2013389472410476, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:28:00\", \"yhat\": 3.2562547475484647, \"yhat_lower\": 2.7366249183997082, \"yhat_upper\": 3.775884576697221, \"fact\": 3.303433319153471, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:29:00\", \"yhat\": 3.2584610314293663, \"yhat_lower\": 2.680012650033677, \"yhat_upper\": 3.8369094128250554, \"fact\": 3.282481127060928, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:30:00\", \"yhat\": 3.2696664449953765, \"yhat_lower\": 3.0202566284714054, \"yhat_upper\": 3.5190762615193476, \"fact\": 3.2652271356713536, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:31:00\", \"yhat\": 3.281472284289896, \"yhat_lower\": 2.917527991117878, \"yhat_upper\": 3.645416577461914, \"fact\": 3.1595061912084845, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:32:00\", \"yhat\": 3.2705958660740513, \"yhat_lower\": 2.8286938601659974, \"yhat_upper\": 3.712497871982105, \"fact\": 3.150058882565577, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:33:00\", \"yhat\": 3.280616032387926, \"yhat_lower\": 2.765903843371479, \"yhat_upper\": 3.7953282214043726, \"fact\": 3.2408736119745805, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:34:00\", \"yhat\": 3.271384709082296, \"yhat_lower\": 2.6984307760544146, \"yhat_upper\": 3.844338642110177, \"fact\": 3.1901242584634275, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:35:00\", \"yhat\": 3.1978595435991877, \"yhat_lower\": 2.9502038390924232, \"yhat_upper\": 3.445515248105952, \"fact\": 3.305247070725088, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:36:00\", \"yhat\": 3.1907356615572233, \"yhat_lower\": 2.8290881698069277, \"yhat_upper\": 3.552383153307519, \"fact\": 3.1486164121920943, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:37:00\", \"yhat\": 3.197296466292553, \"yhat_lower\": 2.758267101893754, \"yhat_upper\": 3.6363258306913524, \"fact\": 3.3311019146556613, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:38:00\", \"yhat\": 3.191254232785377, \"yhat_lower\": 2.6797907331690514, \"yhat_upper\": 3.7027177324017027, \"fact\": 3.2369006752018885, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:39:00\", \"yhat\": 3.1968188833470137, \"yhat_lower\": 2.627534387726682, \"yhat_upper\": 3.7661033789673453, \"fact\": 3.4338477225305613, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:40:00\", \"yhat\": 3.419887979474071, \"yhat_lower\": 3.1647901635816216, \"yhat_upper\": 3.67498579536652, \"fact\": 3.5746933953177287, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:41:00\", \"yhat\": 3.41683462514806, \"yhat_lower\": 3.069644846444164, \"yhat_upper\": 3.7640244038519564, \"fact\": 3.668791853750908, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:42:00\", \"yhat\": 3.416166778139527, \"yhat_lower\": 2.999025194770077, \"yhat_upper\": 3.833308361508977, \"fact\": 3.692430901451204, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:43:00\", \"yhat\": 3.416020702846854, \"yhat_lower\": 2.9395324959847677, \"yhat_upper\": 3.8925089097089405, \"fact\": 3.7236669409703915, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:44:00\", \"yhat\": 3.4159887524287837, \"yhat_lower\": 2.8868568514229205, \"yhat_upper\": 3.945120653434647, \"fact\": 3.8603194598248907, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:45:00\", \"yhat\": 3.8530788803695195, \"yhat_lower\": 3.59761714175841, \"yhat_upper\": 4.108540618980629, \"fact\": 3.9691359848159276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:46:00\", \"yhat\": 3.8518375754393213, \"yhat_lower\": 3.499395275225139, \"yhat_upper\": 4.204279875653503, \"fact\": 3.962226709383252, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:47:00\", \"yhat\": 3.8516247695528265, \"yhat_lower\": 3.4248677406517016, \"yhat_upper\": 4.278381798453951, \"fact\": 3.9138960369194913, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:48:00\", \"yhat\": 3.851588286699802, \"yhat_lower\": 3.3618448076409866, \"yhat_upper\": 4.341331765758618, \"fact\": 3.866906827861522, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:49:00\", \"yhat\": 3.8515820321803114, \"yhat_lower\": 3.3061050380669537, \"yhat_upper\": 4.397059026293669, \"fact\": 3.8996568831849046, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:50:00\", \"yhat\": 3.8988561825116723, \"yhat_lower\": 3.645171115660895, \"yhat_upper\": 4.152541249362449, \"fact\": 3.931161464982215, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:51:00\", \"yhat\": 3.898697667796094, \"yhat_lower\": 3.5473819091321963, \"yhat_upper\": 4.250013426459991, \"fact\": 3.9222762574162413, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:52:00\", \"yhat\": 3.8986662866371975, \"yhat_lower\": 3.472674327369955, \"yhat_upper\": 4.324658245904439, \"fact\": 3.9522308518159854, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:53:00\", \"yhat\": 3.8986600741090416, \"yhat_lower\": 3.409462149799599, \"yhat_upper\": 4.387857998418484, \"fact\": 3.9672379603949333, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:54:00\", \"yhat\": 3.898658844214817, \"yhat_lower\": 3.3535713900666417, \"yhat_upper\": 4.443746298362992, \"fact\": 3.949120794105074, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:55:00\", \"yhat\": 3.9496474888402164, \"yhat_lower\": 3.698600518755039, \"yhat_upper\": 4.200694458925394, \"fact\": 4.011080429852479, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:56:00\", \"yhat\": 3.9497540887271394, \"yhat_lower\": 3.6020184786016833, \"yhat_upper\": 4.297489698852595, \"fact\": 3.9773963745259766, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:57:00\", \"yhat\": 3.949775663911271, \"yhat_lower\": 3.5281076528348265, \"yhat_upper\": 4.371443674987716, \"fact\": 4.063919451853195, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:58:00\", \"yhat\": 3.9497800306004276, \"yhat_lower\": 3.4655444388283563, \"yhat_upper\": 4.434015622372499, \"fact\": 4.041478475360821, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:59:00\", \"yhat\": 3.9497809143923837, \"yhat_lower\": 3.4102226414227776, \"yhat_upper\": 4.48933918736199, \"fact\": 4.062740372256043, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:00:00\", \"yhat\": 4.0618417683651264, \"yhat_lower\": 3.8127500534326275, \"yhat_upper\": 4.310933483297625, \"fact\": 4.0505187731741525, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:01:00\", \"yhat\": 4.0616836770411835, \"yhat_lower\": 3.7171252771761365, \"yhat_upper\": 4.4062420769062305, \"fact\": 4.1897089265414085, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:02:00\", \"yhat\": 4.0616558640448694, \"yhat_lower\": 3.6439547565158477, \"yhat_upper\": 4.479356971573892, \"fact\": 4.284031357825327, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:03:00\", \"yhat\": 4.061650970906241, \"yhat_lower\": 3.581998129680549, \"yhat_upper\": 4.5413038121319325, \"fact\": 4.343010092731889, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:04:00\", \"yhat\": 4.061650110056681, \"yhat_lower\": 3.5272053848879654, \"yhat_upper\": 4.596094835225397, \"fact\": 4.185387068316425, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:05:00\", \"yhat\": 4.190887900270959, \"yhat_lower\": 3.9412199539073236, \"yhat_upper\": 4.440555846634595, \"fact\": 4.0414341396536315, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:06:00\", \"yhat\": 4.192060159818795, \"yhat_lower\": 3.846132011079779, \"yhat_upper\": 4.537988308557811, \"fact\": 4.158591747922278, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:07:00\", \"yhat\": 4.192309975202877, \"yhat_lower\": 3.772834599921291, \"yhat_upper\": 4.611785350484464, \"fact\": 4.11021899046745, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:08:00\", \"yhat\": 4.1923632123262085, \"yhat_lower\": 3.7106654541701727, \"yhat_upper\": 4.674060970482245, \"fact\": 4.381527688619375, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:09:00\", \"yhat\": 4.192374557469387, \"yhat_lower\": 3.655663269235498, \"yhat_upper\": 4.729085845703276, \"fact\": 4.3351854149025995, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:10:00\", \"yhat\": 4.333420584015721, \"yhat_lower\": 4.080301226657321, \"yhat_upper\": 4.586539941374122, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:11:00\", \"yhat\": 4.332949074232229, \"yhat_lower\": 3.9835646315603794, \"yhat_upper\": 4.682333516904079, \"fact\": 4.184798061879761, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:12:00\", \"yhat\": 4.332823100985965, \"yhat_lower\": 3.9103315159587098, \"yhat_upper\": 4.75531468601322, \"fact\": 4.217342874859245, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:13:00\", \"yhat\": 4.332789444719796, \"yhat_lower\": 3.8485241588932197, \"yhat_upper\": 4.8170547305463725, \"fact\": 4.134349504828188, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:14:00\", \"yhat\": 4.332780452776777, \"yhat_lower\": 3.793878111908856, \"yhat_upper\": 4.871682793644697, \"fact\": 4.00615462019463, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:15:00\", \"yhat\": 4.0133347078693555, \"yhat_lower\": 3.760327243058606, \"yhat_upper\": 4.266342172680105, \"fact\": 4.174443032790151, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:16:00\", \"yhat\": 4.015330545901115, \"yhat_lower\": 3.665716831009192, \"yhat_upper\": 4.364944260793038, \"fact\": 4.158682107023693, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:17:00\", \"yhat\": 4.015885325958055, \"yhat_lower\": 3.592937931121839, \"yhat_upper\": 4.438832720794272, \"fact\": 4.039980382510705, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:18:00\", \"yhat\": 4.01603953732525, \"yhat_lower\": 3.531159374915808, \"yhat_upper\": 4.500919699734693, \"fact\": 3.963354168012908, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:19:00\", \"yhat\": 4.016082403224042, \"yhat_lower\": 3.476440227582816, \"yhat_upper\": 4.555724578865267, \"fact\": 4.013776178380292, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:20:00\", \"yhat\": 4.0132657355033245, \"yhat_lower\": 3.7602299366308074, \"yhat_upper\": 4.266301534375842, \"fact\": 3.8392000488227365, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:21:00\", \"yhat\": 4.013112385065999, \"yhat_lower\": 3.665031391077879, \"yhat_upper\": 4.361193379054119, \"fact\": 3.9196928506772672, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:22:00\", \"yhat\": 4.013066314569791, \"yhat_lower\": 3.593186294568872, \"yhat_upper\": 4.43294633457071, \"fact\": 4.026390515550767, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:23:00\", \"yhat\": 4.013052473783564, \"yhat_lower\": 3.532588289790978, \"yhat_upper\": 4.493516657776149, \"fact\": 4.1533871249773675, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:24:00\", \"yhat\": 4.013048315648116, \"yhat_lower\": 3.4789929536646675, \"yhat_upper\": 4.547103677631565, \"fact\": 4.189958026263005, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:25:00\", \"yhat\": 4.184984375526587, \"yhat_lower\": 3.9310081968795965, \"yhat_upper\": 4.438960554173577, \"fact\": 4.126055761269775, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:26:00\", \"yhat\": 4.183448811268614, \"yhat_lower\": 3.8333598240955955, \"yhat_upper\": 4.533537798441634, \"fact\": 4.19189206344511, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:27:00\", \"yhat\": 4.182974721366584, \"yhat_lower\": 3.7602463876543033, \"yhat_upper\": 4.605703055078865, \"fact\": 4.22553102867423, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:28:00\", \"yhat\": 4.182828350914133, \"yhat_lower\": 3.6988350742474254, \"yhat_upper\": 4.666821627580841, \"fact\": 4.210411801001582, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:29:00\", \"yhat\": 4.182783160520373, \"yhat_lower\": 3.6446203363229257, \"yhat_upper\": 4.72094598471782, \"fact\": 4.182752319021494, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:30:00\", \"yhat\": 4.184107265618835, \"yhat_lower\": 3.9320616681192377, \"yhat_upper\": 4.436152863118433, \"fact\": 4.217524711732356, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:31:00\", \"yhat\": 4.184546688169388, \"yhat_lower\": 3.8374175627862965, \"yhat_upper\": 4.53167581355248, \"fact\": 4.130474550476257, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:32:00\", \"yhat\": 4.184689197238242, \"yhat_lower\": 3.7658563500763855, \"yhat_upper\": 4.603522044400099, \"fact\": 4.17480129452376, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:33:00\", \"yhat\": 4.184735414335385, \"yhat_lower\": 3.7054789869933686, \"yhat_upper\": 4.663991841677403, \"fact\": 4.320493820499588, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:34:00\", \"yhat\": 4.184750402996006, \"yhat_lower\": 3.6520775080667978, \"yhat_upper\": 4.7174232979252135, \"fact\": 4.185929353510199, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:35:00\", \"yhat\": 4.191009962120155, \"yhat_lower\": 3.9389796843243885, \"yhat_upper\": 4.443040239915922, \"fact\": 4.20876999105369, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:36:00\", \"yhat\": 4.192449228584313, \"yhat_lower\": 3.846860640055711, \"yhat_upper\": 4.538037817112915, \"fact\": 4.205431875057931, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:37:00\", \"yhat\": 4.1928569529563084, \"yhat_lower\": 3.77659156670936, \"yhat_upper\": 4.609122339203257, \"fact\": 4.267783231196223, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:38:00\", \"yhat\": 4.1929724556569266, \"yhat_lower\": 3.717006231524479, \"yhat_upper\": 4.668938679789374, \"fact\": 4.243656661707888, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:39:00\", \"yhat\": 4.193005175981652, \"yhat_lower\": 3.6641880721485856, \"yhat_upper\": 4.7218222798147185, \"fact\": 4.277196878166224, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:40:00\", \"yhat\": 4.275152783569864, \"yhat_lower\": 4.0251582185766415, \"yhat_upper\": 4.525147348563087, \"fact\": 4.3318998015163706, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:41:00\", \"yhat\": 4.274561857529326, \"yhat_lower\": 3.9319413097377236, \"yhat_upper\": 4.6171824053209285, \"fact\": 4.363011737742668, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:42:00\", \"yhat\": 4.274391027086348, \"yhat_lower\": 3.8618700226476608, \"yhat_upper\": 4.686912031525035, \"fact\": 4.180371396839616, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:43:00\", \"yhat\": 4.274341641819417, \"yhat_lower\": 3.8027942513478252, \"yhat_upper\": 4.745889032291009, \"fact\": 4.168647619776069, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:44:00\", \"yhat\": 4.274327365063194, \"yhat_lower\": 3.750526740682871, \"yhat_upper\": 4.798127989443518, \"fact\": 4.175629966333796, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:45:00\", \"yhat\": 4.176868115862079, \"yhat_lower\": 3.9273546407982467, \"yhat_upper\": 4.426381590925911, \"fact\": 4.05020272321786, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:46:00\", \"yhat\": 4.17724858771519, \"yhat_lower\": 3.83535281549149, \"yhat_upper\": 4.51914435993889, \"fact\": 4.1803453970069935, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:47:00\", \"yhat\": 4.177365503182751, \"yhat_lower\": 3.7659211661660725, \"yhat_upper\": 4.588809840199429, \"fact\": 4.324238542138023, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:48:00\", \"yhat\": 4.177401430220304, \"yhat_lower\": 3.707294370172451, \"yhat_upper\": 4.647508490268158, \"fact\": 4.332892480853049, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:49:00\", \"yhat\": 4.177412470265342, \"yhat_lower\": 3.6553905026611013, \"yhat_upper\": 4.6994344378695825, \"fact\": 4.291603988308282, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:50:00\", \"yhat\": 4.292236119823976, \"yhat_lower\": 4.042356341645513, \"yhat_upper\": 4.5421158980024385, \"fact\": 4.307690348837449, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:51:00\", \"yhat\": 4.292448679936481, \"yhat_lower\": 3.9500081518690697, \"yhat_upper\": 4.634889208003892, \"fact\": 4.235240633659249, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:52:00\", \"yhat\": 4.292520155254996, \"yhat_lower\": 3.880644027842594, \"yhat_upper\": 4.704396282667398, \"fact\": 4.317974290661283, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:53:00\", \"yhat\": 4.292544189496871, \"yhat_lower\": 3.8222172971692814, \"yhat_upper\": 4.762871081824461, \"fact\": 4.332980571066018, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:54:00\", \"yhat\": 4.292552271234658, \"yhat_lower\": 3.7705354646331726, \"yhat_upper\": 4.814569077836144, \"fact\": 4.487906802061469, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:55:00\", \"yhat\": 4.477299256073399, \"yhat_lower\": 4.227902492407064, \"yhat_upper\": 4.726696019739735, \"fact\": 4.685148103114914, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:56:00\", \"yhat\": 4.473766151591606, \"yhat_lower\": 4.131916534542009, \"yhat_upper\": 4.815615768641203, \"fact\": 4.840059501436562, \"anomaly\": 1}, {\"ds\": \"2021-08-23T04:57:00\", \"yhat\": 4.472589364114719, \"yhat_lower\": 4.061345609456638, \"yhat_upper\": 4.8838331187728, \"fact\": 4.799561104428719, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:58:00\", \"yhat\": 4.4721974060583145, \"yhat_lower\": 4.002523499826597, \"yhat_upper\": 4.941871312290032, \"fact\": 4.795506399361607, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:59:00\", \"yhat\": 4.472066854772718, \"yhat_lower\": 3.950718065904149, \"yhat_upper\": 4.9934156436412875, \"fact\": 4.742588279703727, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:00:00\", \"yhat\": 4.744325973213684, \"yhat_lower\": 4.49373817541368, \"yhat_upper\": 4.994913771013688, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:01:00\", \"yhat\": 4.744958588468329, \"yhat_lower\": 4.39751547248038, \"yhat_upper\": 5.092401704456277, \"fact\": 4.798220230319819, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:02:00\", \"yhat\": 4.745188894939589, \"yhat_lower\": 4.324576912762676, \"yhat_upper\": 5.165800877116502, \"fact\": 4.829701886057892, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:03:00\", \"yhat\": 4.74527273906177, \"yhat_lower\": 4.263099815366656, \"yhat_upper\": 5.2274456627568835, \"fact\": 4.883016949588336, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:04:00\", \"yhat\": 4.745303262897187, \"yhat_lower\": 4.208794511933229, \"yhat_upper\": 5.2818120138611455, \"fact\": 4.8937347142287, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:05:00\", \"yhat\": 4.892190761824069, \"yhat_lower\": 4.643036793862239, \"yhat_upper\": 5.1413447297858985, \"fact\": 4.938648459724199, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:06:00\", \"yhat\": 4.891642550668168, \"yhat_lower\": 4.546259303231988, \"yhat_upper\": 5.237025798104348, \"fact\": 5.17809129022616, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:07:00\", \"yhat\": 4.89144789734171, \"yhat_lower\": 4.473331275992535, \"yhat_upper\": 5.309564518690884, \"fact\": 5.2277973565851275, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:08:00\", \"yhat\": 4.891378781788162, \"yhat_lower\": 4.412042841859964, \"yhat_upper\": 5.370714721716359, \"fact\": 5.060179684851194, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:09:00\", \"yhat\": 4.891354240929656, \"yhat_lower\": 4.357973071344421, \"yhat_upper\": 5.4247354105148915, \"fact\": 5.1297403620303, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:10:00\", \"yhat\": 5.1286471209994025, \"yhat_lower\": 4.877392451085899, \"yhat_upper\": 5.379901790912906, \"fact\": 5.15313317767182, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:11:00\", \"yhat\": 5.128256491683382, \"yhat_lower\": 4.779962647124747, \"yhat_upper\": 5.476550336242018, \"fact\": 5.300808308865612, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:12:00\", \"yhat\": 5.128116914720735, \"yhat_lower\": 4.706490469294971, \"yhat_upper\": 5.549743360146499, \"fact\": 5.26705268243037, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:13:00\", \"yhat\": 5.128067042046814, \"yhat_lower\": 4.644723485280574, \"yhat_upper\": 5.611410598813054, \"fact\": 5.18963904990192, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:14:00\", \"yhat\": 5.128049221888266, \"yhat_lower\": 4.590223379791123, \"yhat_upper\": 5.665875063985409, \"fact\": 5.127358854626321, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:15:00\", \"yhat\": 5.1307849090197735, \"yhat_lower\": 4.880137669467795, \"yhat_upper\": 5.381432148571752, \"fact\": 5.29558515008685, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:16:00\", \"yhat\": 5.13208622484106, \"yhat_lower\": 4.7843963056384915, \"yhat_upper\": 5.479776144043628, \"fact\": 5.426325324638567, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:17:00\", \"yhat\": 5.13258050271066, \"yhat_lower\": 4.711636634473419, \"yhat_upper\": 5.5535243709479, \"fact\": 5.398406115283306, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:18:00\", \"yhat\": 5.132768243924883, \"yhat_lower\": 4.650235082453734, \"yhat_upper\": 5.615301405396033, \"fact\": 5.538297490098523, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:19:00\", \"yhat\": 5.1328395535377265, \"yhat_lower\": 4.595966441360065, \"yhat_upper\": 5.669712665715388, \"fact\": 5.653105045264966, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:20:00\", \"yhat\": 5.647487996388624, \"yhat_lower\": 5.395450786513213, \"yhat_upper\": 5.899525206264035, \"fact\": 5.765696569733555, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:21:00\", \"yhat\": 5.645423423714422, \"yhat_lower\": 5.294571453871599, \"yhat_upper\": 5.996275393557244, \"fact\": 5.666272705776069, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:22:00\", \"yhat\": 5.644664580339386, \"yhat_lower\": 5.218927529247918, \"yhat_upper\": 6.070401631430854, \"fact\": 5.567606762643266, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:23:00\", \"yhat\": 5.64438566389579, \"yhat_lower\": 5.155622371395589, \"yhat_upper\": 6.13314895639599, \"fact\": 5.677067547194454, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:24:00\", \"yhat\": 5.644283146848045, \"yhat_lower\": 5.099914265307548, \"yhat_upper\": 6.1886520283885424, \"fact\": 5.952771138793346, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:25:00\", \"yhat\": 5.944345554601432, \"yhat_lower\": 5.689287712170162, \"yhat_upper\": 6.199403397032701, \"fact\": 5.893822573112458, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:26:00\", \"yhat\": 5.9409156590365635, \"yhat_lower\": 5.585182904561281, \"yhat_upper\": 6.296648413511846, \"fact\": 5.956312217973574, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:27:00\", \"yhat\": 5.9395194135872345, \"yhat_lower\": 5.507529477329984, \"yhat_upper\": 6.371509349844485, \"fact\": 5.867959474518728, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:28:00\", \"yhat\": 5.93895102853938, \"yhat_lower\": 5.4428554717585955, \"yhat_upper\": 6.435046585320165, \"fact\": 5.924113424681968, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:29:00\", \"yhat\": 5.938719649763693, \"yhat_lower\": 5.386113627277958, \"yhat_upper\": 6.491325672249428, \"fact\": 5.755143754694852, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:30:00\", \"yhat\": 5.760599905298446, \"yhat_lower\": 5.505698392057641, \"yhat_upper\": 6.015501418539251, \"fact\": 5.748453921221867, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:31:00\", \"yhat\": 5.76269954403525, \"yhat_lower\": 5.408534223446234, \"yhat_upper\": 6.116864864624266, \"fact\": 5.688476020659092, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:32:00\", \"yhat\": 5.763507528115122, \"yhat_lower\": 5.3343261272171265, \"yhat_upper\": 6.1926889290131175, \"fact\": 5.746675485986374, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:33:00\", \"yhat\": 5.763818456972493, \"yhat_lower\": 5.271563907041106, \"yhat_upper\": 6.256073006903881, \"fact\": 5.843299988713007, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:34:00\", \"yhat\": 5.763938108778456, \"yhat_lower\": 5.2160468166255995, \"yhat_upper\": 6.3118294009313125, \"fact\": 5.834770667584292, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:35:00\", \"yhat\": 5.833525251400562, \"yhat_lower\": 5.579917702524392, \"yhat_upper\": 6.087132800276733, \"fact\": 5.867216105273556, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:36:00\", \"yhat\": 5.833039091214535, \"yhat_lower\": 5.480519561637844, \"yhat_upper\": 6.185558620791226, \"fact\": 5.877789831818705, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:37:00\", \"yhat\": 5.832849313909915, \"yhat_lower\": 5.405577173005054, \"yhat_upper\": 6.260121454814777, \"fact\": 5.788247198986482, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:38:00\", \"yhat\": 5.832775232513733, \"yhat_lower\": 5.342662391134344, \"yhat_upper\": 6.322888073893123, \"fact\": 5.855276906622282, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:39:00\", \"yhat\": 5.832746314128202, \"yhat_lower\": 5.2872099442196125, \"yhat_upper\": 6.378282684036791, \"fact\": 5.952180412895244, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:40:00\", \"yhat\": 5.9482795105879145, \"yhat_lower\": 5.695680856059903, \"yhat_upper\": 6.200878165115926, \"fact\": 6.064808083145066, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:41:00\", \"yhat\": 5.946721639930627, \"yhat_lower\": 5.595674678100532, \"yhat_upper\": 6.297768601760722, \"fact\": 6.090622739284995, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:42:00\", \"yhat\": 5.946099486184229, \"yhat_lower\": 5.520709248793489, \"yhat_upper\": 6.371489723574969, \"fact\": 6.088539270842496, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:43:00\", \"yhat\": 5.945851021857395, \"yhat_lower\": 5.45799268226429, \"yhat_upper\": 6.4337093614505, \"fact\": 6.180880255586056, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:44:00\", \"yhat\": 5.945751794741804, \"yhat_lower\": 5.402809247645458, \"yhat_upper\": 6.48869434183815, \"fact\": 6.0829197927436836, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:45:00\", \"yhat\": 6.084551373470568, \"yhat_lower\": 5.83257580300832, \"yhat_upper\": 6.336526943932816, \"fact\": 6.153305438466777, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:46:00\", \"yhat\": 6.085200810637757, \"yhat_lower\": 5.734496418949186, \"yhat_upper\": 6.435905202326329, \"fact\": 6.245424626413475, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:47:00\", \"yhat\": 6.085459313712216, \"yhat_lower\": 5.660084933617304, \"yhat_upper\": 6.510833693807129, \"fact\": 6.270181897393748, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:48:00\", \"yhat\": 6.085562208715584, \"yhat_lower\": 5.5974217917048, \"yhat_upper\": 6.5737026257263675, \"fact\": 6.304686334947228, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:49:00\", \"yhat\": 6.085603165217707, \"yhat_lower\": 5.542118080539727, \"yhat_upper\": 6.629088249895687, \"fact\": 6.2486697214488025, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:50:00\", \"yhat\": 6.249564989449478, \"yhat_lower\": 5.998729728574593, \"yhat_upper\": 6.500400250324364, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:51:00\", \"yhat\": 6.249913847731205, \"yhat_lower\": 5.9006620611578375, \"yhat_upper\": 6.599165634304572, \"fact\": 6.23101000200763, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:52:00\", \"yhat\": 6.250049787026072, \"yhat_lower\": 5.826299497376384, \"yhat_upper\": 6.673800076675759, \"fact\": 6.230694728169978, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:53:00\", \"yhat\": 6.250102758369614, \"yhat_lower\": 5.763704124714489, \"yhat_upper\": 6.736501392024739, \"fact\": 6.157703819607037, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:54:00\", \"yhat\": 6.250123399665712, \"yhat_lower\": 5.70847562095993, \"yhat_upper\": 6.791771178371495, \"fact\": 6.301928313075152, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:55:00\", \"yhat\": 6.297998816680268, \"yhat_lower\": 6.047622146148059, \"yhat_upper\": 6.5483754872124775, \"fact\": 6.4061636350278155, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:56:00\", \"yhat\": 6.2964962608616055, \"yhat_lower\": 5.948543514563678, \"yhat_upper\": 6.644449007159533, \"fact\": 6.462931053129455, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:57:00\", \"yhat\": 6.295921715484458, \"yhat_lower\": 5.874201734901785, \"yhat_upper\": 6.7176416960671315, \"fact\": 6.586302157616276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:58:00\", \"yhat\": 6.295702021556085, \"yhat_lower\": 5.811949830944344, \"yhat_upper\": 6.779454212167827, \"fact\": 6.590380090978745, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:59:00\", \"yhat\": 6.295618015272015, \"yhat_lower\": 5.757145241285006, \"yhat_upper\": 6.834090789259024, \"fact\": 6.598384601991288, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:00:00\", \"yhat\": 6.597412969192818, \"yhat_lower\": 6.347656558636209, \"yhat_upper\": 6.847169379749427, \"fact\": 6.6087284233126855, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:01:00\", \"yhat\": 6.59703629058395, \"yhat_lower\": 6.248195014739094, \"yhat_upper\": 6.9458775664288055, \"fact\": 6.519586448521761, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:02:00\", \"yhat\": 6.596890261369413, \"yhat_lower\": 6.172821559170344, \"yhat_upper\": 7.020958963568483, \"fact\": 6.585441774813497, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:03:00\", \"yhat\": 6.596833649363857, \"yhat_lower\": 6.109464555847566, \"yhat_upper\": 7.084202742880148, \"fact\": 6.612122789230208, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:04:00\", \"yhat\": 6.5968117022542785, \"yhat_lower\": 6.0536274334602656, \"yhat_upper\": 7.139995971048291, \"fact\": 6.713398361671289, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:05:00\", \"yhat\": 6.710415654780143, \"yhat_lower\": 6.461540792495042, \"yhat_upper\": 6.959290517065244, \"fact\": 6.822549277291775, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:06:00\", \"yhat\": 6.709252188759664, \"yhat_lower\": 6.361705119017242, \"yhat_upper\": 7.056799258502086, \"fact\": 6.97551658913424, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:07:00\", \"yhat\": 6.708798354967001, \"yhat_lower\": 6.28635789586271, \"yhat_upper\": 7.131238814071293, \"fact\": 7.0245338623762, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:08:00\", \"yhat\": 6.708621327784654, \"yhat_lower\": 6.223168335613451, \"yhat_upper\": 7.194074319955856, \"fact\": 7.011984857308559, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:09:00\", \"yhat\": 6.70855227470003, \"yhat_lower\": 6.167539339228818, \"yhat_upper\": 7.249565210171242, \"fact\": 6.939497193677334, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:10:00\", \"yhat\": 6.940139064073755, \"yhat_lower\": 6.691350168667293, \"yhat_upper\": 7.188927959480216, \"fact\": 7.010406398571905, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:11:00\", \"yhat\": 6.940216818249961, \"yhat_lower\": 6.5899212851856594, \"yhat_upper\": 7.290512351314262, \"fact\": 6.931851888092667, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:12:00\", \"yhat\": 6.9402262371481545, \"yhat_lower\": 6.51198887286548, \"yhat_upper\": 7.368463601430829, \"fact\": 6.879178023131081, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:13:00\", \"yhat\": 6.940227378124081, \"yhat_lower\": 6.446211499044236, \"yhat_upper\": 7.434243257203925, \"fact\": 7.109475269891421, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:14:00\", \"yhat\": 6.940227516338343, \"yhat_lower\": 6.388218259339513, \"yhat_upper\": 7.492236773337173, \"fact\": 7.284680664017118, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:15:00\", \"yhat\": 7.285591777087916, \"yhat_lower\": 7.0349793271436605, \"yhat_upper\": 7.536204227032171, \"fact\": 7.395090828652547, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:16:00\", \"yhat\": 7.2855250830497615, \"yhat_lower\": 6.930073841430036, \"yhat_upper\": 7.640976324669487, \"fact\": 7.371434651213532, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:17:00\", \"yhat\": 7.285529965094447, \"yhat_lower\": 6.849834182204316, \"yhat_upper\": 7.721225747984579, \"fact\": 7.245236231448149, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:18:00\", \"yhat\": 7.285529607725769, \"yhat_lower\": 6.782220577985497, \"yhat_upper\": 7.78883863746604, \"fact\": 7.344627723533745, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:19:00\", \"yhat\": 7.2855296338853766, \"yhat_lower\": 6.722671875989988, \"yhat_upper\": 7.848387391780765, \"fact\": 7.362549605351548, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:20:00\", \"yhat\": 7.362640079566995, \"yhat_lower\": 7.1123280018815604, \"yhat_upper\": 7.612952157252429, \"fact\": 7.316384307810927, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:21:00\", \"yhat\": 7.362638866088396, \"yhat_lower\": 7.007640630503108, \"yhat_upper\": 7.717637101673684, \"fact\": 7.4436762713471, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:22:00\", \"yhat\": 7.362638882364086, \"yhat_lower\": 6.927458702289933, \"yhat_upper\": 7.797819062438239, \"fact\": 7.586315011635683, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:23:00\", \"yhat\": 7.36263888214579, \"yhat_lower\": 6.859906389331664, \"yhat_upper\": 7.865371374959915, \"fact\": 7.84596167034078, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:24:00\", \"yhat\": 7.362638882148718, \"yhat_lower\": 6.800412835249899, \"yhat_upper\": 7.924864929047537, \"fact\": 7.810708032610894, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:25:00\", \"yhat\": 7.816550529752005, \"yhat_lower\": 7.565506288878929, \"yhat_upper\": 8.067594770625082, \"fact\": 7.869544211046324, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:26:00\", \"yhat\": 7.810872902450107, \"yhat_lower\": 7.451632008381344, \"yhat_upper\": 8.170113796518871, \"fact\": 7.588004256487661, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:27:00\", \"yhat\": 7.816390312386423, \"yhat_lower\": 7.378028388187327, \"yhat_upper\": 8.254752236585517, \"fact\": 7.4272223763164, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:28:00\", \"yhat\": 7.811028598630542, \"yhat_lower\": 7.302984694464954, \"yhat_upper\": 8.31907250279613, \"fact\": 7.22636705323483, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:29:00\", \"yhat\": 7.816239009807493, \"yhat_lower\": 7.249410032610338, \"yhat_upper\": 8.383067987004647, \"fact\": 7.215400231065601, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:30:00\", \"yhat\": 7.216353160724422, \"yhat_lower\": 6.960673766754205, \"yhat_upper\": 7.472032554694639, \"fact\": 7.212214491649582, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:31:00\", \"yhat\": 7.216171635984013, \"yhat_lower\": 6.848633137177756, \"yhat_upper\": 7.5837101347902705, \"fact\": 7.351039971128483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:32:00\", \"yhat\": 7.2162062148546315, \"yhat_lower\": 6.764587423651902, \"yhat_upper\": 7.667825006057361, \"fact\": 7.376476250774716, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:33:00\", \"yhat\": 7.216199627883123, \"yhat_lower\": 6.693711652636985, \"yhat_upper\": 7.738687603129261, \"fact\": 7.335800040585095, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:34:00\", \"yhat\": 7.2162008826434105, \"yhat_lower\": 6.631395357824935, \"yhat_upper\": 7.801006407461886, \"fact\": 7.448679719340017, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:35:00\", \"yhat\": 7.452503657511436, \"yhat_lower\": 7.197316006803971, \"yhat_upper\": 7.7076913082189, \"fact\": 7.483511703168986, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:36:00\", \"yhat\": 7.451971856621101, \"yhat_lower\": 7.085280914072586, \"yhat_upper\": 7.818662799169616, \"fact\": 7.414570983492366, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:37:00\", \"yhat\": 7.452045814978763, \"yhat_lower\": 7.001258908688272, \"yhat_upper\": 7.902832721269253, \"fact\": 7.334626120276795, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:38:00\", \"yhat\": 7.452035529477614, \"yhat_lower\": 6.930462901947463, \"yhat_upper\": 7.9736081570077655, \"fact\": 7.3049778908374945, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:39:00\", \"yhat\": 7.4520369598978835, \"yhat_lower\": 6.868208484460012, \"yhat_upper\": 8.035865435335754, \"fact\": 7.278459085454509, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:40:00\", \"yhat\": 7.2776470273555205, \"yhat_lower\": 7.023662163873742, \"yhat_upper\": 7.531631890837299, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:41:00\", \"yhat\": 7.277767424063659, \"yhat_lower\": 6.912274743879037, \"yhat_upper\": 7.643260104248281, \"fact\": 7.413871916691975, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:42:00\", \"yhat\": 7.277749573903248, \"yhat_lower\": 6.828334039306306, \"yhat_upper\": 7.72716510850019, \"fact\": 7.306328534468085, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:43:00\", \"yhat\": 7.2777522203894485, \"yhat_lower\": 6.7576893307120836, \"yhat_upper\": 7.797815110066813, \"fact\": 7.135863705449194, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:44:00\", \"yhat\": 7.2777518280182285, \"yhat_lower\": 6.695565072539987, \"yhat_upper\": 7.85993858349647, \"fact\": 7.296605351643508, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:45:00\", \"yhat\": 7.299926322053273, \"yhat_lower\": 7.045973898437952, \"yhat_upper\": 7.5538787456685945, \"fact\": 7.432244315830181, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:46:00\", \"yhat\": 7.296710973417641, \"yhat_lower\": 6.932907651159899, \"yhat_upper\": 7.660514295675383, \"fact\": 7.395988175550756, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:47:00\", \"yhat\": 7.299824059525925, \"yhat_lower\": 6.856032897993685, \"yhat_upper\": 7.743615221058165, \"fact\": 7.278183825443562, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:48:00\", \"yhat\": 7.296809983537339, \"yhat_lower\": 6.782313473379718, \"yhat_upper\": 7.8113064936949606, \"fact\": 7.250066035906667, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:49:00\", \"yhat\": 7.299728198372706, \"yhat_lower\": 6.725791140553761, \"yhat_upper\": 7.873665256191651, \"fact\": 7.282209302585056, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:50:00\", \"yhat\": 7.281830555035022, \"yhat_lower\": 7.028360741030704, \"yhat_upper\": 7.53530036903934, \"fact\": 7.2156324032840775, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:51:00\", \"yhat\": 7.282196985995753, \"yhat_lower\": 6.918948906692463, \"yhat_upper\": 7.645445065299044, \"fact\": 7.196476313520412, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:52:00\", \"yhat\": 7.281842471097979, \"yhat_lower\": 6.838776874319301, \"yhat_upper\": 7.724908067876658, \"fact\": 7.113119567118843, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:53:00\", \"yhat\": 7.2821854574343226, \"yhat_lower\": 6.768474134281684, \"yhat_upper\": 7.795896780586961, \"fact\": 7.162704804924952, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:54:00\", \"yhat\": 7.281853624759147, \"yhat_lower\": 6.708825467730545, \"yhat_upper\": 7.85488178178775, \"fact\": 7.221109884038875, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:55:00\", \"yhat\": 7.218293857199037, \"yhat_lower\": 6.965864852706779, \"yhat_upper\": 7.4707228616912955, \"fact\": 7.28587585791872, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:56:00\", \"yhat\": 7.221017748060954, \"yhat_lower\": 6.8592003456224875, \"yhat_upper\": 7.582835150499421, \"fact\": 7.33450767010157, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:57:00\", \"yhat\": 7.218382978632386, \"yhat_lower\": 6.777084426991344, \"yhat_upper\": 7.659681530273428, \"fact\": 7.2076185280683, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:58:00\", \"yhat\": 7.220931542541012, \"yhat_lower\": 6.709243507435033, \"yhat_upper\": 7.732619577646991, \"fact\": 7.200436641971628, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:59:00\", \"yhat\": 7.2184663636430315, \"yhat_lower\": 6.64771049144449, \"yhat_upper\": 7.789222235841573, \"fact\": 7.174060851045539, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:00:00\", \"yhat\": 7.173296648626436, \"yhat_lower\": 6.921698040754108, \"yhat_upper\": 7.424895256498764, \"fact\": 7.262444992057902, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:01:00\", \"yhat\": 7.174035703487625, \"yhat_lower\": 6.813351027858519, \"yhat_upper\": 7.534720379116732, \"fact\": 7.34306802733499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:02:00\", \"yhat\": 7.173320968655342, \"yhat_lower\": 6.733424725979266, \"yhat_upper\": 7.613217211331418, \"fact\": 7.316689086557331, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:03:00\", \"yhat\": 7.174012183756283, \"yhat_lower\": 6.66392607118319, \"yhat_upper\": 7.684098296329377, \"fact\": 7.435901366061946, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:04:00\", \"yhat\": 7.173343714424456, \"yhat_lower\": 6.604389175244254, \"yhat_upper\": 7.742298253604657, \"fact\": 7.519301570079593, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:05:00\", \"yhat\": 7.5185764523606995, \"yhat_lower\": 7.267408573893648, \"yhat_upper\": 7.769744330827751, \"fact\": 7.444483463234448, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:06:00\", \"yhat\": 7.5192773500714, \"yhat_lower\": 7.159106717072483, \"yhat_upper\": 7.8794479830703175, \"fact\": 7.558503416641305, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:07:00\", \"yhat\": 7.518599863384665, \"yhat_lower\": 7.079367201404851, \"yhat_upper\": 7.957832525364479, \"fact\": 7.502724062217367, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:08:00\", \"yhat\": 7.519254721010387, \"yhat_lower\": 7.0098955496762745, \"yhat_upper\": 8.028613892344499, \"fact\": 7.543900869874692, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:09:00\", \"yhat\": 7.5186217366014505, \"yhat_lower\": 6.950503127021667, \"yhat_upper\": 8.086740346181234, \"fact\": 7.61793683008212, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:10:00\", \"yhat\": 7.6129619954947305, \"yhat_lower\": 7.36238405221503, \"yhat_upper\": 7.863539938774431, \"fact\": 7.576099179026605, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:11:00\", \"yhat\": 7.617772867406523, \"yhat_lower\": 7.258488404227632, \"yhat_upper\": 7.977057330585414, \"fact\": 7.474889511780991, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:12:00\", \"yhat\": 7.613120554220001, \"yhat_lower\": 7.174955351196553, \"yhat_upper\": 8.051285757243448, \"fact\": 7.493594475005889, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:13:00\", \"yhat\": 7.617619534525926, \"yhat_lower\": 7.109513656535809, \"yhat_upper\": 8.125725412516044, \"fact\": 7.394645478479456, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:14:00\", \"yhat\": 7.613268833491493, \"yhat_lower\": 7.0465397897777375, \"yhat_upper\": 8.179997877205249, \"fact\": 7.358314631980785, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:15:00\", \"yhat\": 7.366710105295156, \"yhat_lower\": 7.116849636792478, \"yhat_upper\": 7.616570573797834, \"fact\": 7.414394947365127, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:16:00\", \"yhat\": 7.358583069850688, \"yhat_lower\": 7.000451585044503, \"yhat_upper\": 7.716714554656874, \"fact\": 7.362071254261016, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:17:00\", \"yhat\": 7.3664502504898755, \"yhat_lower\": 6.929648571223621, \"yhat_upper\": 7.80325192975613, \"fact\": 7.2610336329398955, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:18:00\", \"yhat\": 7.358834616027282, \"yhat_lower\": 6.852359396667534, \"yhat_upper\": 7.8653098353870305, \"fact\": 7.397969492007248, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:19:00\", \"yhat\": 7.366206747280877, \"yhat_lower\": 6.801268417557214, \"yhat_upper\": 7.93114507700454, \"fact\": 7.175585543122942, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:20:00\", \"yhat\": 7.160009880253454, \"yhat_lower\": 6.908780770491768, \"yhat_upper\": 7.411238990015139, \"fact\": 7.132322801642127, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:21:00\", \"yhat\": 7.175142985123323, \"yhat_lower\": 6.815577064714107, \"yhat_upper\": 7.534708905532538, \"fact\": 7.1510859667762, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:22:00\", \"yhat\": 7.160439863662528, \"yhat_lower\": 6.721703528517741, \"yhat_upper\": 7.599176198807315, \"fact\": 7.086966133877971, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:23:00\", \"yhat\": 7.174725219017548, \"yhat_lower\": 6.66622165940641, \"yhat_upper\": 7.683228778628686, \"fact\": 7.091083736255178, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:24:00\", \"yhat\": 7.160845759600488, \"yhat_lower\": 6.593519673505681, \"yhat_upper\": 7.728171845695296, \"fact\": 7.047475782418074, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:25:00\", \"yhat\": 7.059168865816141, \"yhat_lower\": 6.809302025875383, \"yhat_upper\": 7.309035705756899, \"fact\": 7.009527254558687, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:26:00\", \"yhat\": 7.047824418929619, \"yhat_lower\": 6.68997450046545, \"yhat_upper\": 7.405674337393789, \"fact\": 7.115014684339309, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:27:00\", \"yhat\": 7.058830624117755, \"yhat_lower\": 6.622271359099034, \"yhat_upper\": 7.495389889136477, \"fact\": 7.158507807273718, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:28:00\", \"yhat\": 7.048152575742628, \"yhat_lower\": 6.542075732781259, \"yhat_upper\": 7.554229418703996, \"fact\": 7.223216693033921, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:29:00\", \"yhat\": 7.058512251503032, \"yhat_lower\": 6.493950713650285, \"yhat_upper\": 7.623073789355779, \"fact\": 7.414873061673024, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:30:00\", \"yhat\": 7.404198552420598, \"yhat_lower\": 7.15410286299506, \"yhat_upper\": 7.654294241846136, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:31:00\", \"yhat\": 7.414555212821825, \"yhat_lower\": 7.0563641970363005, \"yhat_upper\": 7.77274622860735, \"fact\": 7.2522816003485655, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:32:00\", \"yhat\": 7.404506936865536, \"yhat_lower\": 6.96753671776917, \"yhat_upper\": 7.841477155961901, \"fact\": 7.362085934503852, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:33:00\", \"yhat\": 7.414256010966854, \"yhat_lower\": 6.907696795778013, \"yhat_upper\": 7.920815226155695, \"fact\": 7.467224271777104, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:34:00\", \"yhat\": 7.404797229555353, \"yhat_lower\": 6.839701439786028, \"yhat_upper\": 7.969893019324678, \"fact\": 7.364294904567715, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:35:00\", \"yhat\": 7.37200267618703, \"yhat_lower\": 7.121570013351947, \"yhat_upper\": 7.622435339022113, \"fact\": 7.459430953032399, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:36:00\", \"yhat\": 7.364531163162113, \"yhat_lower\": 7.005931471991403, \"yhat_upper\": 7.7231308543328225, \"fact\": 7.452578150899747, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:37:00\", \"yhat\": 7.371773659390415, \"yhat_lower\": 6.934273894071852, \"yhat_upper\": 7.809273424708978, \"fact\": 7.5133858350161615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:38:00\", \"yhat\": 7.364753160136509, \"yhat_lower\": 6.857615811286102, \"yhat_upper\": 7.871890508986915, \"fact\": 7.4258638789745675, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:39:00\", \"yhat\": 7.371558467066665, \"yhat_lower\": 6.805792910338943, \"yhat_upper\": 7.937324023794386, \"fact\": 7.3737932149732766, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:40:00\", \"yhat\": 7.3710961687573855, \"yhat_lower\": 7.121466609863671, \"yhat_upper\": 7.6207257276511, \"fact\": 7.598358267725344, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:41:00\", \"yhat\": 7.373708129141845, \"yhat_lower\": 7.016100490728412, \"yhat_upper\": 7.731315767555278, \"fact\": 7.492834789309395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:42:00\", \"yhat\": 7.371178570319385, \"yhat_lower\": 6.934945176430296, \"yhat_upper\": 7.807411964208474, \"fact\": 7.522201737971649, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:43:00\", \"yhat\": 7.373628327166523, \"yhat_lower\": 6.86789389606429, \"yhat_upper\": 7.879362758268757, \"fact\": 7.302638063120661, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:44:00\", \"yhat\": 7.3712558547192275, \"yhat_lower\": 6.807093757405459, \"yhat_upper\": 7.935417952032996, \"fact\": 7.279557282830666, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:45:00\", \"yhat\": 7.279680278601407, \"yhat_lower\": 7.026770458357441, \"yhat_upper\": 7.532590098845373, \"fact\": 7.363046511604048, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:46:00\", \"yhat\": 7.2796634094689345, \"yhat_lower\": 6.919927888741431, \"yhat_upper\": 7.639398930196438, \"fact\": 7.326486104423132, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:47:00\", \"yhat\": 7.279665723106458, \"yhat_lower\": 6.838472425900878, \"yhat_upper\": 7.720859020312038, \"fact\": 7.246927464543807, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:48:00\", \"yhat\": 7.279665405786133, \"yhat_lower\": 6.769840514931834, \"yhat_upper\": 7.789490296640432, \"fact\": 7.41642187662266, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:49:00\", \"yhat\": 7.279665449307293, \"yhat_lower\": 6.709413337743624, \"yhat_upper\": 7.849917560870963, \"fact\": 7.502878653438836, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:50:00\", \"yhat\": 7.48774425214232, \"yhat_lower\": 7.235928582859503, \"yhat_upper\": 7.739559921425136, \"fact\": 7.651020501300728, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:51:00\", \"yhat\": 7.502467812969404, \"yhat_lower\": 7.1423287414388295, \"yhat_upper\": 7.862606884499979, \"fact\": 7.73101396367219, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:52:00\", \"yhat\": 7.488143939881755, \"yhat_lower\": 7.04861169041849, \"yhat_upper\": 7.92767618934502, \"fact\": 7.7908900897128355, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:53:00\", \"yhat\": 7.502078975206474, \"yhat_lower\": 6.992764898193691, \"yhat_upper\": 8.011393052219256, \"fact\": 7.721905539978192, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:54:00\", \"yhat\": 7.488522222203083, \"yhat_lower\": 6.920224330684986, \"yhat_upper\": 8.05682011372118, \"fact\": 7.676797763099813, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:55:00\", \"yhat\": 7.693138196022208, \"yhat_lower\": 7.441416486671045, \"yhat_upper\": 7.94485990537337, \"fact\": 7.49859598323504, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:56:00\", \"yhat\": 7.677195211861952, \"yhat_lower\": 7.317594823233135, \"yhat_upper\": 8.03679560049077, \"fact\": 7.476065058965288, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:57:00\", \"yhat\": 7.692750414416336, \"yhat_lower\": 7.253730437008519, \"yhat_upper\": 8.131770391824153, \"fact\": 7.482103132721876, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:58:00\", \"yhat\": 7.677573561446044, \"yhat_lower\": 7.169021454017259, \"yhat_upper\": 8.18612566887483, \"fact\": 7.533694637573916, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:59:00\", \"yhat\": 7.692381267438722, \"yhat_lower\": 7.124833328103077, \"yhat_upper\": 8.259929206774366, \"fact\": 7.520250704663931, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:00:00\", \"yhat\": 7.503523314070336, \"yhat_lower\": 7.25193017492475, \"yhat_upper\": 7.755116453215923, \"fact\": 7.430552773592014, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:01:00\", \"yhat\": 7.519916055035945, \"yhat_lower\": 7.161147081475889, \"yhat_upper\": 7.878685028596001, \"fact\": 7.425522429366651, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:02:00\", \"yhat\": 7.50385126866882, \"yhat_lower\": 7.065608974196779, \"yhat_upper\": 7.94209356314086, \"fact\": 7.19210405586305, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:03:00\", \"yhat\": 7.5195946615256215, \"yhat_lower\": 7.012218517520609, \"yhat_upper\": 8.026970805530635, \"fact\": 7.28277232480738, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:04:00\", \"yhat\": 7.504166232352682, \"yhat_lower\": 6.937763499042452, \"yhat_upper\": 8.070568965662911, \"fact\": 7.175360535016683, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:05:00\", \"yhat\": 7.173873349518272, \"yhat_lower\": 6.92057524359665, \"yhat_upper\": 7.427171455439893, \"fact\": 7.262163774530336, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:06:00\", \"yhat\": 7.1740774981144915, \"yhat_lower\": 6.813741999158462, \"yhat_upper\": 7.534412997070521, \"fact\": 7.203036103460411, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:07:00\", \"yhat\": 7.174049474273899, \"yhat_lower\": 6.7321066552662145, \"yhat_upper\": 7.615992293281584, \"fact\": 7.104577394867066, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:08:00\", \"yhat\": 7.174053321156298, \"yhat_lower\": 6.663353761605052, \"yhat_upper\": 7.684752880707544, \"fact\": 7.146838037080654, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:09:00\", \"yhat\": 7.174052793087915, \"yhat_lower\": 6.602816702678393, \"yhat_upper\": 7.745288883497437, \"fact\": 7.1098713925408195, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:10:00\", \"yhat\": 7.109610716156644, \"yhat_lower\": 6.8569584487037725, \"yhat_upper\": 7.362262983609516, \"fact\": 6.964204225280627, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:11:00\", \"yhat\": 7.109623670135193, \"yhat_lower\": 6.751142793652526, \"yhat_upper\": 7.46810454661786, \"fact\": 6.8317439585381985, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:12:00\", \"yhat\": 7.1096230264038445, \"yhat_lower\": 6.670143872328218, \"yhat_upper\": 7.549102180479471, \"fact\": 6.846925861641189, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:13:00\", \"yhat\": 7.1096230583932485, \"yhat_lower\": 6.60190522250948, \"yhat_upper\": 7.617340894277017, \"fact\": 6.8792347865250285, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:14:00\", \"yhat\": 7.109623056803576, \"yhat_lower\": 6.5418090280733505, \"yhat_upper\": 7.677437085533802, \"fact\": 6.918101973663316, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:15:00\", \"yhat\": 6.918571675911672, \"yhat_lower\": 6.666129851358794, \"yhat_upper\": 7.171013500464551, \"fact\": 6.946297846175937, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:16:00\", \"yhat\": 6.918518927797419, \"yhat_lower\": 6.559127626959058, \"yhat_upper\": 7.27791022863578, \"fact\": 6.91741109605579, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:17:00\", \"yhat\": 6.918524851472613, \"yhat_lower\": 6.477611750346601, \"yhat_upper\": 7.359437952598625, \"fact\": 6.792759709575465, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:18:00\", \"yhat\": 6.91852418623693, \"yhat_lower\": 6.408947621156285, \"yhat_upper\": 7.428100751317576, \"fact\": 6.781526290147463, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:19:00\", \"yhat\": 6.918524260943679, \"yhat_lower\": 6.3484981595290915, \"yhat_upper\": 7.488550362358266, \"fact\": 6.527562112720121, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:20:00\", \"yhat\": 6.524082428954757, \"yhat_lower\": 6.270737748103554, \"yhat_upper\": 6.77742710980596, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:21:00\", \"yhat\": 6.524353174122666, \"yhat_lower\": 6.163606756826468, \"yhat_upper\": 6.885099591418864, \"fact\": 6.342845929573227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:22:00\", \"yhat\": 6.524332108143431, \"yhat_lower\": 6.0816654476008045, \"yhat_upper\": 6.966998768686058, \"fact\": 6.295282891714099, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:23:00\", \"yhat\": 6.5243337472326335, \"yhat_lower\": 6.0126889971262445, \"yhat_upper\": 7.0359784973390225, \"fact\": 6.416976346172642, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:24:00\", \"yhat\": 6.524333619699354, \"yhat_lower\": 5.951964779507084, \"yhat_upper\": 7.096702459891625, \"fact\": 6.474370432036268, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:25:00\", \"yhat\": 6.47518585052719, \"yhat_lower\": 6.221926612312983, \"yhat_upper\": 6.728445088741396, \"fact\": 6.601555135123274, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:26:00\", \"yhat\": 6.475088733600407, \"yhat_lower\": 6.113228785705835, \"yhat_upper\": 6.836948681494978, \"fact\": 6.565698424868521, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:27:00\", \"yhat\": 6.475100300296003, \"yhat_lower\": 6.030774856505277, \"yhat_upper\": 6.919425744086729, \"fact\": 6.58040116897878, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:28:00\", \"yhat\": 6.475098922694266, \"yhat_lower\": 5.961342522837147, \"yhat_upper\": 6.988855322551385, \"fact\": 6.482049789735297, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:29:00\", \"yhat\": 6.47509908676762, \"yhat_lower\": 5.90024115370073, \"yhat_upper\": 7.04995701983451, \"fact\": 6.390248110625829, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:30:00\", \"yhat\": 6.38844965217483, \"yhat_lower\": 6.135529623849783, \"yhat_upper\": 6.641369680499877, \"fact\": 6.32894900581122, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:31:00\", \"yhat\": 6.388565804348265, \"yhat_lower\": 6.026995615077918, \"yhat_upper\": 6.7501359936186125, \"fact\": 6.342132763662364, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:32:00\", \"yhat\": 6.388558302741883, \"yhat_lower\": 5.944356677448673, \"yhat_upper\": 6.832759928035093, \"fact\": 6.431054046458639, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:33:00\", \"yhat\": 6.3885587872278515, \"yhat_lower\": 5.874838106959432, \"yhat_upper\": 6.902279467496271, \"fact\": 6.373515189094005, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:34:00\", \"yhat\": 6.388558755937666, \"yhat_lower\": 5.813665695893781, \"yhat_upper\": 6.963451815981551, \"fact\": 6.205522054823765, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:35:00\", \"yhat\": 6.201622734221125, \"yhat_lower\": 5.948848893286743, \"yhat_upper\": 6.454396575155507, \"fact\": 6.316785939738493, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:36:00\", \"yhat\": 6.201902527464482, \"yhat_lower\": 5.84008981575688, \"yhat_upper\": 6.563715239172085, \"fact\": 6.333618541503614, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:37:00\", \"yhat\": 6.201882451080157, \"yhat_lower\": 5.757252301609696, \"yhat_upper\": 6.646512600550618, \"fact\": 6.445636379481378, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:38:00\", \"yhat\": 6.201883891648209, \"yhat_lower\": 5.68758852321547, \"yhat_upper\": 6.716179260080948, \"fact\": 6.591432527622528, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:39:00\", \"yhat\": 6.201883788281174, \"yhat_lower\": 5.62629511752273, \"yhat_upper\": 6.777472459039618, \"fact\": 6.518538014853173, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:40:00\", \"yhat\": 6.516651549904689, \"yhat_lower\": 6.263767053096791, \"yhat_upper\": 6.769536046712588, \"fact\": 6.403509692296891, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:41:00\", \"yhat\": 6.516793122976042, \"yhat_lower\": 6.155216029300217, \"yhat_upper\": 6.8783702166518665, \"fact\": 6.514920639375976, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:42:00\", \"yhat\": 6.51678249837655, \"yhat_lower\": 6.072586159934022, \"yhat_upper\": 6.960978836819078, \"fact\": 6.698467040888667, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:43:00\", \"yhat\": 6.516783295718256, \"yhat_lower\": 6.003072379895382, \"yhat_upper\": 7.03049421154113, \"fact\": 6.759388401607078, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:44:00\", \"yhat\": 6.516783235880349, \"yhat_lower\": 5.941903933114492, \"yhat_upper\": 7.091662538646206, \"fact\": 6.716490662775344, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:45:00\", \"yhat\": 6.7151680066399955, \"yhat_lower\": 6.461906009888023, \"yhat_upper\": 6.968430003391968, \"fact\": 6.5987942999302085, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:46:00\", \"yhat\": 6.715278354532299, \"yhat_lower\": 6.352098642794707, \"yhat_upper\": 7.078458066269891, \"fact\": 6.65333830003684, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:47:00\", \"yhat\": 6.7152691483168585, \"yhat_lower\": 6.268780763763916, \"yhat_upper\": 7.161757532869801, \"fact\": 6.556226307271936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:48:00\", \"yhat\": 6.715269916382301, \"yhat_lower\": 6.198714292697794, \"yhat_upper\": 7.231825540066808, \"fact\": 6.631915596619567, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:49:00\", \"yhat\": 6.715269852303361, \"yhat_lower\": 6.137078341756499, \"yhat_upper\": 7.293461362850223, \"fact\": 6.7418854984709515, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:50:00\", \"yhat\": 6.7372070439716305, \"yhat_lower\": 6.485036258986656, \"yhat_upper\": 6.989377828956605, \"fact\": 6.90468821514332, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:51:00\", \"yhat\": 6.741697496775951, \"yhat_lower\": 6.380384793047463, \"yhat_upper\": 7.10301020050444, \"fact\": 6.92379664141639, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:52:00\", \"yhat\": 6.73738749089885, \"yhat_lower\": 6.296626057474203, \"yhat_upper\": 7.178148924323496, \"fact\": 6.946555214531447, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:53:00\", \"yhat\": 6.741524301031401, \"yhat_lower\": 6.2305487671795525, \"yhat_upper\": 7.252499834883249, \"fact\": 6.930459476706841, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:54:00\", \"yhat\": 6.737553726846411, \"yhat_lower\": 6.167515984802557, \"yhat_upper\": 7.307591468890265, \"fact\": 7.022422718896414, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:55:00\", \"yhat\": 7.025127179715844, \"yhat_lower\": 6.772290969883668, \"yhat_upper\": 7.27796338954802, \"fact\": 7.053346772430454, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:56:00\", \"yhat\": 7.025046233722833, \"yhat_lower\": 6.662245009736234, \"yhat_upper\": 7.387847457709432, \"fact\": 7.097472113550277, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:57:00\", \"yhat\": 7.025048656480721, \"yhat_lower\": 6.578720496461311, \"yhat_upper\": 7.471376816500132, \"fact\": 7.192623177672057, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:58:00\", \"yhat\": 7.025048583966251, \"yhat_lower\": 6.508525254586266, \"yhat_upper\": 7.541571913346236, \"fact\": 7.258527915260533, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:59:00\", \"yhat\": 7.025048586136649, \"yhat_lower\": 6.446789327113626, \"yhat_upper\": 7.603307845159673, \"fact\": 7.282872270839376, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:00:00\", \"yhat\": 7.283477784093431, \"yhat_lower\": 7.031459165457045, \"yhat_upper\": 7.535496402729816, \"fact\": 7.242022079132392, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:01:00\", \"yhat\": 7.2834359980198995, \"yhat_lower\": 6.921176028782994, \"yhat_upper\": 7.645695967256805, \"fact\": 7.261334072336341, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:02:00\", \"yhat\": 7.283438881649497, \"yhat_lower\": 6.837729743243464, \"yhat_upper\": 7.72914802005553, \"fact\": 7.264136729062933, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:03:00\", \"yhat\": 7.283438682652105, \"yhat_lower\": 6.767588614400614, \"yhat_upper\": 7.799288750903596, \"fact\": 7.286273159581655, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:04:00\", \"yhat\": 7.283438696384785, \"yhat_lower\": 6.705905538581739, \"yhat_upper\": 7.860971854187831, \"fact\": 7.357895750482174, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:05:00\", \"yhat\": 7.360161235850887, \"yhat_lower\": 7.109137204016968, \"yhat_upper\": 7.611185267684806, \"fact\": 7.330285522164443, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:06:00\", \"yhat\": 7.36001061469296, \"yhat_lower\": 6.9991709978394185, \"yhat_upper\": 7.720850231546501, \"fact\": 7.421393852719808, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:07:00\", \"yhat\": 7.360020628764791, \"yhat_lower\": 6.916043847915583, \"yhat_upper\": 7.803997409613999, \"fact\": 7.5620596009564744, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:08:00\", \"yhat\": 7.36001996297762, \"yhat_lower\": 6.846167585378935, \"yhat_upper\": 7.8738723405763045, \"fact\": 7.565735575531843, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:09:00\", \"yhat\": 7.3600200072425865, \"yhat_lower\": 6.7847184301832115, \"yhat_upper\": 7.9353215843019616, \"fact\": 7.58361194350413, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:10:00\", \"yhat\": 7.584280854622248, \"yhat_lower\": 7.333727651065556, \"yhat_upper\": 7.834834058178941, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:11:00\", \"yhat\": 7.584219188674755, \"yhat_lower\": 7.223745222504951, \"yhat_upper\": 7.9446931548445585, \"fact\": 7.610778235091248, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:12:00\", \"yhat\": 7.584224873569171, \"yhat_lower\": 7.14072136852975, \"yhat_upper\": 8.027728378608591, \"fact\": 7.521885308219655, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:13:00\", \"yhat\": 7.584224349486985, \"yhat_lower\": 7.070914456498682, \"yhat_upper\": 8.097534242475287, \"fact\": 7.716909631502675, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:14:00\", \"yhat\": 7.584224397801363, \"yhat_lower\": 7.009528610856101, \"yhat_upper\": 8.158920184746625, \"fact\": 7.747519051979066, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:15:00\", \"yhat\": 7.74787753137804, \"yhat_lower\": 7.497061983613828, \"yhat_upper\": 7.998693079142252, \"fact\": 7.785511706436309, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:16:00\", \"yhat\": 7.747855233865918, \"yhat_lower\": 7.387703886253121, \"yhat_upper\": 8.108006581478715, \"fact\": 7.930365226719392, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:17:00\", \"yhat\": 7.747856620776989, \"yhat_lower\": 7.304839634870624, \"yhat_upper\": 8.190873606683352, \"fact\": 7.967473463214496, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:18:00\", \"yhat\": 7.747856534510758, \"yhat_lower\": 7.23518279493787, \"yhat_upper\": 8.260530274083646, \"fact\": 7.999580916809377, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:19:00\", \"yhat\": 7.7478565398765395, \"yhat_lower\": 7.1739194983259695, \"yhat_upper\": 8.32179358142711, \"fact\": 7.92745812562292, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:20:00\", \"yhat\": 7.9250143526215835, \"yhat_lower\": 7.674640754605663, \"yhat_upper\": 8.175387950637504, \"fact\": 8.055342945626094, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:21:00\", \"yhat\": 7.925212633755637, \"yhat_lower\": 7.565354432256526, \"yhat_upper\": 8.285070835254746, \"fact\": 8.069067375478213, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:22:00\", \"yhat\": 7.925196545760516, \"yhat_lower\": 7.482512233159351, \"yhat_upper\": 8.36788085836168, \"fact\": 8.155734179368574, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:23:00\", \"yhat\": 7.925197851096942, \"yhat_lower\": 7.412881161109606, \"yhat_upper\": 8.437514541084278, \"fact\": 8.011806921777461, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:24:00\", \"yhat\": 7.925197745185474, \"yhat_lower\": 7.351642910519293, \"yhat_upper\": 8.498752579851654, \"fact\": 8.092111510811511, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:25:00\", \"yhat\": 8.094341676070655, \"yhat_lower\": 7.843806090677641, \"yhat_upper\": 8.34487726146367, \"fact\": 8.220078277501383, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:26:00\", \"yhat\": 8.094284665939771, \"yhat_lower\": 7.7354489592017375, \"yhat_upper\": 8.453120372677803, \"fact\": 8.267900885640357, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:27:00\", \"yhat\": 8.09428612330039, \"yhat_lower\": 7.653066731201085, \"yhat_upper\": 8.535505515399695, \"fact\": 8.340179387722713, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:28:00\", \"yhat\": 8.094286086045608, \"yhat_lower\": 7.583807709129626, \"yhat_upper\": 8.60476446296159, \"fact\": 8.360308596655782, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:29:00\", \"yhat\": 8.09428608699796, \"yhat_lower\": 7.522882779266974, \"yhat_upper\": 8.665689394728945, \"fact\": 8.356915788188523, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:30:00\", \"yhat\": 8.35677989846051, \"yhat_lower\": 8.10683156929266, \"yhat_upper\": 8.606728227628361, \"fact\": 8.288188793887379, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:31:00\", \"yhat\": 8.35678712117698, \"yhat_lower\": 7.998030768026832, \"yhat_upper\": 8.715543474327129, \"fact\": 8.371033308450802, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:32:00\", \"yhat\": 8.356786737280169, \"yhat_lower\": 7.915498189887397, \"yhat_upper\": 8.798075284672942, \"fact\": 8.296495018073724, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:33:00\", \"yhat\": 8.356786757684786, \"yhat_lower\": 7.846124640295601, \"yhat_upper\": 8.86744887507397, \"fact\": 8.267777641850003, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:34:00\", \"yhat\": 8.356786756600254, \"yhat_lower\": 7.7851090129793015, \"yhat_upper\": 8.928464500221207, \"fact\": 8.144346886350423, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:35:00\", \"yhat\": 8.14091634919591, \"yhat_lower\": 7.891281913911041, \"yhat_upper\": 8.39055078448078, \"fact\": 8.061674389304113, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:36:00\", \"yhat\": 8.141020221246304, \"yhat_lower\": 7.782986911851095, \"yhat_upper\": 8.499053530641513, \"fact\": 8.101904105964518, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:37:00\", \"yhat\": 8.141017076140344, \"yhat_lower\": 7.700620301292485, \"yhat_upper\": 8.581413850988202, \"fact\": 8.049382116624201, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:38:00\", \"yhat\": 8.14101717136992, \"yhat_lower\": 7.631395656975849, \"yhat_upper\": 8.650638685763992, \"fact\": 7.9510567258113305, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:39:00\", \"yhat\": 8.141017168486497, \"yhat_lower\": 7.570509713101261, \"yhat_upper\": 8.711524623871734, \"fact\": 7.962974507940454, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:40:00\", \"yhat\": 7.963560214730579, \"yhat_lower\": 7.7145512518722965, \"yhat_upper\": 8.212569177588861, \"fact\": 7.805239859715092, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:41:00\", \"yhat\": 7.963529376160262, \"yhat_lower\": 7.6060889238597955, \"yhat_upper\": 8.32096982846073, \"fact\": 7.663667118812604, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:42:00\", \"yhat\": 7.9635309998693184, \"yhat_lower\": 7.523847532664423, \"yhat_upper\": 8.403214467074214, \"fact\": 7.514024098971325, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:43:00\", \"yhat\": 7.963530914377966, \"yhat_lower\": 7.4547186048484075, \"yhat_upper\": 8.472343223907524, \"fact\": 7.471366107835003, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:44:00\", \"yhat\": 7.963530918879247, \"yhat_lower\": 7.393918922586617, \"yhat_upper\": 8.533142915171876, \"fact\": 7.445667100893326, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:45:00\", \"yhat\": 7.44469112595848, \"yhat_lower\": 7.1952359229309, \"yhat_upper\": 7.69414632898606, \"fact\": 7.456711779886499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:46:00\", \"yhat\": 7.444652679123371, \"yhat_lower\": 7.08512565985799, \"yhat_upper\": 7.804179698388753, \"fact\": 7.444329373125276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:47:00\", \"yhat\": 7.44465116457717, \"yhat_lower\": 7.001385607952969, \"yhat_upper\": 7.887916721201371, \"fact\": 7.468336779368962, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:48:00\", \"yhat\": 7.444651104914256, \"yhat_lower\": 6.931117625668272, \"yhat_upper\": 7.95818458416024, \"fact\": 7.585589594686708, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:49:00\", \"yhat\": 7.44465110256394, \"yhat_lower\": 6.8693692459937505, \"yhat_upper\": 8.01993295913413, \"fact\": 7.750432747546225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:50:00\", \"yhat\": 7.757347648965532, \"yhat_lower\": 7.508058903025873, \"yhat_upper\": 8.006636394905192, \"fact\": 7.789461459883152, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:51:00\", \"yhat\": 7.757679352998595, \"yhat_lower\": 7.397694685800869, \"yhat_upper\": 8.11766402019632, \"fact\": 7.849428734659802, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:52:00\", \"yhat\": 7.757695264659352, \"yhat_lower\": 7.313518845693804, \"yhat_upper\": 8.2018716836249, \"fact\": 7.945508717131604, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:53:00\", \"yhat\": 7.757696027933002, \"yhat_lower\": 7.242905886748412, \"yhat_upper\": 8.272486169117592, \"fact\": 7.897018421083583, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:54:00\", \"yhat\": 7.7576960645468205, \"yhat_lower\": 7.180872273552947, \"yhat_upper\": 8.334519855540695, \"fact\": 7.790206365474418, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:55:00\", \"yhat\": 7.785450412115646, \"yhat_lower\": 7.536623833355443, \"yhat_upper\": 8.03427699087585, \"fact\": 7.839967858463782, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:56:00\", \"yhat\": 7.785160945242204, \"yhat_lower\": 7.4254055281859115, \"yhat_upper\": 8.144916362298495, \"fact\": 7.8667860803525524, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:57:00\", \"yhat\": 7.78514332709827, \"yhat_lower\": 7.340979419057152, \"yhat_upper\": 8.229307235139387, \"fact\": 7.7525973626559095, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:58:00\", \"yhat\": 7.785142254785601, \"yhat_lower\": 7.270204954101484, \"yhat_upper\": 8.300079555469718, \"fact\": 7.70504444156228, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:59:00\", \"yhat\": 7.7851421895202435, \"yhat_lower\": 7.208045523201257, \"yhat_upper\": 8.36223885583923, \"fact\": 7.801695429233526, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:00:00\", \"yhat\": 7.805945474674204, \"yhat_lower\": 7.557532697859198, \"yhat_upper\": 8.05435825148921, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:01:00\", \"yhat\": 7.8059507327521, \"yhat_lower\": 7.446978402169089, \"yhat_upper\": 8.164923063335111, \"fact\": 7.652667153528996, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:02:00\", \"yhat\": 7.805950739257297, \"yhat_lower\": 7.363209011596261, \"yhat_upper\": 8.248692466918333, \"fact\": 7.578881723592664, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:03:00\", \"yhat\": 7.805950739265345, \"yhat_lower\": 7.292940652416668, \"yhat_upper\": 8.318960826114022, \"fact\": 7.491151863279462, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:04:00\", \"yhat\": 7.805950739265355, \"yhat_lower\": 7.2311999576084505, \"yhat_upper\": 8.380701520922258, \"fact\": 7.503454922925876, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:05:00\", \"yhat\": 7.504214115415658, \"yhat_lower\": 7.256110106442083, \"yhat_upper\": 7.752318124389232, \"fact\": 7.599057949270826, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:06:00\", \"yhat\": 7.504201655900327, \"yhat_lower\": 7.145563482410016, \"yhat_upper\": 7.862839829390638, \"fact\": 7.540289550698573, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:07:00\", \"yhat\": 7.504201860380119, \"yhat_lower\": 7.061940915093566, \"yhat_upper\": 7.946462805666672, \"fact\": 7.709498641608279, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:08:00\", \"yhat\": 7.504201857024292, \"yhat_lower\": 6.9917863392763575, \"yhat_upper\": 8.016617374772226, \"fact\": 7.830648777977522, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:09:00\", \"yhat\": 7.504201857079366, \"yhat_lower\": 6.9301421414829285, \"yhat_upper\": 8.078261572675803, \"fact\": 7.833850854121761, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:10:00\", \"yhat\": 7.833693409943327, \"yhat_lower\": 7.585388290489109, \"yhat_upper\": 8.081998529397543, \"fact\": 7.896527014556835, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:11:00\", \"yhat\": 7.833695991055009, \"yhat_lower\": 7.474636410824233, \"yhat_upper\": 8.192755571285785, \"fact\": 7.740317372019487, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:12:00\", \"yhat\": 7.8336959487407265, \"yhat_lower\": 7.390866248229954, \"yhat_upper\": 8.276525649251498, \"fact\": 7.734078442460585, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:13:00\", \"yhat\": 7.83369594943442, \"yhat_lower\": 7.320593576168439, \"yhat_upper\": 8.3467983227004, \"fact\": 7.68652453910119, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:14:00\", \"yhat\": 7.833695949423047, \"yhat_lower\": 7.2588482113250405, \"yhat_upper\": 8.408543687521055, \"fact\": 7.654062933595664, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:15:00\", \"yhat\": 7.6527031421021405, \"yhat_lower\": 7.404706403658943, \"yhat_upper\": 7.900699880545338, \"fact\": 7.7323556114676295, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:16:00\", \"yhat\": 7.65266637708427, \"yhat_lower\": 7.294347054849067, \"yhat_upper\": 8.010985699319473, \"fact\": 7.823575479244249, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:17:00\", \"yhat\": 7.652665383059418, \"yhat_lower\": 7.210588571089591, \"yhat_upper\": 8.094742195029244, \"fact\": 7.961063693882232, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:18:00\", \"yhat\": 7.652665356183722, \"yhat_lower\": 7.14034211392129, \"yhat_upper\": 8.164988598446156, \"fact\": 7.66166136402624, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:19:00\", \"yhat\": 7.652665355457078, \"yhat_lower\": 7.078628413881239, \"yhat_upper\": 8.226702297032917, \"fact\": 7.735994319948233, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:20:00\", \"yhat\": 7.7390174192800005, \"yhat_lower\": 7.489109376725954, \"yhat_upper\": 7.9889254618340475, \"fact\": 7.8172661459687465, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:21:00\", \"yhat\": 7.738968244148513, \"yhat_lower\": 7.379535497383331, \"yhat_upper\": 8.098400990913694, \"fact\": 7.800477360464126, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:22:00\", \"yhat\": 7.738969044053938, \"yhat_lower\": 7.296409500688008, \"yhat_upper\": 8.18152858741987, \"fact\": 7.726932237108902, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:23:00\", \"yhat\": 7.7389690310423065, \"yhat_lower\": 7.226594996681524, \"yhat_upper\": 8.251343065403088, \"fact\": 7.811868370741103, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:24:00\", \"yhat\": 7.738969031253959, \"yhat_lower\": 7.1652135659064875, \"yhat_upper\": 8.312724496601431, \"fact\": 7.658004719265347, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:25:00\", \"yhat\": 7.6527683199757, \"yhat_lower\": 7.4029238432659366, \"yhat_upper\": 7.902612796685464, \"fact\": 7.670100990217529, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:26:00\", \"yhat\": 7.653253125423005, \"yhat_lower\": 7.294286490943151, \"yhat_upper\": 8.012219759902859, \"fact\": 7.45312553026062, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:27:00\", \"yhat\": 7.653208240319953, \"yhat_lower\": 7.211716357126987, \"yhat_upper\": 8.094700123512919, \"fact\": 7.57061971942359, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:28:00\", \"yhat\": 7.653212395950809, \"yhat_lower\": 7.14232301796495, \"yhat_upper\": 8.164101773936668, \"fact\": 7.584558764339831, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:29:00\", \"yhat\": 7.653212011206949, \"yhat_lower\": 7.081287536666198, \"yhat_upper\": 8.2251364857477, \"fact\": 7.736367838262079, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:30:00\", \"yhat\": 7.74031817189977, \"yhat_lower\": 7.489620213035748, \"yhat_upper\": 7.991016130763793, \"fact\": 7.883967912330481, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:31:00\", \"yhat\": 7.740434905871727, \"yhat_lower\": 7.381253515753026, \"yhat_upper\": 8.099616295990426, \"fact\": 7.9454144774542215, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:32:00\", \"yhat\": 7.740438355408261, \"yhat_lower\": 7.298542156911591, \"yhat_upper\": 8.182334553904932, \"fact\": 7.9815247789264765, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:33:00\", \"yhat\": 7.740438457343474, \"yhat_lower\": 7.229032394346596, \"yhat_upper\": 8.251844520340352, \"fact\": 7.828608211241088, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:34:00\", \"yhat\": 7.740438460355701, \"yhat_lower\": 7.167900113228994, \"yhat_upper\": 8.312976807482409, \"fact\": 7.8866167493939185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:35:00\", \"yhat\": 7.8881782856063145, \"yhat_lower\": 7.637376876376174, \"yhat_upper\": 8.138979694836456, \"fact\": 7.718286285065371, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:36:00\", \"yhat\": 7.88826673353236, \"yhat_lower\": 7.528397094261709, \"yhat_upper\": 8.248136372803012, \"fact\": 7.764341416031271, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:37:00\", \"yhat\": 7.888271743365343, \"yhat_lower\": 7.445187205471714, \"yhat_upper\": 8.331356281258973, \"fact\": 7.840706888425015, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:38:00\", \"yhat\": 7.888272027130352, \"yhat_lower\": 7.375286910767667, \"yhat_upper\": 8.401257143493037, \"fact\": 7.938059917879748, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:39:00\", \"yhat\": 7.888272043203259, \"yhat_lower\": 7.313829500143328, \"yhat_upper\": 8.462714586263191, \"fact\": 7.761060058402809, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:40:00\", \"yhat\": 7.756683374015198, \"yhat_lower\": 7.5052150282678, \"yhat_upper\": 8.008151719762596, \"fact\": 7.6946908748491, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:41:00\", \"yhat\": 7.756647060032067, \"yhat_lower\": 7.396632271384411, \"yhat_upper\": 8.116661848679723, \"fact\": 7.672013085482828, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:42:00\", \"yhat\": 7.756646758729699, \"yhat_lower\": 7.313915100296371, \"yhat_upper\": 8.199378417163027, \"fact\": 7.749640954645437, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:43:00\", \"yhat\": 7.75664675622975, \"yhat_lower\": 7.2443848960451955, \"yhat_upper\": 8.268908616414304, \"fact\": 7.74351636626246, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:44:00\", \"yhat\": 7.756646756209007, \"yhat_lower\": 7.183224479666816, \"yhat_upper\": 8.330069032751199, \"fact\": 7.758280802421245, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:45:00\", \"yhat\": 7.758673323332085, \"yhat_lower\": 7.507983280423414, \"yhat_upper\": 8.009363366240756, \"fact\": 7.9905599789244945, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:46:00\", \"yhat\": 7.758672843216749, \"yhat_lower\": 7.39947214975057, \"yhat_upper\": 8.117873536682927, \"fact\": 7.870475361188625, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:47:00\", \"yhat\": 7.758672843804006, \"yhat_lower\": 7.316857669848515, \"yhat_upper\": 8.200488017759497, \"fact\": 7.972400000133551, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:48:00\", \"yhat\": 7.7586728438032875, \"yhat_lower\": 7.247423234766146, \"yhat_upper\": 8.26992245284043, \"fact\": 8.089531300610558, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:49:00\", \"yhat\": 7.758672843803288, \"yhat_lower\": 7.186351537596924, \"yhat_upper\": 8.330994150009653, \"fact\": 8.097777022768552, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:50:00\", \"yhat\": 8.097971613555105, \"yhat_lower\": 7.84630905884594, \"yhat_upper\": 8.349634168264268, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:51:00\", \"yhat\": 8.097976908584714, \"yhat_lower\": 7.73814479368437, \"yhat_upper\": 8.457809023485058, \"fact\": 8.031589183895466, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:52:00\", \"yhat\": 8.097977052668302, \"yhat_lower\": 7.655595310649848, \"yhat_upper\": 8.540358794686755, \"fact\": 8.148437931838542, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:53:00\", \"yhat\": 8.097977056588975, \"yhat_lower\": 7.586189829598146, \"yhat_upper\": 8.609764283579805, \"fact\": 8.221370040659716, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:54:00\", \"yhat\": 8.097977056695662, \"yhat_lower\": 7.525132589987503, \"yhat_upper\": 8.670821523403822, \"fact\": 8.333189126475943, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:55:00\", \"yhat\": 8.336000947410634, \"yhat_lower\": 8.084449969116045, \"yhat_upper\": 8.587551925705222, \"fact\": 8.511437080644786, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:56:00\", \"yhat\": 8.336324835083964, \"yhat_lower\": 7.9763668632271765, \"yhat_upper\": 8.696282806940753, \"fact\": 8.530259401373554, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:57:00\", \"yhat\": 8.336362143016215, \"yhat_lower\": 7.893402480532579, \"yhat_upper\": 8.779321805499851, \"fact\": 8.464149676702108, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:58:00\", \"yhat\": 8.336366440437585, \"yhat_lower\": 7.823631272893781, \"yhat_upper\": 8.849101607981389, \"fact\": 8.510761154617697, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:59:00\", \"yhat\": 8.336366935448414, \"yhat_lower\": 7.762271024244416, \"yhat_upper\": 8.910462846652411, \"fact\": 8.588384748465963, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:00:00\", \"yhat\": 8.590606460246187, \"yhat_lower\": 8.339147803229634, \"yhat_upper\": 8.84206511726274, \"fact\": 8.596579830973859, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:01:00\", \"yhat\": 8.590969953979386, \"yhat_lower\": 8.230555773503506, \"yhat_upper\": 8.951384134455266, \"fact\": 8.665254766764672, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:02:00\", \"yhat\": 8.591029425102171, \"yhat_lower\": 8.147029387554538, \"yhat_upper\": 9.035029462649804, \"fact\": 8.571601855976125, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:03:00\", \"yhat\": 8.591039155158352, \"yhat_lower\": 8.076775318996848, \"yhat_upper\": 9.105302991319856, \"fact\": 8.483149022444422, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:04:00\", \"yhat\": 8.591040747090517, \"yhat_lower\": 8.01500787094247, \"yhat_upper\": 9.167073623238563, \"fact\": 8.392816789809771, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:05:00\", \"yhat\": 8.389850594527848, \"yhat_lower\": 8.138777236426531, \"yhat_upper\": 8.640923952629166, \"fact\": 8.289463311811762, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:06:00\", \"yhat\": 8.389366709801426, \"yhat_lower\": 8.029184119839424, \"yhat_upper\": 8.749549299763427, \"fact\": 8.293193709584163, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:07:00\", \"yhat\": 8.389287772170483, \"yhat_lower\": 7.945405660704092, \"yhat_upper\": 8.833169883636875, \"fact\": 8.201046712843748, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:08:00\", \"yhat\": 8.389274894827516, \"yhat_lower\": 7.875047021985941, \"yhat_upper\": 8.903502767669089, \"fact\": 8.074013353443654, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:09:00\", \"yhat\": 8.389272794106226, \"yhat_lower\": 7.813212500054001, \"yhat_upper\": 8.965333088158452, \"fact\": 8.060346196714583, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:10:00\", \"yhat\": 8.058937161999022, \"yhat_lower\": 7.808143416972668, \"yhat_upper\": 8.309730907025378, \"fact\": 8.129960019946706, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:11:00\", \"yhat\": 8.058598873118921, \"yhat_lower\": 7.698242349360891, \"yhat_upper\": 8.418955396876951, \"fact\": 8.093286965059585, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:12:00\", \"yhat\": 8.058517654845776, \"yhat_lower\": 7.613759015432909, \"yhat_upper\": 8.503276294258644, \"fact\": 8.207114051737939, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:13:00\", \"yhat\": 8.058498155511684, \"yhat_lower\": 7.542742951696224, \"yhat_upper\": 8.574253359327145, \"fact\": 8.174797102772132, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:14:00\", \"yhat\": 8.058493474003258, \"yhat_lower\": 7.480346227263013, \"yhat_upper\": 8.636640720743504, \"fact\": 8.244861920292358, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:15:00\", \"yhat\": 8.246892614491909, \"yhat_lower\": 7.996525775894294, \"yhat_upper\": 8.497259453089523, \"fact\": 8.004603702913197, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:16:00\", \"yhat\": 8.247386192360105, \"yhat_lower\": 7.887997559955304, \"yhat_upper\": 8.606774824764907, \"fact\": 7.962191492988927, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:17:00\", \"yhat\": 8.247506160749253, \"yhat_lower\": 7.804137694633451, \"yhat_upper\": 8.690874626865057, \"fact\": 7.82693977677464, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:18:00\", \"yhat\": 8.24753532010854, \"yhat_lower\": 7.733511803607085, \"yhat_upper\": 8.761558836609995, \"fact\": 7.780715623518733, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:19:00\", \"yhat\": 8.247542407544156, \"yhat_lower\": 7.67141697409807, \"yhat_upper\": 8.823667840990241, \"fact\": 7.602800054795464, \"anomaly\": 1}, {\"ds\": \"2021-08-23T11:20:00\", \"yhat\": 7.59623858516438, \"yhat_lower\": 7.344633151593722, \"yhat_upper\": 7.847844018735037, \"fact\": 7.7126592728826395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:21:00\", \"yhat\": 7.594418087949245, \"yhat_lower\": 7.23267192764706, \"yhat_upper\": 7.95616424825143, \"fact\": 7.7702415551012605, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:22:00\", \"yhat\": 7.5939129861509205, \"yhat_lower\": 7.147125757009206, \"yhat_upper\": 8.040700215292635, \"fact\": 7.755515291272416, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:23:00\", \"yhat\": 7.5937728443124435, \"yhat_lower\": 7.0753973201417875, \"yhat_upper\": 8.1121483684831, \"fact\": 7.893932649872157, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:24:00\", \"yhat\": 7.593733961586314, \"yhat_lower\": 7.01244155927682, \"yhat_upper\": 8.175026363895807, \"fact\": 7.9497835809896715, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:25:00\", \"yhat\": 7.952566801747894, \"yhat_lower\": 7.701134783110021, \"yhat_upper\": 8.203998820385767, \"fact\": 7.8758994800134285, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:26:00\", \"yhat\": 7.953324016617681, \"yhat_lower\": 7.592165394774707, \"yhat_upper\": 8.314482638460655, \"fact\": 7.882184263103129, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:27:00\", \"yhat\": 7.953530027713758, \"yhat_lower\": 7.507702294813531, \"yhat_upper\": 8.399357760613986, \"fact\": 8.064546783500113, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:28:00\", \"yhat\": 7.953586075968223, \"yhat_lower\": 7.436485927019855, \"yhat_upper\": 8.470686224916593, \"fact\": 8.081645734366429, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:29:00\", \"yhat\": 7.953601324694571, \"yhat_lower\": 7.373855332366786, \"yhat_upper\": 8.533347317022354, \"fact\": 8.172757664947504, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:30:00\", \"yhat\": 8.17608890268794, \"yhat_lower\": 7.924661754466152, \"yhat_upper\": 8.427516050909729, \"fact\": 8.098672806113793, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:31:00\", \"yhat\": 8.177064926023974, \"yhat_lower\": 7.8159681095646905, \"yhat_upper\": 8.538161742483256, \"fact\": 8.151170322208227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:32:00\", \"yhat\": 8.177350892270368, \"yhat_lower\": 7.731537986483442, \"yhat_upper\": 8.623163798057295, \"fact\": 8.26088485879859, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:33:00\", \"yhat\": 8.177434677863456, \"yhat_lower\": 7.660273263367266, \"yhat_upper\": 8.694596092359646, \"fact\": 8.191009434921096, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:34:00\", \"yhat\": 8.177459226304741, \"yhat_lower\": 7.597575618164689, \"yhat_upper\": 8.757342834444794, \"fact\": 8.194555208030412, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:35:00\", \"yhat\": 8.194369078645694, \"yhat_lower\": 7.943355707410617, \"yhat_upper\": 8.445382449880771, \"fact\": 8.360453709951065, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:36:00\", \"yhat\": 8.194315746980525, \"yhat_lower\": 7.834196314623494, \"yhat_upper\": 8.554435179337556, \"fact\": 8.396733578661529, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:37:00\", \"yhat\": 8.194300465854903, \"yhat_lower\": 7.749963676266971, \"yhat_upper\": 8.638637255442836, \"fact\": 8.457129588862593, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:38:00\", \"yhat\": 8.194296087352948, \"yhat_lower\": 7.679036179673822, \"yhat_upper\": 8.709555995032073, \"fact\": 8.320222281734633, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:39:00\", \"yhat\": 8.194294832780486, \"yhat_lower\": 7.616680029479724, \"yhat_upper\": 8.771909636081247, \"fact\": 8.38706323868159, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:40:00\", \"yhat\": 8.388105066596077, \"yhat_lower\": 8.136919047898676, \"yhat_upper\": 8.639291085293479, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:41:00\", \"yhat\": 8.388387172795701, \"yhat_lower\": 8.02827812277926, \"yhat_upper\": 8.748496222812141, \"fact\": 8.47380305154199, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:42:00\", \"yhat\": 8.388463561522437, \"yhat_lower\": 7.9443647664251875, \"yhat_upper\": 8.832562356619686, \"fact\": 8.471000521610067, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:43:00\", \"yhat\": 8.388484246064571, \"yhat_lower\": 7.873673229011009, \"yhat_upper\": 8.903295263118133, \"fact\": 8.583404963654896, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:44:00\", \"yhat\": 8.388489847025625, \"yhat_lower\": 7.811508128008471, \"yhat_upper\": 8.965471566042778, \"fact\": 8.531063469573645, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:45:00\", \"yhat\": 8.530281518573727, \"yhat_lower\": 8.279453522286037, \"yhat_upper\": 8.781109514861416, \"fact\": 8.471403101314356, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:46:00\", \"yhat\": 8.530104147694015, \"yhat_lower\": 8.170648628888824, \"yhat_upper\": 8.889559666499206, \"fact\": 8.409649600014262, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:47:00\", \"yhat\": 8.53006391444542, \"yhat_lower\": 8.08702825744653, \"yhat_upper\": 8.973099571444308, \"fact\": 8.370469524136148, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:48:00\", \"yhat\": 8.530054788289563, \"yhat_lower\": 8.016702870692871, \"yhat_upper\": 9.043406705886255, \"fact\": 8.48614212062726, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:49:00\", \"yhat\": 8.530052718192724, \"yhat_lower\": 7.954883149125969, \"yhat_upper\": 9.10522228725948, \"fact\": 8.64617716198996, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:50:00\", \"yhat\": 8.651398057014003, \"yhat_lower\": 8.400587818186933, \"yhat_upper\": 8.902208295841072, \"fact\": 8.53530065692971, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:51:00\", \"yhat\": 8.652412414630717, \"yhat_lower\": 8.292465451911058, \"yhat_upper\": 9.012359377350377, \"fact\": 8.526391763137674, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:52:00\", \"yhat\": 8.652609492214129, \"yhat_lower\": 8.208808766183328, \"yhat_upper\": 9.09641021824493, \"fact\": 8.4747311830338, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:53:00\", \"yhat\": 8.652647782037405, \"yhat_lower\": 8.138351330354315, \"yhat_upper\": 9.166944233720496, \"fact\": 8.369368219481078, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:54:00\", \"yhat\": 8.652655221293262, \"yhat_lower\": 8.076399474149184, \"yhat_upper\": 9.22891096843734, \"fact\": 8.560972818522371, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:55:00\", \"yhat\": 8.565238578996546, \"yhat_lower\": 8.314087646341852, \"yhat_upper\": 8.81638951165124, \"fact\": 8.506389603340054, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:56:00\", \"yhat\": 8.565927499078633, \"yhat_lower\": 8.20641916274409, \"yhat_upper\": 8.925435835413175, \"fact\": 8.481984739041978, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:57:00\", \"yhat\": 8.566038759634019, \"yhat_lower\": 8.123407871295697, \"yhat_upper\": 9.00866964797234, \"fact\": 8.485287372932227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:58:00\", \"yhat\": 8.566056728207597, \"yhat_lower\": 8.053533627844017, \"yhat_upper\": 9.078579828571177, \"fact\": 8.509799875799924, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:59:00\", \"yhat\": 8.566059630131242, \"yhat_lower\": 7.992081411314299, \"yhat_upper\": 9.140037848948186, \"fact\": 8.462839177620474, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:00:00\", \"yhat\": 8.461853030083159, \"yhat_lower\": 8.21146217708092, \"yhat_upper\": 8.712243883085398, \"fact\": 8.500847291856171, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:01:00\", \"yhat\": 8.46169021953827, \"yhat_lower\": 8.103546412972372, \"yhat_upper\": 8.819834026104166, \"fact\": 8.407545286261158, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:02:00\", \"yhat\": 8.461663339915775, \"yhat_lower\": 8.020846612376905, \"yhat_upper\": 8.902480067454645, \"fact\": 8.435490902768226, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:03:00\", \"yhat\": 8.461658902155888, \"yhat_lower\": 7.951314539604307, \"yhat_upper\": 8.972003264707467, \"fact\": 8.405689339518776, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:04:00\", \"yhat\": 8.46165816949259, \"yhat_lower\": 7.890171955685458, \"yhat_upper\": 9.033144383299723, \"fact\": 8.404404408484888, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:05:00\", \"yhat\": 8.404303156957047, \"yhat_lower\": 8.154565127931654, \"yhat_upper\": 8.65404118598244, \"fact\": 8.370573940680746, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:06:00\", \"yhat\": 8.404288480696254, \"yhat_lower\": 8.047285505828318, \"yhat_upper\": 8.761291455564189, \"fact\": 8.356621268629302, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:07:00\", \"yhat\": 8.404286353393728, \"yhat_lower\": 7.965047014611288, \"yhat_upper\": 8.843525692176167, \"fact\": 8.273825661013671, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:08:00\", \"yhat\": 8.404286045044339, \"yhat_lower\": 7.895887516119246, \"yhat_upper\": 8.91268457396943, \"fact\": 8.417744225285109, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:09:00\", \"yhat\": 8.404286000349547, \"yhat_lower\": 7.835062572264436, \"yhat_upper\": 8.973509428434658, \"fact\": 8.333018409415137, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:10:00\", \"yhat\": 8.331671347877455, \"yhat_lower\": 8.082108194943032, \"yhat_upper\": 8.581234500811878, \"fact\": 8.395519857078213, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:11:00\", \"yhat\": 8.331557323685972, \"yhat_lower\": 7.975458709976184, \"yhat_upper\": 8.68765593739576, \"fact\": 8.329430969980034, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:12:00\", \"yhat\": 8.331547671924803, \"yhat_lower\": 7.893915023520018, \"yhat_upper\": 8.769180320329587, \"fact\": 8.393907016426743, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:13:00\", \"yhat\": 8.331546854935947, \"yhat_lower\": 7.825330810775263, \"yhat_upper\": 8.837762899096631, \"fact\": 8.505097929522941, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:14:00\", \"yhat\": 8.331546785780612, \"yhat_lower\": 7.764988398489146, \"yhat_upper\": 8.898105173072077, \"fact\": 8.511009348963547, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:15:00\", \"yhat\": 8.511117418173919, \"yhat_lower\": 8.261952078469244, \"yhat_upper\": 8.760282757878594, \"fact\": 8.485964064563397, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:16:00\", \"yhat\": 8.511119905543465, \"yhat_lower\": 8.155882034561955, \"yhat_upper\": 8.866357776524975, \"fact\": 8.532367389569465, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:17:00\", \"yhat\": 8.511119962793881, \"yhat_lower\": 8.074826980858639, \"yhat_upper\": 8.947412944729123, \"fact\": 8.527169421117446, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:18:00\", \"yhat\": 8.511119964111582, \"yhat_lower\": 8.006629855041025, \"yhat_upper\": 9.01561007318214, \"fact\": 8.770144851734896, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:19:00\", \"yhat\": 8.511119964141912, \"yhat_lower\": 7.946612214735361, \"yhat_upper\": 9.075627713548462, \"fact\": 8.941922134099055, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:20:00\", \"yhat\": 8.946517099857603, \"yhat_lower\": 8.696585584680863, \"yhat_upper\": 9.196448615034344, \"fact\": 8.83656128758854, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:21:00\", \"yhat\": 8.94714653039474, \"yhat_lower\": 8.58959553017276, \"yhat_upper\": 9.30469753061672, \"fact\": 8.75134541259338, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:22:00\", \"yhat\": 8.947232751450978, \"yhat_lower\": 8.507205912179195, \"yhat_upper\": 9.38725959072276, \"fact\": 8.663598406050742, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:23:00\", \"yhat\": 8.947244562238826, \"yhat_lower\": 8.437872447497893, \"yhat_upper\": 9.456616676979758, \"fact\": 8.672674873252237, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:24:00\", \"yhat\": 8.947246180111717, \"yhat_lower\": 8.376892011105607, \"yhat_upper\": 9.517600349117828, \"fact\": 8.52103640042284, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:25:00\", \"yhat\": 8.517791959361817, \"yhat_lower\": 8.267809029740594, \"yhat_upper\": 8.767774888983041, \"fact\": 8.52272103376713, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:26:00\", \"yhat\": 8.517577996651394, \"yhat_lower\": 8.16024108416056, \"yhat_upper\": 8.874914909142227, \"fact\": 8.645248319087003, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:27:00\", \"yhat\": 8.51756388634993, \"yhat_lower\": 8.078168401075331, \"yhat_upper\": 8.956959371624528, \"fact\": 8.674972483541307, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:28:00\", \"yhat\": 8.517562955811112, \"yhat_lower\": 8.009174295915642, \"yhat_upper\": 9.025951615706582, \"fact\": 8.76474826986135, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:29:00\", \"yhat\": 8.517562894444422, \"yhat_lower\": 7.948484295084365, \"yhat_upper\": 9.08664149380448, \"fact\": 8.811453323118272, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:30:00\", \"yhat\": 8.812672565340371, \"yhat_lower\": 8.56308253291425, \"yhat_upper\": 9.062262597766493, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:31:00\", \"yhat\": 8.812783960024724, \"yhat_lower\": 8.455728873971168, \"yhat_upper\": 9.16983904607828, \"fact\": 8.485875363354573, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:32:00\", \"yhat\": 8.812794137473862, \"yhat_lower\": 8.373533920020062, \"yhat_upper\": 9.252054354927662, \"fact\": 8.399451833349502, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:33:00\", \"yhat\": 8.812795067324972, \"yhat_lower\": 8.304429784616298, \"yhat_upper\": 9.321160350033646, \"fact\": 8.457620981862641, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:34:00\", \"yhat\": 8.812795152279765, \"yhat_lower\": 8.243652619195817, \"yhat_upper\": 9.381937685363713, \"fact\": 8.612568848026724, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:35:00\", \"yhat\": 8.616870602504287, \"yhat_lower\": 8.366417592312342, \"yhat_upper\": 8.867323612696232, \"fact\": 8.514394842156392, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:36:00\", \"yhat\": 8.617341531865693, \"yhat_lower\": 8.258325857382232, \"yhat_upper\": 8.976357206349153, \"fact\": 8.387880106011288, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:37:00\", \"yhat\": 8.617393086287171, \"yhat_lower\": 8.17530730991868, \"yhat_upper\": 9.059478862655663, \"fact\": 8.223871883913581, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:38:00\", \"yhat\": 8.617398730145023, \"yhat_lower\": 8.105510751766866, \"yhat_upper\": 9.12928670852318, \"fact\": 8.098826371466577, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:39:00\", \"yhat\": 8.617399347999527, \"yhat_lower\": 8.044142548857764, \"yhat_upper\": 9.19065614714129, \"fact\": 8.05572889460056, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:40:00\", \"yhat\": 8.053720005320836, \"yhat_lower\": 7.802923173467119, \"yhat_upper\": 8.304516837174551, \"fact\": 7.956979270891584, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:41:00\", \"yhat\": 8.053406962489992, \"yhat_lower\": 7.692859923036228, \"yhat_upper\": 8.413954001943756, \"fact\": 7.811500666817628, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:42:00\", \"yhat\": 8.05335818139741, \"yhat_lower\": 7.608661258631887, \"yhat_upper\": 8.498055104162933, \"fact\": 7.690415462062634, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:43:00\", \"yhat\": 8.053350579897682, \"yhat_lower\": 7.5379666186322, \"yhat_upper\": 8.568734541163163, \"fact\": 7.717134221024015, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:44:00\", \"yhat\": 8.053349395365005, \"yhat_lower\": 7.475852963172992, \"yhat_upper\": 8.63084582755702, \"fact\": 7.835378833401439, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:45:00\", \"yhat\": 7.839783257065222, \"yhat_lower\": 7.588813876893046, \"yhat_upper\": 8.090752637237397, \"fact\": 7.711894191123989, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:46:00\", \"yhat\": 7.84073273029625, \"yhat_lower\": 7.47913649730015, \"yhat_upper\": 8.20232896329235, \"fact\": 7.7229591895282015, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:47:00\", \"yhat\": 7.840937410746011, \"yhat_lower\": 7.394203136655246, \"yhat_upper\": 8.287671684836775, \"fact\": 7.669836539613878, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:48:00\", \"yhat\": 7.84098153425065, \"yhat_lower\": 7.322696524354954, \"yhat_upper\": 8.359266544146347, \"fact\": 7.717692584250162, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:49:00\", \"yhat\": 7.840991046070973, \"yhat_lower\": 7.25985730355874, \"yhat_upper\": 8.422124788583204, \"fact\": 7.761794676176121, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:50:00\", \"yhat\": 7.763574752062494, \"yhat_lower\": 7.5130182366002005, \"yhat_upper\": 8.014131267524787, \"fact\": 7.780476902942309, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:51:00\", \"yhat\": 7.763961413494715, \"yhat_lower\": 7.403386068982599, \"yhat_upper\": 8.124536758006832, \"fact\": 7.977593528807279, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:52:00\", \"yhat\": 7.764045402646139, \"yhat_lower\": 7.318804986121937, \"yhat_upper\": 8.209285819170342, \"fact\": 7.918981702230322, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:53:00\", \"yhat\": 7.764063646455759, \"yhat_lower\": 7.247653793526038, \"yhat_upper\": 8.28047349938548, \"fact\": 8.014169824247498, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:54:00\", \"yhat\": 7.7640676093079115, \"yhat_lower\": 7.185132264585387, \"yhat_upper\": 8.343002954030435, \"fact\": 8.002420669187153, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:55:00\", \"yhat\": 8.002646764243062, \"yhat_lower\": 7.751982074920538, \"yhat_upper\": 8.253311453565585, \"fact\": 8.151076376650083, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:56:00\", \"yhat\": 8.002699974271932, \"yhat_lower\": 7.642213311730124, \"yhat_upper\": 8.36318663681374, \"fact\": 7.979406800773713, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:57:00\", \"yhat\": 8.002712496912736, \"yhat_lower\": 7.557631057187925, \"yhat_upper\": 8.447793936637545, \"fact\": 7.92353421269369, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:58:00\", \"yhat\": 8.002715444036351, \"yhat_lower\": 7.486491025602734, \"yhat_upper\": 8.518939862469967, \"fact\": 8.068779742758723, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:59:00\", \"yhat\": 8.002716137623091, \"yhat_lower\": 7.42398032879753, \"yhat_upper\": 8.581451946448652, \"fact\": 8.078786779675173, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:00:00\", \"yhat\": 8.079744277284977, \"yhat_lower\": 7.828545228504787, \"yhat_upper\": 8.330943326065167, \"fact\": 8.191788462425002, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:01:00\", \"yhat\": 8.079933005514029, \"yhat_lower\": 7.7193378970676845, \"yhat_upper\": 8.440528113960374, \"fact\": 8.000415544530842, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:02:00\", \"yhat\": 8.079970204922233, \"yhat_lower\": 7.6353082001872155, \"yhat_upper\": 8.52463220965725, \"fact\": 8.071115630032562, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:03:00\", \"yhat\": 8.079977537137333, \"yhat_lower\": 7.564641162923976, \"yhat_upper\": 8.595313911350692, \"fact\": 8.081479750948631, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:04:00\", \"yhat\": 8.079978982358664, \"yhat_lower\": 7.50252872288446, \"yhat_upper\": 8.657429241832869, \"fact\": 8.098170821285184, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:05:00\", \"yhat\": 8.098602250947065, \"yhat_lower\": 7.84724639497471, \"yhat_upper\": 8.34995810691942, \"fact\": 8.267139845953881, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:06:00\", \"yhat\": 8.098627646003948, \"yhat_lower\": 7.738648008308724, \"yhat_upper\": 8.458607283699171, \"fact\": 8.212596119789714, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:07:00\", \"yhat\": 8.098629140822156, \"yhat_lower\": 7.655703306274004, \"yhat_upper\": 8.541554975370309, \"fact\": 8.230590163089623, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:08:00\", \"yhat\": 8.098629228810992, \"yhat_lower\": 7.585996238219318, \"yhat_upper\": 8.611262219402667, \"fact\": 8.318860440882997, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:09:00\", \"yhat\": 8.098629233990241, \"yhat_lower\": 7.524693228600985, \"yhat_upper\": 8.672565239379496, \"fact\": 8.392351095262217, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:10:00\", \"yhat\": 8.39441334506416, \"yhat_lower\": 8.14309072558311, \"yhat_upper\": 8.64573596454521, \"fact\": 8.398247511408044, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:11:00\", \"yhat\": 8.394664127788591, \"yhat_lower\": 8.034751005204415, \"yhat_upper\": 8.754577250372767, \"fact\": 8.545377931691302, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:12:00\", \"yhat\": 8.394694624566824, \"yhat_lower\": 7.951628261999314, \"yhat_upper\": 8.837760987134335, \"fact\": 8.553662460728718, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:13:00\", \"yhat\": 8.394698333169499, \"yhat_lower\": 7.881739877053193, \"yhat_upper\": 8.907656789285806, \"fact\": 8.539053365383428, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:14:00\", \"yhat\": 8.39469878415923, \"yhat_lower\": 7.820285326748267, \"yhat_upper\": 8.969112241570192, \"fact\": 8.738610081903111, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:15:00\", \"yhat\": 8.743675396416167, \"yhat_lower\": 8.492133606051246, \"yhat_upper\": 8.995217186781089, \"fact\": 8.789728699261456, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:16:00\", \"yhat\": 8.744877036577897, \"yhat_lower\": 8.384570792346729, \"yhat_upper\": 9.105183280809065, \"fact\": 8.672292432735887, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:17:00\", \"yhat\": 8.745162100629608, \"yhat_lower\": 8.301138762316905, \"yhat_upper\": 9.189185438942312, \"fact\": 8.583695199589734, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:18:00\", \"yhat\": 8.745229726126963, \"yhat_lower\": 8.230758470421389, \"yhat_upper\": 9.259700981832538, \"fact\": 8.545572696616933, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:19:00\", \"yhat\": 8.745245768864955, \"yhat_lower\": 8.168835139241754, \"yhat_upper\": 9.321656398488155, \"fact\": 8.53469919243193, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:20:00\", \"yhat\": 8.534102767438169, \"yhat_lower\": 8.282929426256112, \"yhat_upper\": 8.785276108620225, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:21:00\", \"yhat\": 8.533973318153501, \"yhat_lower\": 8.173913275985608, \"yhat_upper\": 8.894033360321394, \"fact\": 8.619454458907168, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:22:00\", \"yhat\": 8.533945222219433, \"yhat_lower\": 8.090139877443274, \"yhat_upper\": 8.977750566995592, \"fact\": 8.64014873041566, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:23:00\", \"yhat\": 8.533939124221185, \"yhat_lower\": 8.019692396537994, \"yhat_upper\": 9.048185851904375, \"fact\": 8.773110778116337, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:24:00\", \"yhat\": 8.533937800699334, \"yhat_lower\": 7.957767350120923, \"yhat_upper\": 9.110108251277746, \"fact\": 8.842045243191007, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:25:00\", \"yhat\": 8.844745836593091, \"yhat_lower\": 8.593799696890654, \"yhat_upper\": 9.095691976295528, \"fact\": 8.779304562733579, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:26:00\", \"yhat\": 8.84531819053351, \"yhat_lower\": 8.48530969842997, \"yhat_upper\": 9.205326682637049, \"fact\": 8.715667021210756, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:27:00\", \"yhat\": 8.84543949314532, \"yhat_lower\": 8.401562450440956, \"yhat_upper\": 9.289316535849686, \"fact\": 8.95869877998149, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:28:00\", \"yhat\": 8.845465201579549, \"yhat_lower\": 8.331057517841174, \"yhat_upper\": 9.359872885317923, \"fact\": 9.131002557332641, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:29:00\", \"yhat\": 8.845470650131567, \"yhat_lower\": 8.269068642710293, \"yhat_upper\": 9.421872657552841, \"fact\": 9.110278629189814, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:30:00\", \"yhat\": 9.110690355057125, \"yhat_lower\": 8.858932411825945, \"yhat_upper\": 9.362448298288305, \"fact\": 9.026194022516984, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:31:00\", \"yhat\": 9.11077016020162, \"yhat_lower\": 8.749341523635154, \"yhat_upper\": 9.472198796768085, \"fact\": 8.996799590069418, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:32:00\", \"yhat\": 9.110785628894732, \"yhat_lower\": 8.665092960717743, \"yhat_upper\": 9.55647829707172, \"fact\": 8.89038427307193, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:33:00\", \"yhat\": 9.110788627203526, \"yhat_lower\": 8.594260233503922, \"yhat_upper\": 9.62731702090313, \"fact\": 8.845887105325563, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:34:00\", \"yhat\": 9.110789208368047, \"yhat_lower\": 8.532006020542033, \"yhat_upper\": 9.68957239619406, \"fact\": 8.940727418078595, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:35:00\", \"yhat\": 8.943460801790058, \"yhat_lower\": 8.692001612227486, \"yhat_upper\": 9.19491999135263, \"fact\": 8.890937823525107, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:36:00\", \"yhat\": 8.943867709521834, \"yhat_lower\": 8.582689103026603, \"yhat_upper\": 9.305046316017066, \"fact\": 8.689691616597951, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:37:00\", \"yhat\": 8.94392828422325, \"yhat_lower\": 8.498650699309442, \"yhat_upper\": 9.38920586913706, \"fact\": 8.859131071315861, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:38:00\", \"yhat\": 8.943937301733033, \"yhat_lower\": 8.428006688605166, \"yhat_upper\": 9.4598679148609, \"fact\": 8.75225132967224, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:39:00\", \"yhat\": 8.943938644133091, \"yhat_lower\": 8.365916075698298, \"yhat_upper\": 9.521961212567884, \"fact\": 8.745441955414979, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:40:00\", \"yhat\": 8.744949007641312, \"yhat_lower\": 8.492846045473566, \"yhat_upper\": 8.997051969809057, \"fact\": 8.792889390472723, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:41:00\", \"yhat\": 8.744860429561502, \"yhat_lower\": 8.38393151365433, \"yhat_upper\": 9.105789345468674, \"fact\": 8.787700796349098, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:42:00\", \"yhat\": 8.744844512913447, \"yhat_lower\": 8.30036839845512, \"yhat_upper\": 9.189320627371774, \"fact\": 8.865140236693664, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:43:00\", \"yhat\": 8.744841652841455, \"yhat_lower\": 8.23010673642605, \"yhat_upper\": 9.25957656925686, \"fact\": 8.873378150594053, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:44:00\", \"yhat\": 8.74484113891341, \"yhat_lower\": 8.168331215749516, \"yhat_upper\": 9.321351062077303, \"fact\": 9.0222393846978, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:45:00\", \"yhat\": 9.026010895737457, \"yhat_lower\": 8.774193562332592, \"yhat_upper\": 9.277828229142322, \"fact\": 9.065340509014483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:46:00\", \"yhat\": 9.026796644448252, \"yhat_lower\": 8.666257278681334, \"yhat_upper\": 9.38733601021517, \"fact\": 9.08761005037332, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:47:00\", \"yhat\": 9.026960345688956, \"yhat_lower\": 8.582849633651739, \"yhat_upper\": 9.471071057726173, \"fact\": 9.21261808729404, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:48:00\", \"yhat\": 9.026994450862581, \"yhat_lower\": 8.512582340607306, \"yhat_upper\": 9.541406561117856, \"fact\": 9.171105600168334, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:49:00\", \"yhat\": 9.027001556263023, \"yhat_lower\": 8.450777243492661, \"yhat_upper\": 9.603225869033386, \"fact\": 9.2291796823891, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:50:00\", \"yhat\": 9.230566387839685, \"yhat_lower\": 8.979153553287873, \"yhat_upper\": 9.481979222391498, \"fact\": 9.306666947502116, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:51:00\", \"yhat\": 9.230942816102184, \"yhat_lower\": 8.870968476736696, \"yhat_upper\": 9.590917155467672, \"fact\": 9.262624362293195, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:52:00\", \"yhat\": 9.231044999472667, \"yhat_lower\": 8.787393052521605, \"yhat_upper\": 9.67469694642373, \"fact\": 9.242218868074156, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:53:00\", \"yhat\": 9.231072737669406, \"yhat_lower\": 8.716961485970835, \"yhat_upper\": 9.745183989367977, \"fact\": 9.33795232275775, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:54:00\", \"yhat\": 9.23108026734429, \"yhat_lower\": 8.655008801490633, \"yhat_upper\": 9.807151733197946, \"fact\": 9.323311197520256, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:55:00\", \"yhat\": 9.323541233218217, \"yhat_lower\": 9.072606227893077, \"yhat_upper\": 9.574476238543356, \"fact\": 9.224541361617664, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:56:00\", \"yhat\": 9.32360950944532, \"yhat_lower\": 8.964446235838071, \"yhat_upper\": 9.68277278305257, \"fact\": 9.235951852873002, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:57:00\", \"yhat\": 9.323629774313899, \"yhat_lower\": 8.880966473090659, \"yhat_upper\": 9.766293075537138, \"fact\": 9.183230028411051, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:58:00\", \"yhat\": 9.323635789070659, \"yhat_lower\": 8.81062660425546, \"yhat_upper\": 9.836644973885857, \"fact\": 9.303308572775062, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:59:00\", \"yhat\": 9.323637574293135, \"yhat_lower\": 8.748756886960502, \"yhat_upper\": 9.89851826162577, \"fact\": 9.41516862839868, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:00:00\", \"yhat\": 9.41858998307072, \"yhat_lower\": 9.167787202888528, \"yhat_upper\": 9.669392763252914, \"fact\": 9.344349304080247, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:01:00\", \"yhat\": 9.419512424886916, \"yhat_lower\": 9.060397287501697, \"yhat_upper\": 9.778627562272135, \"fact\": 9.418666704403686, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:02:00\", \"yhat\": 9.41976112722439, \"yhat_lower\": 8.977165992843851, \"yhat_upper\": 9.86235626160493, \"fact\": 9.318795523294629, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:03:00\", \"yhat\": 9.419828180616355, \"yhat_lower\": 8.906942778294876, \"yhat_upper\": 9.932713582937833, \"fact\": 9.361514185397724, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:04:00\", \"yhat\": 9.419846259084855, \"yhat_lower\": 8.845150134650629, \"yhat_upper\": 9.99454238351908, \"fact\": 9.455447864087226, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:05:00\", \"yhat\": 9.457644272408771, \"yhat_lower\": 9.207078435092633, \"yhat_upper\": 9.70821010972491, \"fact\": 9.401919535507847, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:06:00\", \"yhat\": 9.458264958988194, \"yhat_lower\": 9.099976514728732, \"yhat_upper\": 9.816553403247655, \"fact\": 9.38713489217632, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:07:00\", \"yhat\": 9.458440359812391, \"yhat_lower\": 9.01712244065381, \"yhat_upper\": 9.899758278970971, \"fact\": 9.455945295107508, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:08:00\", \"yhat\": 9.458489926614943, \"yhat_lower\": 8.947236214113317, \"yhat_upper\": 9.969743639116569, \"fact\": 9.609159720517681, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:09:00\", \"yhat\": 9.458503933777832, \"yhat_lower\": 8.885735480856829, \"yhat_upper\": 10.031272386698836, \"fact\": 9.614996053596242, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:10:00\", \"yhat\": 9.616088217243465, \"yhat_lower\": 9.365781117766849, \"yhat_upper\": 9.866395316720082, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:11:00\", \"yhat\": 9.616387060292897, \"yhat_lower\": 9.25837327373383, \"yhat_upper\": 9.974400846851966, \"fact\": 9.556691781795077, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:12:00\", \"yhat\": 9.616468831159764, \"yhat_lower\": 9.175459036775093, \"yhat_upper\": 10.057478625544436, \"fact\": 9.643000959964645, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:13:00\", \"yhat\": 9.6164912056961, \"yhat_lower\": 9.105586202743877, \"yhat_upper\": 10.127396208648323, \"fact\": 9.718788895128835, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:14:00\", \"yhat\": 9.616497327923923, \"yhat_lower\": 9.044118031182697, \"yhat_upper\": 10.18887662466515, \"fact\": 9.638302318559198, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:15:00\", \"yhat\": 9.637248300556097, \"yhat_lower\": 9.387190567175672, \"yhat_upper\": 9.887306033936522, \"fact\": 9.86400121471953, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:16:00\", \"yhat\": 9.63691171049266, \"yhat_lower\": 9.279604973051503, \"yhat_upper\": 9.994218447933816, \"fact\": 9.832149494497711, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:17:00\", \"yhat\": 9.636804223836387, \"yhat_lower\": 9.196744937096742, \"yhat_upper\": 10.076863510576032, \"fact\": 9.8378481484009, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:18:00\", \"yhat\": 9.636769899052231, \"yhat_lower\": 9.126958969694, \"yhat_upper\": 10.146580828410462, \"fact\": 9.86632383278163, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:19:00\", \"yhat\": 9.636758937777145, \"yhat_lower\": 9.065576979596988, \"yhat_upper\": 10.207940895957302, \"fact\": 9.892267601353337, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:20:00\", \"yhat\": 9.892984523085198, \"yhat_lower\": 9.64280468249078, \"yhat_upper\": 10.143164363679617, \"fact\": 9.931774604936024, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:21:00\", \"yhat\": 9.89328320847738, \"yhat_lower\": 9.536409963818917, \"yhat_upper\": 10.250156453135842, \"fact\": 9.954188808547201, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:22:00\", \"yhat\": 9.893407647393843, \"yhat_lower\": 9.454037955598052, \"yhat_upper\": 10.332777339189635, \"fact\": 9.817695310369409, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:23:00\", \"yhat\": 9.893459491388683, \"yhat_lower\": 9.384423560043343, \"yhat_upper\": 10.402495422734022, \"fact\": 9.84172254699343, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:24:00\", \"yhat\": 9.89348109073941, \"yhat_lower\": 9.323086478592941, \"yhat_upper\": 10.463875702885879, \"fact\": 9.80607724404463, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:25:00\", \"yhat\": 9.805327324638462, \"yhat_lower\": 9.55552968404251, \"yhat_upper\": 10.055124965234414, \"fact\": 9.634992469023846, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:26:00\", \"yhat\": 9.805017266543171, \"yhat_lower\": 9.448781795960567, \"yhat_upper\": 10.161252737125775, \"fact\": 9.719664071742129, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:27:00\", \"yhat\": 9.804889071404247, \"yhat_lower\": 9.366380800741975, \"yhat_upper\": 10.243397342066519, \"fact\": 9.803939082783222, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:28:00\", \"yhat\": 9.804836068454499, \"yhat_lower\": 9.296858438211332, \"yhat_upper\": 10.312813698697665, \"fact\": 9.800414529471565, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:29:00\", \"yhat\": 9.804814154108092, \"yhat_lower\": 9.235652792535912, \"yhat_upper\": 10.373975515680272, \"fact\": 9.82701899851565, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:30:00\", \"yhat\": 9.827654759040891, \"yhat_lower\": 9.577891573116228, \"yhat_upper\": 10.077417944965555, \"fact\": 9.77933964253321, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:31:00\", \"yhat\": 9.827946976327457, \"yhat_lower\": 9.472019995620055, \"yhat_upper\": 10.183873957034859, \"fact\": 9.756520180732126, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:32:00\", \"yhat\": 9.828081289389024, \"yhat_lower\": 9.390041361512932, \"yhat_upper\": 10.266121217265116, \"fact\": 9.850925560836, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:33:00\", \"yhat\": 9.828143024266927, \"yhat_lower\": 9.320711972003341, \"yhat_upper\": 10.335574076530513, \"fact\": 9.804925591815215, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:34:00\", \"yhat\": 9.828171399728742, \"yhat_lower\": 9.259591128449685, \"yhat_upper\": 10.396751671007799, \"fact\": 9.619049334366524, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:35:00\", \"yhat\": 9.61612180040592, \"yhat_lower\": 9.36633592067755, \"yhat_upper\": 9.865907680134292, \"fact\": 9.600139673643671, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:36:00\", \"yhat\": 9.614903094693846, \"yhat_lower\": 9.25894126353854, \"yhat_upper\": 9.97086492584915, \"fact\": 9.654070612123258, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:37:00\", \"yhat\": 9.61439575861077, \"yhat_lower\": 9.176407479023059, \"yhat_upper\": 10.052384038198483, \"fact\": 9.81409008687884, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:38:00\", \"yhat\": 9.614184559222238, \"yhat_lower\": 9.106940102082241, \"yhat_upper\": 10.121429016362235, \"fact\": 9.86346342581928, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:39:00\", \"yhat\": 9.614096638841243, \"yhat_lower\": 9.045852646858195, \"yhat_upper\": 10.18234063082429, \"fact\": 9.857124185840512, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:40:00\", \"yhat\": 9.857475077784809, \"yhat_lower\": 9.60795088850332, \"yhat_upper\": 10.106999267066298, \"fact\": 9.983032579376141, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:41:00\", \"yhat\": 9.857575109623617, \"yhat_lower\": 9.5013942006526, \"yhat_upper\": 10.213756018594635, \"fact\": 10.037199180536911, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:42:00\", \"yhat\": 9.85760362657574, \"yhat_lower\": 9.419263111931338, \"yhat_upper\": 10.295944141220142, \"fact\": 9.993484385678066, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:43:00\", \"yhat\": 9.857611756152963, \"yhat_lower\": 9.350055790661001, \"yhat_upper\": 10.365167721644925, \"fact\": 10.0400027689603, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:44:00\", \"yhat\": 9.85761407372272, \"yhat_lower\": 9.289161080117132, \"yhat_upper\": 10.426067067328308, \"fact\": 10.034298117029037, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:45:00\", \"yhat\": 10.034449699916522, \"yhat_lower\": 9.78529274112155, \"yhat_upper\": 10.283606658711493, \"fact\": 10.076049094922666, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:46:00\", \"yhat\": 10.034502322873168, \"yhat_lower\": 9.678942052488342, \"yhat_upper\": 10.390062593257994, \"fact\": 10.0988034535548, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:47:00\", \"yhat\": 10.034520591264885, \"yhat_lower\": 9.596841801840691, \"yhat_upper\": 10.472199380689078, \"fact\": 10.03315333035482, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:48:00\", \"yhat\": 10.034526933252435, \"yhat_lower\": 9.527595265685223, \"yhat_upper\": 10.541458600819647, \"fact\": 9.989417587885512, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:49:00\", \"yhat\": 10.034529134913463, \"yhat_lower\": 9.466644341057519, \"yhat_upper\": 10.602413928769407, \"fact\": 10.142657199531792, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:50:00\", \"yhat\": 10.145073826929071, \"yhat_lower\": 9.896140273431905, \"yhat_upper\": 10.394007380426237, \"fact\": 10.255063743963055, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:51:00\", \"yhat\": 10.145823788958696, \"yhat_lower\": 9.7906304300729, \"yhat_upper\": 10.501017147844491, \"fact\": 10.289207345135177, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:52:00\", \"yhat\": 10.14605652779403, \"yhat_lower\": 9.708957366184052, \"yhat_upper\": 10.583155689404009, \"fact\": 10.290051522452643, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:53:00\", \"yhat\": 10.146128754604632, \"yhat_lower\": 9.63999961251967, \"yhat_upper\": 10.652257896689594, \"fact\": 10.208202234151164, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:54:00\", \"yhat\": 10.146151169051118, \"yhat_lower\": 9.579277844212216, \"yhat_upper\": 10.71302449389002, \"fact\": 10.20744863055363, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:55:00\", \"yhat\": 10.207058054530734, \"yhat_lower\": 9.958545278187964, \"yhat_upper\": 10.455570830873503, \"fact\": 10.102381099087888, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:56:00\", \"yhat\": 10.206960334886224, \"yhat_lower\": 9.851813759040972, \"yhat_upper\": 10.562106910731476, \"fact\": 10.187155935748017, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:57:00\", \"yhat\": 10.206935886050752, \"yhat_lower\": 9.769715668515532, \"yhat_upper\": 10.644156103585972, \"fact\": 10.126046394947553, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:58:00\", \"yhat\": 10.206929769107132, \"yhat_lower\": 9.700609624208168, \"yhat_upper\": 10.713249914006097, \"fact\": 10.077830439271654, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:59:00\", \"yhat\": 10.206928238686622, \"yhat_lower\": 9.639830133842604, \"yhat_upper\": 10.77402634353064, \"fact\": 10.112502220252225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:00:00\", \"yhat\": 10.112839948161906, \"yhat_lower\": 9.864632499941695, \"yhat_upper\": 10.361047396382116, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:01:00\", \"yhat\": 10.112939587682847, \"yhat_lower\": 9.75858311078441, \"yhat_upper\": 10.467296064581284, \"fact\": 10.2942943861814, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:02:00\", \"yhat\": 10.112968984229147, \"yhat_lower\": 9.67681166152166, \"yhat_upper\": 10.549126306936634, \"fact\": 10.205446118651967, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:03:00\", \"yhat\": 10.112977657062237, \"yhat_lower\": 9.607897383024762, \"yhat_upper\": 10.618057931099711, \"fact\": 10.271409386655742, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:04:00\", \"yhat\": 10.112980215799343, \"yhat_lower\": 9.547259049455294, \"yhat_upper\": 10.678701382143393, \"fact\": 10.256522349950478, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:05:00\", \"yhat\": 10.256539109565086, \"yhat_lower\": 10.008445460677523, \"yhat_upper\": 10.504632758452649, \"fact\": 10.17902731704118, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:06:00\", \"yhat\": 10.256544720739209, \"yhat_lower\": 9.902670150689213, \"yhat_upper\": 10.610419290789205, \"fact\": 10.223078359670582, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:07:00\", \"yhat\": 10.256546599378769, \"yhat_lower\": 9.82108831154804, \"yhat_upper\": 10.692004887209498, \"fact\": 10.289101894089889, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:08:00\", \"yhat\": 10.256547228353476, \"yhat_lower\": 9.752302667167239, \"yhat_upper\": 10.760791789539713, \"fact\": 10.452816223055665, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:09:00\", \"yhat\": 10.256547438936277, \"yhat_lower\": 9.69176222237537, \"yhat_upper\": 10.821332655497184, \"fact\": 10.530367461184968, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:10:00\", \"yhat\": 10.533023109523674, \"yhat_lower\": 10.284970642958163, \"yhat_upper\": 10.781075576089185, \"fact\": 10.515200566630206, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:11:00\", \"yhat\": 10.533857799882155, \"yhat_lower\": 10.179511421243697, \"yhat_upper\": 10.888204178520612, \"fact\": 10.462488799078955, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:12:00\", \"yhat\": 10.534120149374889, \"yhat_lower\": 10.097784089113022, \"yhat_upper\": 10.970456209636756, \"fact\": 10.536617371571872, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:13:00\", \"yhat\": 10.5342026078047, \"yhat_lower\": 10.028763874849723, \"yhat_upper\": 11.039641340759676, \"fact\": 10.582085913026225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:14:00\", \"yhat\": 10.534228525112852, \"yhat_lower\": 9.967989555307105, \"yhat_upper\": 11.100467494918599, \"fact\": 10.453705254361472, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:15:00\", \"yhat\": 10.451433203469724, \"yhat_lower\": 10.203665884290773, \"yhat_upper\": 10.699200522648676, \"fact\": 10.481826344423022, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:16:00\", \"yhat\": 10.450853906864433, \"yhat_lower\": 10.096956458519736, \"yhat_upper\": 10.80475135520913, \"fact\": 10.353428837573519, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:17:00\", \"yhat\": 10.450706205702403, \"yhat_lower\": 10.015120727142008, \"yhat_upper\": 10.886291684262797, \"fact\": 10.342528897524867, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:18:00\", \"yhat\": 10.450668546870872, \"yhat_lower\": 9.946298824207995, \"yhat_upper\": 10.95503826953375, \"fact\": 10.289505252298003, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:19:00\", \"yhat\": 10.450658945134686, \"yhat_lower\": 9.885783324112914, \"yhat_upper\": 11.015534566156457, \"fact\": 10.233404516009793, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:20:00\", \"yhat\": 10.231924669263208, \"yhat_lower\": 9.984492058815759, \"yhat_upper\": 10.479357279710657, \"fact\": 10.398350843814256, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:21:00\", \"yhat\": 10.23140989269186, \"yhat_lower\": 9.878211519398185, \"yhat_upper\": 10.584608265985533, \"fact\": 10.413367861232464, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:22:00\", \"yhat\": 10.231230823528772, \"yhat_lower\": 9.796390075888539, \"yhat_upper\": 10.666071571169006, \"fact\": 10.465737097515472, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:23:00\", \"yhat\": 10.231168532882783, \"yhat_lower\": 9.727474929217532, \"yhat_upper\": 10.734862136548035, \"fact\": 10.540956107018431, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:24:00\", \"yhat\": 10.231146864581493, \"yhat_lower\": 9.666853730741044, \"yhat_upper\": 10.795439998421942, \"fact\": 10.419642110204657, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:25:00\", \"yhat\": 10.418151428056591, \"yhat_lower\": 10.170641129619149, \"yhat_upper\": 10.665661726494033, \"fact\": 10.38830467957498, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:26:00\", \"yhat\": 10.417627868553792, \"yhat_lower\": 10.064619316866414, \"yhat_upper\": 10.77063642024117, \"fact\": 10.337534746596601, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:27:00\", \"yhat\": 10.417443983241068, \"yhat_lower\": 9.983034108567642, \"yhat_upper\": 10.851853857914493, \"fact\": 10.446651275126646, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:28:00\", \"yhat\": 10.41737939878017, \"yhat_lower\": 9.91431787054973, \"yhat_upper\": 10.92044092701061, \"fact\": 10.514004036753205, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:29:00\", \"yhat\": 10.417356715334018, \"yhat_lower\": 9.853865782653541, \"yhat_upper\": 10.980847648014494, \"fact\": 10.507311180202013, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:30:00\", \"yhat\": 10.507657909656631, \"yhat_lower\": 10.260541928032278, \"yhat_upper\": 10.754773891280983, \"fact\": 10.600130615972407, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:31:00\", \"yhat\": 10.507759950733425, \"yhat_lower\": 10.155045861978685, \"yhat_upper\": 10.860474039488164, \"fact\": 10.608687106522943, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:32:00\", \"yhat\": 10.507789981009811, \"yhat_lower\": 10.073709943885106, \"yhat_upper\": 10.941870018134516, \"fact\": 10.484335112185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:33:00\", \"yhat\": 10.50779881879875, \"yhat_lower\": 10.005162021055453, \"yhat_upper\": 11.010435616542049, \"fact\": 10.621271569245923, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:34:00\", \"yhat\": 10.507801419724307, \"yhat_lower\": 9.94484409698481, \"yhat_upper\": 11.070758742463806, \"fact\": 10.639575926010757, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:35:00\", \"yhat\": 10.640380560812297, \"yhat_lower\": 10.393288314828384, \"yhat_upper\": 10.88747280679621, \"fact\": 10.596954129260547, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:36:00\", \"yhat\": 10.640651148783938, \"yhat_lower\": 10.288429189364287, \"yhat_upper\": 10.99287310820359, \"fact\": 10.62736816641365, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:37:00\", \"yhat\": 10.640742143916459, \"yhat_lower\": 10.207465002565757, \"yhat_upper\": 11.07401928526716, \"fact\": 10.668971329410926, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:38:00\", \"yhat\": 10.640772744368105, \"yhat_lower\": 10.139153759828018, \"yhat_upper\": 11.142391728908192, \"fact\": 10.960130410890418, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:39:00\", \"yhat\": 10.64078303489261, \"yhat_lower\": 10.079009536890078, \"yhat_upper\": 11.202556532895143, \"fact\": 11.0, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:40:00\", \"yhat\": 11.002449717124964, \"yhat_lower\": 10.754723829064067, \"yhat_upper\": 11.250175605185861, \"fact\": 10.944748604963694, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:41:00\", \"yhat\": 11.003232704244631, \"yhat_lower\": 10.6496269858613, \"yhat_upper\": 11.356838422627963, \"fact\": 10.762400197925471, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:42:00\", \"yhat\": 11.003482965314907, \"yhat_lower\": 10.568224188879329, \"yhat_upper\": 11.438741741750485, \"fact\": 10.633397214168852, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:43:00\", \"yhat\": 11.00356295462983, \"yhat_lower\": 10.499477434149867, \"yhat_upper\": 11.507648475109793, \"fact\": 10.508366912453496, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:44:00\", \"yhat\": 11.003588521093262, \"yhat_lower\": 10.438937616308948, \"yhat_upper\": 11.568239425877575, \"fact\": 10.747813043137848, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:45:00\", \"yhat\": 10.753023652141298, \"yhat_lower\": 10.504176407430581, \"yhat_upper\": 11.001870896852015, \"fact\": 10.616517623097478, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:46:00\", \"yhat\": 10.753580208279164, \"yhat_lower\": 10.397611751794214, \"yhat_upper\": 11.109548664764114, \"fact\": 10.519134892650595, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:47:00\", \"yhat\": 10.753639655214137, \"yhat_lower\": 10.315676380457917, \"yhat_upper\": 11.191602929970356, \"fact\": 10.505485347067411, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:48:00\", \"yhat\": 10.753646004866647, \"yhat_lower\": 10.246750314296527, \"yhat_upper\": 11.260541695436768, \"fact\": 10.370020036709334, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:49:00\", \"yhat\": 10.753646683086425, \"yhat_lower\": 10.186127352451907, \"yhat_upper\": 11.321166013720942, \"fact\": 10.252602215750233, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:50:00\", \"yhat\": 10.249528990426677, \"yhat_lower\": 10.000494500134103, \"yhat_upper\": 10.498563480719252, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:51:00\", \"yhat\": 10.24893105049125, \"yhat_lower\": 9.892907117973756, \"yhat_upper\": 10.604954983008742, \"fact\": 10.239477262630865, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:52:00\", \"yhat\": 10.248814712725958, \"yhat_lower\": 9.810610147510738, \"yhat_upper\": 10.687019277941177, \"fact\": 10.27736285358397, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:53:00\", \"yhat\": 10.248792077550029, \"yhat_lower\": 9.741448155615867, \"yhat_upper\": 10.75613599948419, \"fact\": 10.253281566040584, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:54:00\", \"yhat\": 10.248787673552856, \"yhat_lower\": 9.680639106585334, \"yhat_upper\": 10.816936240520379, \"fact\": 10.045963893343206, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:55:00\", \"yhat\": 10.04141186901753, \"yhat_lower\": 9.792272756278606, \"yhat_upper\": 10.290550981756454, \"fact\": 9.974512039077938, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:56:00\", \"yhat\": 10.040566033296491, \"yhat_lower\": 9.684396394529312, \"yhat_upper\": 10.39673567206367, \"fact\": 10.041043064809825, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:57:00\", \"yhat\": 10.040408864086531, \"yhat_lower\": 9.60205461424478, \"yhat_upper\": 10.478763113928283, \"fact\": 10.047700947811453, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:58:00\", \"yhat\": 10.040379659644174, \"yhat_lower\": 9.53288849637576, \"yhat_upper\": 10.547870822912587, \"fact\": 10.004137092919867, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:59:00\", \"yhat\": 10.040374233012242, \"yhat_lower\": 9.472080462426588, \"yhat_upper\": 10.608668003597897, \"fact\": 9.966989635494258, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:00:00\", \"yhat\": 9.966018942157637, \"yhat_lower\": 9.717376828463316, \"yhat_upper\": 10.214661055851959, \"fact\": 9.988342774645961, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:01:00\", \"yhat\": 9.965908889371159, \"yhat_lower\": 9.61008468120122, \"yhat_upper\": 10.321733097541097, \"fact\": 9.964268279658732, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:02:00\", \"yhat\": 9.965896412087805, \"yhat_lower\": 9.52801585505357, \"yhat_upper\": 10.40377696912204, \"fact\": 9.838689442516403, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:03:00\", \"yhat\": 9.965894997470285, \"yhat_lower\": 9.459035486820877, \"yhat_upper\": 10.472754508119692, \"fact\": 9.773522635065854, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:04:00\", \"yhat\": 9.965894837087397, \"yhat_lower\": 9.398375560441725, \"yhat_upper\": 10.53341411373307, \"fact\": 9.868386927448714, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:05:00\", \"yhat\": 9.870660500490633, \"yhat_lower\": 9.622259281356689, \"yhat_upper\": 10.119061719624577, \"fact\": 9.830469543424808, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:06:00\", \"yhat\": 9.870796392862808, \"yhat_lower\": 9.515156610877787, \"yhat_upper\": 10.226436174847828, \"fact\": 9.788865576129703, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:07:00\", \"yhat\": 9.870804515204371, \"yhat_lower\": 9.433263428358591, \"yhat_upper\": 10.308345602050151, \"fact\": 9.914847367291713, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:08:00\", \"yhat\": 9.870805000679983, \"yhat_lower\": 9.364429764205195, \"yhat_upper\": 10.377180237154771, \"fact\": 9.807562371531388, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:09:00\", \"yhat\": 9.870805029697054, \"yhat_lower\": 9.3038921415177, \"yhat_upper\": 10.437717917876409, \"fact\": 9.670822674017861, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:10:00\", \"yhat\": 9.667596458569419, \"yhat_lower\": 9.419155140501758, \"yhat_upper\": 9.91603777663708, \"fact\": 9.616577898394782, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:11:00\", \"yhat\": 9.667655573059132, \"yhat_lower\": 9.311984154344719, \"yhat_upper\": 10.023326991773546, \"fact\": 9.573703532341133, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:12:00\", \"yhat\": 9.66765448989437, \"yhat_lower\": 9.230362175366896, \"yhat_upper\": 10.104946804421843, \"fact\": 9.467645765284308, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:13:00\", \"yhat\": 9.66765450974138, \"yhat_lower\": 9.161741457375207, \"yhat_upper\": 10.173567562107554, \"fact\": 9.486973369882458, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:14:00\", \"yhat\": 9.667654509377721, \"yhat_lower\": 9.101375915622476, \"yhat_upper\": 10.233933103132966, \"fact\": 9.442311708770832, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:15:00\", \"yhat\": 9.44122218833253, \"yhat_lower\": 9.193177968471263, \"yhat_upper\": 9.689266408193797, \"fact\": 9.395669890818453, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:16:00\", \"yhat\": 9.44113286559513, \"yhat_lower\": 9.085966931506842, \"yhat_upper\": 9.796298799683417, \"fact\": 9.456601403941736, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:17:00\", \"yhat\": 9.441125542601327, \"yhat_lower\": 9.004071181073382, \"yhat_upper\": 9.878179904129272, \"fact\": 9.564992092172044, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:18:00\", \"yhat\": 9.441124942236405, \"yhat_lower\": 8.93524821565893, \"yhat_upper\": 9.94700166881388, \"fact\": 9.63165317584744, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:19:00\", \"yhat\": 9.441124893016365, \"yhat_lower\": 8.874725971869882, \"yhat_upper\": 10.007523814162848, \"fact\": 9.578406412111097, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:20:00\", \"yhat\": 9.577010257908446, \"yhat_lower\": 9.329278857373401, \"yhat_upper\": 9.824741658443491, \"fact\": 9.46403283204649, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:21:00\", \"yhat\": 9.576968584288453, \"yhat_lower\": 9.221979994094195, \"yhat_upper\": 9.931957174482712, \"fact\": 9.216432465535892, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:22:00\", \"yhat\": 9.576967340378145, \"yhat_lower\": 9.140204222374976, \"yhat_upper\": 10.013730458381314, \"fact\": 9.323236419089412, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:23:00\", \"yhat\": 9.576967303248832, \"yhat_lower\": 9.071487232808513, \"yhat_upper\": 10.082447373689151, \"fact\": 9.391465325298743, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:24:00\", \"yhat\": 9.576967302140565, \"yhat_lower\": 9.011053642401437, \"yhat_upper\": 10.142880961879692, \"fact\": 9.50366014614707, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:25:00\", \"yhat\": 9.506830532297522, \"yhat_lower\": 9.258337076208072, \"yhat_upper\": 9.755323988386973, \"fact\": 9.592600239141852, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:26:00\", \"yhat\": 9.50678636797026, \"yhat_lower\": 9.15023908783813, \"yhat_upper\": 9.86333364810239, \"fact\": 9.355788749450348, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:27:00\", \"yhat\": 9.506786983191155, \"yhat_lower\": 9.068093834829146, \"yhat_upper\": 9.945480131553165, \"fact\": 9.222799348520082, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:28:00\", \"yhat\": 9.506786974620963, \"yhat_lower\": 8.999068442700635, \"yhat_upper\": 10.014505506541292, \"fact\": 9.034232188045483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:29:00\", \"yhat\": 9.506786974740349, \"yhat_lower\": 8.93836413305676, \"yhat_upper\": 10.075209816423937, \"fact\": 8.988900736784247, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:30:00\", \"yhat\": 8.9873429545356, \"yhat_lower\": 8.737903393522299, \"yhat_upper\": 9.236782515548903, \"fact\": 8.940239461563786, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:31:00\", \"yhat\": 8.987286699369655, \"yhat_lower\": 8.628465373826847, \"yhat_upper\": 9.346108024912462, \"fact\": 8.867726672403123, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:32:00\", \"yhat\": 8.98728466786384, \"yhat_lower\": 8.545194369056874, \"yhat_upper\": 9.429374966670805, \"fact\": 8.750332311139447, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:33:00\", \"yhat\": 8.987284594501405, \"yhat_lower\": 8.475287869821173, \"yhat_upper\": 9.499281319181637, \"fact\": 8.749543232452918, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:34:00\", \"yhat\": 8.987284591852116, \"yhat_lower\": 8.413840900963045, \"yhat_upper\": 9.560728282741188, \"fact\": 8.714350103767188, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:35:00\", \"yhat\": 8.71309938082775, \"yhat_lower\": 8.46400152406582, \"yhat_upper\": 8.96219723758968, \"fact\": 8.70989589254306, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:36:00\", \"yhat\": 8.712982433292986, \"yhat_lower\": 8.354472945290455, \"yhat_upper\": 9.071491921295516, \"fact\": 8.93646758528286, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:37:00\", \"yhat\": 8.712971498236582, \"yhat_lower\": 8.270896445100064, \"yhat_upper\": 9.1550465513731, \"fact\": 9.012239346556045, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:38:00\", \"yhat\": 8.71297047576562, \"yhat_lower\": 8.200748670193134, \"yhat_upper\": 9.225192281338105, \"fact\": 9.039800746733981, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:39:00\", \"yhat\": 8.712970380160545, \"yhat_lower\": 8.139110031273379, \"yhat_upper\": 9.286830729047711, \"fact\": 8.977564792960163, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:40:00\", \"yhat\": 8.97530631701115, \"yhat_lower\": 8.726024972419532, \"yhat_upper\": 9.224587661602767, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:41:00\", \"yhat\": 8.975146983066967, \"yhat_lower\": 8.61604763877353, \"yhat_upper\": 9.334246327360404, \"fact\": 8.798698884079773, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:42:00\", \"yhat\": 8.97513574216543, \"yhat_lower\": 8.532304690128239, \"yhat_upper\": 9.41796679420262, \"fact\": 8.757817163308653, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:43:00\", \"yhat\": 8.975134949127462, \"yhat_lower\": 8.462036451662238, \"yhat_upper\": 9.488233446592686, \"fact\": 8.739247557388522, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:44:00\", \"yhat\": 8.975134893179172, \"yhat_lower\": 8.400293637216713, \"yhat_upper\": 9.549976149141632, \"fact\": 8.70356646824997, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:45:00\", \"yhat\": 8.702234387513121, \"yhat_lower\": 8.453219710059951, \"yhat_upper\": 8.95124906496629, \"fact\": 8.782616489057622, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:46:00\", \"yhat\": 8.702291586140268, \"yhat_lower\": 8.343246994978601, \"yhat_upper\": 9.061336177301934, \"fact\": 8.479925780652454, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:47:00\", \"yhat\": 8.702289130070708, \"yhat_lower\": 8.260018108495998, \"yhat_upper\": 9.144560151645418, \"fact\": 8.273358954380925, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:48:00\", \"yhat\": 8.702289235532639, \"yhat_lower\": 8.190133517405952, \"yhat_upper\": 9.214444953659326, \"fact\": 8.447199865827617, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:49:00\", \"yhat\": 8.702289231004176, \"yhat_lower\": 8.128701479841103, \"yhat_upper\": 9.275876982167249, \"fact\": 8.523194953304365, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:50:00\", \"yhat\": 8.525177179581291, \"yhat_lower\": 8.274455920180683, \"yhat_upper\": 8.7758984389819, \"fact\": 8.530052782649555, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:51:00\", \"yhat\": 8.524988491194868, \"yhat_lower\": 8.163243232052801, \"yhat_upper\": 8.886733750336935, \"fact\": 8.396411307804495, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:52:00\", \"yhat\": 8.5250064524678, \"yhat_lower\": 8.079629754584783, \"yhat_upper\": 8.970383150350816, \"fact\": 8.314908428588723, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:53:00\", \"yhat\": 8.52500474273181, \"yhat_lower\": 8.009341604555459, \"yhat_upper\": 9.04066788090816, \"fact\": 8.244009975240218, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:54:00\", \"yhat\": 8.52500490548181, \"yhat_lower\": 7.947551844132463, \"yhat_upper\": 9.102457966831155, \"fact\": 8.180232114481395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:55:00\", \"yhat\": 8.177851481912983, \"yhat_lower\": 7.927338642087731, \"yhat_upper\": 8.428364321738234, \"fact\": 7.997073407217911, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:56:00\", \"yhat\": 8.178025809157027, \"yhat_lower\": 7.816203313556452, \"yhat_upper\": 8.539848304757603, \"fact\": 7.997788244170042, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:57:00\", \"yhat\": 8.17801304364738, \"yhat_lower\": 7.732287565953062, \"yhat_upper\": 8.6237385213417, \"fact\": 8.027379343471765, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:58:00\", \"yhat\": 8.178013978430911, \"yhat_lower\": 7.66181986206173, \"yhat_upper\": 8.694208094800093, \"fact\": 7.891617442415619, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:59:00\", \"yhat\": 8.178013909979258, \"yhat_lower\": 7.599879521588968, \"yhat_upper\": 8.756148298369547, \"fact\": 7.993391171167953, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:00:00\", \"yhat\": 7.998191386002311, \"yhat_lower\": 7.747442178929054, \"yhat_upper\": 8.248940593075568, \"fact\": 7.839794824705354, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:01:00\", \"yhat\": 7.997879276145051, \"yhat_lower\": 7.635887285235066, \"yhat_upper\": 8.359871267055036, \"fact\": 7.730599469753859, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:02:00\", \"yhat\": 7.997899569520735, \"yhat_lower\": 7.551972521576454, \"yhat_upper\": 8.443826617465016, \"fact\": 7.6509477022655386, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:03:00\", \"yhat\": 7.997898250045918, \"yhat_lower\": 7.481481352421691, \"yhat_upper\": 8.514315147670144, \"fact\": 7.6005718066277375, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:04:00\", \"yhat\": 7.997898335838141, \"yhat_lower\": 7.419520939210173, \"yhat_upper\": 8.576275732466108, \"fact\": 7.616974853712176, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:05:00\", \"yhat\": 7.617759735970455, \"yhat_lower\": 7.367069397810061, \"yhat_upper\": 7.868450074130848, \"fact\": 7.452726173004684, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:06:00\", \"yhat\": 7.617756450656629, \"yhat_lower\": 7.255661234840034, \"yhat_upper\": 7.979851666473225, \"fact\": 7.4873100141103475, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:07:00\", \"yhat\": 7.617756464408102, \"yhat_lower\": 7.171262249539907, \"yhat_upper\": 8.064250679276297, \"fact\": 7.355716834977905, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:08:00\", \"yhat\": 7.617756464350542, \"yhat_lower\": 7.100454502782307, \"yhat_upper\": 8.135058425918777, \"fact\": 7.304617707670855, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:09:00\", \"yhat\": 7.617756464350783, \"yhat_lower\": 7.038234631657517, \"yhat_upper\": 8.197278297044049, \"fact\": 7.489866921022014, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:10:00\", \"yhat\": 7.497407115272219, \"yhat_lower\": 7.246233501575262, \"yhat_upper\": 7.748580728969176, \"fact\": 7.457128971331552, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:11:00\", \"yhat\": 7.497434203651614, \"yhat_lower\": 7.134986811930751, \"yhat_upper\": 7.859881595372477, \"fact\": 7.49124494359832, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:12:00\", \"yhat\": 7.4974343009674485, \"yhat_lower\": 7.05059309781191, \"yhat_upper\": 7.944275504122987, \"fact\": 7.746174323894706, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:13:00\", \"yhat\": 7.497434301317059, \"yhat_lower\": 6.979779900920512, \"yhat_upper\": 8.015088701713605, \"fact\": 7.728164560761447, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:14:00\", \"yhat\": 7.4974343013183145, \"yhat_lower\": 6.917550609611226, \"yhat_upper\": 8.077317993025403, \"fact\": 7.57497190780261, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:15:00\", \"yhat\": 7.569166103804073, \"yhat_lower\": 7.317435117697556, \"yhat_upper\": 7.82089708991059, \"fact\": 7.629350721280201, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:16:00\", \"yhat\": 7.569802525660964, \"yhat_lower\": 7.2066005957845, \"yhat_upper\": 7.933004455537428, \"fact\": 7.670839399995044, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:17:00\", \"yhat\": 7.569732762234566, \"yhat_lower\": 7.122647542703057, \"yhat_upper\": 8.016817981766076, \"fact\": 7.8020911978599985, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:18:00\", \"yhat\": 7.569740409576671, \"yhat_lower\": 7.052132506340897, \"yhat_upper\": 8.087348312812445, \"fact\": 7.688201610108968, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:19:00\", \"yhat\": 7.569739571288698, \"yhat_lower\": 6.99013301459613, \"yhat_upper\": 8.149346127981268, \"fact\": 7.491134163279598, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:20:00\", \"yhat\": 7.49399729718513, \"yhat_lower\": 7.2430228531460195, \"yhat_upper\": 7.744971741224241, \"fact\": 7.541546760013012, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:21:00\", \"yhat\": 7.491215997489166, \"yhat_lower\": 7.131984413800495, \"yhat_upper\": 7.850447581177837, \"fact\": 7.322022918010769, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:22:00\", \"yhat\": 7.493917801964262, \"yhat_lower\": 7.055600226737752, \"yhat_upper\": 7.932235377190771, \"fact\": 7.235580785625353, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:23:00\", \"yhat\": 7.491293220574403, \"yhat_lower\": 6.983262477196419, \"yhat_upper\": 7.999323963952387, \"fact\": 7.270589900870376, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:24:00\", \"yhat\": 7.493842786072384, \"yhat_lower\": 6.927051679030923, \"yhat_upper\": 8.060633893113845, \"fact\": 7.166069908720111, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:25:00\", \"yhat\": 7.161707794897096, \"yhat_lower\": 6.90934625121356, \"yhat_upper\": 7.414069338580632, \"fact\": 7.084649033319625, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:26:00\", \"yhat\": 7.162216050773891, \"yhat_lower\": 6.798255200110867, \"yhat_upper\": 7.526176901436915, \"fact\": 6.953837567532185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:27:00\", \"yhat\": 7.162156830852821, \"yhat_lower\": 6.7142227533336225, \"yhat_upper\": 7.610090908372019, \"fact\": 6.9788882663663205, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:28:00\", \"yhat\": 7.162163730918736, \"yhat_lower\": 6.643615198702406, \"yhat_upper\": 7.6807122631350655, \"fact\": 7.166048798085546, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:29:00\", \"yhat\": 7.162162926950936, \"yhat_lower\": 6.581532200234819, \"yhat_upper\": 7.742793653667053, \"fact\": 7.397644550791485, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:30:00\", \"yhat\": 7.406943270228067, \"yhat_lower\": 7.15383589316496, \"yhat_upper\": 7.660050647291174, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:31:00\", \"yhat\": 7.405949313812806, \"yhat_lower\": 7.039755535771491, \"yhat_upper\": 7.7721430918541206, \"fact\": 7.244896929081159, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:32:00\", \"yhat\": 7.4060555595558, \"yhat_lower\": 6.954966374894545, \"yhat_upper\": 7.857144744217055, \"fact\": 7.163683211087717, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:33:00\", \"yhat\": 7.406044202762151, \"yhat_lower\": 6.883612905722169, \"yhat_upper\": 7.928475499802133, \"fact\": 6.997342471102844, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:34:00\", \"yhat\": 7.406045416709725, \"yhat_lower\": 6.820912915723485, \"yhat_upper\": 7.991177917695965, \"fact\": 6.910312134996908, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:35:00\", \"yhat\": 6.905890360459139, \"yhat_lower\": 6.653573468113107, \"yhat_upper\": 7.1582072528051714, \"fact\": 6.920281767120731, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:36:00\", \"yhat\": 6.910181518066455, \"yhat_lower\": 6.549041348685839, \"yhat_upper\": 7.271321687447071, \"fact\": 7.005098218639339, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:37:00\", \"yhat\": 6.906017119033094, \"yhat_lower\": 6.465362549098307, \"yhat_upper\": 7.346671688967881, \"fact\": 7.073528376327899, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:38:00\", \"yhat\": 6.910058503875145, \"yhat_lower\": 6.399328462451917, \"yhat_upper\": 7.4207885452983735, \"fact\": 7.092071643143026, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:39:00\", \"yhat\": 6.906136499448884, \"yhat_lower\": 6.336325469273886, \"yhat_upper\": 7.475947529623882, \"fact\": 7.2003894873370955, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:40:00\", \"yhat\": 7.2067355773258965, \"yhat_lower\": 6.954710206056364, \"yhat_upper\": 7.458760948595429, \"fact\": 7.29287665449782, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:41:00\", \"yhat\": 7.200577522453847, \"yhat_lower\": 6.839813565421762, \"yhat_upper\": 7.561341479485932, \"fact\": 7.219469085171615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:42:00\", \"yhat\": 7.206553113703592, \"yhat_lower\": 6.766372744896895, \"yhat_upper\": 7.646733482510289, \"fact\": 7.191066675166035, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:43:00\", \"yhat\": 7.200754579665499, \"yhat_lower\": 6.690556591285611, \"yhat_upper\": 7.7109525680453865, \"fact\": 7.150610552736501, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:44:00\", \"yhat\": 7.206381302710246, \"yhat_lower\": 6.637174685582005, \"yhat_upper\": 7.775587919838486, \"fact\": 7.173786787560158, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:45:00\", \"yhat\": 7.1753581125262365, \"yhat_lower\": 6.922817727992856, \"yhat_upper\": 7.4278984970596165, \"fact\": 7.165902938765192, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:46:00\", \"yhat\": 7.175068918309635, \"yhat_lower\": 6.80910021880904, \"yhat_upper\": 7.54103761781023, \"fact\": 7.184761105184088, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:47:00\", \"yhat\": 7.175122143006449, \"yhat_lower\": 6.724686207158312, \"yhat_upper\": 7.625558078854587, \"fact\": 7.095968849846142, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:48:00\", \"yhat\": 7.175112347276838, \"yhat_lower\": 6.653507608159348, \"yhat_upper\": 7.696717086394328, \"fact\": 7.189463215776056, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:49:00\", \"yhat\": 7.175114150130106, \"yhat_lower\": 6.59098227615027, \"yhat_upper\": 7.759246024109943, \"fact\": 7.2416172252622815, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:50:00\", \"yhat\": 7.2428212046653195, \"yhat_lower\": 6.990628098786309, \"yhat_upper\": 7.49501431054433, \"fact\": 7.289594697210025, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:51:00\", \"yhat\": 7.242596179389664, \"yhat_lower\": 6.877242083286759, \"yhat_upper\": 7.607950275492569, \"fact\": 7.287819788227195, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:52:00\", \"yhat\": 7.242638236898751, \"yhat_lower\": 6.793005616434362, \"yhat_upper\": 7.692270857363139, \"fact\": 7.252759139403707, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:53:00\", \"yhat\": 7.242630376297023, \"yhat_lower\": 6.721978678552502, \"yhat_upper\": 7.763282074041544, \"fact\": 7.312186655332198, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:54:00\", \"yhat\": 7.2426318454534435, \"yhat_lower\": 6.659583635828087, \"yhat_upper\": 7.8256800550788, \"fact\": 7.417825510401695, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:55:00\", \"yhat\": 7.422223649962312, \"yhat_lower\": 7.17041192998206, \"yhat_upper\": 7.6740353699425645, \"fact\": 7.537862680510393, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:56:00\", \"yhat\": 7.421412635525187, \"yhat_lower\": 7.056493585622967, \"yhat_upper\": 7.786331685427408, \"fact\": 7.474088346812236, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:57:00\", \"yhat\": 7.42156218612679, \"yhat_lower\": 6.972419203481223, \"yhat_upper\": 7.870705168772357, \"fact\": 7.353827173698256, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:58:00\", \"yhat\": 7.42153460908079, \"yhat_lower\": 6.901426747209679, \"yhat_upper\": 7.9416424709519005, \"fact\": 7.203553863120317, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:59:00\", \"yhat\": 7.42153969427241, \"yhat_lower\": 6.839084117630604, \"yhat_upper\": 8.003995270914217, \"fact\": 7.1667714268010965, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:00:00\", \"yhat\": 7.166259548584659, \"yhat_lower\": 6.91438449994657, \"yhat_upper\": 7.418134597222748, \"fact\": 7.199926729249083, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:01:00\", \"yhat\": 7.166339966490083, \"yhat_lower\": 6.800752396262416, \"yhat_upper\": 7.531927536717751, \"fact\": 7.017751526939817, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:02:00\", \"yhat\": 7.166327332548444, \"yhat_lower\": 6.716015404099314, \"yhat_upper\": 7.616639260997574, \"fact\": 7.082192901082215, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:03:00\", \"yhat\": 7.1663293173860305, \"yhat_lower\": 6.644718779784825, \"yhat_upper\": 7.687939854987236, \"fact\": 7.060415319852113, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:04:00\", \"yhat\": 7.16632900556092, \"yhat_lower\": 6.582079464193524, \"yhat_upper\": 7.750578546928316, \"fact\": 7.068729453386899, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:05:00\", \"yhat\": 7.069589447303465, \"yhat_lower\": 6.817788963137929, \"yhat_upper\": 7.321389931469001, \"fact\": 7.039528369282021, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:06:00\", \"yhat\": 7.069453590168522, \"yhat_lower\": 6.704401730869556, \"yhat_upper\": 7.434505449467489, \"fact\": 7.033655777722624, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:07:00\", \"yhat\": 7.069475052135589, \"yhat_lower\": 6.619940229984988, \"yhat_upper\": 7.51900987428619, \"fact\": 7.062204617401134, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:08:00\", \"yhat\": 7.069471661691424, \"yhat_lower\": 6.548833462782674, \"yhat_upper\": 7.590109860600175, \"fact\": 6.993569720043028, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:09:00\", \"yhat\": 7.069472197295249, \"yhat_lower\": 6.48635916371062, \"yhat_upper\": 7.652585230879877, \"fact\": 6.9882948401110525, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:10:00\", \"yhat\": 6.988801942242213, \"yhat_lower\": 6.737509924834264, \"yhat_upper\": 7.240093959650162, \"fact\": 6.8390032876923215, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:11:00\", \"yhat\": 6.988721462241647, \"yhat_lower\": 6.62443884182381, \"yhat_upper\": 7.353004082659483, \"fact\": 6.691998504671839, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:12:00\", \"yhat\": 6.98873423487677, \"yhat_lower\": 6.540160301382951, \"yhat_upper\": 7.437308168370588, \"fact\": 6.752681942577438, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:13:00\", \"yhat\": 6.988732207786724, \"yhat_lower\": 6.469213736960752, \"yhat_upper\": 7.508250678612697, \"fact\": 6.73868451382265, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:14:00\", \"yhat\": 6.988732529497477, \"yhat_lower\": 6.406878381852167, \"yhat_upper\": 7.570586677142787, \"fact\": 6.680331145067498, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:15:00\", \"yhat\": 6.677716616136112, \"yhat_lower\": 6.426397813028462, \"yhat_upper\": 6.929035419243762, \"fact\": 6.6180921787104054, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:16:00\", \"yhat\": 6.678137044072399, \"yhat_lower\": 6.313601508891899, \"yhat_upper\": 7.042672579252899, \"fact\": 6.6895657202333645, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:17:00\", \"yhat\": 6.678069437381385, \"yhat_lower\": 6.2291442965141615, \"yhat_upper\": 7.126994578248609, \"fact\": 6.72316112495938, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:18:00\", \"yhat\": 6.678080308839429, \"yhat_lower\": 6.158124454089077, \"yhat_upper\": 7.198036163589781, \"fact\": 6.738952790095521, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:19:00\", \"yhat\": 6.678078560660392, \"yhat_lower\": 6.095715600963967, \"yhat_upper\": 7.260441520356817, \"fact\": 6.664365358351624, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:20:00\", \"yhat\": 6.6604405759630625, \"yhat_lower\": 6.409513371531347, \"yhat_upper\": 6.911367780394778, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:21:00\", \"yhat\": 6.661092647072432, \"yhat_lower\": 6.297104663813606, \"yhat_upper\": 7.025080630331258, \"fact\": 6.724600878108458, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:22:00\", \"yhat\": 6.660984310688506, \"yhat_lower\": 6.212767927102645, \"yhat_upper\": 7.109200694274367, \"fact\": 6.580937541938436, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:23:00\", \"yhat\": 6.661002309909624, \"yhat_lower\": 6.141875399592989, \"yhat_upper\": 7.180129220226259, \"fact\": 6.555562177433832, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:24:00\", \"yhat\": 6.660999319483425, \"yhat_lower\": 6.0795726605945335, \"yhat_upper\": 7.242425978372316, \"fact\": 6.659379361607502, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:25:00\", \"yhat\": 6.668198547811226, \"yhat_lower\": 6.418155337927641, \"yhat_upper\": 6.918241757694811, \"fact\": 6.375346888821504, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:26:00\", \"yhat\": 6.659635499640006, \"yhat_lower\": 6.301818416867237, \"yhat_upper\": 7.0174525824127745, \"fact\": 6.228907112687021, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:27:00\", \"yhat\": 6.6679498488655256, \"yhat_lower\": 6.231325786160343, \"yhat_upper\": 7.104573911570708, \"fact\": 6.35302739173681, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:28:00\", \"yhat\": 6.659876975554334, \"yhat_lower\": 6.1538465329416345, \"yhat_upper\": 7.165907418167033, \"fact\": 6.189166144427423, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:29:00\", \"yhat\": 6.6677153862021, \"yhat_lower\": 6.1031311579030945, \"yhat_upper\": 7.232299614501105, \"fact\": 6.260671502798964, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:30:00\", \"yhat\": 6.257265877742868, \"yhat_lower\": 6.006083353559222, \"yhat_upper\": 6.508448401926514, \"fact\": 6.171678268702035, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:31:00\", \"yhat\": 6.260569470640141, \"yhat_lower\": 5.900964436772674, \"yhat_upper\": 6.620174504507609, \"fact\": 6.186759614812712, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:32:00\", \"yhat\": 6.257364853029232, \"yhat_lower\": 5.8186152883602515, \"yhat_upper\": 6.696114417698213, \"fact\": 6.140920120718393, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:33:00\", \"yhat\": 6.2604734606426655, \"yhat_lower\": 5.75191441393562, \"yhat_upper\": 6.769032507349711, \"fact\": 6.2395658921642525, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:34:00\", \"yhat\": 6.2574579865775535, \"yhat_lower\": 5.690091236395257, \"yhat_upper\": 6.82482473675985, \"fact\": 6.243797647964152, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:35:00\", \"yhat\": 6.241172156995438, \"yhat_lower\": 5.9903530005877, \"yhat_upper\": 6.491991313403175, \"fact\": 6.470077371588114, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:36:00\", \"yhat\": 6.243718293358708, \"yhat_lower\": 5.884568154177088, \"yhat_upper\": 6.602868432540329, \"fact\": 6.60046767084194, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:37:00\", \"yhat\": 6.241249113133898, \"yhat_lower\": 5.8030782060790145, \"yhat_upper\": 6.679420020188781, \"fact\": 6.625989069250561, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:38:00\", \"yhat\": 6.243643663194352, \"yhat_lower\": 5.735727929713654, \"yhat_upper\": 6.7515593966750505, \"fact\": 6.7475051661190895, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:39:00\", \"yhat\": 6.241321487625956, \"yhat_lower\": 5.674688968869951, \"yhat_upper\": 6.80795400638196, \"fact\": 6.844731750554106, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:40:00\", \"yhat\": 6.848414326779806, \"yhat_lower\": 6.596058314494082, \"yhat_upper\": 7.10077033906553, \"fact\": 6.859763545701101, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:41:00\", \"yhat\": 6.847968056284806, \"yhat_lower\": 6.482445945075264, \"yhat_upper\": 7.213490167494348, \"fact\": 6.807310091228302, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:42:00\", \"yhat\": 6.848022137271187, \"yhat_lower\": 6.397735959816673, \"yhat_upper\": 7.2983083147257, \"fact\": 6.841886616435936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:43:00\", \"yhat\": 6.8480155835036385, \"yhat_lower\": 6.326477329113023, \"yhat_upper\": 7.369553837894254, \"fact\": 6.85893746778489, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:44:00\", \"yhat\": 6.848016377717501, \"yhat_lower\": 6.263862842769224, \"yhat_upper\": 7.4321699126657785, \"fact\": 6.846026479115778, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:45:00\", \"yhat\": 6.8453303282550175, \"yhat_lower\": 6.593491778657855, \"yhat_upper\": 7.09716887785218, \"fact\": 6.883238199122709, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:46:00\", \"yhat\": 6.845421008692728, \"yhat_lower\": 6.480649724798994, \"yhat_upper\": 7.210192292586463, \"fact\": 6.809841352593101, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:47:00\", \"yhat\": 6.8454091966815005, \"yhat_lower\": 6.3961121817684425, \"yhat_upper\": 7.2947062115945585, \"fact\": 6.751200710300513, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:48:00\", \"yhat\": 6.84541073531114, \"yhat_lower\": 6.325040862707935, \"yhat_upper\": 7.3657806079143455, \"fact\": 6.805567687218024, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:49:00\", \"yhat\": 6.845410534889626, \"yhat_lower\": 6.262583097140611, \"yhat_upper\": 7.428237972638641, \"fact\": 6.772889900582233, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:50:00\", \"yhat\": 6.774927971137638, \"yhat_lower\": 6.524557406600048, \"yhat_upper\": 7.025298535675228, \"fact\": 6.728335674496716, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:51:00\", \"yhat\": 6.772952338160717, \"yhat_lower\": 6.414311751818976, \"yhat_upper\": 7.131592924502459, \"fact\": 6.747618665608875, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:52:00\", \"yhat\": 6.774867446373799, \"yhat_lower\": 6.3373666484705895, \"yhat_upper\": 7.212368244277008, \"fact\": 6.555395135552946, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:53:00\", \"yhat\": 6.773011008710196, \"yhat_lower\": 6.265815902140084, \"yhat_upper\": 7.280206115280307, \"fact\": 6.593569618569199, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:54:00\", \"yhat\": 6.774810573233653, \"yhat_lower\": 6.209016140605826, \"yhat_upper\": 7.34060500586148, \"fact\": 6.537512510098631, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:55:00\", \"yhat\": 6.534465477256504, \"yhat_lower\": 6.283044278135245, \"yhat_upper\": 6.785886676377762, \"fact\": 6.511672421125268, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:56:00\", \"yhat\": 6.534792647826327, \"yhat_lower\": 6.1709929870391464, \"yhat_upper\": 6.898592308613508, \"fact\": 6.631520179746892, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:57:00\", \"yhat\": 6.534757518378335, \"yhat_lower\": 6.086607022918886, \"yhat_upper\": 6.9829080138377835, \"fact\": 6.75546745691182, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:58:00\", \"yhat\": 6.534761290349992, \"yhat_lower\": 6.015726543862899, \"yhat_upper\": 7.053796036837085, \"fact\": 6.765024078734705, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:59:00\", \"yhat\": 6.534760885340207, \"yhat_lower\": 5.953428104244104, \"yhat_upper\": 7.11609366643631, \"fact\": 6.798885033129787, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:00:00\", \"yhat\": 6.800542387966737, \"yhat_lower\": 6.549330083029052, \"yhat_upper\": 7.051754692904422, \"fact\": 6.74534060560366, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:01:00\", \"yhat\": 6.800347818992969, \"yhat_lower\": 6.436595992369229, \"yhat_upper\": 7.164099645616709, \"fact\": 6.872906486758738, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:02:00\", \"yhat\": 6.800370660864069, \"yhat_lower\": 6.352271964013913, \"yhat_upper\": 7.248469357714225, \"fact\": 6.914632913487516, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:03:00\", \"yhat\": 6.800367979290202, \"yhat_lower\": 6.281373686137165, \"yhat_upper\": 7.3193622724432394, \"fact\": 7.086807423198176, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:04:00\", \"yhat\": 6.800368294099719, \"yhat_lower\": 6.219070039761726, \"yhat_upper\": 7.381666548437713, \"fact\": 7.073886368734035, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:05:00\", \"yhat\": 7.072402435618398, \"yhat_lower\": 6.82114743998009, \"yhat_upper\": 7.323657431256705, \"fact\": 7.020129069863576, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:06:00\", \"yhat\": 7.072498655578617, \"yhat_lower\": 6.708782407486071, \"yhat_upper\": 7.4362149036711624, \"fact\": 7.101131503472381, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:07:00\", \"yhat\": 7.072492416563767, \"yhat_lower\": 6.624105838501655, \"yhat_upper\": 7.520878994625879, \"fact\": 7.010405102545185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:08:00\", \"yhat\": 7.072492821108793, \"yhat_lower\": 6.553034062815197, \"yhat_upper\": 7.591951579402389, \"fact\": 6.951266834994014, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:09:00\", \"yhat\": 7.07249279487762, \"yhat_lower\": 6.490579912604701, \"yhat_upper\": 7.65440567715054, \"fact\": 6.963550333967537, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:10:00\", \"yhat\": 6.964407393020498, \"yhat_lower\": 6.713454556882263, \"yhat_upper\": 7.215360229158734, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:11:00\", \"yhat\": 6.9643273051951216, \"yhat_lower\": 6.601128255251094, \"yhat_upper\": 7.327526355139149, \"fact\": 7.031916357257972, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:12:00\", \"yhat\": 6.9643347889965606, \"yhat_lower\": 6.516806535482838, \"yhat_upper\": 7.411863042510283, \"fact\": 6.966991581251915, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:13:00\", \"yhat\": 6.96433408967324, \"yhat_lower\": 6.445968847124983, \"yhat_upper\": 7.482699332221498, \"fact\": 7.1046647071880225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:14:00\", \"yhat\": 6.964334155021461, \"yhat_lower\": 6.38371503864915, \"yhat_upper\": 7.544953271393771, \"fact\": 7.040671190034965, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:15:00\", \"yhat\": 7.037103658043733, \"yhat_lower\": 6.78622124459446, \"yhat_upper\": 7.287986071493007, \"fact\": 7.190168047613055, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:16:00\", \"yhat\": 7.037372346409672, \"yhat_lower\": 6.674709529418991, \"yhat_upper\": 7.400035163400353, \"fact\": 7.253047411598573, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:17:00\", \"yhat\": 7.037352110168436, \"yhat_lower\": 6.590503787582585, \"yhat_upper\": 7.484200432754288, \"fact\": 7.2720044758545415, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:18:00\", \"yhat\": 7.037353634259209, \"yhat_lower\": 6.519806429875265, \"yhat_upper\": 7.554900838643153, \"fact\": 7.381451693947673, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:19:00\", \"yhat\": 7.037353519472443, \"yhat_lower\": 6.45766882928098, \"yhat_upper\": 7.617038209663907, \"fact\": 7.473923616291, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:20:00\", \"yhat\": 7.477776029845417, \"yhat_lower\": 7.226905603509754, \"yhat_upper\": 7.728646456181081, \"fact\": 7.377898618253228, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:21:00\", \"yhat\": 7.477741887624239, \"yhat_lower\": 7.114988128822711, \"yhat_upper\": 7.840495646425767, \"fact\": 7.4365645152964674, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:22:00\", \"yhat\": 7.4777421902115, \"yhat_lower\": 7.030313048141197, \"yhat_upper\": 7.925171332281803, \"fact\": 7.424375555436707, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:23:00\", \"yhat\": 7.477742187529804, \"yhat_lower\": 6.959286940125583, \"yhat_upper\": 7.996197434934025, \"fact\": 7.322828741550124, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:24:00\", \"yhat\": 7.477742187553571, \"yhat_lower\": 6.896881751749428, \"yhat_upper\": 8.058602623357714, \"fact\": 7.259170692504289, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:25:00\", \"yhat\": 7.2567168944616505, \"yhat_lower\": 7.006072985654786, \"yhat_upper\": 7.507360803268515, \"fact\": 7.123867211441125, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:26:00\", \"yhat\": 7.256795716763838, \"yhat_lower\": 6.89448958475306, \"yhat_upper\": 7.619101848774616, \"fact\": 7.120132713051596, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:27:00\", \"yhat\": 7.256793184788829, \"yhat_lower\": 6.810111202536724, \"yhat_upper\": 7.703475167040933, \"fact\": 7.0565544845028185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:28:00\", \"yhat\": 7.256793266122376, \"yhat_lower\": 6.73930918935305, \"yhat_upper\": 7.774277342891701, \"fact\": 7.139838404300698, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:29:00\", \"yhat\": 7.256793263509733, \"yhat_lower\": 6.677091136469581, \"yhat_upper\": 7.836495390549885, \"fact\": 7.20277666346131, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:30:00\", \"yhat\": 7.205440170563385, \"yhat_lower\": 6.954965903978387, \"yhat_upper\": 7.455914437148383, \"fact\": 7.040986511007052, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:31:00\", \"yhat\": 7.20547266192142, \"yhat_lower\": 6.843328144897782, \"yhat_upper\": 7.567617178945058, \"fact\": 7.006594977513499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:32:00\", \"yhat\": 7.205473058274164, \"yhat_lower\": 6.7586725713629106, \"yhat_upper\": 7.652273545185417, \"fact\": 7.105131073775493, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:33:00\", \"yhat\": 7.205473063109157, \"yhat_lower\": 6.687676228385733, \"yhat_upper\": 7.72326989783258, \"fact\": 6.966567283612587, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:34:00\", \"yhat\": 7.205473063168137, \"yhat_lower\": 6.625303726230022, \"yhat_upper\": 7.785642400106252, \"fact\": 7.067989237821224, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:35:00\", \"yhat\": 7.0725971521236275, \"yhat_lower\": 6.821858508890813, \"yhat_upper\": 7.323335795356442, \"fact\": 7.134185474168518, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:36:00\", \"yhat\": 7.072435948838359, \"yhat_lower\": 6.710504487097107, \"yhat_upper\": 7.43436741057961, \"fact\": 7.0416050260755325, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:37:00\", \"yhat\": 7.072441588374486, \"yhat_lower\": 6.626424199974522, \"yhat_upper\": 7.5184589767744505, \"fact\": 6.980618485802484, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:38:00\", \"yhat\": 7.0724413910809405, \"yhat_lower\": 6.555841749444252, \"yhat_upper\": 7.589041032717629, \"fact\": 7.066809141768836, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:39:00\", \"yhat\": 7.0724413979830585, \"yhat_lower\": 6.493806245637723, \"yhat_upper\": 7.651076550328394, \"fact\": 7.191769766968483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:40:00\", \"yhat\": 7.205842636225949, \"yhat_lower\": 6.955967151116606, \"yhat_upper\": 7.455718121335292, \"fact\": 7.352789477352357, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:41:00\", \"yhat\": 7.192147882634176, \"yhat_lower\": 6.834786599538338, \"yhat_upper\": 7.549509165730013, \"fact\": 7.435857234044891, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:42:00\", \"yhat\": 7.205474679928187, \"yhat_lower\": 6.769332347019433, \"yhat_upper\": 7.641617012836941, \"fact\": 7.224490309562595, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:43:00\", \"yhat\": 7.1925059525301, \"yhat_lower\": 6.6871202996102985, \"yhat_upper\": 7.697891605449901, \"fact\": 7.123376652717213, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:44:00\", \"yhat\": 7.20512623080217, \"yhat_lower\": 6.641212190679784, \"yhat_upper\": 7.769040270924556, \"fact\": 7.0722055728658, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:45:00\", \"yhat\": 7.05674553395191, \"yhat_lower\": 6.8064854427037345, \"yhat_upper\": 7.307005625200085, \"fact\": 7.0742890656413255, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:46:00\", \"yhat\": 7.071798459896775, \"yhat_lower\": 6.713948014641266, \"yhat_upper\": 7.429648905152284, \"fact\": 7.242089094524295, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:47:00\", \"yhat\": 7.057141926315996, \"yhat_lower\": 6.620381184092856, \"yhat_upper\": 7.493902668539136, \"fact\": 7.124376062669945, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:48:00\", \"yhat\": 7.071412505829328, \"yhat_lower\": 6.565335109644032, \"yhat_upper\": 7.577489902014625, \"fact\": 7.211386630870367, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:49:00\", \"yhat\": 7.05751771696101, \"yhat_lower\": 6.492817374714798, \"yhat_upper\": 7.622218059207222, \"fact\": 7.327778305274825, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:50:00\", \"yhat\": 7.337577152494852, \"yhat_lower\": 7.0872324450297235, \"yhat_upper\": 7.58792185995998, \"fact\": 7.114185757892747, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:51:00\", \"yhat\": 7.328048551617149, \"yhat_lower\": 6.969873950564092, \"yhat_upper\": 7.686223152670206, \"fact\": 7.13394669208722, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:52:00\", \"yhat\": 7.337314359384924, \"yhat_lower\": 6.900231028184155, \"yhat_upper\": 7.774397690585692, \"fact\": 6.998725732620053, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:53:00\", \"yhat\": 7.3283040970503714, \"yhat_lower\": 6.821768213297846, \"yhat_upper\": 7.834839980802897, \"fact\": 6.999429650181499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:54:00\", \"yhat\": 7.337065861741822, \"yhat_lower\": 6.771904475511329, \"yhat_upper\": 7.902227247972315, \"fact\": 6.88988017320615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:55:00\", \"yhat\": 6.885315580374561, \"yhat_lower\": 6.633676344887812, \"yhat_upper\": 7.13695481586131, \"fact\": 7.011925284409866, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:56:00\", \"yhat\": 6.8857629900837525, \"yhat_lower\": 6.522592321076656, \"yhat_upper\": 7.248933659090849, \"fact\": 7.0993986854425275, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:57:00\", \"yhat\": 6.885719136128917, \"yhat_lower\": 6.438572737407546, \"yhat_upper\": 7.332865534850288, \"fact\": 7.271220399150457, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:58:00\", \"yhat\": 6.885723434581354, \"yhat_lower\": 6.367999465344272, \"yhat_upper\": 7.4034474038184355, \"fact\": 7.264494897726525, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:59:00\", \"yhat\": 6.885723013258045, \"yhat_lower\": 6.305954704749167, \"yhat_upper\": 7.4654913217669225, \"fact\": 7.044423132287613, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:00:00\", \"yhat\": 7.0536403608448035, \"yhat_lower\": 6.802129077409046, \"yhat_upper\": 7.305151644280561, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:01:00\", \"yhat\": 7.0450296877754335, \"yhat_lower\": 6.683772977201631, \"yhat_upper\": 7.406286398349236, \"fact\": 7.021339661711941, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:02:00\", \"yhat\": 7.053073720778145, \"yhat_lower\": 6.612593066972749, \"yhat_upper\": 7.493554374583542, \"fact\": 7.317534903185268, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:03:00\", \"yhat\": 7.04555903912348, \"yhat_lower\": 6.534655074519172, \"yhat_upper\": 7.556463003727789, \"fact\": 7.10716948495657, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:04:00\", \"yhat\": 7.052579204300814, \"yhat_lower\": 6.482696754452679, \"yhat_upper\": 7.62246165414895, \"fact\": 7.215310153650435, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:05:00\", \"yhat\": 7.218657222721772, \"yhat_lower\": 6.965159052125586, \"yhat_upper\": 7.472155393317958, \"fact\": 7.220570452422764, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:06:00\", \"yhat\": 7.218825197379227, \"yhat_lower\": 6.85453385789717, \"yhat_upper\": 7.583116536861283, \"fact\": 7.103080980776757, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:07:00\", \"yhat\": 7.218833627287587, \"yhat_lower\": 6.77009253188357, \"yhat_upper\": 7.6675747226916044, \"fact\": 7.050846940115519, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:08:00\", \"yhat\": 7.218834050347565, \"yhat_lower\": 6.69918062118574, \"yhat_upper\": 7.7384874795093905, \"fact\": 6.939961443394882, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:09:00\", \"yhat\": 7.218834071579082, \"yhat_lower\": 6.636844947591255, \"yhat_upper\": 7.80082319556691, \"fact\": 6.998102784901203, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:10:00\", \"yhat\": 6.9999817303214, \"yhat_lower\": 6.7466685023181485, \"yhat_upper\": 7.253294958324651, \"fact\": 7.099749789012837, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:11:00\", \"yhat\": 7.000050533044942, \"yhat_lower\": 6.63593108238495, \"yhat_upper\": 7.364169983704935, \"fact\": 7.235330438059645, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:12:00\", \"yhat\": 7.00005305244477, \"yhat_lower\": 6.551548330818587, \"yhat_upper\": 7.448557774070952, \"fact\": 7.338052774675268, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:13:00\", \"yhat\": 7.000053144699482, \"yhat_lower\": 6.480692200798091, \"yhat_upper\": 7.519414088600873, \"fact\": 7.288772432558911, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:14:00\", \"yhat\": 7.00005314807764, \"yhat_lower\": 6.418404364929072, \"yhat_upper\": 7.581701931226209, \"fact\": 7.324544402704568, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:15:00\", \"yhat\": 7.325769054774548, \"yhat_lower\": 7.072539439260948, \"yhat_upper\": 7.578998670288147, \"fact\": 7.121821576872811, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:16:00\", \"yhat\": 7.325825187062364, \"yhat_lower\": 6.96142838736375, \"yhat_upper\": 7.690221986760978, \"fact\": 7.287459513397984, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:17:00\", \"yhat\": 7.325827759902285, \"yhat_lower\": 6.876766102452637, \"yhat_upper\": 7.774889417351933, \"fact\": 7.314871558542801, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:18:00\", \"yhat\": 7.32582787782916, \"yhat_lower\": 6.805695758803259, \"yhat_upper\": 7.84595999685506, \"fact\": 7.415176143796352, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:19:00\", \"yhat\": 7.325827883234373, \"yhat_lower\": 6.743231183005246, \"yhat_upper\": 7.9084245834635, \"fact\": 7.516025127146469, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:20:00\", \"yhat\": 7.519557228738009, \"yhat_lower\": 7.2658402512386475, \"yhat_upper\": 7.77327420623737, \"fact\": 7.6050364669125985, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:21:00\", \"yhat\": 7.5200651268529075, \"yhat_lower\": 7.155587980315242, \"yhat_upper\": 7.884542273390573, \"fact\": 7.566205083257227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:22:00\", \"yhat\": 7.520138160000011, \"yhat_lower\": 7.07078897294257, \"yhat_upper\": 7.969487347057451, \"fact\": 7.729722886759445, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:23:00\", \"yhat\": 7.520148661792436, \"yhat_lower\": 6.999502660143899, \"yhat_upper\": 8.040794663440973, \"fact\": 7.763741051140791, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:24:00\", \"yhat\": 7.520150171896389, \"yhat_lower\": 6.9368472798164476, \"yhat_upper\": 8.10345306397633, \"fact\": 7.791223704044699, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:25:00\", \"yhat\": 7.792077741431366, \"yhat_lower\": 7.5384821135383, \"yhat_upper\": 8.045673369324433, \"fact\": 8.00363971231057, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:26:00\", \"yhat\": 7.792046415790713, \"yhat_lower\": 7.427452208344807, \"yhat_upper\": 8.156640623236619, \"fact\": 7.849663097795245, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:27:00\", \"yhat\": 7.792047564798681, \"yhat_lower\": 7.343286305202935, \"yhat_upper\": 8.240808824394428, \"fact\": 7.787666292025311, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:28:00\", \"yhat\": 7.792047522653675, \"yhat_lower\": 7.272576366136444, \"yhat_upper\": 8.311518679170907, \"fact\": 7.948607630624028, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:29:00\", \"yhat\": 7.792047524199532, \"yhat_lower\": 7.2104001387265395, \"yhat_upper\": 8.373694909672524, \"fact\": 8.10370677263385, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:30:00\", \"yhat\": 8.108906777967789, \"yhat_lower\": 7.854506878107899, \"yhat_upper\": 8.36330667782768, \"fact\": 7.939931606789101, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:31:00\", \"yhat\": 8.109344041835927, \"yhat_lower\": 7.743795814893018, \"yhat_upper\": 8.474892268778836, \"fact\": 8.01138413900431, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:32:00\", \"yhat\": 8.109380810969437, \"yhat_lower\": 7.658947956791965, \"yhat_upper\": 8.55981366514691, \"fact\": 8.024263331132907, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:33:00\", \"yhat\": 8.109383902853486, \"yhat_lower\": 7.58767118817815, \"yhat_upper\": 8.63109661752882, \"fact\": 8.02728778518364, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:34:00\", \"yhat\": 8.109384162847292, \"yhat_lower\": 7.525020326847561, \"yhat_upper\": 8.693747998847023, \"fact\": 8.145123103951551, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:35:00\", \"yhat\": 8.14854852027868, \"yhat_lower\": 7.894151313038731, \"yhat_upper\": 8.40294572751863, \"fact\": 8.346190638990999, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:36:00\", \"yhat\": 8.148650456129728, \"yhat_lower\": 7.783611913723136, \"yhat_upper\": 8.513688998536319, \"fact\": 8.422543666781964, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:37:00\", \"yhat\": 8.148653489605584, \"yhat_lower\": 7.699316635721408, \"yhat_upper\": 8.59799034348976, \"fact\": 8.459908928046268, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:38:00\", \"yhat\": 8.148653579877806, \"yhat_lower\": 7.628502149125702, \"yhat_upper\": 8.668805010629908, \"fact\": 8.455258423436057, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:39:00\", \"yhat\": 8.148653582564187, \"yhat_lower\": 7.566234905239464, \"yhat_upper\": 8.731072259888908, \"fact\": 8.556138297516846, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:40:00\", \"yhat\": 8.559337743941045, \"yhat_lower\": 8.304869568143616, \"yhat_upper\": 8.813805919738474, \"fact\": 8.519475678661328, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:41:00\", \"yhat\": 8.55967801435906, \"yhat_lower\": 8.194048587272157, \"yhat_upper\": 8.925307441445963, \"fact\": 8.41012741828165, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:42:00\", \"yhat\": 8.55971420310612, \"yhat_lower\": 8.109083983864776, \"yhat_upper\": 9.010344422347464, \"fact\": 8.331208792762425, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:43:00\", \"yhat\": 8.559718051884458, \"yhat_lower\": 8.037704203579201, \"yhat_upper\": 9.081731900189714, \"fact\": 8.236846240515225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:44:00\", \"yhat\": 8.55971846121321, \"yhat_lower\": 7.974966853533057, \"yhat_upper\": 9.144470068893364, \"fact\": 8.256041617140585, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:45:00\", \"yhat\": 8.256446300367262, \"yhat_lower\": 8.00220595361776, \"yhat_upper\": 8.510686647116763, \"fact\": 8.380900569385801, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:46:00\", \"yhat\": 8.25648753757218, \"yhat_lower\": 7.8909641420738295, \"yhat_upper\": 8.622010933070532, \"fact\": 8.283185908846015, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:47:00\", \"yhat\": 8.256491739641744, \"yhat_lower\": 7.805907930809316, \"yhat_upper\": 8.707075548474172, \"fact\": 8.19681328000246, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:48:00\", \"yhat\": 8.256492167832468, \"yhat_lower\": 7.734486380502248, \"yhat_upper\": 8.778497955162686, \"fact\": 8.268775956135276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:49:00\", \"yhat\": 8.256492211465085, \"yhat_lower\": 7.671719615563745, \"yhat_upper\": 8.841264807366425, \"fact\": 8.42869425982205, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:50:00\", \"yhat\": 8.433972931515521, \"yhat_lower\": 8.179597249012575, \"yhat_upper\": 8.688348614018468, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:51:00\", \"yhat\": 8.433627570176709, \"yhat_lower\": 8.067584238141595, \"yhat_upper\": 8.799670902211822, \"fact\": 8.475701630597108, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:52:00\", \"yhat\": 8.43365016571992, \"yhat_lower\": 7.983134418564238, \"yhat_upper\": 8.884165912875602, \"fact\": 8.648756666874846, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:53:00\", \"yhat\": 8.433648687388342, \"yhat_lower\": 7.912149860957917, \"yhat_upper\": 8.955147513818767, \"fact\": 8.687765792214106, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:54:00\", \"yhat\": 8.433648784109373, \"yhat_lower\": 7.849734138461978, \"yhat_upper\": 9.017563429756768, \"fact\": 8.748978959879818, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:55:00\", \"yhat\": 8.75110640865237, \"yhat_lower\": 8.496762290379833, \"yhat_upper\": 9.005450526924909, \"fact\": 8.799798123977336, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:56:00\", \"yhat\": 8.751178623062, \"yhat_lower\": 8.385174407151624, \"yhat_upper\": 9.117182838972376, \"fact\": 8.712653545197707, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:57:00\", \"yhat\": 8.751181074317685, \"yhat_lower\": 8.30019841735437, \"yhat_upper\": 9.202163731281, \"fact\": 8.7413195426343, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:58:00\", \"yhat\": 8.75118115752344, \"yhat_lower\": 8.228862291362258, \"yhat_upper\": 9.273500023684623, \"fact\": 8.735522823807608, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:59:00\", \"yhat\": 8.751181160347787, \"yhat_lower\": 8.166160800611303, \"yhat_upper\": 9.336201520084272, \"fact\": 8.755033678541, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:00:00\", \"yhat\": 8.755706054193782, \"yhat_lower\": 8.5017529542068, \"yhat_upper\": 9.009659154180763, \"fact\": 8.697623905237386, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:01:00\", \"yhat\": 8.755727367222551, \"yhat_lower\": 8.39034787932722, \"yhat_upper\": 9.121106855117883, \"fact\": 8.732542420245244, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:02:00\", \"yhat\": 8.755728042805009, \"yhat_lower\": 8.305552665700095, \"yhat_upper\": 9.205903419909923, \"fact\": 8.667663294380052, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:03:00\", \"yhat\": 8.755728064219687, \"yhat_lower\": 8.234366202103606, \"yhat_upper\": 9.277089926335767, \"fact\": 8.74224875192919, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:04:00\", \"yhat\": 8.755728064898491, \"yhat_lower\": 8.17179428537325, \"yhat_upper\": 9.339661844423732, \"fact\": 8.813368356071924, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:05:00\", \"yhat\": 8.815798951545332, \"yhat_lower\": 8.562149112061316, \"yhat_upper\": 9.069448791029348, \"fact\": 8.763653819520787, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:06:00\", \"yhat\": 8.815900890152937, \"yhat_lower\": 8.451056396831643, \"yhat_upper\": 9.180745383474232, \"fact\": 8.727719225687869, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:07:00\", \"yhat\": 8.81590516543438, \"yhat_lower\": 8.366378747035252, \"yhat_upper\": 9.265431583833507, \"fact\": 8.757287262181396, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:08:00\", \"yhat\": 8.815905344738686, \"yhat_lower\": 8.295286060182855, \"yhat_upper\": 9.336524629294518, \"fact\": 8.58461198633341, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:09:00\", \"yhat\": 8.815905352258667, \"yhat_lower\": 8.23279711945526, \"yhat_upper\": 9.399013585062075, \"fact\": 8.580523889099103, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:10:00\", \"yhat\": 8.580362723804022, \"yhat_lower\": 8.326853112002222, \"yhat_upper\": 8.833872335605822, \"fact\": 8.729985918072733, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:11:00\", \"yhat\": 8.580356656980483, \"yhat_lower\": 8.215837046984399, \"yhat_upper\": 8.944876266976566, \"fact\": 8.715254942693004, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:12:00\", \"yhat\": 8.580356428604095, \"yhat_lower\": 8.131303956753406, \"yhat_upper\": 9.029408900454783, \"fact\": 8.657186335028134, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:13:00\", \"yhat\": 8.580356420007211, \"yhat_lower\": 8.060329538582451, \"yhat_upper\": 9.100383301431972, \"fact\": 8.715123818586068, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:14:00\", \"yhat\": 8.580356419683595, \"yhat_lower\": 7.99794073657419, \"yhat_upper\": 9.162772102793, \"fact\": 8.803699468934434, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:15:00\", \"yhat\": 8.806450034302976, \"yhat_lower\": 8.553075118765864, \"yhat_upper\": 9.059824949840088, \"fact\": 8.770428664936265, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:16:00\", \"yhat\": 8.806158991074216, \"yhat_lower\": 8.441572581831046, \"yhat_upper\": 9.170745400317386, \"fact\": 8.68461158678178, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:17:00\", \"yhat\": 8.806189786983296, \"yhat_lower\": 8.357679472774645, \"yhat_upper\": 9.254700101191947, \"fact\": 8.571580251558387, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:18:00\", \"yhat\": 8.80618652840202, \"yhat_lower\": 8.28709972157471, \"yhat_upper\": 9.325273335229328, \"fact\": 8.629115838099489, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:19:00\", \"yhat\": 8.806186873199502, \"yhat_lower\": 8.225036902210283, \"yhat_upper\": 9.387336844188722, \"fact\": 8.680104200208032, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:20:00\", \"yhat\": 8.68140738640574, \"yhat_lower\": 8.428265245907497, \"yhat_upper\": 8.934549526903982, \"fact\": 8.720381281982103, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:21:00\", \"yhat\": 8.681206473157925, \"yhat_lower\": 8.316765266710705, \"yhat_upper\": 9.045647679605144, \"fact\": 8.674145386553628, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:22:00\", \"yhat\": 8.6812374481124, \"yhat_lower\": 8.233101914538715, \"yhat_upper\": 9.129372981686085, \"fact\": 8.645195557966613, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:23:00\", \"yhat\": 8.681232672679146, \"yhat_lower\": 8.162633055588254, \"yhat_upper\": 9.199832289770038, \"fact\": 8.542567468006013, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:24:00\", \"yhat\": 8.68123340891147, \"yhat_lower\": 8.100674721536304, \"yhat_upper\": 9.261792096286637, \"fact\": 8.614450952639153, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:25:00\", \"yhat\": 8.617623322347557, \"yhat_lower\": 8.364769013424496, \"yhat_upper\": 8.870477631270617, \"fact\": 8.600759594883009, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:26:00\", \"yhat\": 8.617158210772903, \"yhat_lower\": 8.253204853244553, \"yhat_upper\": 8.981111568301253, \"fact\": 8.344461174673786, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:27:00\", \"yhat\": 8.617226402313221, \"yhat_lower\": 8.169671192639882, \"yhat_upper\": 9.064781611986561, \"fact\": 8.345833211443853, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:28:00\", \"yhat\": 8.61721640452683, \"yhat_lower\": 8.09928858505197, \"yhat_upper\": 9.135144224001692, \"fact\": 8.308939856017505, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:29:00\", \"yhat\": 8.617217870335232, \"yhat_lower\": 8.037409169683444, \"yhat_upper\": 9.197026570987019, \"fact\": 8.288296800857225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:30:00\", \"yhat\": 8.298189492177734, \"yhat_lower\": 8.046133045695523, \"yhat_upper\": 8.550245938659945, \"fact\": 8.200204061185255, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:31:00\", \"yhat\": 8.28859806674758, \"yhat_lower\": 7.927798800188566, \"yhat_upper\": 8.649397333306595, \"fact\": 8.316763381802183, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:32:00\", \"yhat\": 8.297897400852088, \"yhat_lower\": 7.857667635206764, \"yhat_upper\": 8.738127166497414, \"fact\": 8.213260542060581, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:33:00\", \"yhat\": 8.28888126290502, \"yhat_lower\": 7.778633272272173, \"yhat_upper\": 8.799129253537867, \"fact\": 8.100444362690379, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:34:00\", \"yhat\": 8.297622828974912, \"yhat_lower\": 7.728353759755649, \"yhat_upper\": 8.866891898194176, \"fact\": 8.166018118282045, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:35:00\", \"yhat\": 8.154120802005647, \"yhat_lower\": 7.902030261934824, \"yhat_upper\": 8.40621134207647, \"fact\": 8.133296418077531, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:36:00\", \"yhat\": 8.165645749740973, \"yhat_lower\": 7.804782187374016, \"yhat_upper\": 8.52650931210793, \"fact\": 8.2170409947153, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:37:00\", \"yhat\": 8.154481515957805, \"yhat_lower\": 7.7141761672328455, \"yhat_upper\": 8.594786864682764, \"fact\": 8.174451684276958, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:38:00\", \"yhat\": 8.1652963256062, \"yhat_lower\": 7.654957313392368, \"yhat_upper\": 8.675635337820031, \"fact\": 8.145406367187972, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:39:00\", \"yhat\": 8.154820003629915, \"yhat_lower\": 7.585449337442692, \"yhat_upper\": 8.724190669817139, \"fact\": 8.179618234404483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:40:00\", \"yhat\": 8.189034354851302, \"yhat_lower\": 7.937347911562023, \"yhat_upper\": 8.44072079814058, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:41:00\", \"yhat\": 8.179912033639834, \"yhat_lower\": 7.819595429633585, \"yhat_upper\": 8.540228637646083, \"fact\": 8.079524030680783, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:42:00\", \"yhat\": 8.188749722659978, \"yhat_lower\": 7.749123912990297, \"yhat_upper\": 8.628375532329658, \"fact\": 8.044864923024296, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:43:00\", \"yhat\": 8.180187784814752, \"yhat_lower\": 7.670622315253084, \"yhat_upper\": 8.68975325437642, \"fact\": 7.985665500760242, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:44:00\", \"yhat\": 8.1884825753984, \"yhat_lower\": 7.619984009050429, \"yhat_upper\": 8.75698114174637, \"fact\": 8.046488503559157, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:45:00\", \"yhat\": 8.03966137384912, \"yhat_lower\": 7.788116975729213, \"yhat_upper\": 8.291205771969027, \"fact\": 7.987912077062759, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:46:00\", \"yhat\": 8.046277520746237, \"yhat_lower\": 7.686355874633648, \"yhat_upper\": 8.406199166858826, \"fact\": 7.950148874417816, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:47:00\", \"yhat\": 8.039865836535832, \"yhat_lower\": 7.600650929721418, \"yhat_upper\": 8.479080743350245, \"fact\": 8.068015846901767, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:48:00\", \"yhat\": 8.046079376690429, \"yhat_lower\": 7.537072389939165, \"yhat_upper\": 8.555086363441692, \"fact\": 8.09246969731638, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:49:00\", \"yhat\": 8.040057857229108, \"yhat_lower\": 7.472131541821604, \"yhat_upper\": 8.607984172636613, \"fact\": 8.019705123658905, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:50:00\", \"yhat\": 8.026120815909106, \"yhat_lower\": 7.774834628100456, \"yhat_upper\": 8.277407003717757, \"fact\": 8.06028447175568, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:51:00\", \"yhat\": 8.019905304885793, \"yhat_lower\": 7.660308585562578, \"yhat_upper\": 8.379502024209009, \"fact\": 8.006729199085527, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:52:00\", \"yhat\": 8.025926880699336, \"yhat_lower\": 7.587124219673318, \"yhat_upper\": 8.464729541725355, \"fact\": 7.884033492434073, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:53:00\", \"yhat\": 8.020093188965506, \"yhat_lower\": 7.511545701134459, \"yhat_upper\": 8.528640676796552, \"fact\": 8.046823619428089, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:54:00\", \"yhat\": 8.025744858943458, \"yhat_lower\": 7.458341932307344, \"yhat_upper\": 8.593147785579571, \"fact\": 7.942622275786526, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:55:00\", \"yhat\": 7.930438435577516, \"yhat_lower\": 7.679024411472945, \"yhat_upper\": 8.181852459682087, \"fact\": 8.107336569826192, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:56:00\", \"yhat\": 7.942220305414503, \"yhat_lower\": 7.582371615541745, \"yhat_upper\": 8.302068995287263, \"fact\": 8.118646844437311, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:57:00\", \"yhat\": 7.9308271441062095, \"yhat_lower\": 7.491736755447252, \"yhat_upper\": 8.369917532765166, \"fact\": 8.101259000219994, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:58:00\", \"yhat\": 7.941844421193188, \"yhat_lower\": 7.432940380162401, \"yhat_upper\": 8.450748462223974, \"fact\": 7.975741033032815, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:59:00\", \"yhat\": 7.931190627120871, \"yhat_lower\": 7.363399774895639, \"yhat_upper\": 8.498981479346103, \"fact\": 7.988226254020678, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:00:00\", \"yhat\": 7.9895145920203285, \"yhat_lower\": 7.737215683345835, \"yhat_upper\": 8.241813500694823, \"fact\": 8.062133599963992, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:01:00\", \"yhat\": 7.989216732186696, \"yhat_lower\": 7.627231990466299, \"yhat_upper\": 8.351201473907093, \"fact\": 8.023293650410814, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:02:00\", \"yhat\": 7.989285596475815, \"yhat_lower\": 7.54482985514088, \"yhat_upper\": 8.433741337810751, \"fact\": 7.840974331834362, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:03:00\", \"yhat\": 7.989269675261269, \"yhat_lower\": 7.475217578888254, \"yhat_upper\": 8.503321771634285, \"fact\": 7.651628623492227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:04:00\", \"yhat\": 7.98927335619773, \"yhat_lower\": 7.414024034866996, \"yhat_upper\": 8.564522677528464, \"fact\": 7.656945468320031, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:05:00\", \"yhat\": 7.643592413729259, \"yhat_lower\": 7.391920684220081, \"yhat_upper\": 7.895264143238436, \"fact\": 7.567227283798734, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:06:00\", \"yhat\": 7.656488931048908, \"yhat_lower\": 7.29624973678623, \"yhat_upper\": 8.016728125311586, \"fact\": 7.485420053891467, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:07:00\", \"yhat\": 7.6440333421163995, \"yhat_lower\": 7.204470399576512, \"yhat_upper\": 8.083596284656286, \"fact\": 7.453326960684346, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:08:00\", \"yhat\": 7.656063077882291, \"yhat_lower\": 7.146606635186908, \"yhat_upper\": 8.165519520577675, \"fact\": 7.5675711212537005, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:09:00\", \"yhat\": 7.644444635480143, \"yhat_lower\": 7.07603733791208, \"yhat_upper\": 8.212851933048206, \"fact\": 7.59136442192483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:10:00\", \"yhat\": 7.601231367687085, \"yhat_lower\": 7.349792115994011, \"yhat_upper\": 7.8526706193801585, \"fact\": 7.819711007934736, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:11:00\", \"yhat\": 7.591700428749495, \"yhat_lower\": 7.231745188327408, \"yhat_upper\": 7.951655669171582, \"fact\": 7.983399267364478, \"anomaly\": 1}, {\"ds\": \"2021-08-23T22:12:00\", \"yhat\": 7.600906803165737, \"yhat_lower\": 7.161709042345346, \"yhat_upper\": 8.040104563986128, \"fact\": 7.958116508233395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:13:00\", \"yhat\": 7.592013940621235, \"yhat_lower\": 7.082959110317633, \"yhat_upper\": 8.101068770924837, \"fact\": 7.968943931383387, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:14:00\", \"yhat\": 7.6006039675590795, \"yhat_lower\": 7.0326585898450915, \"yhat_upper\": 8.168549345273068, \"fact\": 8.088943997843543, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:15:00\", \"yhat\": 8.09295495298188, \"yhat_lower\": 7.84015514230051, \"yhat_upper\": 8.345754763663251, \"fact\": 7.94868555720843, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:16:00\", \"yhat\": 8.092441012973348, \"yhat_lower\": 7.728750091851999, \"yhat_upper\": 8.456131934094696, \"fact\": 8.031676300784632, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:17:00\", \"yhat\": 8.092506866198642, \"yhat_lower\": 7.645231639764697, \"yhat_upper\": 8.539782092632587, \"fact\": 7.919155930994936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:18:00\", \"yhat\": 8.092498428156828, \"yhat_lower\": 7.574895046589965, \"yhat_upper\": 8.610101809723691, \"fact\": 7.860433362299011, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:19:00\", \"yhat\": 8.092499509357474, \"yhat_lower\": 7.513049859018121, \"yhat_upper\": 8.671949159696826, \"fact\": 7.887708781348885, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:20:00\", \"yhat\": 7.8886960043342444, \"yhat_lower\": 7.635907084081201, \"yhat_upper\": 8.141484924587289, \"fact\": 7.95518511616727, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:21:00\", \"yhat\": 7.888623551243643, \"yhat_lower\": 7.525580131570147, \"yhat_upper\": 8.251666970917139, \"fact\": 8.031980714285634, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:22:00\", \"yhat\": 7.88862886863436, \"yhat_lower\": 7.442085010522148, \"yhat_upper\": 8.335172726746572, \"fact\": 7.986336725108602, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:23:00\", \"yhat\": 7.888628478386769, \"yhat_lower\": 7.371884718252424, \"yhat_upper\": 8.405372238521114, \"fact\": 7.9750917218656125, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:24:00\", \"yhat\": 7.888628507027354, \"yhat_lower\": 7.310143235182004, \"yhat_upper\": 8.467113778872704, \"fact\": 7.88889753640553, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:25:00\", \"yhat\": 7.886225983596472, \"yhat_lower\": 7.633721357153316, \"yhat_upper\": 8.138730610039628, \"fact\": 7.99517540935556, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:26:00\", \"yhat\": 7.886430544223814, \"yhat_lower\": 7.523719838510416, \"yhat_upper\": 8.249141249937212, \"fact\": 8.048314544065995, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:27:00\", \"yhat\": 7.886414881029691, \"yhat_lower\": 7.440269559661288, \"yhat_upper\": 8.332560202398096, \"fact\": 7.831803761276401, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:28:00\", \"yhat\": 7.886416080359461, \"yhat_lower\": 7.370125224943679, \"yhat_upper\": 8.402706935775244, \"fact\": 7.813286153136449, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:29:00\", \"yhat\": 7.886415988526857, \"yhat_lower\": 7.308432417340612, \"yhat_upper\": 8.464399559713103, \"fact\": 7.800293226728714, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:30:00\", \"yhat\": 7.800363237210505, \"yhat_lower\": 7.548781480111039, \"yhat_upper\": 8.051944994309972, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:31:00\", \"yhat\": 7.800295502411265, \"yhat_lower\": 7.44003859776619, \"yhat_upper\": 8.16055240705634, \"fact\": 7.568500650268759, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:32:00\", \"yhat\": 7.800361035498751, \"yhat_lower\": 7.360837236990321, \"yhat_upper\": 8.239884834007182, \"fact\": 7.485083521432123, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:33:00\", \"yhat\": 7.800297632556636, \"yhat_lower\": 7.29081644950358, \"yhat_upper\": 8.309778815609693, \"fact\": 7.562902259069609, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:34:00\", \"yhat\": 7.800358974593507, \"yhat_lower\": 7.231972256014665, \"yhat_upper\": 8.36874569317235, \"fact\": 7.774237559343768, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:35:00\", \"yhat\": 7.775403417312147, \"yhat_lower\": 7.523244807904434, \"yhat_upper\": 8.027562026719862, \"fact\": 7.84399038958902, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:36:00\", \"yhat\": 7.774275535880446, \"yhat_lower\": 7.413359727516846, \"yhat_upper\": 8.135191344244047, \"fact\": 7.703560195883743, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:37:00\", \"yhat\": 7.775366677819242, \"yhat_lower\": 7.334976144092362, \"yhat_upper\": 8.215757211546121, \"fact\": 7.580990260422031, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:38:00\", \"yhat\": 7.774311078624916, \"yhat_lower\": 7.263897936878491, \"yhat_upper\": 8.284724220371341, \"fact\": 7.536262826528088, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:39:00\", \"yhat\": 7.775332292840447, \"yhat_lower\": 7.205860173211591, \"yhat_upper\": 8.344804412469301, \"fact\": 7.479715123694341, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:40:00\", \"yhat\": 7.479944326746334, \"yhat_lower\": 7.227851320738915, \"yhat_upper\": 7.732037332753753, \"fact\": 7.547983789043043, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:41:00\", \"yhat\": 7.479722800843295, \"yhat_lower\": 7.1188015306397014, \"yhat_upper\": 7.840644071046889, \"fact\": 7.661272545133261, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:42:00\", \"yhat\": 7.479936906743241, \"yhat_lower\": 7.039573654917003, \"yhat_upper\": 7.9203001585694786, \"fact\": 7.799921735142088, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:43:00\", \"yhat\": 7.4797299723136215, \"yhat_lower\": 6.9693090116155645, \"yhat_upper\": 7.9901509330116784, \"fact\": 7.90744271501311, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:44:00\", \"yhat\": 7.479929975481087, \"yhat_lower\": 6.910471365675477, \"yhat_upper\": 8.049388585286698, \"fact\": 7.9914944717499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:45:00\", \"yhat\": 7.992831826320691, \"yhat_lower\": 7.740697630989267, \"yhat_upper\": 8.244966021652115, \"fact\": 8.078038554719182, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:46:00\", \"yhat\": 7.991538971212558, \"yhat_lower\": 7.630528262305753, \"yhat_upper\": 8.352549680119363, \"fact\": 7.887233092209016, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:47:00\", \"yhat\": 7.992788807544024, \"yhat_lower\": 7.552328612089921, \"yhat_upper\": 8.433249002998126, \"fact\": 7.727544853299987, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:48:00\", \"yhat\": 7.991580558571942, \"yhat_lower\": 7.481033163607713, \"yhat_upper\": 8.50212795353617, \"fact\": 7.797725220766124, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:49:00\", \"yhat\": 7.9927486039725935, \"yhat_lower\": 7.423158304049574, \"yhat_upper\": 8.562338903895613, \"fact\": 7.873085248908442, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:50:00\", \"yhat\": 7.874290611601964, \"yhat_lower\": 7.621878341554407, \"yhat_upper\": 8.126702881649521, \"fact\": 7.980822066822155, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:51:00\", \"yhat\": 7.873127035735559, \"yhat_lower\": 7.5115791361467075, \"yhat_upper\": 8.23467493532441, \"fact\": 7.734172080818521, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:52:00\", \"yhat\": 7.874250273416762, \"yhat_lower\": 7.433181494062872, \"yhat_upper\": 8.315319052770652, \"fact\": 7.599489257353818, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:53:00\", \"yhat\": 7.873165975499538, \"yhat_lower\": 7.361858717422135, \"yhat_upper\": 8.384473233576943, \"fact\": 7.722687896015395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:54:00\", \"yhat\": 7.874212683594335, \"yhat_lower\": 7.30380482480906, \"yhat_upper\": 8.44462054237961, \"fact\": 7.77275116820956, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:55:00\", \"yhat\": 7.774825652182994, \"yhat_lower\": 7.521869810970636, \"yhat_upper\": 8.027781493395352, \"fact\": 7.558314501085786, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:56:00\", \"yhat\": 7.77282178658255, \"yhat_lower\": 7.410478614218573, \"yhat_upper\": 8.135164958946527, \"fact\": 7.60533623053003, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:57:00\", \"yhat\": 7.774757437759453, \"yhat_lower\": 7.332727010862397, \"yhat_upper\": 8.216787864656508, \"fact\": 7.564962022147053, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:58:00\", \"yhat\": 7.772887678890487, \"yhat_lower\": 7.260455842600711, \"yhat_upper\": 8.285319515180262, \"fact\": 7.507104599166352, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:59:00\", \"yhat\": 7.774693788519015, \"yhat_lower\": 7.203039183116839, \"yhat_upper\": 8.34634839392119, \"fact\": 7.394733417407842, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:00:00\", \"yhat\": 7.385688797667205, \"yhat_lower\": 7.132552822126157, \"yhat_upper\": 7.6388247732082535, \"fact\": 7.209009286177776, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:01:00\", \"yhat\": 7.394455328793662, \"yhat_lower\": 7.032092706828553, \"yhat_upper\": 7.756817950758772, \"fact\": 7.296538174554642, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:02:00\", \"yhat\": 7.385958336084743, \"yhat_lower\": 6.9438268074600105, \"yhat_upper\": 7.828089864709475, \"fact\": 7.206584493381573, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:03:00\", \"yhat\": 7.394194077685835, \"yhat_lower\": 6.881735123874807, \"yhat_upper\": 7.906653031496863, \"fact\": 7.160033858921166, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:04:00\", \"yhat\": 7.386211554686991, \"yhat_lower\": 6.814479224515522, \"yhat_upper\": 7.95794388485846, \"fact\": 7.254636375974447, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:05:00\", \"yhat\": 7.259141253237945, \"yhat_lower\": 7.005935555482245, \"yhat_upper\": 7.512346950993645, \"fact\": 7.383418162205393, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:06:00\", \"yhat\": 7.254784853775417, \"yhat_lower\": 6.892094207516899, \"yhat_upper\": 7.617475500033936, \"fact\": 7.412786701811927, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:07:00\", \"yhat\": 7.258997669167945, \"yhat_lower\": 6.816543482107363, \"yhat_upper\": 7.701451856228527, \"fact\": 7.410993240415173, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:08:00\", \"yhat\": 7.254923705408612, \"yhat_lower\": 6.742000635756372, \"yhat_upper\": 7.767846775060852, \"fact\": 7.311113765840335, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:09:00\", \"yhat\": 7.2588633939935425, \"yhat_lower\": 6.686663753839192, \"yhat_upper\": 7.831063034147893, \"fact\": 7.3759026127290195, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:10:00\", \"yhat\": 7.377722826500255, \"yhat_lower\": 7.124707059929779, \"yhat_upper\": 7.630738593070731, \"fact\": 7.429606304723798, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:11:00\", \"yhat\": 7.375965698815666, \"yhat_lower\": 7.0133952128731885, \"yhat_upper\": 7.738536184758143, \"fact\": 7.49942313491552, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:12:00\", \"yhat\": 7.37766192688994, \"yhat_lower\": 6.935404606005896, \"yhat_upper\": 7.819919247773983, \"fact\": 7.391456931311621, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:13:00\", \"yhat\": 7.3760244877298895, \"yhat_lower\": 6.863271155694184, \"yhat_upper\": 7.888777819765595, \"fact\": 7.285664791754202, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:14:00\", \"yhat\": 7.377605175518006, \"yhat_lower\": 6.8056266157813665, \"yhat_upper\": 7.949583735254646, \"fact\": 7.115643401562619, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:15:00\", \"yhat\": 7.109097062740931, \"yhat_lower\": 6.855988233676483, \"yhat_upper\": 7.362205891805379, \"fact\": 7.054269618633998, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:16:00\", \"yhat\": 7.115410784128555, \"yhat_lower\": 6.75263313980147, \"yhat_upper\": 7.478188428455639, \"fact\": 7.060118316641897, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:17:00\", \"yhat\": 7.109321414353122, \"yhat_lower\": 6.666835479886579, \"yhat_upper\": 7.551807348819665, \"fact\": 7.161535062516319, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:18:00\", \"yhat\": 7.115194404620739, \"yhat_lower\": 6.602147999712708, \"yhat_upper\": 7.628240809528771, \"fact\": 7.255915033132671, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:19:00\", \"yhat\": 7.1095301050371145, \"yhat_lower\": 6.537239550961617, \"yhat_upper\": 7.681820659112612, \"fact\": 7.426012747469036, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:20:00\", \"yhat\": 7.435183771218641, \"yhat_lower\": 7.182046143669651, \"yhat_upper\": 7.6883213987676315, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:21:00\", \"yhat\": 7.42634269186817, \"yhat_lower\": 7.06348758950777, \"yhat_upper\": 7.78919779422857, \"fact\": 7.317126681220951, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:22:00\", \"yhat\": 7.434865697174387, \"yhat_lower\": 6.992296996412565, \"yhat_upper\": 7.8774343979362085, \"fact\": 7.437457589321834, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:23:00\", \"yhat\": 7.426649322615331, \"yhat_lower\": 6.913493322803598, \"yhat_upper\": 7.939805322427064, \"fact\": 7.411908464884772, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:24:00\", \"yhat\": 7.4345700980307186, \"yhat_lower\": 6.862164486094167, \"yhat_upper\": 8.00697570996727, \"fact\": 7.524143393749286, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:25:00\", \"yhat\": 7.522268346908923, \"yhat_lower\": 7.2690560658477485, \"yhat_upper\": 7.775480627970098, \"fact\": 7.496314903881952, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:26:00\", \"yhat\": 7.524076742141832, \"yhat_lower\": 7.161329417566667, \"yhat_upper\": 7.886824066716998, \"fact\": 7.573752510226136, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:27:00\", \"yhat\": 7.52233262927595, \"yhat_lower\": 7.079817227671923, \"yhat_upper\": 7.964848030879977, \"fact\": 7.541365430808015, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:28:00\", \"yhat\": 7.5240147447967045, \"yhat_lower\": 7.011011068682215, \"yhat_upper\": 8.037018420911194, \"fact\": 7.502722693475748, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:29:00\", \"yhat\": 7.522392422824019, \"yhat_lower\": 6.950101678549461, \"yhat_upper\": 8.094683167098578, \"fact\": 7.432187339829274, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:30:00\", \"yhat\": 7.429892489954869, \"yhat_lower\": 7.177032281079992, \"yhat_upper\": 7.682752698829747, \"fact\": 7.367743829771953, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:31:00\", \"yhat\": 7.432107393596378, \"yhat_lower\": 7.069869225372073, \"yhat_upper\": 7.794345561820683, \"fact\": 7.2855991505679105, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:32:00\", \"yhat\": 7.429969651081765, \"yhat_lower\": 6.988076253242481, \"yhat_upper\": 7.87186304892105, \"fact\": 7.3253574361749, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:33:00\", \"yhat\": 7.43203292055008, \"yhat_lower\": 6.91974943317916, \"yhat_upper\": 7.944316407921001, \"fact\": 7.612270582135634, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:34:00\", \"yhat\": 7.430041529692772, \"yhat_lower\": 6.858556735252098, \"yhat_upper\": 8.001526324133446, \"fact\": 7.591724855148331, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:35:00\", \"yhat\": 7.587698807782413, \"yhat_lower\": 7.334433116303468, \"yhat_upper\": 7.840964499261358, \"fact\": 7.518090746071456, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:36:00\", \"yhat\": 7.59157874538491, \"yhat_lower\": 7.228613493569347, \"yhat_upper\": 7.9545439972004734, \"fact\": 7.676593906453708, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:37:00\", \"yhat\": 7.587839615059046, \"yhat_lower\": 7.145108066981556, \"yhat_upper\": 8.030571163136536, \"fact\": 7.676014289757855, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:38:00\", \"yhat\": 7.591443048161889, \"yhat_lower\": 7.078131122512384, \"yhat_upper\": 8.104754973811392, \"fact\": 7.662263279799936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:39:00\", \"yhat\": 7.587970387678022, \"yhat_lower\": 7.015369487278913, \"yhat_upper\": 8.160571288077131, \"fact\": 7.744231691853355, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:40:00\", \"yhat\": 7.74470804214502, \"yhat_lower\": 7.491578873673213, \"yhat_upper\": 7.997837210616827, \"fact\": 7.535410761101995, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:41:00\", \"yhat\": 7.744248862463998, \"yhat_lower\": 7.381445018164147, \"yhat_upper\": 8.107052706763849, \"fact\": 7.555415160113135, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:42:00\", \"yhat\": 7.744691490469382, \"yhat_lower\": 7.302170483729033, \"yhat_upper\": 8.18721249720973, \"fact\": 7.735896999116704, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:43:00\", \"yhat\": 7.744264817514877, \"yhat_lower\": 7.231181223432841, \"yhat_upper\": 8.257348411596913, \"fact\": 7.847623077982126, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:44:00\", \"yhat\": 7.744676110537215, \"yhat_lower\": 7.17234040639972, \"yhat_upper\": 8.317011814674709, \"fact\": 7.7968137342359105, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:45:00\", \"yhat\": 7.790966825013142, \"yhat_lower\": 7.537462835422848, \"yhat_upper\": 8.044470814603436, \"fact\": 7.784207158858803, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:46:00\", \"yhat\": 7.796596808255675, \"yhat_lower\": 7.433149220333608, \"yhat_upper\": 8.160044396177742, \"fact\": 7.853358920798734, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:47:00\", \"yhat\": 7.791175702829961, \"yhat_lower\": 7.347904842006693, \"yhat_upper\": 8.23444656365323, \"fact\": 7.9176391649767295, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:48:00\", \"yhat\": 7.796395680007634, \"yhat_lower\": 7.282401556501674, \"yhat_upper\": 8.310389803513594, \"fact\": 7.831808587137508, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:49:00\", \"yhat\": 7.791369369025712, \"yhat_lower\": 7.218040405546062, \"yhat_upper\": 8.364698332505363, \"fact\": 7.74727118708158, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:50:00\", \"yhat\": 7.752406772961804, \"yhat_lower\": 7.499159830772723, \"yhat_upper\": 8.005653715150885, \"fact\": 7.749417906852305, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:51:00\", \"yhat\": 7.747462479312985, \"yhat_lower\": 7.384341056107206, \"yhat_upper\": 8.110583902518766, \"fact\": 7.788491835544637, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:52:00\", \"yhat\": 7.752222606055269, \"yhat_lower\": 7.309364637946218, \"yhat_upper\": 8.195080574164319, \"fact\": 7.682725698948679, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:53:00\", \"yhat\": 7.747639786301426, \"yhat_lower\": 7.234106931023541, \"yhat_upper\": 8.26117264157931, \"fact\": 7.663473876690589, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:54:00\", \"yhat\": 7.752051903464116, \"yhat_lower\": 7.179247861790422, \"yhat_upper\": 8.32485594513781, \"fact\": 7.650759642073896, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:55:00\", \"yhat\": 7.642282915223809, \"yhat_lower\": 7.389362135013348, \"yhat_upper\": 7.895203695434271, \"fact\": 7.643660841766507, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:56:00\", \"yhat\": 7.650442234015386, \"yhat_lower\": 7.2877785547753495, \"yhat_upper\": 8.013105913255421, \"fact\": 7.740792599980338, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:57:00\", \"yhat\": 7.642588438049094, \"yhat_lower\": 7.20029162120723, \"yhat_upper\": 8.084885254890958, \"fact\": 7.729485101072052, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:58:00\", \"yhat\": 7.650148151384946, \"yhat_lower\": 7.137262626369366, \"yhat_upper\": 8.163033676400527, \"fact\": 7.809879193660448, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:59:00\", \"yhat\": 7.642871508858766, \"yhat_lower\": 7.070791030071477, \"yhat_upper\": 8.214951987646055, \"fact\": 7.870193732739887, \"anomaly\": 0}], \"data-a4cdb69cb061d4522db309b74e93ce10\": [{\"ds\": \"2021-08-23T00:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.082844108170518, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.1674626685853957, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.2000638083637936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.2814511443512329, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.3429855599321083, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.2755731156274361, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.3259830242634005, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.4015225334641455, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.4579557754303325, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.4239244375389235, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.4248304660409077, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5154668939682374, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5347447133251277, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5788794305034655, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5726670357289692, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6529094883797053, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5430597588849078, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7045537848463952, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.725605597123208, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8969706823799903, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8337969714925286, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6294768866812936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.567784829262433, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5549744824391043, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.4655315966944646, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5393699211046206, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5668600641982584, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6655541826966052, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7580343014578879, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7003402751751524, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7381733427541626, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8166089669392944, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8202484912521655, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7872173390481985, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7582781883694865, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6414662620123128, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.570877626485185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6024371681340028, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7349602229944048, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7985687642651969, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8061596609015358, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6931954985336808, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.760725739200367, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7189225397241747, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7880738117048671, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8704947902250355, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.967249743848884, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8691529633007926, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8629364499573176, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7756583985416396, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7897277717701854, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6222619168405523, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7314104084301887, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:55:00\", \"yhat\": 1.7324618046870077, \"yhat_lower\": 1.5209716187737432, \"yhat_upper\": 1.9439519906002722, \"fact\": 1.9129068757687002, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:56:00\", \"yhat\": 1.7326506211511794, \"yhat_lower\": 1.431620296009358, \"yhat_upper\": 2.033680946293001, \"fact\": 1.8975244367609747, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:57:00\", \"yhat\": 1.7326845300194211, \"yhat_lower\": 1.362926683150179, \"yhat_upper\": 2.1024423768886633, \"fact\": 1.7613237273260038, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:58:00\", \"yhat\": 1.7326906195908496, \"yhat_lower\": 1.3050689186996047, \"yhat_upper\": 2.1603123204820944, \"fact\": 1.7500453495271577, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:59:00\", \"yhat\": 1.7326917131950335, \"yhat_lower\": 1.2541454030724348, \"yhat_upper\": 2.211238023317632, \"fact\": 1.762571819220517, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:00:00\", \"yhat\": 1.7648229574886871, \"yhat_lower\": 1.5493576659277932, \"yhat_upper\": 1.980288249049581, \"fact\": 1.6311805915464404, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:01:00\", \"yhat\": 1.7664662837660827, \"yhat_lower\": 1.4726893242716057, \"yhat_upper\": 2.0602432432605595, \"fact\": 1.6367814595846615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:02:00\", \"yhat\": 1.767665908547982, \"yhat_lower\": 1.4187819220893685, \"yhat_upper\": 2.1165498950065955, \"fact\": 1.4275645069609109, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:03:00\", \"yhat\": 1.7685416321563379, \"yhat_lower\": 1.3760580453223883, \"yhat_upper\": 2.161025218990287, \"fact\": 1.5905556060578103, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:04:00\", \"yhat\": 1.7691809085782686, \"yhat_lower\": 1.339997015098217, \"yhat_upper\": 2.1983648020583204, \"fact\": 1.6655632693644886, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:05:00\", \"yhat\": 1.6650696741336137, \"yhat_lower\": 1.4346867846187878, \"yhat_upper\": 1.8954525636484396, \"fact\": 1.546791983263702, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:06:00\", \"yhat\": 1.665071234912231, \"yhat_lower\": 1.3403231365488284, \"yhat_upper\": 1.9898193332756335, \"fact\": 1.8056647493831086, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:07:00\", \"yhat\": 1.6650712299769526, \"yhat_lower\": 1.2677696347707297, \"yhat_upper\": 2.0623728251831754, \"fact\": 1.7934579666991242, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:08:00\", \"yhat\": 1.6650712299925583, \"yhat_lower\": 1.206556474693036, \"yhat_upper\": 2.1235859852920806, \"fact\": 1.705101463531864, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:09:00\", \"yhat\": 1.665071229992509, \"yhat_lower\": 1.1526036660207635, \"yhat_upper\": 2.1775387939642545, \"fact\": 1.7224407924287297, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:10:00\", \"yhat\": 1.7189795020452858, \"yhat_lower\": 1.4816164433267345, \"yhat_upper\": 1.9563425607638372, \"fact\": 1.6633223909604884, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:11:00\", \"yhat\": 1.716666315528499, \"yhat_lower\": 1.4023946846380166, \"yhat_upper\": 2.030937946418981, \"fact\": 1.6588597657693875, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:12:00\", \"yhat\": 1.7151204088669143, \"yhat_lower\": 1.3504416032894788, \"yhat_upper\": 2.07979921444435, \"fact\": 1.5859053445587559, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:13:00\", \"yhat\": 1.7140872766966424, \"yhat_lower\": 1.3113166674310557, \"yhat_upper\": 2.1168578859622293, \"fact\": 1.8477342784230981, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:14:00\", \"yhat\": 1.7133968326305327, \"yhat_lower\": 1.27941331200412, \"yhat_upper\": 2.147380353256945, \"fact\": 1.892257718603778, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:15:00\", \"yhat\": 1.8651646014999852, \"yhat_lower\": 1.6214768656830687, \"yhat_upper\": 2.1088523373169017, \"fact\": 2.065957311209133, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:16:00\", \"yhat\": 1.8472379362629077, \"yhat_lower\": 1.5262788041101425, \"yhat_upper\": 2.168197068415673, \"fact\": 2.0592974557159858, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:17:00\", \"yhat\": 1.8353764245257713, \"yhat_lower\": 1.4644925665765978, \"yhat_upper\": 2.206260282474945, \"fact\": 2.060554824830489, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:18:00\", \"yhat\": 1.827528034497311, \"yhat_lower\": 1.4192843883193276, \"yhat_upper\": 2.2357716806752945, \"fact\": 2.1274093355782053, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:19:00\", \"yhat\": 1.8223350011467658, \"yhat_lower\": 1.3836642496281624, \"yhat_upper\": 2.261005752665369, \"fact\": 2.033973783734165, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:20:00\", \"yhat\": 2.0245629353826717, \"yhat_lower\": 1.7794560356883378, \"yhat_upper\": 2.2696698350770057, \"fact\": 2.039052392155165, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:21:00\", \"yhat\": 2.017743654668316, \"yhat_lower\": 1.6864678094347605, \"yhat_upper\": 2.349019499901871, \"fact\": 2.2018149811854757, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:22:00\", \"yhat\": 2.012802273432074, \"yhat_lower\": 1.622309720619191, \"yhat_upper\": 2.403294826244957, \"fact\": 2.1549872175178706, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:23:00\", \"yhat\": 2.0092216540757715, \"yhat_lower\": 1.572722426065072, \"yhat_upper\": 2.4457208820864706, \"fact\": 2.1714092548496255, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:24:00\", \"yhat\": 2.0066270688046135, \"yhat_lower\": 1.5319185550130399, \"yhat_upper\": 2.4813355825961874, \"fact\": 2.392593747792554, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:25:00\", \"yhat\": 2.3707718252337275, \"yhat_lower\": 2.119680407639439, \"yhat_upper\": 2.621863242828016, \"fact\": 2.369397260991428, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:26:00\", \"yhat\": 2.357869432886782, \"yhat_lower\": 2.017166375244786, \"yhat_upper\": 2.698572490528778, \"fact\": 2.553716627751497, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:27:00\", \"yhat\": 2.3502407866102795, \"yhat_lower\": 1.9457708659393564, \"yhat_upper\": 2.7547107072812027, \"fact\": 2.48438777779565, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:28:00\", \"yhat\": 2.3457302863521026, \"yhat_lower\": 1.889665337625986, \"yhat_upper\": 2.801795235078219, \"fact\": 2.523275431247673, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:29:00\", \"yhat\": 2.343063415738154, \"yhat_lower\": 1.8424630037446055, \"yhat_upper\": 2.8436638277317026, \"fact\": 2.541655645961276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:30:00\", \"yhat\": 2.540459285803163, \"yhat_lower\": 2.2904929282539914, \"yhat_upper\": 2.790425643352335, \"fact\": 2.5946662175765676, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:31:00\", \"yhat\": 2.540728141477548, \"yhat_lower\": 2.2043266949890357, \"yhat_upper\": 2.8771295879660603, \"fact\": 2.6388582691705813, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:32:00\", \"yhat\": 2.5406677220685943, \"yhat_lower\": 2.132754632171186, \"yhat_upper\": 2.9485808119660026, \"fact\": 2.6823768968397044, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:33:00\", \"yhat\": 2.540681300003993, \"yhat_lower\": 2.07266098228124, \"yhat_upper\": 3.008701617726746, \"fact\": 2.9349245206759322, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:34:00\", \"yhat\": 2.540678248661173, \"yhat_lower\": 2.019312358327148, \"yhat_upper\": 3.0620441389951982, \"fact\": 2.9313232387612618, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:35:00\", \"yhat\": 2.9352974198285415, \"yhat_lower\": 2.6816005813336723, \"yhat_upper\": 3.1889942583234108, \"fact\": 2.7479986630107325, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:36:00\", \"yhat\": 2.9342174141414032, \"yhat_lower\": 2.5890632851659965, \"yhat_upper\": 3.27937154311681, \"fact\": 2.890996166493898, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:37:00\", \"yhat\": 2.9345109116606416, \"yhat_lower\": 2.5144740120737152, \"yhat_upper\": 3.354547811247568, \"fact\": 3.102050247761979, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:38:00\", \"yhat\": 2.9344311520863866, \"yhat_lower\": 2.4516917460375955, \"yhat_upper\": 3.4171705581351777, \"fact\": 3.2153245723915553, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:39:00\", \"yhat\": 2.934452827191859, \"yhat_lower\": 2.3960926704643537, \"yhat_upper\": 3.472812983919364, \"fact\": 3.351469110459854, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:40:00\", \"yhat\": 3.3483772476226807, \"yhat_lower\": 3.083307441915901, \"yhat_upper\": 3.6134470533294607, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:41:00\", \"yhat\": 3.348686154560237, \"yhat_lower\": 2.978296467387896, \"yhat_upper\": 3.7190758417325775, \"fact\": 3.263568933965749, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:42:00\", \"yhat\": 3.348655291775859, \"yhat_lower\": 2.8964997444716976, \"yhat_upper\": 3.8008108390800204, \"fact\": 3.1765726494156343, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:43:00\", \"yhat\": 3.3486583752658805, \"yhat_lower\": 2.8274407710776805, \"yhat_upper\": 3.8698759794540805, \"fact\": 3.03359878070924, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:44:00\", \"yhat\": 3.348658067195468, \"yhat_lower\": 2.766511834539758, \"yhat_upper\": 3.9308042998511783, \"fact\": 3.0229695218101025, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:45:00\", \"yhat\": 3.0229229335265977, \"yhat_lower\": 2.759094916532928, \"yhat_upper\": 3.2867509505202674, \"fact\": 3.1900447587564402, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:46:00\", \"yhat\": 3.0229424054328, \"yhat_lower\": 2.6500866843814497, \"yhat_upper\": 3.39579812648415, \"fact\": 3.124001365720735, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:47:00\", \"yhat\": 3.0229342670103767, \"yhat_lower\": 2.566298152340734, \"yhat_upper\": 3.4795703816800194, \"fact\": 3.0901049942288012, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:48:00\", \"yhat\": 3.022937668522219, \"yhat_lower\": 2.495700838075068, \"yhat_upper\": 3.5501744989693704, \"fact\": 3.008162397059522, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:49:00\", \"yhat\": 3.0229362468360232, \"yhat_lower\": 2.4334834422446194, \"yhat_upper\": 3.612389051427427, \"fact\": 3.0342427632947664, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:50:00\", \"yhat\": 3.033979243535028, \"yhat_lower\": 2.7715624774369862, \"yhat_upper\": 3.29639600963307, \"fact\": 2.9627319946168917, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:51:00\", \"yhat\": 3.033939399271535, \"yhat_lower\": 2.6675269272207265, \"yhat_upper\": 3.4003518713223437, \"fact\": 2.9569461503037706, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:52:00\", \"yhat\": 3.033933374807431, \"yhat_lower\": 2.5876854401735248, \"yhat_upper\": 3.4801813094413374, \"fact\": 3.0267749492582157, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:53:00\", \"yhat\": 3.033932463906725, \"yhat_lower\": 2.5201830757737165, \"yhat_upper\": 3.5476818520397337, \"fact\": 3.07180359176354, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:54:00\", \"yhat\": 3.0339323261782765, \"yhat_lower\": 2.460584374854987, \"yhat_upper\": 3.607280277501566, \"fact\": 3.1560782394784286, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:55:00\", \"yhat\": 3.15436640658461, \"yhat_lower\": 2.8956863064015694, \"yhat_upper\": 3.4130465067676505, \"fact\": 2.997043850204673, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:56:00\", \"yhat\": 3.154227147361811, \"yhat_lower\": 2.7918802326113314, \"yhat_upper\": 3.5165740621122903, \"fact\": 3.009950987266252, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:57:00\", \"yhat\": 3.154215818492501, \"yhat_lower\": 2.7120947181902997, \"yhat_upper\": 3.5963369187947025, \"fact\": 3.0938716467439757, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:58:00\", \"yhat\": 3.1542148968782824, \"yhat_lower\": 2.6446756367519493, \"yhat_upper\": 3.6637541570046155, \"fact\": 3.0880073603636, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:59:00\", \"yhat\": 3.154214821904095, \"yhat_lower\": 2.585191010156913, \"yhat_upper\": 3.723238633651277, \"fact\": 3.11206377340535, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:00:00\", \"yhat\": 3.1106639702154433, \"yhat_lower\": 2.8540462339565362, \"yhat_upper\": 3.3672817064743503, \"fact\": 3.071783339491452, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:01:00\", \"yhat\": 3.1099779656333957, \"yhat_lower\": 2.753563425940895, \"yhat_upper\": 3.466392505325896, \"fact\": 2.9694802366080912, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:02:00\", \"yhat\": 3.1096417738815956, \"yhat_lower\": 2.678385237243149, \"yhat_upper\": 3.540898310520042, \"fact\": 3.1296100628743804, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:03:00\", \"yhat\": 3.109477015661408, \"yhat_lower\": 2.6156588437861275, \"yhat_upper\": 3.603295187536689, \"fact\": 3.002978165799547, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:04:00\", \"yhat\": 3.109396272243481, \"yhat_lower\": 2.5605734039148578, \"yhat_upper\": 3.658219140572104, \"fact\": 2.961692345489058, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:05:00\", \"yhat\": 2.965787033189844, \"yhat_lower\": 2.7087503222310163, \"yhat_upper\": 3.2228237441486716, \"fact\": 2.988327400999106, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:06:00\", \"yhat\": 2.967019660899941, \"yhat_lower\": 2.613799246425694, \"yhat_upper\": 3.3202400753741883, \"fact\": 2.817236951076069, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:07:00\", \"yhat\": 2.967390719984962, \"yhat_lower\": 2.5415646043468643, \"yhat_upper\": 3.3932168356230594, \"fact\": 2.7591756473744242, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:08:00\", \"yhat\": 2.967502420252162, \"yhat_lower\": 2.4804125270406647, \"yhat_upper\": 3.4545923134636594, \"fact\": 2.7415743889488313, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:09:00\", \"yhat\": 2.96753604548921, \"yhat_lower\": 2.4262459816248163, \"yhat_upper\": 3.508826109353604, \"fact\": 2.634959930239999, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:10:00\", \"yhat\": 2.6400907570695664, \"yhat_lower\": 2.383394752666771, \"yhat_upper\": 2.8967867614723617, \"fact\": 2.684944460100623, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:11:00\", \"yhat\": 2.6404810586106437, \"yhat_lower\": 2.285826349232641, \"yhat_upper\": 2.9951357679886463, \"fact\": 2.7044345238588345, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:12:00\", \"yhat\": 2.6405107488141972, \"yhat_lower\": 2.2101365207535446, \"yhat_upper\": 3.07088497687485, \"fact\": 2.6484580732244156, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:13:00\", \"yhat\": 2.6405130073453438, \"yhat_lower\": 2.1459119581350796, \"yhat_upper\": 3.135114056555608, \"fact\": 2.7494103531133773, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:14:00\", \"yhat\": 2.640513179151607, \"yhat_lower\": 2.089118720120073, \"yhat_upper\": 3.1919076381831415, \"fact\": 2.8828342883822207, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:15:00\", \"yhat\": 2.875977278267513, \"yhat_lower\": 2.620809859683987, \"yhat_upper\": 3.1311446968510386, \"fact\": 2.8354131880299063, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:16:00\", \"yhat\": 2.874651973186076, \"yhat_lower\": 2.5217034282116035, \"yhat_upper\": 3.227600518160548, \"fact\": 2.8000865445536682, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:17:00\", \"yhat\": 2.874395821666755, \"yhat_lower\": 2.4466425909828837, \"yhat_upper\": 3.302149052350626, \"fact\": 2.7125150434931227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:18:00\", \"yhat\": 2.8743463133672926, \"yhat_lower\": 2.3832569135284105, \"yhat_upper\": 3.3654357132061747, \"fact\": 2.5930717283678337, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:19:00\", \"yhat\": 2.8743367445319326, \"yhat_lower\": 2.3272304029369106, \"yhat_upper\": 3.4214430861269545, \"fact\": 2.608611290894402, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:20:00\", \"yhat\": 2.6112004733309084, \"yhat_lower\": 2.3582774225825283, \"yhat_upper\": 2.8641235240792886, \"fact\": 2.630785813099688, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:21:00\", \"yhat\": 2.6124367826371135, \"yhat_lower\": 2.2612149951181593, \"yhat_upper\": 2.963658570156068, \"fact\": 2.4460733245935717, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:22:00\", \"yhat\": 2.613027108246873, \"yhat_lower\": 2.188038891790566, \"yhat_upper\": 3.03801532470318, \"fact\": 2.3347403540561436, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:23:00\", \"yhat\": 2.6133089829555636, \"yhat_lower\": 2.126615425937818, \"yhat_upper\": 3.100002539973309, \"fact\": 2.262071173411276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:24:00\", \"yhat\": 2.6134435753738594, \"yhat_lower\": 2.0724716333673605, \"yhat_upper\": 3.1544155173803583, \"fact\": 2.298347870588908, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:25:00\", \"yhat\": 2.3092081841918843, \"yhat_lower\": 2.058868967907293, \"yhat_upper\": 2.5595474004764758, \"fact\": 2.3476057569157662, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:26:00\", \"yhat\": 2.299015257587928, \"yhat_lower\": 1.9355471426844162, \"yhat_upper\": 2.6624833724914403, \"fact\": 2.135029126951106, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:27:00\", \"yhat\": 2.308581809397736, \"yhat_lower\": 1.86678428208665, \"yhat_upper\": 2.7503793367088223, \"fact\": 2.1239990673356894, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:28:00\", \"yhat\": 2.2996031404554693, \"yhat_lower\": 1.7855751474070074, \"yhat_upper\": 2.8136311335039315, \"fact\": 2.0556779001073835, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:29:00\", \"yhat\": 2.308030053054445, \"yhat_lower\": 1.7356143965229234, \"yhat_upper\": 2.8804457095859664, \"fact\": 2.0694340149175385, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:30:00\", \"yhat\": 2.076690472981364, \"yhat_lower\": 1.8263758664441987, \"yhat_upper\": 2.3270050795185293, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:31:00\", \"yhat\": 2.069933752324449, \"yhat_lower\": 1.705201603615039, \"yhat_upper\": 2.4346659010338594, \"fact\": 2.162436461794182, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:32:00\", \"yhat\": 2.076225151466293, \"yhat_lower\": 1.6332757248949223, \"yhat_upper\": 2.5191745780376635, \"fact\": 2.2670705003332525, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:33:00\", \"yhat\": 2.0703670280996733, \"yhat_lower\": 1.5545487669724989, \"yhat_upper\": 2.5861852892268478, \"fact\": 2.29288072551883, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:34:00\", \"yhat\": 2.075821714506436, \"yhat_lower\": 1.5016324814606539, \"yhat_upper\": 2.6500109475522184, \"fact\": 2.3569619929709806, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:35:00\", \"yhat\": 2.3584429606971, \"yhat_lower\": 2.1091499730761765, \"yhat_upper\": 2.607735948318023, \"fact\": 2.410609579163354, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:36:00\", \"yhat\": 2.3570643927267643, \"yhat_lower\": 1.9948346923113647, \"yhat_upper\": 2.719294093142164, \"fact\": 2.3144117890462743, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:37:00\", \"yhat\": 2.3583476412509, \"yhat_lower\": 1.9180924075693333, \"yhat_upper\": 2.7986028749324667, \"fact\": 2.4445136543567934, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:38:00\", \"yhat\": 2.357153121422983, \"yhat_lower\": 1.8448712907803038, \"yhat_upper\": 2.8694349520656623, \"fact\": 2.465681531052395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:39:00\", \"yhat\": 2.358265047595076, \"yhat_lower\": 1.7877799650393729, \"yhat_upper\": 2.9287501301507795, \"fact\": 2.534376307983406, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:40:00\", \"yhat\": 2.5500422667291547, \"yhat_lower\": 2.3016771259640856, \"yhat_upper\": 2.798407407494224, \"fact\": 2.6272076036465988, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:41:00\", \"yhat\": 2.5354335488837045, \"yhat_lower\": 2.1745973053645384, \"yhat_upper\": 2.8962697924028706, \"fact\": 2.5816446195896057, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:42:00\", \"yhat\": 2.549056375328712, \"yhat_lower\": 2.110492233972347, \"yhat_upper\": 2.9876205166850767, \"fact\": 2.6662380206684615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:43:00\", \"yhat\": 2.5363529059131134, \"yhat_lower\": 2.02604306455059, \"yhat_upper\": 3.046662747275637, \"fact\": 2.7168521403799497, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:44:00\", \"yhat\": 2.548199062497762, \"yhat_lower\": 1.9799167259335855, \"yhat_upper\": 3.1164813990619384, \"fact\": 2.8538032872934025, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:45:00\", \"yhat\": 2.8516004686382512, \"yhat_lower\": 2.6011644707240524, \"yhat_upper\": 3.10203646655245, \"fact\": 2.854838809029115, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:46:00\", \"yhat\": 2.851618103341481, \"yhat_lower\": 2.500276460585571, \"yhat_upper\": 3.202959746097391, \"fact\": 2.8618450419844574, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:47:00\", \"yhat\": 2.8516179621665563, \"yhat_lower\": 2.4224565040084793, \"yhat_upper\": 3.280779420324633, \"fact\": 2.9749993982224634, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:48:00\", \"yhat\": 2.8516179632967344, \"yhat_lower\": 2.356726017983553, \"yhat_upper\": 3.346509908609916, \"fact\": 2.9242167077789762, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:49:00\", \"yhat\": 2.8516179632876866, \"yhat_lower\": 2.298755847639495, \"yhat_upper\": 3.4044800789358782, \"fact\": 3.046298158099033, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:50:00\", \"yhat\": 3.0606560956161064, \"yhat_lower\": 2.8147741278439877, \"yhat_upper\": 3.306538063388225, \"fact\": 3.2619941973050857, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:51:00\", \"yhat\": 3.0473316848125234, \"yhat_lower\": 2.689148068143719, \"yhat_upper\": 3.4055153014813278, \"fact\": 3.2881410304426844, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:52:00\", \"yhat\": 3.0596969652054433, \"yhat_lower\": 2.6246440140291227, \"yhat_upper\": 3.494749916381764, \"fact\": 3.17823623114512, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:53:00\", \"yhat\": 3.0482217741857833, \"yhat_lower\": 2.541661819102959, \"yhat_upper\": 3.5547817292686075, \"fact\": 3.2035656084512185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:54:00\", \"yhat\": 3.0588709470919695, \"yhat_lower\": 2.4949329801448945, \"yhat_upper\": 3.6228089140390445, \"fact\": 3.2670646744239535, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:55:00\", \"yhat\": 3.266783828640226, \"yhat_lower\": 3.01636407595188, \"yhat_upper\": 3.517203581328572, \"fact\": 3.141727652556658, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:56:00\", \"yhat\": 3.266784448415951, \"yhat_lower\": 2.9134190542736205, \"yhat_upper\": 3.6201498425582814, \"fact\": 2.9955668695370674, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:57:00\", \"yhat\": 3.2667844470482184, \"yhat_lower\": 2.8343201494468584, \"yhat_upper\": 3.6992487446495783, \"fact\": 2.9382006257672204, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:58:00\", \"yhat\": 3.266784447051237, \"yhat_lower\": 2.7676014816616963, \"yhat_upper\": 3.7659674124407774, \"fact\": 3.1072176080352674, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:59:00\", \"yhat\": 3.26678444705123, \"yhat_lower\": 2.70880425280032, \"yhat_upper\": 3.8247646413021403, \"fact\": 3.2265123861605005, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:00:00\", \"yhat\": 3.228122278641863, \"yhat_lower\": 2.9750583920217446, \"yhat_upper\": 3.481186165261981, \"fact\": 3.193007278757366, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:01:00\", \"yhat\": 3.228133265781497, \"yhat_lower\": 2.8678002303031285, \"yhat_upper\": 3.5884663012598654, \"fact\": 2.9939694331844597, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:02:00\", \"yhat\": 3.228133340766155, \"yhat_lower\": 2.785809323070364, \"yhat_upper\": 3.6704573584619458, \"fact\": 3.0510071595638975, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:03:00\", \"yhat\": 3.228133341277908, \"yhat_lower\": 2.7168005150160024, \"yhat_upper\": 3.7394661675398133, \"fact\": 3.0843334587124414, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:04:00\", \"yhat\": 3.2281333412814006, \"yhat_lower\": 2.6560564387955092, \"yhat_upper\": 3.800210243767292, \"fact\": 3.017355148653572, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:05:00\", \"yhat\": 3.0245044986582035, \"yhat_lower\": 2.775543924190105, \"yhat_upper\": 3.2734650731263017, \"fact\": 3.0840789077005564, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:06:00\", \"yhat\": 3.017949854162934, \"yhat_lower\": 2.6531159030056024, \"yhat_upper\": 3.3827838053202655, \"fact\": 3.2646089479518845, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:07:00\", \"yhat\": 3.0239592626310507, \"yhat_lower\": 2.5814412147665555, \"yhat_upper\": 3.466477310495546, \"fact\": 3.165542668097864, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:08:00\", \"yhat\": 3.01844973573562, \"yhat_lower\": 2.502478831521387, \"yhat_upper\": 3.534420639949853, \"fact\": 3.0844463441003063, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:09:00\", \"yhat\": 3.0235009627860903, \"yhat_lower\": 2.4494215389146623, \"yhat_upper\": 3.5975803866575182, \"fact\": 3.1069823468616202, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:10:00\", \"yhat\": 3.093201140076813, \"yhat_lower\": 2.8438174806726204, \"yhat_upper\": 3.3425847994810054, \"fact\": 3.219189334092936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:11:00\", \"yhat\": 3.1058632318437795, \"yhat_lower\": 2.740609649126394, \"yhat_upper\": 3.471116814561165, \"fact\": 3.253827606819794, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:12:00\", \"yhat\": 3.094229376375343, \"yhat_lower\": 2.6511570835315688, \"yhat_upper\": 3.537301669219117, \"fact\": 3.2185308345572, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:13:00\", \"yhat\": 3.1049184943782286, \"yhat_lower\": 2.588355830076726, \"yhat_upper\": 3.6214811586797313, \"fact\": 3.155315043321703, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:14:00\", \"yhat\": 3.095097395604086, \"yhat_lower\": 2.520342785746619, \"yhat_upper\": 3.6698520054615527, \"fact\": 3.3632975565070162, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:15:00\", \"yhat\": 3.3912968472352842, \"yhat_lower\": 3.140001588056288, \"yhat_upper\": 3.6425921064142806, \"fact\": 3.343103013230474, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:16:00\", \"yhat\": 3.3651657474822896, \"yhat_lower\": 2.9994015459983867, \"yhat_upper\": 3.7309299489661925, \"fact\": 3.2149037491158556, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:17:00\", \"yhat\": 3.3895533071861346, \"yhat_lower\": 2.945234248726223, \"yhat_upper\": 3.8338723656460463, \"fact\": 3.3955861520011412, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:18:00\", \"yhat\": 3.366792953663683, \"yhat_lower\": 2.8495159158670127, \"yhat_upper\": 3.884069991460353, \"fact\": 3.198464588834615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:19:00\", \"yhat\": 3.388034672751522, \"yhat_lower\": 2.8121554464046383, \"yhat_upper\": 3.9639138990984053, \"fact\": 3.1356264595407213, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:20:00\", \"yhat\": 3.13185700637819, \"yhat_lower\": 2.8789454186077554, \"yhat_upper\": 3.3847685941486247, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:21:00\", \"yhat\": 3.1353194920197893, \"yhat_lower\": 2.764655736458891, \"yhat_upper\": 3.5059832475806876, \"fact\": 3.216974287061278, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:22:00\", \"yhat\": 3.132138975827825, \"yhat_lower\": 2.6825807948955758, \"yhat_upper\": 3.5816971567600744, \"fact\": 3.265503557337653, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:23:00\", \"yhat\": 3.135060484909571, \"yhat_lower\": 2.610846920573899, \"yhat_upper\": 3.659274049245243, \"fact\": 3.282716546203024, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:24:00\", \"yhat\": 3.132376890549546, \"yhat_lower\": 2.5491581384326105, \"yhat_upper\": 3.7155956426664813, \"fact\": 3.2557944933176817, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:25:00\", \"yhat\": 3.258884125032105, \"yhat_lower\": 3.00710323375902, \"yhat_upper\": 3.5106650163051896, \"fact\": 3.253280546730072, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:26:00\", \"yhat\": 3.256043948178181, \"yhat_lower\": 2.8886241249718436, \"yhat_upper\": 3.623463771384518, \"fact\": 3.2468023667661132, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:27:00\", \"yhat\": 3.258654810995231, \"yhat_lower\": 2.812519542212457, \"yhat_upper\": 3.7047900797780047, \"fact\": 3.2013389472410476, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:28:00\", \"yhat\": 3.2562547475484647, \"yhat_lower\": 2.7366249183997082, \"yhat_upper\": 3.775884576697221, \"fact\": 3.303433319153471, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:29:00\", \"yhat\": 3.2584610314293663, \"yhat_lower\": 2.680012650033677, \"yhat_upper\": 3.8369094128250554, \"fact\": 3.282481127060928, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:30:00\", \"yhat\": 3.2696664449953765, \"yhat_lower\": 3.0202566284714054, \"yhat_upper\": 3.5190762615193476, \"fact\": 3.2652271356713536, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:31:00\", \"yhat\": 3.281472284289896, \"yhat_lower\": 2.917527991117878, \"yhat_upper\": 3.645416577461914, \"fact\": 3.1595061912084845, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:32:00\", \"yhat\": 3.2705958660740513, \"yhat_lower\": 2.8286938601659974, \"yhat_upper\": 3.712497871982105, \"fact\": 3.150058882565577, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:33:00\", \"yhat\": 3.280616032387926, \"yhat_lower\": 2.765903843371479, \"yhat_upper\": 3.7953282214043726, \"fact\": 3.2408736119745805, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:34:00\", \"yhat\": 3.271384709082296, \"yhat_lower\": 2.6984307760544146, \"yhat_upper\": 3.844338642110177, \"fact\": 3.1901242584634275, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:35:00\", \"yhat\": 3.1978595435991877, \"yhat_lower\": 2.9502038390924232, \"yhat_upper\": 3.445515248105952, \"fact\": 3.305247070725088, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:36:00\", \"yhat\": 3.1907356615572233, \"yhat_lower\": 2.8290881698069277, \"yhat_upper\": 3.552383153307519, \"fact\": 3.1486164121920943, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:37:00\", \"yhat\": 3.197296466292553, \"yhat_lower\": 2.758267101893754, \"yhat_upper\": 3.6363258306913524, \"fact\": 3.3311019146556613, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:38:00\", \"yhat\": 3.191254232785377, \"yhat_lower\": 2.6797907331690514, \"yhat_upper\": 3.7027177324017027, \"fact\": 3.2369006752018885, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:39:00\", \"yhat\": 3.1968188833470137, \"yhat_lower\": 2.627534387726682, \"yhat_upper\": 3.7661033789673453, \"fact\": 3.4338477225305613, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:40:00\", \"yhat\": 3.419887979474071, \"yhat_lower\": 3.1647901635816216, \"yhat_upper\": 3.67498579536652, \"fact\": 3.5746933953177287, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:41:00\", \"yhat\": 3.41683462514806, \"yhat_lower\": 3.069644846444164, \"yhat_upper\": 3.7640244038519564, \"fact\": 3.668791853750908, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:42:00\", \"yhat\": 3.416166778139527, \"yhat_lower\": 2.999025194770077, \"yhat_upper\": 3.833308361508977, \"fact\": 3.692430901451204, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:43:00\", \"yhat\": 3.416020702846854, \"yhat_lower\": 2.9395324959847677, \"yhat_upper\": 3.8925089097089405, \"fact\": 3.7236669409703915, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:44:00\", \"yhat\": 3.4159887524287837, \"yhat_lower\": 2.8868568514229205, \"yhat_upper\": 3.945120653434647, \"fact\": 3.8603194598248907, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:45:00\", \"yhat\": 3.8530788803695195, \"yhat_lower\": 3.59761714175841, \"yhat_upper\": 4.108540618980629, \"fact\": 3.9691359848159276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:46:00\", \"yhat\": 3.8518375754393213, \"yhat_lower\": 3.499395275225139, \"yhat_upper\": 4.204279875653503, \"fact\": 3.962226709383252, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:47:00\", \"yhat\": 3.8516247695528265, \"yhat_lower\": 3.4248677406517016, \"yhat_upper\": 4.278381798453951, \"fact\": 3.9138960369194913, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:48:00\", \"yhat\": 3.851588286699802, \"yhat_lower\": 3.3618448076409866, \"yhat_upper\": 4.341331765758618, \"fact\": 3.866906827861522, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:49:00\", \"yhat\": 3.8515820321803114, \"yhat_lower\": 3.3061050380669537, \"yhat_upper\": 4.397059026293669, \"fact\": 3.8996568831849046, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:50:00\", \"yhat\": 3.8988561825116723, \"yhat_lower\": 3.645171115660895, \"yhat_upper\": 4.152541249362449, \"fact\": 3.931161464982215, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:51:00\", \"yhat\": 3.898697667796094, \"yhat_lower\": 3.5473819091321963, \"yhat_upper\": 4.250013426459991, \"fact\": 3.9222762574162413, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:52:00\", \"yhat\": 3.8986662866371975, \"yhat_lower\": 3.472674327369955, \"yhat_upper\": 4.324658245904439, \"fact\": 3.9522308518159854, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:53:00\", \"yhat\": 3.8986600741090416, \"yhat_lower\": 3.409462149799599, \"yhat_upper\": 4.387857998418484, \"fact\": 3.9672379603949333, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:54:00\", \"yhat\": 3.898658844214817, \"yhat_lower\": 3.3535713900666417, \"yhat_upper\": 4.443746298362992, \"fact\": 3.949120794105074, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:55:00\", \"yhat\": 3.9496474888402164, \"yhat_lower\": 3.698600518755039, \"yhat_upper\": 4.200694458925394, \"fact\": 4.011080429852479, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:56:00\", \"yhat\": 3.9497540887271394, \"yhat_lower\": 3.6020184786016833, \"yhat_upper\": 4.297489698852595, \"fact\": 3.9773963745259766, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:57:00\", \"yhat\": 3.949775663911271, \"yhat_lower\": 3.5281076528348265, \"yhat_upper\": 4.371443674987716, \"fact\": 4.063919451853195, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:58:00\", \"yhat\": 3.9497800306004276, \"yhat_lower\": 3.4655444388283563, \"yhat_upper\": 4.434015622372499, \"fact\": 4.041478475360821, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:59:00\", \"yhat\": 3.9497809143923837, \"yhat_lower\": 3.4102226414227776, \"yhat_upper\": 4.48933918736199, \"fact\": 4.062740372256043, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:00:00\", \"yhat\": 4.0618417683651264, \"yhat_lower\": 3.8127500534326275, \"yhat_upper\": 4.310933483297625, \"fact\": 4.0505187731741525, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:01:00\", \"yhat\": 4.0616836770411835, \"yhat_lower\": 3.7171252771761365, \"yhat_upper\": 4.4062420769062305, \"fact\": 4.1897089265414085, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:02:00\", \"yhat\": 4.0616558640448694, \"yhat_lower\": 3.6439547565158477, \"yhat_upper\": 4.479356971573892, \"fact\": 4.284031357825327, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:03:00\", \"yhat\": 4.061650970906241, \"yhat_lower\": 3.581998129680549, \"yhat_upper\": 4.5413038121319325, \"fact\": 4.343010092731889, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:04:00\", \"yhat\": 4.061650110056681, \"yhat_lower\": 3.5272053848879654, \"yhat_upper\": 4.596094835225397, \"fact\": 4.185387068316425, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:05:00\", \"yhat\": 4.190887900270959, \"yhat_lower\": 3.9412199539073236, \"yhat_upper\": 4.440555846634595, \"fact\": 4.0414341396536315, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:06:00\", \"yhat\": 4.192060159818795, \"yhat_lower\": 3.846132011079779, \"yhat_upper\": 4.537988308557811, \"fact\": 4.158591747922278, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:07:00\", \"yhat\": 4.192309975202877, \"yhat_lower\": 3.772834599921291, \"yhat_upper\": 4.611785350484464, \"fact\": 4.11021899046745, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:08:00\", \"yhat\": 4.1923632123262085, \"yhat_lower\": 3.7106654541701727, \"yhat_upper\": 4.674060970482245, \"fact\": 4.381527688619375, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:09:00\", \"yhat\": 4.192374557469387, \"yhat_lower\": 3.655663269235498, \"yhat_upper\": 4.729085845703276, \"fact\": 4.3351854149025995, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:10:00\", \"yhat\": 4.333420584015721, \"yhat_lower\": 4.080301226657321, \"yhat_upper\": 4.586539941374122, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:11:00\", \"yhat\": 4.332949074232229, \"yhat_lower\": 3.9835646315603794, \"yhat_upper\": 4.682333516904079, \"fact\": 4.184798061879761, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:12:00\", \"yhat\": 4.332823100985965, \"yhat_lower\": 3.9103315159587098, \"yhat_upper\": 4.75531468601322, \"fact\": 4.217342874859245, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:13:00\", \"yhat\": 4.332789444719796, \"yhat_lower\": 3.8485241588932197, \"yhat_upper\": 4.8170547305463725, \"fact\": 4.134349504828188, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:14:00\", \"yhat\": 4.332780452776777, \"yhat_lower\": 3.793878111908856, \"yhat_upper\": 4.871682793644697, \"fact\": 4.00615462019463, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:15:00\", \"yhat\": 4.0133347078693555, \"yhat_lower\": 3.760327243058606, \"yhat_upper\": 4.266342172680105, \"fact\": 4.174443032790151, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:16:00\", \"yhat\": 4.015330545901115, \"yhat_lower\": 3.665716831009192, \"yhat_upper\": 4.364944260793038, \"fact\": 4.158682107023693, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:17:00\", \"yhat\": 4.015885325958055, \"yhat_lower\": 3.592937931121839, \"yhat_upper\": 4.438832720794272, \"fact\": 4.039980382510705, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:18:00\", \"yhat\": 4.01603953732525, \"yhat_lower\": 3.531159374915808, \"yhat_upper\": 4.500919699734693, \"fact\": 3.963354168012908, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:19:00\", \"yhat\": 4.016082403224042, \"yhat_lower\": 3.476440227582816, \"yhat_upper\": 4.555724578865267, \"fact\": 4.013776178380292, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:20:00\", \"yhat\": 4.0132657355033245, \"yhat_lower\": 3.7602299366308074, \"yhat_upper\": 4.266301534375842, \"fact\": 3.8392000488227365, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:21:00\", \"yhat\": 4.013112385065999, \"yhat_lower\": 3.665031391077879, \"yhat_upper\": 4.361193379054119, \"fact\": 3.9196928506772672, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:22:00\", \"yhat\": 4.013066314569791, \"yhat_lower\": 3.593186294568872, \"yhat_upper\": 4.43294633457071, \"fact\": 4.026390515550767, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:23:00\", \"yhat\": 4.013052473783564, \"yhat_lower\": 3.532588289790978, \"yhat_upper\": 4.493516657776149, \"fact\": 4.1533871249773675, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:24:00\", \"yhat\": 4.013048315648116, \"yhat_lower\": 3.4789929536646675, \"yhat_upper\": 4.547103677631565, \"fact\": 4.189958026263005, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:25:00\", \"yhat\": 4.184984375526587, \"yhat_lower\": 3.9310081968795965, \"yhat_upper\": 4.438960554173577, \"fact\": 4.126055761269775, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:26:00\", \"yhat\": 4.183448811268614, \"yhat_lower\": 3.8333598240955955, \"yhat_upper\": 4.533537798441634, \"fact\": 4.19189206344511, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:27:00\", \"yhat\": 4.182974721366584, \"yhat_lower\": 3.7602463876543033, \"yhat_upper\": 4.605703055078865, \"fact\": 4.22553102867423, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:28:00\", \"yhat\": 4.182828350914133, \"yhat_lower\": 3.6988350742474254, \"yhat_upper\": 4.666821627580841, \"fact\": 4.210411801001582, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:29:00\", \"yhat\": 4.182783160520373, \"yhat_lower\": 3.6446203363229257, \"yhat_upper\": 4.72094598471782, \"fact\": 4.182752319021494, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:30:00\", \"yhat\": 4.184107265618835, \"yhat_lower\": 3.9320616681192377, \"yhat_upper\": 4.436152863118433, \"fact\": 4.217524711732356, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:31:00\", \"yhat\": 4.184546688169388, \"yhat_lower\": 3.8374175627862965, \"yhat_upper\": 4.53167581355248, \"fact\": 4.130474550476257, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:32:00\", \"yhat\": 4.184689197238242, \"yhat_lower\": 3.7658563500763855, \"yhat_upper\": 4.603522044400099, \"fact\": 4.17480129452376, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:33:00\", \"yhat\": 4.184735414335385, \"yhat_lower\": 3.7054789869933686, \"yhat_upper\": 4.663991841677403, \"fact\": 4.320493820499588, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:34:00\", \"yhat\": 4.184750402996006, \"yhat_lower\": 3.6520775080667978, \"yhat_upper\": 4.7174232979252135, \"fact\": 4.185929353510199, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:35:00\", \"yhat\": 4.191009962120155, \"yhat_lower\": 3.9389796843243885, \"yhat_upper\": 4.443040239915922, \"fact\": 4.20876999105369, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:36:00\", \"yhat\": 4.192449228584313, \"yhat_lower\": 3.846860640055711, \"yhat_upper\": 4.538037817112915, \"fact\": 4.205431875057931, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:37:00\", \"yhat\": 4.1928569529563084, \"yhat_lower\": 3.77659156670936, \"yhat_upper\": 4.609122339203257, \"fact\": 4.267783231196223, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:38:00\", \"yhat\": 4.1929724556569266, \"yhat_lower\": 3.717006231524479, \"yhat_upper\": 4.668938679789374, \"fact\": 4.243656661707888, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:39:00\", \"yhat\": 4.193005175981652, \"yhat_lower\": 3.6641880721485856, \"yhat_upper\": 4.7218222798147185, \"fact\": 4.277196878166224, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:40:00\", \"yhat\": 4.275152783569864, \"yhat_lower\": 4.0251582185766415, \"yhat_upper\": 4.525147348563087, \"fact\": 4.3318998015163706, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:41:00\", \"yhat\": 4.274561857529326, \"yhat_lower\": 3.9319413097377236, \"yhat_upper\": 4.6171824053209285, \"fact\": 4.363011737742668, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:42:00\", \"yhat\": 4.274391027086348, \"yhat_lower\": 3.8618700226476608, \"yhat_upper\": 4.686912031525035, \"fact\": 4.180371396839616, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:43:00\", \"yhat\": 4.274341641819417, \"yhat_lower\": 3.8027942513478252, \"yhat_upper\": 4.745889032291009, \"fact\": 4.168647619776069, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:44:00\", \"yhat\": 4.274327365063194, \"yhat_lower\": 3.750526740682871, \"yhat_upper\": 4.798127989443518, \"fact\": 4.175629966333796, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:45:00\", \"yhat\": 4.176868115862079, \"yhat_lower\": 3.9273546407982467, \"yhat_upper\": 4.426381590925911, \"fact\": 4.05020272321786, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:46:00\", \"yhat\": 4.17724858771519, \"yhat_lower\": 3.83535281549149, \"yhat_upper\": 4.51914435993889, \"fact\": 4.1803453970069935, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:47:00\", \"yhat\": 4.177365503182751, \"yhat_lower\": 3.7659211661660725, \"yhat_upper\": 4.588809840199429, \"fact\": 4.324238542138023, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:48:00\", \"yhat\": 4.177401430220304, \"yhat_lower\": 3.707294370172451, \"yhat_upper\": 4.647508490268158, \"fact\": 4.332892480853049, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:49:00\", \"yhat\": 4.177412470265342, \"yhat_lower\": 3.6553905026611013, \"yhat_upper\": 4.6994344378695825, \"fact\": 4.291603988308282, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:50:00\", \"yhat\": 4.292236119823976, \"yhat_lower\": 4.042356341645513, \"yhat_upper\": 4.5421158980024385, \"fact\": 4.307690348837449, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:51:00\", \"yhat\": 4.292448679936481, \"yhat_lower\": 3.9500081518690697, \"yhat_upper\": 4.634889208003892, \"fact\": 4.235240633659249, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:52:00\", \"yhat\": 4.292520155254996, \"yhat_lower\": 3.880644027842594, \"yhat_upper\": 4.704396282667398, \"fact\": 4.317974290661283, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:53:00\", \"yhat\": 4.292544189496871, \"yhat_lower\": 3.8222172971692814, \"yhat_upper\": 4.762871081824461, \"fact\": 4.332980571066018, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:54:00\", \"yhat\": 4.292552271234658, \"yhat_lower\": 3.7705354646331726, \"yhat_upper\": 4.814569077836144, \"fact\": 4.487906802061469, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:55:00\", \"yhat\": 4.477299256073399, \"yhat_lower\": 4.227902492407064, \"yhat_upper\": 4.726696019739735, \"fact\": 4.685148103114914, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:57:00\", \"yhat\": 4.472589364114719, \"yhat_lower\": 4.061345609456638, \"yhat_upper\": 4.8838331187728, \"fact\": 4.799561104428719, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:58:00\", \"yhat\": 4.4721974060583145, \"yhat_lower\": 4.002523499826597, \"yhat_upper\": 4.941871312290032, \"fact\": 4.795506399361607, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:59:00\", \"yhat\": 4.472066854772718, \"yhat_lower\": 3.950718065904149, \"yhat_upper\": 4.9934156436412875, \"fact\": 4.742588279703727, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:00:00\", \"yhat\": 4.744325973213684, \"yhat_lower\": 4.49373817541368, \"yhat_upper\": 4.994913771013688, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:01:00\", \"yhat\": 4.744958588468329, \"yhat_lower\": 4.39751547248038, \"yhat_upper\": 5.092401704456277, \"fact\": 4.798220230319819, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:02:00\", \"yhat\": 4.745188894939589, \"yhat_lower\": 4.324576912762676, \"yhat_upper\": 5.165800877116502, \"fact\": 4.829701886057892, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:03:00\", \"yhat\": 4.74527273906177, \"yhat_lower\": 4.263099815366656, \"yhat_upper\": 5.2274456627568835, \"fact\": 4.883016949588336, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:04:00\", \"yhat\": 4.745303262897187, \"yhat_lower\": 4.208794511933229, \"yhat_upper\": 5.2818120138611455, \"fact\": 4.8937347142287, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:05:00\", \"yhat\": 4.892190761824069, \"yhat_lower\": 4.643036793862239, \"yhat_upper\": 5.1413447297858985, \"fact\": 4.938648459724199, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:06:00\", \"yhat\": 4.891642550668168, \"yhat_lower\": 4.546259303231988, \"yhat_upper\": 5.237025798104348, \"fact\": 5.17809129022616, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:07:00\", \"yhat\": 4.89144789734171, \"yhat_lower\": 4.473331275992535, \"yhat_upper\": 5.309564518690884, \"fact\": 5.2277973565851275, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:08:00\", \"yhat\": 4.891378781788162, \"yhat_lower\": 4.412042841859964, \"yhat_upper\": 5.370714721716359, \"fact\": 5.060179684851194, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:09:00\", \"yhat\": 4.891354240929656, \"yhat_lower\": 4.357973071344421, \"yhat_upper\": 5.4247354105148915, \"fact\": 5.1297403620303, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:10:00\", \"yhat\": 5.1286471209994025, \"yhat_lower\": 4.877392451085899, \"yhat_upper\": 5.379901790912906, \"fact\": 5.15313317767182, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:11:00\", \"yhat\": 5.128256491683382, \"yhat_lower\": 4.779962647124747, \"yhat_upper\": 5.476550336242018, \"fact\": 5.300808308865612, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:12:00\", \"yhat\": 5.128116914720735, \"yhat_lower\": 4.706490469294971, \"yhat_upper\": 5.549743360146499, \"fact\": 5.26705268243037, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:13:00\", \"yhat\": 5.128067042046814, \"yhat_lower\": 4.644723485280574, \"yhat_upper\": 5.611410598813054, \"fact\": 5.18963904990192, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:14:00\", \"yhat\": 5.128049221888266, \"yhat_lower\": 4.590223379791123, \"yhat_upper\": 5.665875063985409, \"fact\": 5.127358854626321, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:15:00\", \"yhat\": 5.1307849090197735, \"yhat_lower\": 4.880137669467795, \"yhat_upper\": 5.381432148571752, \"fact\": 5.29558515008685, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:16:00\", \"yhat\": 5.13208622484106, \"yhat_lower\": 4.7843963056384915, \"yhat_upper\": 5.479776144043628, \"fact\": 5.426325324638567, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:17:00\", \"yhat\": 5.13258050271066, \"yhat_lower\": 4.711636634473419, \"yhat_upper\": 5.5535243709479, \"fact\": 5.398406115283306, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:18:00\", \"yhat\": 5.132768243924883, \"yhat_lower\": 4.650235082453734, \"yhat_upper\": 5.615301405396033, \"fact\": 5.538297490098523, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:19:00\", \"yhat\": 5.1328395535377265, \"yhat_lower\": 4.595966441360065, \"yhat_upper\": 5.669712665715388, \"fact\": 5.653105045264966, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:20:00\", \"yhat\": 5.647487996388624, \"yhat_lower\": 5.395450786513213, \"yhat_upper\": 5.899525206264035, \"fact\": 5.765696569733555, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:21:00\", \"yhat\": 5.645423423714422, \"yhat_lower\": 5.294571453871599, \"yhat_upper\": 5.996275393557244, \"fact\": 5.666272705776069, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:22:00\", \"yhat\": 5.644664580339386, \"yhat_lower\": 5.218927529247918, \"yhat_upper\": 6.070401631430854, \"fact\": 5.567606762643266, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:23:00\", \"yhat\": 5.64438566389579, \"yhat_lower\": 5.155622371395589, \"yhat_upper\": 6.13314895639599, \"fact\": 5.677067547194454, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:24:00\", \"yhat\": 5.644283146848045, \"yhat_lower\": 5.099914265307548, \"yhat_upper\": 6.1886520283885424, \"fact\": 5.952771138793346, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:25:00\", \"yhat\": 5.944345554601432, \"yhat_lower\": 5.689287712170162, \"yhat_upper\": 6.199403397032701, \"fact\": 5.893822573112458, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:26:00\", \"yhat\": 5.9409156590365635, \"yhat_lower\": 5.585182904561281, \"yhat_upper\": 6.296648413511846, \"fact\": 5.956312217973574, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:27:00\", \"yhat\": 5.9395194135872345, \"yhat_lower\": 5.507529477329984, \"yhat_upper\": 6.371509349844485, \"fact\": 5.867959474518728, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:28:00\", \"yhat\": 5.93895102853938, \"yhat_lower\": 5.4428554717585955, \"yhat_upper\": 6.435046585320165, \"fact\": 5.924113424681968, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:29:00\", \"yhat\": 5.938719649763693, \"yhat_lower\": 5.386113627277958, \"yhat_upper\": 6.491325672249428, \"fact\": 5.755143754694852, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:30:00\", \"yhat\": 5.760599905298446, \"yhat_lower\": 5.505698392057641, \"yhat_upper\": 6.015501418539251, \"fact\": 5.748453921221867, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:31:00\", \"yhat\": 5.76269954403525, \"yhat_lower\": 5.408534223446234, \"yhat_upper\": 6.116864864624266, \"fact\": 5.688476020659092, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:32:00\", \"yhat\": 5.763507528115122, \"yhat_lower\": 5.3343261272171265, \"yhat_upper\": 6.1926889290131175, \"fact\": 5.746675485986374, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:33:00\", \"yhat\": 5.763818456972493, \"yhat_lower\": 5.271563907041106, \"yhat_upper\": 6.256073006903881, \"fact\": 5.843299988713007, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:34:00\", \"yhat\": 5.763938108778456, \"yhat_lower\": 5.2160468166255995, \"yhat_upper\": 6.3118294009313125, \"fact\": 5.834770667584292, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:35:00\", \"yhat\": 5.833525251400562, \"yhat_lower\": 5.579917702524392, \"yhat_upper\": 6.087132800276733, \"fact\": 5.867216105273556, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:36:00\", \"yhat\": 5.833039091214535, \"yhat_lower\": 5.480519561637844, \"yhat_upper\": 6.185558620791226, \"fact\": 5.877789831818705, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:37:00\", \"yhat\": 5.832849313909915, \"yhat_lower\": 5.405577173005054, \"yhat_upper\": 6.260121454814777, \"fact\": 5.788247198986482, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:38:00\", \"yhat\": 5.832775232513733, \"yhat_lower\": 5.342662391134344, \"yhat_upper\": 6.322888073893123, \"fact\": 5.855276906622282, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:39:00\", \"yhat\": 5.832746314128202, \"yhat_lower\": 5.2872099442196125, \"yhat_upper\": 6.378282684036791, \"fact\": 5.952180412895244, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:40:00\", \"yhat\": 5.9482795105879145, \"yhat_lower\": 5.695680856059903, \"yhat_upper\": 6.200878165115926, \"fact\": 6.064808083145066, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:41:00\", \"yhat\": 5.946721639930627, \"yhat_lower\": 5.595674678100532, \"yhat_upper\": 6.297768601760722, \"fact\": 6.090622739284995, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:42:00\", \"yhat\": 5.946099486184229, \"yhat_lower\": 5.520709248793489, \"yhat_upper\": 6.371489723574969, \"fact\": 6.088539270842496, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:43:00\", \"yhat\": 5.945851021857395, \"yhat_lower\": 5.45799268226429, \"yhat_upper\": 6.4337093614505, \"fact\": 6.180880255586056, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:44:00\", \"yhat\": 5.945751794741804, \"yhat_lower\": 5.402809247645458, \"yhat_upper\": 6.48869434183815, \"fact\": 6.0829197927436836, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:45:00\", \"yhat\": 6.084551373470568, \"yhat_lower\": 5.83257580300832, \"yhat_upper\": 6.336526943932816, \"fact\": 6.153305438466777, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:46:00\", \"yhat\": 6.085200810637757, \"yhat_lower\": 5.734496418949186, \"yhat_upper\": 6.435905202326329, \"fact\": 6.245424626413475, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:47:00\", \"yhat\": 6.085459313712216, \"yhat_lower\": 5.660084933617304, \"yhat_upper\": 6.510833693807129, \"fact\": 6.270181897393748, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:48:00\", \"yhat\": 6.085562208715584, \"yhat_lower\": 5.5974217917048, \"yhat_upper\": 6.5737026257263675, \"fact\": 6.304686334947228, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:49:00\", \"yhat\": 6.085603165217707, \"yhat_lower\": 5.542118080539727, \"yhat_upper\": 6.629088249895687, \"fact\": 6.2486697214488025, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:50:00\", \"yhat\": 6.249564989449478, \"yhat_lower\": 5.998729728574593, \"yhat_upper\": 6.500400250324364, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:51:00\", \"yhat\": 6.249913847731205, \"yhat_lower\": 5.9006620611578375, \"yhat_upper\": 6.599165634304572, \"fact\": 6.23101000200763, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:52:00\", \"yhat\": 6.250049787026072, \"yhat_lower\": 5.826299497376384, \"yhat_upper\": 6.673800076675759, \"fact\": 6.230694728169978, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:53:00\", \"yhat\": 6.250102758369614, \"yhat_lower\": 5.763704124714489, \"yhat_upper\": 6.736501392024739, \"fact\": 6.157703819607037, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:54:00\", \"yhat\": 6.250123399665712, \"yhat_lower\": 5.70847562095993, \"yhat_upper\": 6.791771178371495, \"fact\": 6.301928313075152, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:55:00\", \"yhat\": 6.297998816680268, \"yhat_lower\": 6.047622146148059, \"yhat_upper\": 6.5483754872124775, \"fact\": 6.4061636350278155, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:56:00\", \"yhat\": 6.2964962608616055, \"yhat_lower\": 5.948543514563678, \"yhat_upper\": 6.644449007159533, \"fact\": 6.462931053129455, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:57:00\", \"yhat\": 6.295921715484458, \"yhat_lower\": 5.874201734901785, \"yhat_upper\": 6.7176416960671315, \"fact\": 6.586302157616276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:58:00\", \"yhat\": 6.295702021556085, \"yhat_lower\": 5.811949830944344, \"yhat_upper\": 6.779454212167827, \"fact\": 6.590380090978745, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:59:00\", \"yhat\": 6.295618015272015, \"yhat_lower\": 5.757145241285006, \"yhat_upper\": 6.834090789259024, \"fact\": 6.598384601991288, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:00:00\", \"yhat\": 6.597412969192818, \"yhat_lower\": 6.347656558636209, \"yhat_upper\": 6.847169379749427, \"fact\": 6.6087284233126855, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:01:00\", \"yhat\": 6.59703629058395, \"yhat_lower\": 6.248195014739094, \"yhat_upper\": 6.9458775664288055, \"fact\": 6.519586448521761, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:02:00\", \"yhat\": 6.596890261369413, \"yhat_lower\": 6.172821559170344, \"yhat_upper\": 7.020958963568483, \"fact\": 6.585441774813497, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:03:00\", \"yhat\": 6.596833649363857, \"yhat_lower\": 6.109464555847566, \"yhat_upper\": 7.084202742880148, \"fact\": 6.612122789230208, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:04:00\", \"yhat\": 6.5968117022542785, \"yhat_lower\": 6.0536274334602656, \"yhat_upper\": 7.139995971048291, \"fact\": 6.713398361671289, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:05:00\", \"yhat\": 6.710415654780143, \"yhat_lower\": 6.461540792495042, \"yhat_upper\": 6.959290517065244, \"fact\": 6.822549277291775, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:06:00\", \"yhat\": 6.709252188759664, \"yhat_lower\": 6.361705119017242, \"yhat_upper\": 7.056799258502086, \"fact\": 6.97551658913424, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:07:00\", \"yhat\": 6.708798354967001, \"yhat_lower\": 6.28635789586271, \"yhat_upper\": 7.131238814071293, \"fact\": 7.0245338623762, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:08:00\", \"yhat\": 6.708621327784654, \"yhat_lower\": 6.223168335613451, \"yhat_upper\": 7.194074319955856, \"fact\": 7.011984857308559, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:09:00\", \"yhat\": 6.70855227470003, \"yhat_lower\": 6.167539339228818, \"yhat_upper\": 7.249565210171242, \"fact\": 6.939497193677334, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:10:00\", \"yhat\": 6.940139064073755, \"yhat_lower\": 6.691350168667293, \"yhat_upper\": 7.188927959480216, \"fact\": 7.010406398571905, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:11:00\", \"yhat\": 6.940216818249961, \"yhat_lower\": 6.5899212851856594, \"yhat_upper\": 7.290512351314262, \"fact\": 6.931851888092667, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:12:00\", \"yhat\": 6.9402262371481545, \"yhat_lower\": 6.51198887286548, \"yhat_upper\": 7.368463601430829, \"fact\": 6.879178023131081, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:13:00\", \"yhat\": 6.940227378124081, \"yhat_lower\": 6.446211499044236, \"yhat_upper\": 7.434243257203925, \"fact\": 7.109475269891421, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:14:00\", \"yhat\": 6.940227516338343, \"yhat_lower\": 6.388218259339513, \"yhat_upper\": 7.492236773337173, \"fact\": 7.284680664017118, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:15:00\", \"yhat\": 7.285591777087916, \"yhat_lower\": 7.0349793271436605, \"yhat_upper\": 7.536204227032171, \"fact\": 7.395090828652547, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:16:00\", \"yhat\": 7.2855250830497615, \"yhat_lower\": 6.930073841430036, \"yhat_upper\": 7.640976324669487, \"fact\": 7.371434651213532, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:17:00\", \"yhat\": 7.285529965094447, \"yhat_lower\": 6.849834182204316, \"yhat_upper\": 7.721225747984579, \"fact\": 7.245236231448149, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:18:00\", \"yhat\": 7.285529607725769, \"yhat_lower\": 6.782220577985497, \"yhat_upper\": 7.78883863746604, \"fact\": 7.344627723533745, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:19:00\", \"yhat\": 7.2855296338853766, \"yhat_lower\": 6.722671875989988, \"yhat_upper\": 7.848387391780765, \"fact\": 7.362549605351548, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:20:00\", \"yhat\": 7.362640079566995, \"yhat_lower\": 7.1123280018815604, \"yhat_upper\": 7.612952157252429, \"fact\": 7.316384307810927, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:21:00\", \"yhat\": 7.362638866088396, \"yhat_lower\": 7.007640630503108, \"yhat_upper\": 7.717637101673684, \"fact\": 7.4436762713471, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:22:00\", \"yhat\": 7.362638882364086, \"yhat_lower\": 6.927458702289933, \"yhat_upper\": 7.797819062438239, \"fact\": 7.586315011635683, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:23:00\", \"yhat\": 7.36263888214579, \"yhat_lower\": 6.859906389331664, \"yhat_upper\": 7.865371374959915, \"fact\": 7.84596167034078, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:24:00\", \"yhat\": 7.362638882148718, \"yhat_lower\": 6.800412835249899, \"yhat_upper\": 7.924864929047537, \"fact\": 7.810708032610894, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:25:00\", \"yhat\": 7.816550529752005, \"yhat_lower\": 7.565506288878929, \"yhat_upper\": 8.067594770625082, \"fact\": 7.869544211046324, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:26:00\", \"yhat\": 7.810872902450107, \"yhat_lower\": 7.451632008381344, \"yhat_upper\": 8.170113796518871, \"fact\": 7.588004256487661, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:27:00\", \"yhat\": 7.816390312386423, \"yhat_lower\": 7.378028388187327, \"yhat_upper\": 8.254752236585517, \"fact\": 7.4272223763164, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:30:00\", \"yhat\": 7.216353160724422, \"yhat_lower\": 6.960673766754205, \"yhat_upper\": 7.472032554694639, \"fact\": 7.212214491649582, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:31:00\", \"yhat\": 7.216171635984013, \"yhat_lower\": 6.848633137177756, \"yhat_upper\": 7.5837101347902705, \"fact\": 7.351039971128483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:32:00\", \"yhat\": 7.2162062148546315, \"yhat_lower\": 6.764587423651902, \"yhat_upper\": 7.667825006057361, \"fact\": 7.376476250774716, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:33:00\", \"yhat\": 7.216199627883123, \"yhat_lower\": 6.693711652636985, \"yhat_upper\": 7.738687603129261, \"fact\": 7.335800040585095, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:34:00\", \"yhat\": 7.2162008826434105, \"yhat_lower\": 6.631395357824935, \"yhat_upper\": 7.801006407461886, \"fact\": 7.448679719340017, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:35:00\", \"yhat\": 7.452503657511436, \"yhat_lower\": 7.197316006803971, \"yhat_upper\": 7.7076913082189, \"fact\": 7.483511703168986, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:36:00\", \"yhat\": 7.451971856621101, \"yhat_lower\": 7.085280914072586, \"yhat_upper\": 7.818662799169616, \"fact\": 7.414570983492366, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:37:00\", \"yhat\": 7.452045814978763, \"yhat_lower\": 7.001258908688272, \"yhat_upper\": 7.902832721269253, \"fact\": 7.334626120276795, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:38:00\", \"yhat\": 7.452035529477614, \"yhat_lower\": 6.930462901947463, \"yhat_upper\": 7.9736081570077655, \"fact\": 7.3049778908374945, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:39:00\", \"yhat\": 7.4520369598978835, \"yhat_lower\": 6.868208484460012, \"yhat_upper\": 8.035865435335754, \"fact\": 7.278459085454509, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:40:00\", \"yhat\": 7.2776470273555205, \"yhat_lower\": 7.023662163873742, \"yhat_upper\": 7.531631890837299, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:41:00\", \"yhat\": 7.277767424063659, \"yhat_lower\": 6.912274743879037, \"yhat_upper\": 7.643260104248281, \"fact\": 7.413871916691975, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:42:00\", \"yhat\": 7.277749573903248, \"yhat_lower\": 6.828334039306306, \"yhat_upper\": 7.72716510850019, \"fact\": 7.306328534468085, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:43:00\", \"yhat\": 7.2777522203894485, \"yhat_lower\": 6.7576893307120836, \"yhat_upper\": 7.797815110066813, \"fact\": 7.135863705449194, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:44:00\", \"yhat\": 7.2777518280182285, \"yhat_lower\": 6.695565072539987, \"yhat_upper\": 7.85993858349647, \"fact\": 7.296605351643508, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:45:00\", \"yhat\": 7.299926322053273, \"yhat_lower\": 7.045973898437952, \"yhat_upper\": 7.5538787456685945, \"fact\": 7.432244315830181, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:46:00\", \"yhat\": 7.296710973417641, \"yhat_lower\": 6.932907651159899, \"yhat_upper\": 7.660514295675383, \"fact\": 7.395988175550756, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:47:00\", \"yhat\": 7.299824059525925, \"yhat_lower\": 6.856032897993685, \"yhat_upper\": 7.743615221058165, \"fact\": 7.278183825443562, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:48:00\", \"yhat\": 7.296809983537339, \"yhat_lower\": 6.782313473379718, \"yhat_upper\": 7.8113064936949606, \"fact\": 7.250066035906667, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:49:00\", \"yhat\": 7.299728198372706, \"yhat_lower\": 6.725791140553761, \"yhat_upper\": 7.873665256191651, \"fact\": 7.282209302585056, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:50:00\", \"yhat\": 7.281830555035022, \"yhat_lower\": 7.028360741030704, \"yhat_upper\": 7.53530036903934, \"fact\": 7.2156324032840775, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:51:00\", \"yhat\": 7.282196985995753, \"yhat_lower\": 6.918948906692463, \"yhat_upper\": 7.645445065299044, \"fact\": 7.196476313520412, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:52:00\", \"yhat\": 7.281842471097979, \"yhat_lower\": 6.838776874319301, \"yhat_upper\": 7.724908067876658, \"fact\": 7.113119567118843, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:53:00\", \"yhat\": 7.2821854574343226, \"yhat_lower\": 6.768474134281684, \"yhat_upper\": 7.795896780586961, \"fact\": 7.162704804924952, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:54:00\", \"yhat\": 7.281853624759147, \"yhat_lower\": 6.708825467730545, \"yhat_upper\": 7.85488178178775, \"fact\": 7.221109884038875, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:55:00\", \"yhat\": 7.218293857199037, \"yhat_lower\": 6.965864852706779, \"yhat_upper\": 7.4707228616912955, \"fact\": 7.28587585791872, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:56:00\", \"yhat\": 7.221017748060954, \"yhat_lower\": 6.8592003456224875, \"yhat_upper\": 7.582835150499421, \"fact\": 7.33450767010157, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:57:00\", \"yhat\": 7.218382978632386, \"yhat_lower\": 6.777084426991344, \"yhat_upper\": 7.659681530273428, \"fact\": 7.2076185280683, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:58:00\", \"yhat\": 7.220931542541012, \"yhat_lower\": 6.709243507435033, \"yhat_upper\": 7.732619577646991, \"fact\": 7.200436641971628, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:59:00\", \"yhat\": 7.2184663636430315, \"yhat_lower\": 6.64771049144449, \"yhat_upper\": 7.789222235841573, \"fact\": 7.174060851045539, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:00:00\", \"yhat\": 7.173296648626436, \"yhat_lower\": 6.921698040754108, \"yhat_upper\": 7.424895256498764, \"fact\": 7.262444992057902, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:01:00\", \"yhat\": 7.174035703487625, \"yhat_lower\": 6.813351027858519, \"yhat_upper\": 7.534720379116732, \"fact\": 7.34306802733499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:02:00\", \"yhat\": 7.173320968655342, \"yhat_lower\": 6.733424725979266, \"yhat_upper\": 7.613217211331418, \"fact\": 7.316689086557331, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:03:00\", \"yhat\": 7.174012183756283, \"yhat_lower\": 6.66392607118319, \"yhat_upper\": 7.684098296329377, \"fact\": 7.435901366061946, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:04:00\", \"yhat\": 7.173343714424456, \"yhat_lower\": 6.604389175244254, \"yhat_upper\": 7.742298253604657, \"fact\": 7.519301570079593, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:05:00\", \"yhat\": 7.5185764523606995, \"yhat_lower\": 7.267408573893648, \"yhat_upper\": 7.769744330827751, \"fact\": 7.444483463234448, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:06:00\", \"yhat\": 7.5192773500714, \"yhat_lower\": 7.159106717072483, \"yhat_upper\": 7.8794479830703175, \"fact\": 7.558503416641305, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:07:00\", \"yhat\": 7.518599863384665, \"yhat_lower\": 7.079367201404851, \"yhat_upper\": 7.957832525364479, \"fact\": 7.502724062217367, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:08:00\", \"yhat\": 7.519254721010387, \"yhat_lower\": 7.0098955496762745, \"yhat_upper\": 8.028613892344499, \"fact\": 7.543900869874692, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:09:00\", \"yhat\": 7.5186217366014505, \"yhat_lower\": 6.950503127021667, \"yhat_upper\": 8.086740346181234, \"fact\": 7.61793683008212, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:10:00\", \"yhat\": 7.6129619954947305, \"yhat_lower\": 7.36238405221503, \"yhat_upper\": 7.863539938774431, \"fact\": 7.576099179026605, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:11:00\", \"yhat\": 7.617772867406523, \"yhat_lower\": 7.258488404227632, \"yhat_upper\": 7.977057330585414, \"fact\": 7.474889511780991, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:12:00\", \"yhat\": 7.613120554220001, \"yhat_lower\": 7.174955351196553, \"yhat_upper\": 8.051285757243448, \"fact\": 7.493594475005889, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:13:00\", \"yhat\": 7.617619534525926, \"yhat_lower\": 7.109513656535809, \"yhat_upper\": 8.125725412516044, \"fact\": 7.394645478479456, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:14:00\", \"yhat\": 7.613268833491493, \"yhat_lower\": 7.0465397897777375, \"yhat_upper\": 8.179997877205249, \"fact\": 7.358314631980785, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:15:00\", \"yhat\": 7.366710105295156, \"yhat_lower\": 7.116849636792478, \"yhat_upper\": 7.616570573797834, \"fact\": 7.414394947365127, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:16:00\", \"yhat\": 7.358583069850688, \"yhat_lower\": 7.000451585044503, \"yhat_upper\": 7.716714554656874, \"fact\": 7.362071254261016, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:17:00\", \"yhat\": 7.3664502504898755, \"yhat_lower\": 6.929648571223621, \"yhat_upper\": 7.80325192975613, \"fact\": 7.2610336329398955, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:18:00\", \"yhat\": 7.358834616027282, \"yhat_lower\": 6.852359396667534, \"yhat_upper\": 7.8653098353870305, \"fact\": 7.397969492007248, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:19:00\", \"yhat\": 7.366206747280877, \"yhat_lower\": 6.801268417557214, \"yhat_upper\": 7.93114507700454, \"fact\": 7.175585543122942, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:20:00\", \"yhat\": 7.160009880253454, \"yhat_lower\": 6.908780770491768, \"yhat_upper\": 7.411238990015139, \"fact\": 7.132322801642127, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:21:00\", \"yhat\": 7.175142985123323, \"yhat_lower\": 6.815577064714107, \"yhat_upper\": 7.534708905532538, \"fact\": 7.1510859667762, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:22:00\", \"yhat\": 7.160439863662528, \"yhat_lower\": 6.721703528517741, \"yhat_upper\": 7.599176198807315, \"fact\": 7.086966133877971, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:23:00\", \"yhat\": 7.174725219017548, \"yhat_lower\": 6.66622165940641, \"yhat_upper\": 7.683228778628686, \"fact\": 7.091083736255178, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:24:00\", \"yhat\": 7.160845759600488, \"yhat_lower\": 6.593519673505681, \"yhat_upper\": 7.728171845695296, \"fact\": 7.047475782418074, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:25:00\", \"yhat\": 7.059168865816141, \"yhat_lower\": 6.809302025875383, \"yhat_upper\": 7.309035705756899, \"fact\": 7.009527254558687, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:26:00\", \"yhat\": 7.047824418929619, \"yhat_lower\": 6.68997450046545, \"yhat_upper\": 7.405674337393789, \"fact\": 7.115014684339309, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:27:00\", \"yhat\": 7.058830624117755, \"yhat_lower\": 6.622271359099034, \"yhat_upper\": 7.495389889136477, \"fact\": 7.158507807273718, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:28:00\", \"yhat\": 7.048152575742628, \"yhat_lower\": 6.542075732781259, \"yhat_upper\": 7.554229418703996, \"fact\": 7.223216693033921, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:29:00\", \"yhat\": 7.058512251503032, \"yhat_lower\": 6.493950713650285, \"yhat_upper\": 7.623073789355779, \"fact\": 7.414873061673024, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:30:00\", \"yhat\": 7.404198552420598, \"yhat_lower\": 7.15410286299506, \"yhat_upper\": 7.654294241846136, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:31:00\", \"yhat\": 7.414555212821825, \"yhat_lower\": 7.0563641970363005, \"yhat_upper\": 7.77274622860735, \"fact\": 7.2522816003485655, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:32:00\", \"yhat\": 7.404506936865536, \"yhat_lower\": 6.96753671776917, \"yhat_upper\": 7.841477155961901, \"fact\": 7.362085934503852, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:33:00\", \"yhat\": 7.414256010966854, \"yhat_lower\": 6.907696795778013, \"yhat_upper\": 7.920815226155695, \"fact\": 7.467224271777104, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:34:00\", \"yhat\": 7.404797229555353, \"yhat_lower\": 6.839701439786028, \"yhat_upper\": 7.969893019324678, \"fact\": 7.364294904567715, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:35:00\", \"yhat\": 7.37200267618703, \"yhat_lower\": 7.121570013351947, \"yhat_upper\": 7.622435339022113, \"fact\": 7.459430953032399, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:36:00\", \"yhat\": 7.364531163162113, \"yhat_lower\": 7.005931471991403, \"yhat_upper\": 7.7231308543328225, \"fact\": 7.452578150899747, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:37:00\", \"yhat\": 7.371773659390415, \"yhat_lower\": 6.934273894071852, \"yhat_upper\": 7.809273424708978, \"fact\": 7.5133858350161615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:38:00\", \"yhat\": 7.364753160136509, \"yhat_lower\": 6.857615811286102, \"yhat_upper\": 7.871890508986915, \"fact\": 7.4258638789745675, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:39:00\", \"yhat\": 7.371558467066665, \"yhat_lower\": 6.805792910338943, \"yhat_upper\": 7.937324023794386, \"fact\": 7.3737932149732766, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:40:00\", \"yhat\": 7.3710961687573855, \"yhat_lower\": 7.121466609863671, \"yhat_upper\": 7.6207257276511, \"fact\": 7.598358267725344, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:41:00\", \"yhat\": 7.373708129141845, \"yhat_lower\": 7.016100490728412, \"yhat_upper\": 7.731315767555278, \"fact\": 7.492834789309395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:42:00\", \"yhat\": 7.371178570319385, \"yhat_lower\": 6.934945176430296, \"yhat_upper\": 7.807411964208474, \"fact\": 7.522201737971649, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:43:00\", \"yhat\": 7.373628327166523, \"yhat_lower\": 6.86789389606429, \"yhat_upper\": 7.879362758268757, \"fact\": 7.302638063120661, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:44:00\", \"yhat\": 7.3712558547192275, \"yhat_lower\": 6.807093757405459, \"yhat_upper\": 7.935417952032996, \"fact\": 7.279557282830666, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:45:00\", \"yhat\": 7.279680278601407, \"yhat_lower\": 7.026770458357441, \"yhat_upper\": 7.532590098845373, \"fact\": 7.363046511604048, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:46:00\", \"yhat\": 7.2796634094689345, \"yhat_lower\": 6.919927888741431, \"yhat_upper\": 7.639398930196438, \"fact\": 7.326486104423132, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:47:00\", \"yhat\": 7.279665723106458, \"yhat_lower\": 6.838472425900878, \"yhat_upper\": 7.720859020312038, \"fact\": 7.246927464543807, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:48:00\", \"yhat\": 7.279665405786133, \"yhat_lower\": 6.769840514931834, \"yhat_upper\": 7.789490296640432, \"fact\": 7.41642187662266, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:49:00\", \"yhat\": 7.279665449307293, \"yhat_lower\": 6.709413337743624, \"yhat_upper\": 7.849917560870963, \"fact\": 7.502878653438836, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:50:00\", \"yhat\": 7.48774425214232, \"yhat_lower\": 7.235928582859503, \"yhat_upper\": 7.739559921425136, \"fact\": 7.651020501300728, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:51:00\", \"yhat\": 7.502467812969404, \"yhat_lower\": 7.1423287414388295, \"yhat_upper\": 7.862606884499979, \"fact\": 7.73101396367219, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:52:00\", \"yhat\": 7.488143939881755, \"yhat_lower\": 7.04861169041849, \"yhat_upper\": 7.92767618934502, \"fact\": 7.7908900897128355, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:53:00\", \"yhat\": 7.502078975206474, \"yhat_lower\": 6.992764898193691, \"yhat_upper\": 8.011393052219256, \"fact\": 7.721905539978192, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:54:00\", \"yhat\": 7.488522222203083, \"yhat_lower\": 6.920224330684986, \"yhat_upper\": 8.05682011372118, \"fact\": 7.676797763099813, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:55:00\", \"yhat\": 7.693138196022208, \"yhat_lower\": 7.441416486671045, \"yhat_upper\": 7.94485990537337, \"fact\": 7.49859598323504, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:56:00\", \"yhat\": 7.677195211861952, \"yhat_lower\": 7.317594823233135, \"yhat_upper\": 8.03679560049077, \"fact\": 7.476065058965288, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:57:00\", \"yhat\": 7.692750414416336, \"yhat_lower\": 7.253730437008519, \"yhat_upper\": 8.131770391824153, \"fact\": 7.482103132721876, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:58:00\", \"yhat\": 7.677573561446044, \"yhat_lower\": 7.169021454017259, \"yhat_upper\": 8.18612566887483, \"fact\": 7.533694637573916, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:59:00\", \"yhat\": 7.692381267438722, \"yhat_lower\": 7.124833328103077, \"yhat_upper\": 8.259929206774366, \"fact\": 7.520250704663931, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:00:00\", \"yhat\": 7.503523314070336, \"yhat_lower\": 7.25193017492475, \"yhat_upper\": 7.755116453215923, \"fact\": 7.430552773592014, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:01:00\", \"yhat\": 7.519916055035945, \"yhat_lower\": 7.161147081475889, \"yhat_upper\": 7.878685028596001, \"fact\": 7.425522429366651, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:02:00\", \"yhat\": 7.50385126866882, \"yhat_lower\": 7.065608974196779, \"yhat_upper\": 7.94209356314086, \"fact\": 7.19210405586305, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:03:00\", \"yhat\": 7.5195946615256215, \"yhat_lower\": 7.012218517520609, \"yhat_upper\": 8.026970805530635, \"fact\": 7.28277232480738, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:04:00\", \"yhat\": 7.504166232352682, \"yhat_lower\": 6.937763499042452, \"yhat_upper\": 8.070568965662911, \"fact\": 7.175360535016683, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:05:00\", \"yhat\": 7.173873349518272, \"yhat_lower\": 6.92057524359665, \"yhat_upper\": 7.427171455439893, \"fact\": 7.262163774530336, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:06:00\", \"yhat\": 7.1740774981144915, \"yhat_lower\": 6.813741999158462, \"yhat_upper\": 7.534412997070521, \"fact\": 7.203036103460411, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:07:00\", \"yhat\": 7.174049474273899, \"yhat_lower\": 6.7321066552662145, \"yhat_upper\": 7.615992293281584, \"fact\": 7.104577394867066, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:08:00\", \"yhat\": 7.174053321156298, \"yhat_lower\": 6.663353761605052, \"yhat_upper\": 7.684752880707544, \"fact\": 7.146838037080654, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:09:00\", \"yhat\": 7.174052793087915, \"yhat_lower\": 6.602816702678393, \"yhat_upper\": 7.745288883497437, \"fact\": 7.1098713925408195, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:10:00\", \"yhat\": 7.109610716156644, \"yhat_lower\": 6.8569584487037725, \"yhat_upper\": 7.362262983609516, \"fact\": 6.964204225280627, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:11:00\", \"yhat\": 7.109623670135193, \"yhat_lower\": 6.751142793652526, \"yhat_upper\": 7.46810454661786, \"fact\": 6.8317439585381985, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:12:00\", \"yhat\": 7.1096230264038445, \"yhat_lower\": 6.670143872328218, \"yhat_upper\": 7.549102180479471, \"fact\": 6.846925861641189, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:13:00\", \"yhat\": 7.1096230583932485, \"yhat_lower\": 6.60190522250948, \"yhat_upper\": 7.617340894277017, \"fact\": 6.8792347865250285, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:14:00\", \"yhat\": 7.109623056803576, \"yhat_lower\": 6.5418090280733505, \"yhat_upper\": 7.677437085533802, \"fact\": 6.918101973663316, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:15:00\", \"yhat\": 6.918571675911672, \"yhat_lower\": 6.666129851358794, \"yhat_upper\": 7.171013500464551, \"fact\": 6.946297846175937, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:16:00\", \"yhat\": 6.918518927797419, \"yhat_lower\": 6.559127626959058, \"yhat_upper\": 7.27791022863578, \"fact\": 6.91741109605579, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:17:00\", \"yhat\": 6.918524851472613, \"yhat_lower\": 6.477611750346601, \"yhat_upper\": 7.359437952598625, \"fact\": 6.792759709575465, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:18:00\", \"yhat\": 6.91852418623693, \"yhat_lower\": 6.408947621156285, \"yhat_upper\": 7.428100751317576, \"fact\": 6.781526290147463, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:19:00\", \"yhat\": 6.918524260943679, \"yhat_lower\": 6.3484981595290915, \"yhat_upper\": 7.488550362358266, \"fact\": 6.527562112720121, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:20:00\", \"yhat\": 6.524082428954757, \"yhat_lower\": 6.270737748103554, \"yhat_upper\": 6.77742710980596, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:21:00\", \"yhat\": 6.524353174122666, \"yhat_lower\": 6.163606756826468, \"yhat_upper\": 6.885099591418864, \"fact\": 6.342845929573227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:22:00\", \"yhat\": 6.524332108143431, \"yhat_lower\": 6.0816654476008045, \"yhat_upper\": 6.966998768686058, \"fact\": 6.295282891714099, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:23:00\", \"yhat\": 6.5243337472326335, \"yhat_lower\": 6.0126889971262445, \"yhat_upper\": 7.0359784973390225, \"fact\": 6.416976346172642, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:24:00\", \"yhat\": 6.524333619699354, \"yhat_lower\": 5.951964779507084, \"yhat_upper\": 7.096702459891625, \"fact\": 6.474370432036268, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:25:00\", \"yhat\": 6.47518585052719, \"yhat_lower\": 6.221926612312983, \"yhat_upper\": 6.728445088741396, \"fact\": 6.601555135123274, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:26:00\", \"yhat\": 6.475088733600407, \"yhat_lower\": 6.113228785705835, \"yhat_upper\": 6.836948681494978, \"fact\": 6.565698424868521, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:27:00\", \"yhat\": 6.475100300296003, \"yhat_lower\": 6.030774856505277, \"yhat_upper\": 6.919425744086729, \"fact\": 6.58040116897878, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:28:00\", \"yhat\": 6.475098922694266, \"yhat_lower\": 5.961342522837147, \"yhat_upper\": 6.988855322551385, \"fact\": 6.482049789735297, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:29:00\", \"yhat\": 6.47509908676762, \"yhat_lower\": 5.90024115370073, \"yhat_upper\": 7.04995701983451, \"fact\": 6.390248110625829, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:30:00\", \"yhat\": 6.38844965217483, \"yhat_lower\": 6.135529623849783, \"yhat_upper\": 6.641369680499877, \"fact\": 6.32894900581122, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:31:00\", \"yhat\": 6.388565804348265, \"yhat_lower\": 6.026995615077918, \"yhat_upper\": 6.7501359936186125, \"fact\": 6.342132763662364, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:32:00\", \"yhat\": 6.388558302741883, \"yhat_lower\": 5.944356677448673, \"yhat_upper\": 6.832759928035093, \"fact\": 6.431054046458639, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:33:00\", \"yhat\": 6.3885587872278515, \"yhat_lower\": 5.874838106959432, \"yhat_upper\": 6.902279467496271, \"fact\": 6.373515189094005, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:34:00\", \"yhat\": 6.388558755937666, \"yhat_lower\": 5.813665695893781, \"yhat_upper\": 6.963451815981551, \"fact\": 6.205522054823765, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:35:00\", \"yhat\": 6.201622734221125, \"yhat_lower\": 5.948848893286743, \"yhat_upper\": 6.454396575155507, \"fact\": 6.316785939738493, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:36:00\", \"yhat\": 6.201902527464482, \"yhat_lower\": 5.84008981575688, \"yhat_upper\": 6.563715239172085, \"fact\": 6.333618541503614, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:37:00\", \"yhat\": 6.201882451080157, \"yhat_lower\": 5.757252301609696, \"yhat_upper\": 6.646512600550618, \"fact\": 6.445636379481378, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:38:00\", \"yhat\": 6.201883891648209, \"yhat_lower\": 5.68758852321547, \"yhat_upper\": 6.716179260080948, \"fact\": 6.591432527622528, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:39:00\", \"yhat\": 6.201883788281174, \"yhat_lower\": 5.62629511752273, \"yhat_upper\": 6.777472459039618, \"fact\": 6.518538014853173, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:40:00\", \"yhat\": 6.516651549904689, \"yhat_lower\": 6.263767053096791, \"yhat_upper\": 6.769536046712588, \"fact\": 6.403509692296891, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:41:00\", \"yhat\": 6.516793122976042, \"yhat_lower\": 6.155216029300217, \"yhat_upper\": 6.8783702166518665, \"fact\": 6.514920639375976, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:42:00\", \"yhat\": 6.51678249837655, \"yhat_lower\": 6.072586159934022, \"yhat_upper\": 6.960978836819078, \"fact\": 6.698467040888667, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:43:00\", \"yhat\": 6.516783295718256, \"yhat_lower\": 6.003072379895382, \"yhat_upper\": 7.03049421154113, \"fact\": 6.759388401607078, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:44:00\", \"yhat\": 6.516783235880349, \"yhat_lower\": 5.941903933114492, \"yhat_upper\": 7.091662538646206, \"fact\": 6.716490662775344, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:45:00\", \"yhat\": 6.7151680066399955, \"yhat_lower\": 6.461906009888023, \"yhat_upper\": 6.968430003391968, \"fact\": 6.5987942999302085, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:46:00\", \"yhat\": 6.715278354532299, \"yhat_lower\": 6.352098642794707, \"yhat_upper\": 7.078458066269891, \"fact\": 6.65333830003684, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:47:00\", \"yhat\": 6.7152691483168585, \"yhat_lower\": 6.268780763763916, \"yhat_upper\": 7.161757532869801, \"fact\": 6.556226307271936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:48:00\", \"yhat\": 6.715269916382301, \"yhat_lower\": 6.198714292697794, \"yhat_upper\": 7.231825540066808, \"fact\": 6.631915596619567, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:49:00\", \"yhat\": 6.715269852303361, \"yhat_lower\": 6.137078341756499, \"yhat_upper\": 7.293461362850223, \"fact\": 6.7418854984709515, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:50:00\", \"yhat\": 6.7372070439716305, \"yhat_lower\": 6.485036258986656, \"yhat_upper\": 6.989377828956605, \"fact\": 6.90468821514332, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:51:00\", \"yhat\": 6.741697496775951, \"yhat_lower\": 6.380384793047463, \"yhat_upper\": 7.10301020050444, \"fact\": 6.92379664141639, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:52:00\", \"yhat\": 6.73738749089885, \"yhat_lower\": 6.296626057474203, \"yhat_upper\": 7.178148924323496, \"fact\": 6.946555214531447, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:53:00\", \"yhat\": 6.741524301031401, \"yhat_lower\": 6.2305487671795525, \"yhat_upper\": 7.252499834883249, \"fact\": 6.930459476706841, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:54:00\", \"yhat\": 6.737553726846411, \"yhat_lower\": 6.167515984802557, \"yhat_upper\": 7.307591468890265, \"fact\": 7.022422718896414, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:55:00\", \"yhat\": 7.025127179715844, \"yhat_lower\": 6.772290969883668, \"yhat_upper\": 7.27796338954802, \"fact\": 7.053346772430454, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:56:00\", \"yhat\": 7.025046233722833, \"yhat_lower\": 6.662245009736234, \"yhat_upper\": 7.387847457709432, \"fact\": 7.097472113550277, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:57:00\", \"yhat\": 7.025048656480721, \"yhat_lower\": 6.578720496461311, \"yhat_upper\": 7.471376816500132, \"fact\": 7.192623177672057, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:58:00\", \"yhat\": 7.025048583966251, \"yhat_lower\": 6.508525254586266, \"yhat_upper\": 7.541571913346236, \"fact\": 7.258527915260533, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:59:00\", \"yhat\": 7.025048586136649, \"yhat_lower\": 6.446789327113626, \"yhat_upper\": 7.603307845159673, \"fact\": 7.282872270839376, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:00:00\", \"yhat\": 7.283477784093431, \"yhat_lower\": 7.031459165457045, \"yhat_upper\": 7.535496402729816, \"fact\": 7.242022079132392, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:01:00\", \"yhat\": 7.2834359980198995, \"yhat_lower\": 6.921176028782994, \"yhat_upper\": 7.645695967256805, \"fact\": 7.261334072336341, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:02:00\", \"yhat\": 7.283438881649497, \"yhat_lower\": 6.837729743243464, \"yhat_upper\": 7.72914802005553, \"fact\": 7.264136729062933, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:03:00\", \"yhat\": 7.283438682652105, \"yhat_lower\": 6.767588614400614, \"yhat_upper\": 7.799288750903596, \"fact\": 7.286273159581655, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:04:00\", \"yhat\": 7.283438696384785, \"yhat_lower\": 6.705905538581739, \"yhat_upper\": 7.860971854187831, \"fact\": 7.357895750482174, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:05:00\", \"yhat\": 7.360161235850887, \"yhat_lower\": 7.109137204016968, \"yhat_upper\": 7.611185267684806, \"fact\": 7.330285522164443, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:06:00\", \"yhat\": 7.36001061469296, \"yhat_lower\": 6.9991709978394185, \"yhat_upper\": 7.720850231546501, \"fact\": 7.421393852719808, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:07:00\", \"yhat\": 7.360020628764791, \"yhat_lower\": 6.916043847915583, \"yhat_upper\": 7.803997409613999, \"fact\": 7.5620596009564744, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:08:00\", \"yhat\": 7.36001996297762, \"yhat_lower\": 6.846167585378935, \"yhat_upper\": 7.8738723405763045, \"fact\": 7.565735575531843, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:09:00\", \"yhat\": 7.3600200072425865, \"yhat_lower\": 6.7847184301832115, \"yhat_upper\": 7.9353215843019616, \"fact\": 7.58361194350413, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:10:00\", \"yhat\": 7.584280854622248, \"yhat_lower\": 7.333727651065556, \"yhat_upper\": 7.834834058178941, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:11:00\", \"yhat\": 7.584219188674755, \"yhat_lower\": 7.223745222504951, \"yhat_upper\": 7.9446931548445585, \"fact\": 7.610778235091248, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:12:00\", \"yhat\": 7.584224873569171, \"yhat_lower\": 7.14072136852975, \"yhat_upper\": 8.027728378608591, \"fact\": 7.521885308219655, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:13:00\", \"yhat\": 7.584224349486985, \"yhat_lower\": 7.070914456498682, \"yhat_upper\": 8.097534242475287, \"fact\": 7.716909631502675, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:14:00\", \"yhat\": 7.584224397801363, \"yhat_lower\": 7.009528610856101, \"yhat_upper\": 8.158920184746625, \"fact\": 7.747519051979066, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:15:00\", \"yhat\": 7.74787753137804, \"yhat_lower\": 7.497061983613828, \"yhat_upper\": 7.998693079142252, \"fact\": 7.785511706436309, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:16:00\", \"yhat\": 7.747855233865918, \"yhat_lower\": 7.387703886253121, \"yhat_upper\": 8.108006581478715, \"fact\": 7.930365226719392, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:17:00\", \"yhat\": 7.747856620776989, \"yhat_lower\": 7.304839634870624, \"yhat_upper\": 8.190873606683352, \"fact\": 7.967473463214496, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:18:00\", \"yhat\": 7.747856534510758, \"yhat_lower\": 7.23518279493787, \"yhat_upper\": 8.260530274083646, \"fact\": 7.999580916809377, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:19:00\", \"yhat\": 7.7478565398765395, \"yhat_lower\": 7.1739194983259695, \"yhat_upper\": 8.32179358142711, \"fact\": 7.92745812562292, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:20:00\", \"yhat\": 7.9250143526215835, \"yhat_lower\": 7.674640754605663, \"yhat_upper\": 8.175387950637504, \"fact\": 8.055342945626094, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:21:00\", \"yhat\": 7.925212633755637, \"yhat_lower\": 7.565354432256526, \"yhat_upper\": 8.285070835254746, \"fact\": 8.069067375478213, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:22:00\", \"yhat\": 7.925196545760516, \"yhat_lower\": 7.482512233159351, \"yhat_upper\": 8.36788085836168, \"fact\": 8.155734179368574, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:23:00\", \"yhat\": 7.925197851096942, \"yhat_lower\": 7.412881161109606, \"yhat_upper\": 8.437514541084278, \"fact\": 8.011806921777461, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:24:00\", \"yhat\": 7.925197745185474, \"yhat_lower\": 7.351642910519293, \"yhat_upper\": 8.498752579851654, \"fact\": 8.092111510811511, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:25:00\", \"yhat\": 8.094341676070655, \"yhat_lower\": 7.843806090677641, \"yhat_upper\": 8.34487726146367, \"fact\": 8.220078277501383, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:26:00\", \"yhat\": 8.094284665939771, \"yhat_lower\": 7.7354489592017375, \"yhat_upper\": 8.453120372677803, \"fact\": 8.267900885640357, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:27:00\", \"yhat\": 8.09428612330039, \"yhat_lower\": 7.653066731201085, \"yhat_upper\": 8.535505515399695, \"fact\": 8.340179387722713, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:28:00\", \"yhat\": 8.094286086045608, \"yhat_lower\": 7.583807709129626, \"yhat_upper\": 8.60476446296159, \"fact\": 8.360308596655782, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:29:00\", \"yhat\": 8.09428608699796, \"yhat_lower\": 7.522882779266974, \"yhat_upper\": 8.665689394728945, \"fact\": 8.356915788188523, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:30:00\", \"yhat\": 8.35677989846051, \"yhat_lower\": 8.10683156929266, \"yhat_upper\": 8.606728227628361, \"fact\": 8.288188793887379, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:31:00\", \"yhat\": 8.35678712117698, \"yhat_lower\": 7.998030768026832, \"yhat_upper\": 8.715543474327129, \"fact\": 8.371033308450802, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:32:00\", \"yhat\": 8.356786737280169, \"yhat_lower\": 7.915498189887397, \"yhat_upper\": 8.798075284672942, \"fact\": 8.296495018073724, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:33:00\", \"yhat\": 8.356786757684786, \"yhat_lower\": 7.846124640295601, \"yhat_upper\": 8.86744887507397, \"fact\": 8.267777641850003, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:34:00\", \"yhat\": 8.356786756600254, \"yhat_lower\": 7.7851090129793015, \"yhat_upper\": 8.928464500221207, \"fact\": 8.144346886350423, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:35:00\", \"yhat\": 8.14091634919591, \"yhat_lower\": 7.891281913911041, \"yhat_upper\": 8.39055078448078, \"fact\": 8.061674389304113, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:36:00\", \"yhat\": 8.141020221246304, \"yhat_lower\": 7.782986911851095, \"yhat_upper\": 8.499053530641513, \"fact\": 8.101904105964518, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:37:00\", \"yhat\": 8.141017076140344, \"yhat_lower\": 7.700620301292485, \"yhat_upper\": 8.581413850988202, \"fact\": 8.049382116624201, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:38:00\", \"yhat\": 8.14101717136992, \"yhat_lower\": 7.631395656975849, \"yhat_upper\": 8.650638685763992, \"fact\": 7.9510567258113305, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:39:00\", \"yhat\": 8.141017168486497, \"yhat_lower\": 7.570509713101261, \"yhat_upper\": 8.711524623871734, \"fact\": 7.962974507940454, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:40:00\", \"yhat\": 7.963560214730579, \"yhat_lower\": 7.7145512518722965, \"yhat_upper\": 8.212569177588861, \"fact\": 7.805239859715092, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:41:00\", \"yhat\": 7.963529376160262, \"yhat_lower\": 7.6060889238597955, \"yhat_upper\": 8.32096982846073, \"fact\": 7.663667118812604, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:43:00\", \"yhat\": 7.963530914377966, \"yhat_lower\": 7.4547186048484075, \"yhat_upper\": 8.472343223907524, \"fact\": 7.471366107835003, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:44:00\", \"yhat\": 7.963530918879247, \"yhat_lower\": 7.393918922586617, \"yhat_upper\": 8.533142915171876, \"fact\": 7.445667100893326, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:45:00\", \"yhat\": 7.44469112595848, \"yhat_lower\": 7.1952359229309, \"yhat_upper\": 7.69414632898606, \"fact\": 7.456711779886499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:46:00\", \"yhat\": 7.444652679123371, \"yhat_lower\": 7.08512565985799, \"yhat_upper\": 7.804179698388753, \"fact\": 7.444329373125276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:47:00\", \"yhat\": 7.44465116457717, \"yhat_lower\": 7.001385607952969, \"yhat_upper\": 7.887916721201371, \"fact\": 7.468336779368962, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:48:00\", \"yhat\": 7.444651104914256, \"yhat_lower\": 6.931117625668272, \"yhat_upper\": 7.95818458416024, \"fact\": 7.585589594686708, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:49:00\", \"yhat\": 7.44465110256394, \"yhat_lower\": 6.8693692459937505, \"yhat_upper\": 8.01993295913413, \"fact\": 7.750432747546225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:50:00\", \"yhat\": 7.757347648965532, \"yhat_lower\": 7.508058903025873, \"yhat_upper\": 8.006636394905192, \"fact\": 7.789461459883152, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:51:00\", \"yhat\": 7.757679352998595, \"yhat_lower\": 7.397694685800869, \"yhat_upper\": 8.11766402019632, \"fact\": 7.849428734659802, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:52:00\", \"yhat\": 7.757695264659352, \"yhat_lower\": 7.313518845693804, \"yhat_upper\": 8.2018716836249, \"fact\": 7.945508717131604, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:53:00\", \"yhat\": 7.757696027933002, \"yhat_lower\": 7.242905886748412, \"yhat_upper\": 8.272486169117592, \"fact\": 7.897018421083583, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:54:00\", \"yhat\": 7.7576960645468205, \"yhat_lower\": 7.180872273552947, \"yhat_upper\": 8.334519855540695, \"fact\": 7.790206365474418, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:55:00\", \"yhat\": 7.785450412115646, \"yhat_lower\": 7.536623833355443, \"yhat_upper\": 8.03427699087585, \"fact\": 7.839967858463782, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:56:00\", \"yhat\": 7.785160945242204, \"yhat_lower\": 7.4254055281859115, \"yhat_upper\": 8.144916362298495, \"fact\": 7.8667860803525524, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:57:00\", \"yhat\": 7.78514332709827, \"yhat_lower\": 7.340979419057152, \"yhat_upper\": 8.229307235139387, \"fact\": 7.7525973626559095, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:58:00\", \"yhat\": 7.785142254785601, \"yhat_lower\": 7.270204954101484, \"yhat_upper\": 8.300079555469718, \"fact\": 7.70504444156228, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:59:00\", \"yhat\": 7.7851421895202435, \"yhat_lower\": 7.208045523201257, \"yhat_upper\": 8.36223885583923, \"fact\": 7.801695429233526, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:00:00\", \"yhat\": 7.805945474674204, \"yhat_lower\": 7.557532697859198, \"yhat_upper\": 8.05435825148921, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:01:00\", \"yhat\": 7.8059507327521, \"yhat_lower\": 7.446978402169089, \"yhat_upper\": 8.164923063335111, \"fact\": 7.652667153528996, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:02:00\", \"yhat\": 7.805950739257297, \"yhat_lower\": 7.363209011596261, \"yhat_upper\": 8.248692466918333, \"fact\": 7.578881723592664, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:03:00\", \"yhat\": 7.805950739265345, \"yhat_lower\": 7.292940652416668, \"yhat_upper\": 8.318960826114022, \"fact\": 7.491151863279462, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:04:00\", \"yhat\": 7.805950739265355, \"yhat_lower\": 7.2311999576084505, \"yhat_upper\": 8.380701520922258, \"fact\": 7.503454922925876, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:05:00\", \"yhat\": 7.504214115415658, \"yhat_lower\": 7.256110106442083, \"yhat_upper\": 7.752318124389232, \"fact\": 7.599057949270826, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:06:00\", \"yhat\": 7.504201655900327, \"yhat_lower\": 7.145563482410016, \"yhat_upper\": 7.862839829390638, \"fact\": 7.540289550698573, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:07:00\", \"yhat\": 7.504201860380119, \"yhat_lower\": 7.061940915093566, \"yhat_upper\": 7.946462805666672, \"fact\": 7.709498641608279, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:08:00\", \"yhat\": 7.504201857024292, \"yhat_lower\": 6.9917863392763575, \"yhat_upper\": 8.016617374772226, \"fact\": 7.830648777977522, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:09:00\", \"yhat\": 7.504201857079366, \"yhat_lower\": 6.9301421414829285, \"yhat_upper\": 8.078261572675803, \"fact\": 7.833850854121761, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:10:00\", \"yhat\": 7.833693409943327, \"yhat_lower\": 7.585388290489109, \"yhat_upper\": 8.081998529397543, \"fact\": 7.896527014556835, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:11:00\", \"yhat\": 7.833695991055009, \"yhat_lower\": 7.474636410824233, \"yhat_upper\": 8.192755571285785, \"fact\": 7.740317372019487, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:12:00\", \"yhat\": 7.8336959487407265, \"yhat_lower\": 7.390866248229954, \"yhat_upper\": 8.276525649251498, \"fact\": 7.734078442460585, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:13:00\", \"yhat\": 7.83369594943442, \"yhat_lower\": 7.320593576168439, \"yhat_upper\": 8.3467983227004, \"fact\": 7.68652453910119, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:14:00\", \"yhat\": 7.833695949423047, \"yhat_lower\": 7.2588482113250405, \"yhat_upper\": 8.408543687521055, \"fact\": 7.654062933595664, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:15:00\", \"yhat\": 7.6527031421021405, \"yhat_lower\": 7.404706403658943, \"yhat_upper\": 7.900699880545338, \"fact\": 7.7323556114676295, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:16:00\", \"yhat\": 7.65266637708427, \"yhat_lower\": 7.294347054849067, \"yhat_upper\": 8.010985699319473, \"fact\": 7.823575479244249, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:17:00\", \"yhat\": 7.652665383059418, \"yhat_lower\": 7.210588571089591, \"yhat_upper\": 8.094742195029244, \"fact\": 7.961063693882232, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:18:00\", \"yhat\": 7.652665356183722, \"yhat_lower\": 7.14034211392129, \"yhat_upper\": 8.164988598446156, \"fact\": 7.66166136402624, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:19:00\", \"yhat\": 7.652665355457078, \"yhat_lower\": 7.078628413881239, \"yhat_upper\": 8.226702297032917, \"fact\": 7.735994319948233, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:20:00\", \"yhat\": 7.7390174192800005, \"yhat_lower\": 7.489109376725954, \"yhat_upper\": 7.9889254618340475, \"fact\": 7.8172661459687465, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:21:00\", \"yhat\": 7.738968244148513, \"yhat_lower\": 7.379535497383331, \"yhat_upper\": 8.098400990913694, \"fact\": 7.800477360464126, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:22:00\", \"yhat\": 7.738969044053938, \"yhat_lower\": 7.296409500688008, \"yhat_upper\": 8.18152858741987, \"fact\": 7.726932237108902, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:23:00\", \"yhat\": 7.7389690310423065, \"yhat_lower\": 7.226594996681524, \"yhat_upper\": 8.251343065403088, \"fact\": 7.811868370741103, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:24:00\", \"yhat\": 7.738969031253959, \"yhat_lower\": 7.1652135659064875, \"yhat_upper\": 8.312724496601431, \"fact\": 7.658004719265347, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:25:00\", \"yhat\": 7.6527683199757, \"yhat_lower\": 7.4029238432659366, \"yhat_upper\": 7.902612796685464, \"fact\": 7.670100990217529, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:26:00\", \"yhat\": 7.653253125423005, \"yhat_lower\": 7.294286490943151, \"yhat_upper\": 8.012219759902859, \"fact\": 7.45312553026062, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:27:00\", \"yhat\": 7.653208240319953, \"yhat_lower\": 7.211716357126987, \"yhat_upper\": 8.094700123512919, \"fact\": 7.57061971942359, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:28:00\", \"yhat\": 7.653212395950809, \"yhat_lower\": 7.14232301796495, \"yhat_upper\": 8.164101773936668, \"fact\": 7.584558764339831, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:29:00\", \"yhat\": 7.653212011206949, \"yhat_lower\": 7.081287536666198, \"yhat_upper\": 8.2251364857477, \"fact\": 7.736367838262079, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:30:00\", \"yhat\": 7.74031817189977, \"yhat_lower\": 7.489620213035748, \"yhat_upper\": 7.991016130763793, \"fact\": 7.883967912330481, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:31:00\", \"yhat\": 7.740434905871727, \"yhat_lower\": 7.381253515753026, \"yhat_upper\": 8.099616295990426, \"fact\": 7.9454144774542215, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:32:00\", \"yhat\": 7.740438355408261, \"yhat_lower\": 7.298542156911591, \"yhat_upper\": 8.182334553904932, \"fact\": 7.9815247789264765, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:33:00\", \"yhat\": 7.740438457343474, \"yhat_lower\": 7.229032394346596, \"yhat_upper\": 8.251844520340352, \"fact\": 7.828608211241088, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:34:00\", \"yhat\": 7.740438460355701, \"yhat_lower\": 7.167900113228994, \"yhat_upper\": 8.312976807482409, \"fact\": 7.8866167493939185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:35:00\", \"yhat\": 7.8881782856063145, \"yhat_lower\": 7.637376876376174, \"yhat_upper\": 8.138979694836456, \"fact\": 7.718286285065371, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:36:00\", \"yhat\": 7.88826673353236, \"yhat_lower\": 7.528397094261709, \"yhat_upper\": 8.248136372803012, \"fact\": 7.764341416031271, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:37:00\", \"yhat\": 7.888271743365343, \"yhat_lower\": 7.445187205471714, \"yhat_upper\": 8.331356281258973, \"fact\": 7.840706888425015, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:38:00\", \"yhat\": 7.888272027130352, \"yhat_lower\": 7.375286910767667, \"yhat_upper\": 8.401257143493037, \"fact\": 7.938059917879748, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:39:00\", \"yhat\": 7.888272043203259, \"yhat_lower\": 7.313829500143328, \"yhat_upper\": 8.462714586263191, \"fact\": 7.761060058402809, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:40:00\", \"yhat\": 7.756683374015198, \"yhat_lower\": 7.5052150282678, \"yhat_upper\": 8.008151719762596, \"fact\": 7.6946908748491, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:41:00\", \"yhat\": 7.756647060032067, \"yhat_lower\": 7.396632271384411, \"yhat_upper\": 8.116661848679723, \"fact\": 7.672013085482828, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:42:00\", \"yhat\": 7.756646758729699, \"yhat_lower\": 7.313915100296371, \"yhat_upper\": 8.199378417163027, \"fact\": 7.749640954645437, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:43:00\", \"yhat\": 7.75664675622975, \"yhat_lower\": 7.2443848960451955, \"yhat_upper\": 8.268908616414304, \"fact\": 7.74351636626246, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:44:00\", \"yhat\": 7.756646756209007, \"yhat_lower\": 7.183224479666816, \"yhat_upper\": 8.330069032751199, \"fact\": 7.758280802421245, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:45:00\", \"yhat\": 7.758673323332085, \"yhat_lower\": 7.507983280423414, \"yhat_upper\": 8.009363366240756, \"fact\": 7.9905599789244945, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:46:00\", \"yhat\": 7.758672843216749, \"yhat_lower\": 7.39947214975057, \"yhat_upper\": 8.117873536682927, \"fact\": 7.870475361188625, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:47:00\", \"yhat\": 7.758672843804006, \"yhat_lower\": 7.316857669848515, \"yhat_upper\": 8.200488017759497, \"fact\": 7.972400000133551, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:48:00\", \"yhat\": 7.7586728438032875, \"yhat_lower\": 7.247423234766146, \"yhat_upper\": 8.26992245284043, \"fact\": 8.089531300610558, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:49:00\", \"yhat\": 7.758672843803288, \"yhat_lower\": 7.186351537596924, \"yhat_upper\": 8.330994150009653, \"fact\": 8.097777022768552, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:50:00\", \"yhat\": 8.097971613555105, \"yhat_lower\": 7.84630905884594, \"yhat_upper\": 8.349634168264268, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:51:00\", \"yhat\": 8.097976908584714, \"yhat_lower\": 7.73814479368437, \"yhat_upper\": 8.457809023485058, \"fact\": 8.031589183895466, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:52:00\", \"yhat\": 8.097977052668302, \"yhat_lower\": 7.655595310649848, \"yhat_upper\": 8.540358794686755, \"fact\": 8.148437931838542, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:53:00\", \"yhat\": 8.097977056588975, \"yhat_lower\": 7.586189829598146, \"yhat_upper\": 8.609764283579805, \"fact\": 8.221370040659716, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:54:00\", \"yhat\": 8.097977056695662, \"yhat_lower\": 7.525132589987503, \"yhat_upper\": 8.670821523403822, \"fact\": 8.333189126475943, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:55:00\", \"yhat\": 8.336000947410634, \"yhat_lower\": 8.084449969116045, \"yhat_upper\": 8.587551925705222, \"fact\": 8.511437080644786, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:56:00\", \"yhat\": 8.336324835083964, \"yhat_lower\": 7.9763668632271765, \"yhat_upper\": 8.696282806940753, \"fact\": 8.530259401373554, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:57:00\", \"yhat\": 8.336362143016215, \"yhat_lower\": 7.893402480532579, \"yhat_upper\": 8.779321805499851, \"fact\": 8.464149676702108, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:58:00\", \"yhat\": 8.336366440437585, \"yhat_lower\": 7.823631272893781, \"yhat_upper\": 8.849101607981389, \"fact\": 8.510761154617697, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:59:00\", \"yhat\": 8.336366935448414, \"yhat_lower\": 7.762271024244416, \"yhat_upper\": 8.910462846652411, \"fact\": 8.588384748465963, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:00:00\", \"yhat\": 8.590606460246187, \"yhat_lower\": 8.339147803229634, \"yhat_upper\": 8.84206511726274, \"fact\": 8.596579830973859, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:01:00\", \"yhat\": 8.590969953979386, \"yhat_lower\": 8.230555773503506, \"yhat_upper\": 8.951384134455266, \"fact\": 8.665254766764672, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:02:00\", \"yhat\": 8.591029425102171, \"yhat_lower\": 8.147029387554538, \"yhat_upper\": 9.035029462649804, \"fact\": 8.571601855976125, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:03:00\", \"yhat\": 8.591039155158352, \"yhat_lower\": 8.076775318996848, \"yhat_upper\": 9.105302991319856, \"fact\": 8.483149022444422, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:04:00\", \"yhat\": 8.591040747090517, \"yhat_lower\": 8.01500787094247, \"yhat_upper\": 9.167073623238563, \"fact\": 8.392816789809771, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:05:00\", \"yhat\": 8.389850594527848, \"yhat_lower\": 8.138777236426531, \"yhat_upper\": 8.640923952629166, \"fact\": 8.289463311811762, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:06:00\", \"yhat\": 8.389366709801426, \"yhat_lower\": 8.029184119839424, \"yhat_upper\": 8.749549299763427, \"fact\": 8.293193709584163, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:07:00\", \"yhat\": 8.389287772170483, \"yhat_lower\": 7.945405660704092, \"yhat_upper\": 8.833169883636875, \"fact\": 8.201046712843748, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:08:00\", \"yhat\": 8.389274894827516, \"yhat_lower\": 7.875047021985941, \"yhat_upper\": 8.903502767669089, \"fact\": 8.074013353443654, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:09:00\", \"yhat\": 8.389272794106226, \"yhat_lower\": 7.813212500054001, \"yhat_upper\": 8.965333088158452, \"fact\": 8.060346196714583, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:10:00\", \"yhat\": 8.058937161999022, \"yhat_lower\": 7.808143416972668, \"yhat_upper\": 8.309730907025378, \"fact\": 8.129960019946706, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:11:00\", \"yhat\": 8.058598873118921, \"yhat_lower\": 7.698242349360891, \"yhat_upper\": 8.418955396876951, \"fact\": 8.093286965059585, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:12:00\", \"yhat\": 8.058517654845776, \"yhat_lower\": 7.613759015432909, \"yhat_upper\": 8.503276294258644, \"fact\": 8.207114051737939, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:13:00\", \"yhat\": 8.058498155511684, \"yhat_lower\": 7.542742951696224, \"yhat_upper\": 8.574253359327145, \"fact\": 8.174797102772132, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:14:00\", \"yhat\": 8.058493474003258, \"yhat_lower\": 7.480346227263013, \"yhat_upper\": 8.636640720743504, \"fact\": 8.244861920292358, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:15:00\", \"yhat\": 8.246892614491909, \"yhat_lower\": 7.996525775894294, \"yhat_upper\": 8.497259453089523, \"fact\": 8.004603702913197, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:16:00\", \"yhat\": 8.247386192360105, \"yhat_lower\": 7.887997559955304, \"yhat_upper\": 8.606774824764907, \"fact\": 7.962191492988927, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:17:00\", \"yhat\": 8.247506160749253, \"yhat_lower\": 7.804137694633451, \"yhat_upper\": 8.690874626865057, \"fact\": 7.82693977677464, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:18:00\", \"yhat\": 8.24753532010854, \"yhat_lower\": 7.733511803607085, \"yhat_upper\": 8.761558836609995, \"fact\": 7.780715623518733, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:20:00\", \"yhat\": 7.59623858516438, \"yhat_lower\": 7.344633151593722, \"yhat_upper\": 7.847844018735037, \"fact\": 7.7126592728826395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:21:00\", \"yhat\": 7.594418087949245, \"yhat_lower\": 7.23267192764706, \"yhat_upper\": 7.95616424825143, \"fact\": 7.7702415551012605, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:22:00\", \"yhat\": 7.5939129861509205, \"yhat_lower\": 7.147125757009206, \"yhat_upper\": 8.040700215292635, \"fact\": 7.755515291272416, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:23:00\", \"yhat\": 7.5937728443124435, \"yhat_lower\": 7.0753973201417875, \"yhat_upper\": 8.1121483684831, \"fact\": 7.893932649872157, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:24:00\", \"yhat\": 7.593733961586314, \"yhat_lower\": 7.01244155927682, \"yhat_upper\": 8.175026363895807, \"fact\": 7.9497835809896715, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:25:00\", \"yhat\": 7.952566801747894, \"yhat_lower\": 7.701134783110021, \"yhat_upper\": 8.203998820385767, \"fact\": 7.8758994800134285, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:26:00\", \"yhat\": 7.953324016617681, \"yhat_lower\": 7.592165394774707, \"yhat_upper\": 8.314482638460655, \"fact\": 7.882184263103129, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:27:00\", \"yhat\": 7.953530027713758, \"yhat_lower\": 7.507702294813531, \"yhat_upper\": 8.399357760613986, \"fact\": 8.064546783500113, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:28:00\", \"yhat\": 7.953586075968223, \"yhat_lower\": 7.436485927019855, \"yhat_upper\": 8.470686224916593, \"fact\": 8.081645734366429, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:29:00\", \"yhat\": 7.953601324694571, \"yhat_lower\": 7.373855332366786, \"yhat_upper\": 8.533347317022354, \"fact\": 8.172757664947504, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:30:00\", \"yhat\": 8.17608890268794, \"yhat_lower\": 7.924661754466152, \"yhat_upper\": 8.427516050909729, \"fact\": 8.098672806113793, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:31:00\", \"yhat\": 8.177064926023974, \"yhat_lower\": 7.8159681095646905, \"yhat_upper\": 8.538161742483256, \"fact\": 8.151170322208227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:32:00\", \"yhat\": 8.177350892270368, \"yhat_lower\": 7.731537986483442, \"yhat_upper\": 8.623163798057295, \"fact\": 8.26088485879859, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:33:00\", \"yhat\": 8.177434677863456, \"yhat_lower\": 7.660273263367266, \"yhat_upper\": 8.694596092359646, \"fact\": 8.191009434921096, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:34:00\", \"yhat\": 8.177459226304741, \"yhat_lower\": 7.597575618164689, \"yhat_upper\": 8.757342834444794, \"fact\": 8.194555208030412, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:35:00\", \"yhat\": 8.194369078645694, \"yhat_lower\": 7.943355707410617, \"yhat_upper\": 8.445382449880771, \"fact\": 8.360453709951065, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:36:00\", \"yhat\": 8.194315746980525, \"yhat_lower\": 7.834196314623494, \"yhat_upper\": 8.554435179337556, \"fact\": 8.396733578661529, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:37:00\", \"yhat\": 8.194300465854903, \"yhat_lower\": 7.749963676266971, \"yhat_upper\": 8.638637255442836, \"fact\": 8.457129588862593, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:38:00\", \"yhat\": 8.194296087352948, \"yhat_lower\": 7.679036179673822, \"yhat_upper\": 8.709555995032073, \"fact\": 8.320222281734633, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:39:00\", \"yhat\": 8.194294832780486, \"yhat_lower\": 7.616680029479724, \"yhat_upper\": 8.771909636081247, \"fact\": 8.38706323868159, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:40:00\", \"yhat\": 8.388105066596077, \"yhat_lower\": 8.136919047898676, \"yhat_upper\": 8.639291085293479, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:41:00\", \"yhat\": 8.388387172795701, \"yhat_lower\": 8.02827812277926, \"yhat_upper\": 8.748496222812141, \"fact\": 8.47380305154199, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:42:00\", \"yhat\": 8.388463561522437, \"yhat_lower\": 7.9443647664251875, \"yhat_upper\": 8.832562356619686, \"fact\": 8.471000521610067, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:43:00\", \"yhat\": 8.388484246064571, \"yhat_lower\": 7.873673229011009, \"yhat_upper\": 8.903295263118133, \"fact\": 8.583404963654896, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:44:00\", \"yhat\": 8.388489847025625, \"yhat_lower\": 7.811508128008471, \"yhat_upper\": 8.965471566042778, \"fact\": 8.531063469573645, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:45:00\", \"yhat\": 8.530281518573727, \"yhat_lower\": 8.279453522286037, \"yhat_upper\": 8.781109514861416, \"fact\": 8.471403101314356, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:46:00\", \"yhat\": 8.530104147694015, \"yhat_lower\": 8.170648628888824, \"yhat_upper\": 8.889559666499206, \"fact\": 8.409649600014262, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:47:00\", \"yhat\": 8.53006391444542, \"yhat_lower\": 8.08702825744653, \"yhat_upper\": 8.973099571444308, \"fact\": 8.370469524136148, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:48:00\", \"yhat\": 8.530054788289563, \"yhat_lower\": 8.016702870692871, \"yhat_upper\": 9.043406705886255, \"fact\": 8.48614212062726, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:49:00\", \"yhat\": 8.530052718192724, \"yhat_lower\": 7.954883149125969, \"yhat_upper\": 9.10522228725948, \"fact\": 8.64617716198996, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:50:00\", \"yhat\": 8.651398057014003, \"yhat_lower\": 8.400587818186933, \"yhat_upper\": 8.902208295841072, \"fact\": 8.53530065692971, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:51:00\", \"yhat\": 8.652412414630717, \"yhat_lower\": 8.292465451911058, \"yhat_upper\": 9.012359377350377, \"fact\": 8.526391763137674, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:52:00\", \"yhat\": 8.652609492214129, \"yhat_lower\": 8.208808766183328, \"yhat_upper\": 9.09641021824493, \"fact\": 8.4747311830338, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:53:00\", \"yhat\": 8.652647782037405, \"yhat_lower\": 8.138351330354315, \"yhat_upper\": 9.166944233720496, \"fact\": 8.369368219481078, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:54:00\", \"yhat\": 8.652655221293262, \"yhat_lower\": 8.076399474149184, \"yhat_upper\": 9.22891096843734, \"fact\": 8.560972818522371, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:55:00\", \"yhat\": 8.565238578996546, \"yhat_lower\": 8.314087646341852, \"yhat_upper\": 8.81638951165124, \"fact\": 8.506389603340054, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:56:00\", \"yhat\": 8.565927499078633, \"yhat_lower\": 8.20641916274409, \"yhat_upper\": 8.925435835413175, \"fact\": 8.481984739041978, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:57:00\", \"yhat\": 8.566038759634019, \"yhat_lower\": 8.123407871295697, \"yhat_upper\": 9.00866964797234, \"fact\": 8.485287372932227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:58:00\", \"yhat\": 8.566056728207597, \"yhat_lower\": 8.053533627844017, \"yhat_upper\": 9.078579828571177, \"fact\": 8.509799875799924, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:59:00\", \"yhat\": 8.566059630131242, \"yhat_lower\": 7.992081411314299, \"yhat_upper\": 9.140037848948186, \"fact\": 8.462839177620474, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:00:00\", \"yhat\": 8.461853030083159, \"yhat_lower\": 8.21146217708092, \"yhat_upper\": 8.712243883085398, \"fact\": 8.500847291856171, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:01:00\", \"yhat\": 8.46169021953827, \"yhat_lower\": 8.103546412972372, \"yhat_upper\": 8.819834026104166, \"fact\": 8.407545286261158, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:02:00\", \"yhat\": 8.461663339915775, \"yhat_lower\": 8.020846612376905, \"yhat_upper\": 8.902480067454645, \"fact\": 8.435490902768226, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:03:00\", \"yhat\": 8.461658902155888, \"yhat_lower\": 7.951314539604307, \"yhat_upper\": 8.972003264707467, \"fact\": 8.405689339518776, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:04:00\", \"yhat\": 8.46165816949259, \"yhat_lower\": 7.890171955685458, \"yhat_upper\": 9.033144383299723, \"fact\": 8.404404408484888, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:05:00\", \"yhat\": 8.404303156957047, \"yhat_lower\": 8.154565127931654, \"yhat_upper\": 8.65404118598244, \"fact\": 8.370573940680746, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:06:00\", \"yhat\": 8.404288480696254, \"yhat_lower\": 8.047285505828318, \"yhat_upper\": 8.761291455564189, \"fact\": 8.356621268629302, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:07:00\", \"yhat\": 8.404286353393728, \"yhat_lower\": 7.965047014611288, \"yhat_upper\": 8.843525692176167, \"fact\": 8.273825661013671, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:08:00\", \"yhat\": 8.404286045044339, \"yhat_lower\": 7.895887516119246, \"yhat_upper\": 8.91268457396943, \"fact\": 8.417744225285109, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:09:00\", \"yhat\": 8.404286000349547, \"yhat_lower\": 7.835062572264436, \"yhat_upper\": 8.973509428434658, \"fact\": 8.333018409415137, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:10:00\", \"yhat\": 8.331671347877455, \"yhat_lower\": 8.082108194943032, \"yhat_upper\": 8.581234500811878, \"fact\": 8.395519857078213, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:11:00\", \"yhat\": 8.331557323685972, \"yhat_lower\": 7.975458709976184, \"yhat_upper\": 8.68765593739576, \"fact\": 8.329430969980034, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:12:00\", \"yhat\": 8.331547671924803, \"yhat_lower\": 7.893915023520018, \"yhat_upper\": 8.769180320329587, \"fact\": 8.393907016426743, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:13:00\", \"yhat\": 8.331546854935947, \"yhat_lower\": 7.825330810775263, \"yhat_upper\": 8.837762899096631, \"fact\": 8.505097929522941, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:14:00\", \"yhat\": 8.331546785780612, \"yhat_lower\": 7.764988398489146, \"yhat_upper\": 8.898105173072077, \"fact\": 8.511009348963547, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:15:00\", \"yhat\": 8.511117418173919, \"yhat_lower\": 8.261952078469244, \"yhat_upper\": 8.760282757878594, \"fact\": 8.485964064563397, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:16:00\", \"yhat\": 8.511119905543465, \"yhat_lower\": 8.155882034561955, \"yhat_upper\": 8.866357776524975, \"fact\": 8.532367389569465, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:17:00\", \"yhat\": 8.511119962793881, \"yhat_lower\": 8.074826980858639, \"yhat_upper\": 8.947412944729123, \"fact\": 8.527169421117446, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:18:00\", \"yhat\": 8.511119964111582, \"yhat_lower\": 8.006629855041025, \"yhat_upper\": 9.01561007318214, \"fact\": 8.770144851734896, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:19:00\", \"yhat\": 8.511119964141912, \"yhat_lower\": 7.946612214735361, \"yhat_upper\": 9.075627713548462, \"fact\": 8.941922134099055, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:20:00\", \"yhat\": 8.946517099857603, \"yhat_lower\": 8.696585584680863, \"yhat_upper\": 9.196448615034344, \"fact\": 8.83656128758854, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:21:00\", \"yhat\": 8.94714653039474, \"yhat_lower\": 8.58959553017276, \"yhat_upper\": 9.30469753061672, \"fact\": 8.75134541259338, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:22:00\", \"yhat\": 8.947232751450978, \"yhat_lower\": 8.507205912179195, \"yhat_upper\": 9.38725959072276, \"fact\": 8.663598406050742, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:23:00\", \"yhat\": 8.947244562238826, \"yhat_lower\": 8.437872447497893, \"yhat_upper\": 9.456616676979758, \"fact\": 8.672674873252237, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:24:00\", \"yhat\": 8.947246180111717, \"yhat_lower\": 8.376892011105607, \"yhat_upper\": 9.517600349117828, \"fact\": 8.52103640042284, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:25:00\", \"yhat\": 8.517791959361817, \"yhat_lower\": 8.267809029740594, \"yhat_upper\": 8.767774888983041, \"fact\": 8.52272103376713, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:26:00\", \"yhat\": 8.517577996651394, \"yhat_lower\": 8.16024108416056, \"yhat_upper\": 8.874914909142227, \"fact\": 8.645248319087003, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:27:00\", \"yhat\": 8.51756388634993, \"yhat_lower\": 8.078168401075331, \"yhat_upper\": 8.956959371624528, \"fact\": 8.674972483541307, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:28:00\", \"yhat\": 8.517562955811112, \"yhat_lower\": 8.009174295915642, \"yhat_upper\": 9.025951615706582, \"fact\": 8.76474826986135, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:29:00\", \"yhat\": 8.517562894444422, \"yhat_lower\": 7.948484295084365, \"yhat_upper\": 9.08664149380448, \"fact\": 8.811453323118272, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:30:00\", \"yhat\": 8.812672565340371, \"yhat_lower\": 8.56308253291425, \"yhat_upper\": 9.062262597766493, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:31:00\", \"yhat\": 8.812783960024724, \"yhat_lower\": 8.455728873971168, \"yhat_upper\": 9.16983904607828, \"fact\": 8.485875363354573, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:32:00\", \"yhat\": 8.812794137473862, \"yhat_lower\": 8.373533920020062, \"yhat_upper\": 9.252054354927662, \"fact\": 8.399451833349502, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:33:00\", \"yhat\": 8.812795067324972, \"yhat_lower\": 8.304429784616298, \"yhat_upper\": 9.321160350033646, \"fact\": 8.457620981862641, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:34:00\", \"yhat\": 8.812795152279765, \"yhat_lower\": 8.243652619195817, \"yhat_upper\": 9.381937685363713, \"fact\": 8.612568848026724, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:35:00\", \"yhat\": 8.616870602504287, \"yhat_lower\": 8.366417592312342, \"yhat_upper\": 8.867323612696232, \"fact\": 8.514394842156392, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:36:00\", \"yhat\": 8.617341531865693, \"yhat_lower\": 8.258325857382232, \"yhat_upper\": 8.976357206349153, \"fact\": 8.387880106011288, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:37:00\", \"yhat\": 8.617393086287171, \"yhat_lower\": 8.17530730991868, \"yhat_upper\": 9.059478862655663, \"fact\": 8.223871883913581, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:39:00\", \"yhat\": 8.617399347999527, \"yhat_lower\": 8.044142548857764, \"yhat_upper\": 9.19065614714129, \"fact\": 8.05572889460056, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:40:00\", \"yhat\": 8.053720005320836, \"yhat_lower\": 7.802923173467119, \"yhat_upper\": 8.304516837174551, \"fact\": 7.956979270891584, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:41:00\", \"yhat\": 8.053406962489992, \"yhat_lower\": 7.692859923036228, \"yhat_upper\": 8.413954001943756, \"fact\": 7.811500666817628, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:42:00\", \"yhat\": 8.05335818139741, \"yhat_lower\": 7.608661258631887, \"yhat_upper\": 8.498055104162933, \"fact\": 7.690415462062634, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:43:00\", \"yhat\": 8.053350579897682, \"yhat_lower\": 7.5379666186322, \"yhat_upper\": 8.568734541163163, \"fact\": 7.717134221024015, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:44:00\", \"yhat\": 8.053349395365005, \"yhat_lower\": 7.475852963172992, \"yhat_upper\": 8.63084582755702, \"fact\": 7.835378833401439, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:45:00\", \"yhat\": 7.839783257065222, \"yhat_lower\": 7.588813876893046, \"yhat_upper\": 8.090752637237397, \"fact\": 7.711894191123989, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:46:00\", \"yhat\": 7.84073273029625, \"yhat_lower\": 7.47913649730015, \"yhat_upper\": 8.20232896329235, \"fact\": 7.7229591895282015, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:47:00\", \"yhat\": 7.840937410746011, \"yhat_lower\": 7.394203136655246, \"yhat_upper\": 8.287671684836775, \"fact\": 7.669836539613878, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:48:00\", \"yhat\": 7.84098153425065, \"yhat_lower\": 7.322696524354954, \"yhat_upper\": 8.359266544146347, \"fact\": 7.717692584250162, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:49:00\", \"yhat\": 7.840991046070973, \"yhat_lower\": 7.25985730355874, \"yhat_upper\": 8.422124788583204, \"fact\": 7.761794676176121, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:50:00\", \"yhat\": 7.763574752062494, \"yhat_lower\": 7.5130182366002005, \"yhat_upper\": 8.014131267524787, \"fact\": 7.780476902942309, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:51:00\", \"yhat\": 7.763961413494715, \"yhat_lower\": 7.403386068982599, \"yhat_upper\": 8.124536758006832, \"fact\": 7.977593528807279, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:52:00\", \"yhat\": 7.764045402646139, \"yhat_lower\": 7.318804986121937, \"yhat_upper\": 8.209285819170342, \"fact\": 7.918981702230322, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:53:00\", \"yhat\": 7.764063646455759, \"yhat_lower\": 7.247653793526038, \"yhat_upper\": 8.28047349938548, \"fact\": 8.014169824247498, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:54:00\", \"yhat\": 7.7640676093079115, \"yhat_lower\": 7.185132264585387, \"yhat_upper\": 8.343002954030435, \"fact\": 8.002420669187153, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:55:00\", \"yhat\": 8.002646764243062, \"yhat_lower\": 7.751982074920538, \"yhat_upper\": 8.253311453565585, \"fact\": 8.151076376650083, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:56:00\", \"yhat\": 8.002699974271932, \"yhat_lower\": 7.642213311730124, \"yhat_upper\": 8.36318663681374, \"fact\": 7.979406800773713, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:57:00\", \"yhat\": 8.002712496912736, \"yhat_lower\": 7.557631057187925, \"yhat_upper\": 8.447793936637545, \"fact\": 7.92353421269369, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:58:00\", \"yhat\": 8.002715444036351, \"yhat_lower\": 7.486491025602734, \"yhat_upper\": 8.518939862469967, \"fact\": 8.068779742758723, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:59:00\", \"yhat\": 8.002716137623091, \"yhat_lower\": 7.42398032879753, \"yhat_upper\": 8.581451946448652, \"fact\": 8.078786779675173, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:00:00\", \"yhat\": 8.079744277284977, \"yhat_lower\": 7.828545228504787, \"yhat_upper\": 8.330943326065167, \"fact\": 8.191788462425002, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:01:00\", \"yhat\": 8.079933005514029, \"yhat_lower\": 7.7193378970676845, \"yhat_upper\": 8.440528113960374, \"fact\": 8.000415544530842, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:02:00\", \"yhat\": 8.079970204922233, \"yhat_lower\": 7.6353082001872155, \"yhat_upper\": 8.52463220965725, \"fact\": 8.071115630032562, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:03:00\", \"yhat\": 8.079977537137333, \"yhat_lower\": 7.564641162923976, \"yhat_upper\": 8.595313911350692, \"fact\": 8.081479750948631, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:04:00\", \"yhat\": 8.079978982358664, \"yhat_lower\": 7.50252872288446, \"yhat_upper\": 8.657429241832869, \"fact\": 8.098170821285184, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:05:00\", \"yhat\": 8.098602250947065, \"yhat_lower\": 7.84724639497471, \"yhat_upper\": 8.34995810691942, \"fact\": 8.267139845953881, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:06:00\", \"yhat\": 8.098627646003948, \"yhat_lower\": 7.738648008308724, \"yhat_upper\": 8.458607283699171, \"fact\": 8.212596119789714, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:07:00\", \"yhat\": 8.098629140822156, \"yhat_lower\": 7.655703306274004, \"yhat_upper\": 8.541554975370309, \"fact\": 8.230590163089623, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:08:00\", \"yhat\": 8.098629228810992, \"yhat_lower\": 7.585996238219318, \"yhat_upper\": 8.611262219402667, \"fact\": 8.318860440882997, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:09:00\", \"yhat\": 8.098629233990241, \"yhat_lower\": 7.524693228600985, \"yhat_upper\": 8.672565239379496, \"fact\": 8.392351095262217, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:10:00\", \"yhat\": 8.39441334506416, \"yhat_lower\": 8.14309072558311, \"yhat_upper\": 8.64573596454521, \"fact\": 8.398247511408044, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:11:00\", \"yhat\": 8.394664127788591, \"yhat_lower\": 8.034751005204415, \"yhat_upper\": 8.754577250372767, \"fact\": 8.545377931691302, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:12:00\", \"yhat\": 8.394694624566824, \"yhat_lower\": 7.951628261999314, \"yhat_upper\": 8.837760987134335, \"fact\": 8.553662460728718, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:13:00\", \"yhat\": 8.394698333169499, \"yhat_lower\": 7.881739877053193, \"yhat_upper\": 8.907656789285806, \"fact\": 8.539053365383428, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:14:00\", \"yhat\": 8.39469878415923, \"yhat_lower\": 7.820285326748267, \"yhat_upper\": 8.969112241570192, \"fact\": 8.738610081903111, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:15:00\", \"yhat\": 8.743675396416167, \"yhat_lower\": 8.492133606051246, \"yhat_upper\": 8.995217186781089, \"fact\": 8.789728699261456, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:16:00\", \"yhat\": 8.744877036577897, \"yhat_lower\": 8.384570792346729, \"yhat_upper\": 9.105183280809065, \"fact\": 8.672292432735887, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:17:00\", \"yhat\": 8.745162100629608, \"yhat_lower\": 8.301138762316905, \"yhat_upper\": 9.189185438942312, \"fact\": 8.583695199589734, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:18:00\", \"yhat\": 8.745229726126963, \"yhat_lower\": 8.230758470421389, \"yhat_upper\": 9.259700981832538, \"fact\": 8.545572696616933, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:19:00\", \"yhat\": 8.745245768864955, \"yhat_lower\": 8.168835139241754, \"yhat_upper\": 9.321656398488155, \"fact\": 8.53469919243193, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:20:00\", \"yhat\": 8.534102767438169, \"yhat_lower\": 8.282929426256112, \"yhat_upper\": 8.785276108620225, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:21:00\", \"yhat\": 8.533973318153501, \"yhat_lower\": 8.173913275985608, \"yhat_upper\": 8.894033360321394, \"fact\": 8.619454458907168, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:22:00\", \"yhat\": 8.533945222219433, \"yhat_lower\": 8.090139877443274, \"yhat_upper\": 8.977750566995592, \"fact\": 8.64014873041566, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:23:00\", \"yhat\": 8.533939124221185, \"yhat_lower\": 8.019692396537994, \"yhat_upper\": 9.048185851904375, \"fact\": 8.773110778116337, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:24:00\", \"yhat\": 8.533937800699334, \"yhat_lower\": 7.957767350120923, \"yhat_upper\": 9.110108251277746, \"fact\": 8.842045243191007, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:25:00\", \"yhat\": 8.844745836593091, \"yhat_lower\": 8.593799696890654, \"yhat_upper\": 9.095691976295528, \"fact\": 8.779304562733579, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:26:00\", \"yhat\": 8.84531819053351, \"yhat_lower\": 8.48530969842997, \"yhat_upper\": 9.205326682637049, \"fact\": 8.715667021210756, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:27:00\", \"yhat\": 8.84543949314532, \"yhat_lower\": 8.401562450440956, \"yhat_upper\": 9.289316535849686, \"fact\": 8.95869877998149, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:28:00\", \"yhat\": 8.845465201579549, \"yhat_lower\": 8.331057517841174, \"yhat_upper\": 9.359872885317923, \"fact\": 9.131002557332641, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:29:00\", \"yhat\": 8.845470650131567, \"yhat_lower\": 8.269068642710293, \"yhat_upper\": 9.421872657552841, \"fact\": 9.110278629189814, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:30:00\", \"yhat\": 9.110690355057125, \"yhat_lower\": 8.858932411825945, \"yhat_upper\": 9.362448298288305, \"fact\": 9.026194022516984, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:31:00\", \"yhat\": 9.11077016020162, \"yhat_lower\": 8.749341523635154, \"yhat_upper\": 9.472198796768085, \"fact\": 8.996799590069418, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:32:00\", \"yhat\": 9.110785628894732, \"yhat_lower\": 8.665092960717743, \"yhat_upper\": 9.55647829707172, \"fact\": 8.89038427307193, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:33:00\", \"yhat\": 9.110788627203526, \"yhat_lower\": 8.594260233503922, \"yhat_upper\": 9.62731702090313, \"fact\": 8.845887105325563, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:34:00\", \"yhat\": 9.110789208368047, \"yhat_lower\": 8.532006020542033, \"yhat_upper\": 9.68957239619406, \"fact\": 8.940727418078595, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:35:00\", \"yhat\": 8.943460801790058, \"yhat_lower\": 8.692001612227486, \"yhat_upper\": 9.19491999135263, \"fact\": 8.890937823525107, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:36:00\", \"yhat\": 8.943867709521834, \"yhat_lower\": 8.582689103026603, \"yhat_upper\": 9.305046316017066, \"fact\": 8.689691616597951, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:37:00\", \"yhat\": 8.94392828422325, \"yhat_lower\": 8.498650699309442, \"yhat_upper\": 9.38920586913706, \"fact\": 8.859131071315861, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:38:00\", \"yhat\": 8.943937301733033, \"yhat_lower\": 8.428006688605166, \"yhat_upper\": 9.4598679148609, \"fact\": 8.75225132967224, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:39:00\", \"yhat\": 8.943938644133091, \"yhat_lower\": 8.365916075698298, \"yhat_upper\": 9.521961212567884, \"fact\": 8.745441955414979, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:40:00\", \"yhat\": 8.744949007641312, \"yhat_lower\": 8.492846045473566, \"yhat_upper\": 8.997051969809057, \"fact\": 8.792889390472723, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:41:00\", \"yhat\": 8.744860429561502, \"yhat_lower\": 8.38393151365433, \"yhat_upper\": 9.105789345468674, \"fact\": 8.787700796349098, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:42:00\", \"yhat\": 8.744844512913447, \"yhat_lower\": 8.30036839845512, \"yhat_upper\": 9.189320627371774, \"fact\": 8.865140236693664, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:43:00\", \"yhat\": 8.744841652841455, \"yhat_lower\": 8.23010673642605, \"yhat_upper\": 9.25957656925686, \"fact\": 8.873378150594053, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:44:00\", \"yhat\": 8.74484113891341, \"yhat_lower\": 8.168331215749516, \"yhat_upper\": 9.321351062077303, \"fact\": 9.0222393846978, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:45:00\", \"yhat\": 9.026010895737457, \"yhat_lower\": 8.774193562332592, \"yhat_upper\": 9.277828229142322, \"fact\": 9.065340509014483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:46:00\", \"yhat\": 9.026796644448252, \"yhat_lower\": 8.666257278681334, \"yhat_upper\": 9.38733601021517, \"fact\": 9.08761005037332, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:47:00\", \"yhat\": 9.026960345688956, \"yhat_lower\": 8.582849633651739, \"yhat_upper\": 9.471071057726173, \"fact\": 9.21261808729404, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:48:00\", \"yhat\": 9.026994450862581, \"yhat_lower\": 8.512582340607306, \"yhat_upper\": 9.541406561117856, \"fact\": 9.171105600168334, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:49:00\", \"yhat\": 9.027001556263023, \"yhat_lower\": 8.450777243492661, \"yhat_upper\": 9.603225869033386, \"fact\": 9.2291796823891, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:50:00\", \"yhat\": 9.230566387839685, \"yhat_lower\": 8.979153553287873, \"yhat_upper\": 9.481979222391498, \"fact\": 9.306666947502116, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:51:00\", \"yhat\": 9.230942816102184, \"yhat_lower\": 8.870968476736696, \"yhat_upper\": 9.590917155467672, \"fact\": 9.262624362293195, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:52:00\", \"yhat\": 9.231044999472667, \"yhat_lower\": 8.787393052521605, \"yhat_upper\": 9.67469694642373, \"fact\": 9.242218868074156, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:53:00\", \"yhat\": 9.231072737669406, \"yhat_lower\": 8.716961485970835, \"yhat_upper\": 9.745183989367977, \"fact\": 9.33795232275775, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:54:00\", \"yhat\": 9.23108026734429, \"yhat_lower\": 8.655008801490633, \"yhat_upper\": 9.807151733197946, \"fact\": 9.323311197520256, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:55:00\", \"yhat\": 9.323541233218217, \"yhat_lower\": 9.072606227893077, \"yhat_upper\": 9.574476238543356, \"fact\": 9.224541361617664, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:56:00\", \"yhat\": 9.32360950944532, \"yhat_lower\": 8.964446235838071, \"yhat_upper\": 9.68277278305257, \"fact\": 9.235951852873002, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:57:00\", \"yhat\": 9.323629774313899, \"yhat_lower\": 8.880966473090659, \"yhat_upper\": 9.766293075537138, \"fact\": 9.183230028411051, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:58:00\", \"yhat\": 9.323635789070659, \"yhat_lower\": 8.81062660425546, \"yhat_upper\": 9.836644973885857, \"fact\": 9.303308572775062, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:59:00\", \"yhat\": 9.323637574293135, \"yhat_lower\": 8.748756886960502, \"yhat_upper\": 9.89851826162577, \"fact\": 9.41516862839868, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:00:00\", \"yhat\": 9.41858998307072, \"yhat_lower\": 9.167787202888528, \"yhat_upper\": 9.669392763252914, \"fact\": 9.344349304080247, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:01:00\", \"yhat\": 9.419512424886916, \"yhat_lower\": 9.060397287501697, \"yhat_upper\": 9.778627562272135, \"fact\": 9.418666704403686, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:02:00\", \"yhat\": 9.41976112722439, \"yhat_lower\": 8.977165992843851, \"yhat_upper\": 9.86235626160493, \"fact\": 9.318795523294629, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:03:00\", \"yhat\": 9.419828180616355, \"yhat_lower\": 8.906942778294876, \"yhat_upper\": 9.932713582937833, \"fact\": 9.361514185397724, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:04:00\", \"yhat\": 9.419846259084855, \"yhat_lower\": 8.845150134650629, \"yhat_upper\": 9.99454238351908, \"fact\": 9.455447864087226, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:05:00\", \"yhat\": 9.457644272408771, \"yhat_lower\": 9.207078435092633, \"yhat_upper\": 9.70821010972491, \"fact\": 9.401919535507847, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:06:00\", \"yhat\": 9.458264958988194, \"yhat_lower\": 9.099976514728732, \"yhat_upper\": 9.816553403247655, \"fact\": 9.38713489217632, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:07:00\", \"yhat\": 9.458440359812391, \"yhat_lower\": 9.01712244065381, \"yhat_upper\": 9.899758278970971, \"fact\": 9.455945295107508, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:08:00\", \"yhat\": 9.458489926614943, \"yhat_lower\": 8.947236214113317, \"yhat_upper\": 9.969743639116569, \"fact\": 9.609159720517681, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:09:00\", \"yhat\": 9.458503933777832, \"yhat_lower\": 8.885735480856829, \"yhat_upper\": 10.031272386698836, \"fact\": 9.614996053596242, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:10:00\", \"yhat\": 9.616088217243465, \"yhat_lower\": 9.365781117766849, \"yhat_upper\": 9.866395316720082, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:11:00\", \"yhat\": 9.616387060292897, \"yhat_lower\": 9.25837327373383, \"yhat_upper\": 9.974400846851966, \"fact\": 9.556691781795077, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:12:00\", \"yhat\": 9.616468831159764, \"yhat_lower\": 9.175459036775093, \"yhat_upper\": 10.057478625544436, \"fact\": 9.643000959964645, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:13:00\", \"yhat\": 9.6164912056961, \"yhat_lower\": 9.105586202743877, \"yhat_upper\": 10.127396208648323, \"fact\": 9.718788895128835, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:14:00\", \"yhat\": 9.616497327923923, \"yhat_lower\": 9.044118031182697, \"yhat_upper\": 10.18887662466515, \"fact\": 9.638302318559198, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:15:00\", \"yhat\": 9.637248300556097, \"yhat_lower\": 9.387190567175672, \"yhat_upper\": 9.887306033936522, \"fact\": 9.86400121471953, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:16:00\", \"yhat\": 9.63691171049266, \"yhat_lower\": 9.279604973051503, \"yhat_upper\": 9.994218447933816, \"fact\": 9.832149494497711, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:17:00\", \"yhat\": 9.636804223836387, \"yhat_lower\": 9.196744937096742, \"yhat_upper\": 10.076863510576032, \"fact\": 9.8378481484009, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:18:00\", \"yhat\": 9.636769899052231, \"yhat_lower\": 9.126958969694, \"yhat_upper\": 10.146580828410462, \"fact\": 9.86632383278163, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:19:00\", \"yhat\": 9.636758937777145, \"yhat_lower\": 9.065576979596988, \"yhat_upper\": 10.207940895957302, \"fact\": 9.892267601353337, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:20:00\", \"yhat\": 9.892984523085198, \"yhat_lower\": 9.64280468249078, \"yhat_upper\": 10.143164363679617, \"fact\": 9.931774604936024, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:21:00\", \"yhat\": 9.89328320847738, \"yhat_lower\": 9.536409963818917, \"yhat_upper\": 10.250156453135842, \"fact\": 9.954188808547201, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:22:00\", \"yhat\": 9.893407647393843, \"yhat_lower\": 9.454037955598052, \"yhat_upper\": 10.332777339189635, \"fact\": 9.817695310369409, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:23:00\", \"yhat\": 9.893459491388683, \"yhat_lower\": 9.384423560043343, \"yhat_upper\": 10.402495422734022, \"fact\": 9.84172254699343, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:24:00\", \"yhat\": 9.89348109073941, \"yhat_lower\": 9.323086478592941, \"yhat_upper\": 10.463875702885879, \"fact\": 9.80607724404463, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:25:00\", \"yhat\": 9.805327324638462, \"yhat_lower\": 9.55552968404251, \"yhat_upper\": 10.055124965234414, \"fact\": 9.634992469023846, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:26:00\", \"yhat\": 9.805017266543171, \"yhat_lower\": 9.448781795960567, \"yhat_upper\": 10.161252737125775, \"fact\": 9.719664071742129, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:27:00\", \"yhat\": 9.804889071404247, \"yhat_lower\": 9.366380800741975, \"yhat_upper\": 10.243397342066519, \"fact\": 9.803939082783222, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:28:00\", \"yhat\": 9.804836068454499, \"yhat_lower\": 9.296858438211332, \"yhat_upper\": 10.312813698697665, \"fact\": 9.800414529471565, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:29:00\", \"yhat\": 9.804814154108092, \"yhat_lower\": 9.235652792535912, \"yhat_upper\": 10.373975515680272, \"fact\": 9.82701899851565, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:30:00\", \"yhat\": 9.827654759040891, \"yhat_lower\": 9.577891573116228, \"yhat_upper\": 10.077417944965555, \"fact\": 9.77933964253321, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:31:00\", \"yhat\": 9.827946976327457, \"yhat_lower\": 9.472019995620055, \"yhat_upper\": 10.183873957034859, \"fact\": 9.756520180732126, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:32:00\", \"yhat\": 9.828081289389024, \"yhat_lower\": 9.390041361512932, \"yhat_upper\": 10.266121217265116, \"fact\": 9.850925560836, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:33:00\", \"yhat\": 9.828143024266927, \"yhat_lower\": 9.320711972003341, \"yhat_upper\": 10.335574076530513, \"fact\": 9.804925591815215, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:34:00\", \"yhat\": 9.828171399728742, \"yhat_lower\": 9.259591128449685, \"yhat_upper\": 10.396751671007799, \"fact\": 9.619049334366524, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:35:00\", \"yhat\": 9.61612180040592, \"yhat_lower\": 9.36633592067755, \"yhat_upper\": 9.865907680134292, \"fact\": 9.600139673643671, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:36:00\", \"yhat\": 9.614903094693846, \"yhat_lower\": 9.25894126353854, \"yhat_upper\": 9.97086492584915, \"fact\": 9.654070612123258, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:37:00\", \"yhat\": 9.61439575861077, \"yhat_lower\": 9.176407479023059, \"yhat_upper\": 10.052384038198483, \"fact\": 9.81409008687884, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:38:00\", \"yhat\": 9.614184559222238, \"yhat_lower\": 9.106940102082241, \"yhat_upper\": 10.121429016362235, \"fact\": 9.86346342581928, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:39:00\", \"yhat\": 9.614096638841243, \"yhat_lower\": 9.045852646858195, \"yhat_upper\": 10.18234063082429, \"fact\": 9.857124185840512, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:40:00\", \"yhat\": 9.857475077784809, \"yhat_lower\": 9.60795088850332, \"yhat_upper\": 10.106999267066298, \"fact\": 9.983032579376141, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:41:00\", \"yhat\": 9.857575109623617, \"yhat_lower\": 9.5013942006526, \"yhat_upper\": 10.213756018594635, \"fact\": 10.037199180536911, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:42:00\", \"yhat\": 9.85760362657574, \"yhat_lower\": 9.419263111931338, \"yhat_upper\": 10.295944141220142, \"fact\": 9.993484385678066, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:43:00\", \"yhat\": 9.857611756152963, \"yhat_lower\": 9.350055790661001, \"yhat_upper\": 10.365167721644925, \"fact\": 10.0400027689603, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:44:00\", \"yhat\": 9.85761407372272, \"yhat_lower\": 9.289161080117132, \"yhat_upper\": 10.426067067328308, \"fact\": 10.034298117029037, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:45:00\", \"yhat\": 10.034449699916522, \"yhat_lower\": 9.78529274112155, \"yhat_upper\": 10.283606658711493, \"fact\": 10.076049094922666, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:46:00\", \"yhat\": 10.034502322873168, \"yhat_lower\": 9.678942052488342, \"yhat_upper\": 10.390062593257994, \"fact\": 10.0988034535548, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:47:00\", \"yhat\": 10.034520591264885, \"yhat_lower\": 9.596841801840691, \"yhat_upper\": 10.472199380689078, \"fact\": 10.03315333035482, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:48:00\", \"yhat\": 10.034526933252435, \"yhat_lower\": 9.527595265685223, \"yhat_upper\": 10.541458600819647, \"fact\": 9.989417587885512, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:49:00\", \"yhat\": 10.034529134913463, \"yhat_lower\": 9.466644341057519, \"yhat_upper\": 10.602413928769407, \"fact\": 10.142657199531792, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:50:00\", \"yhat\": 10.145073826929071, \"yhat_lower\": 9.896140273431905, \"yhat_upper\": 10.394007380426237, \"fact\": 10.255063743963055, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:51:00\", \"yhat\": 10.145823788958696, \"yhat_lower\": 9.7906304300729, \"yhat_upper\": 10.501017147844491, \"fact\": 10.289207345135177, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:52:00\", \"yhat\": 10.14605652779403, \"yhat_lower\": 9.708957366184052, \"yhat_upper\": 10.583155689404009, \"fact\": 10.290051522452643, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:53:00\", \"yhat\": 10.146128754604632, \"yhat_lower\": 9.63999961251967, \"yhat_upper\": 10.652257896689594, \"fact\": 10.208202234151164, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:54:00\", \"yhat\": 10.146151169051118, \"yhat_lower\": 9.579277844212216, \"yhat_upper\": 10.71302449389002, \"fact\": 10.20744863055363, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:55:00\", \"yhat\": 10.207058054530734, \"yhat_lower\": 9.958545278187964, \"yhat_upper\": 10.455570830873503, \"fact\": 10.102381099087888, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:56:00\", \"yhat\": 10.206960334886224, \"yhat_lower\": 9.851813759040972, \"yhat_upper\": 10.562106910731476, \"fact\": 10.187155935748017, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:57:00\", \"yhat\": 10.206935886050752, \"yhat_lower\": 9.769715668515532, \"yhat_upper\": 10.644156103585972, \"fact\": 10.126046394947553, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:58:00\", \"yhat\": 10.206929769107132, \"yhat_lower\": 9.700609624208168, \"yhat_upper\": 10.713249914006097, \"fact\": 10.077830439271654, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:59:00\", \"yhat\": 10.206928238686622, \"yhat_lower\": 9.639830133842604, \"yhat_upper\": 10.77402634353064, \"fact\": 10.112502220252225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:00:00\", \"yhat\": 10.112839948161906, \"yhat_lower\": 9.864632499941695, \"yhat_upper\": 10.361047396382116, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:01:00\", \"yhat\": 10.112939587682847, \"yhat_lower\": 9.75858311078441, \"yhat_upper\": 10.467296064581284, \"fact\": 10.2942943861814, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:02:00\", \"yhat\": 10.112968984229147, \"yhat_lower\": 9.67681166152166, \"yhat_upper\": 10.549126306936634, \"fact\": 10.205446118651967, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:03:00\", \"yhat\": 10.112977657062237, \"yhat_lower\": 9.607897383024762, \"yhat_upper\": 10.618057931099711, \"fact\": 10.271409386655742, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:04:00\", \"yhat\": 10.112980215799343, \"yhat_lower\": 9.547259049455294, \"yhat_upper\": 10.678701382143393, \"fact\": 10.256522349950478, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:05:00\", \"yhat\": 10.256539109565086, \"yhat_lower\": 10.008445460677523, \"yhat_upper\": 10.504632758452649, \"fact\": 10.17902731704118, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:06:00\", \"yhat\": 10.256544720739209, \"yhat_lower\": 9.902670150689213, \"yhat_upper\": 10.610419290789205, \"fact\": 10.223078359670582, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:07:00\", \"yhat\": 10.256546599378769, \"yhat_lower\": 9.82108831154804, \"yhat_upper\": 10.692004887209498, \"fact\": 10.289101894089889, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:08:00\", \"yhat\": 10.256547228353476, \"yhat_lower\": 9.752302667167239, \"yhat_upper\": 10.760791789539713, \"fact\": 10.452816223055665, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:09:00\", \"yhat\": 10.256547438936277, \"yhat_lower\": 9.69176222237537, \"yhat_upper\": 10.821332655497184, \"fact\": 10.530367461184968, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:10:00\", \"yhat\": 10.533023109523674, \"yhat_lower\": 10.284970642958163, \"yhat_upper\": 10.781075576089185, \"fact\": 10.515200566630206, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:11:00\", \"yhat\": 10.533857799882155, \"yhat_lower\": 10.179511421243697, \"yhat_upper\": 10.888204178520612, \"fact\": 10.462488799078955, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:12:00\", \"yhat\": 10.534120149374889, \"yhat_lower\": 10.097784089113022, \"yhat_upper\": 10.970456209636756, \"fact\": 10.536617371571872, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:13:00\", \"yhat\": 10.5342026078047, \"yhat_lower\": 10.028763874849723, \"yhat_upper\": 11.039641340759676, \"fact\": 10.582085913026225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:14:00\", \"yhat\": 10.534228525112852, \"yhat_lower\": 9.967989555307105, \"yhat_upper\": 11.100467494918599, \"fact\": 10.453705254361472, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:15:00\", \"yhat\": 10.451433203469724, \"yhat_lower\": 10.203665884290773, \"yhat_upper\": 10.699200522648676, \"fact\": 10.481826344423022, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:16:00\", \"yhat\": 10.450853906864433, \"yhat_lower\": 10.096956458519736, \"yhat_upper\": 10.80475135520913, \"fact\": 10.353428837573519, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:17:00\", \"yhat\": 10.450706205702403, \"yhat_lower\": 10.015120727142008, \"yhat_upper\": 10.886291684262797, \"fact\": 10.342528897524867, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:18:00\", \"yhat\": 10.450668546870872, \"yhat_lower\": 9.946298824207995, \"yhat_upper\": 10.95503826953375, \"fact\": 10.289505252298003, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:19:00\", \"yhat\": 10.450658945134686, \"yhat_lower\": 9.885783324112914, \"yhat_upper\": 11.015534566156457, \"fact\": 10.233404516009793, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:20:00\", \"yhat\": 10.231924669263208, \"yhat_lower\": 9.984492058815759, \"yhat_upper\": 10.479357279710657, \"fact\": 10.398350843814256, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:21:00\", \"yhat\": 10.23140989269186, \"yhat_lower\": 9.878211519398185, \"yhat_upper\": 10.584608265985533, \"fact\": 10.413367861232464, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:22:00\", \"yhat\": 10.231230823528772, \"yhat_lower\": 9.796390075888539, \"yhat_upper\": 10.666071571169006, \"fact\": 10.465737097515472, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:23:00\", \"yhat\": 10.231168532882783, \"yhat_lower\": 9.727474929217532, \"yhat_upper\": 10.734862136548035, \"fact\": 10.540956107018431, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:24:00\", \"yhat\": 10.231146864581493, \"yhat_lower\": 9.666853730741044, \"yhat_upper\": 10.795439998421942, \"fact\": 10.419642110204657, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:25:00\", \"yhat\": 10.418151428056591, \"yhat_lower\": 10.170641129619149, \"yhat_upper\": 10.665661726494033, \"fact\": 10.38830467957498, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:26:00\", \"yhat\": 10.417627868553792, \"yhat_lower\": 10.064619316866414, \"yhat_upper\": 10.77063642024117, \"fact\": 10.337534746596601, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:27:00\", \"yhat\": 10.417443983241068, \"yhat_lower\": 9.983034108567642, \"yhat_upper\": 10.851853857914493, \"fact\": 10.446651275126646, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:28:00\", \"yhat\": 10.41737939878017, \"yhat_lower\": 9.91431787054973, \"yhat_upper\": 10.92044092701061, \"fact\": 10.514004036753205, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:29:00\", \"yhat\": 10.417356715334018, \"yhat_lower\": 9.853865782653541, \"yhat_upper\": 10.980847648014494, \"fact\": 10.507311180202013, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:30:00\", \"yhat\": 10.507657909656631, \"yhat_lower\": 10.260541928032278, \"yhat_upper\": 10.754773891280983, \"fact\": 10.600130615972407, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:31:00\", \"yhat\": 10.507759950733425, \"yhat_lower\": 10.155045861978685, \"yhat_upper\": 10.860474039488164, \"fact\": 10.608687106522943, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:32:00\", \"yhat\": 10.507789981009811, \"yhat_lower\": 10.073709943885106, \"yhat_upper\": 10.941870018134516, \"fact\": 10.484335112185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:33:00\", \"yhat\": 10.50779881879875, \"yhat_lower\": 10.005162021055453, \"yhat_upper\": 11.010435616542049, \"fact\": 10.621271569245923, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:34:00\", \"yhat\": 10.507801419724307, \"yhat_lower\": 9.94484409698481, \"yhat_upper\": 11.070758742463806, \"fact\": 10.639575926010757, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:35:00\", \"yhat\": 10.640380560812297, \"yhat_lower\": 10.393288314828384, \"yhat_upper\": 10.88747280679621, \"fact\": 10.596954129260547, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:36:00\", \"yhat\": 10.640651148783938, \"yhat_lower\": 10.288429189364287, \"yhat_upper\": 10.99287310820359, \"fact\": 10.62736816641365, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:37:00\", \"yhat\": 10.640742143916459, \"yhat_lower\": 10.207465002565757, \"yhat_upper\": 11.07401928526716, \"fact\": 10.668971329410926, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:38:00\", \"yhat\": 10.640772744368105, \"yhat_lower\": 10.139153759828018, \"yhat_upper\": 11.142391728908192, \"fact\": 10.960130410890418, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:39:00\", \"yhat\": 10.64078303489261, \"yhat_lower\": 10.079009536890078, \"yhat_upper\": 11.202556532895143, \"fact\": 11.0, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:40:00\", \"yhat\": 11.002449717124964, \"yhat_lower\": 10.754723829064067, \"yhat_upper\": 11.250175605185861, \"fact\": 10.944748604963694, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:41:00\", \"yhat\": 11.003232704244631, \"yhat_lower\": 10.6496269858613, \"yhat_upper\": 11.356838422627963, \"fact\": 10.762400197925471, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:42:00\", \"yhat\": 11.003482965314907, \"yhat_lower\": 10.568224188879329, \"yhat_upper\": 11.438741741750485, \"fact\": 10.633397214168852, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:43:00\", \"yhat\": 11.00356295462983, \"yhat_lower\": 10.499477434149867, \"yhat_upper\": 11.507648475109793, \"fact\": 10.508366912453496, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:44:00\", \"yhat\": 11.003588521093262, \"yhat_lower\": 10.438937616308948, \"yhat_upper\": 11.568239425877575, \"fact\": 10.747813043137848, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:45:00\", \"yhat\": 10.753023652141298, \"yhat_lower\": 10.504176407430581, \"yhat_upper\": 11.001870896852015, \"fact\": 10.616517623097478, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:46:00\", \"yhat\": 10.753580208279164, \"yhat_lower\": 10.397611751794214, \"yhat_upper\": 11.109548664764114, \"fact\": 10.519134892650595, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:47:00\", \"yhat\": 10.753639655214137, \"yhat_lower\": 10.315676380457917, \"yhat_upper\": 11.191602929970356, \"fact\": 10.505485347067411, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:48:00\", \"yhat\": 10.753646004866647, \"yhat_lower\": 10.246750314296527, \"yhat_upper\": 11.260541695436768, \"fact\": 10.370020036709334, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:49:00\", \"yhat\": 10.753646683086425, \"yhat_lower\": 10.186127352451907, \"yhat_upper\": 11.321166013720942, \"fact\": 10.252602215750233, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:50:00\", \"yhat\": 10.249528990426677, \"yhat_lower\": 10.000494500134103, \"yhat_upper\": 10.498563480719252, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:51:00\", \"yhat\": 10.24893105049125, \"yhat_lower\": 9.892907117973756, \"yhat_upper\": 10.604954983008742, \"fact\": 10.239477262630865, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:52:00\", \"yhat\": 10.248814712725958, \"yhat_lower\": 9.810610147510738, \"yhat_upper\": 10.687019277941177, \"fact\": 10.27736285358397, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:53:00\", \"yhat\": 10.248792077550029, \"yhat_lower\": 9.741448155615867, \"yhat_upper\": 10.75613599948419, \"fact\": 10.253281566040584, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:54:00\", \"yhat\": 10.248787673552856, \"yhat_lower\": 9.680639106585334, \"yhat_upper\": 10.816936240520379, \"fact\": 10.045963893343206, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:55:00\", \"yhat\": 10.04141186901753, \"yhat_lower\": 9.792272756278606, \"yhat_upper\": 10.290550981756454, \"fact\": 9.974512039077938, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:56:00\", \"yhat\": 10.040566033296491, \"yhat_lower\": 9.684396394529312, \"yhat_upper\": 10.39673567206367, \"fact\": 10.041043064809825, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:57:00\", \"yhat\": 10.040408864086531, \"yhat_lower\": 9.60205461424478, \"yhat_upper\": 10.478763113928283, \"fact\": 10.047700947811453, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:58:00\", \"yhat\": 10.040379659644174, \"yhat_lower\": 9.53288849637576, \"yhat_upper\": 10.547870822912587, \"fact\": 10.004137092919867, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:59:00\", \"yhat\": 10.040374233012242, \"yhat_lower\": 9.472080462426588, \"yhat_upper\": 10.608668003597897, \"fact\": 9.966989635494258, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:00:00\", \"yhat\": 9.966018942157637, \"yhat_lower\": 9.717376828463316, \"yhat_upper\": 10.214661055851959, \"fact\": 9.988342774645961, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:01:00\", \"yhat\": 9.965908889371159, \"yhat_lower\": 9.61008468120122, \"yhat_upper\": 10.321733097541097, \"fact\": 9.964268279658732, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:02:00\", \"yhat\": 9.965896412087805, \"yhat_lower\": 9.52801585505357, \"yhat_upper\": 10.40377696912204, \"fact\": 9.838689442516403, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:03:00\", \"yhat\": 9.965894997470285, \"yhat_lower\": 9.459035486820877, \"yhat_upper\": 10.472754508119692, \"fact\": 9.773522635065854, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:04:00\", \"yhat\": 9.965894837087397, \"yhat_lower\": 9.398375560441725, \"yhat_upper\": 10.53341411373307, \"fact\": 9.868386927448714, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:05:00\", \"yhat\": 9.870660500490633, \"yhat_lower\": 9.622259281356689, \"yhat_upper\": 10.119061719624577, \"fact\": 9.830469543424808, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:06:00\", \"yhat\": 9.870796392862808, \"yhat_lower\": 9.515156610877787, \"yhat_upper\": 10.226436174847828, \"fact\": 9.788865576129703, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:07:00\", \"yhat\": 9.870804515204371, \"yhat_lower\": 9.433263428358591, \"yhat_upper\": 10.308345602050151, \"fact\": 9.914847367291713, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:08:00\", \"yhat\": 9.870805000679983, \"yhat_lower\": 9.364429764205195, \"yhat_upper\": 10.377180237154771, \"fact\": 9.807562371531388, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:09:00\", \"yhat\": 9.870805029697054, \"yhat_lower\": 9.3038921415177, \"yhat_upper\": 10.437717917876409, \"fact\": 9.670822674017861, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:10:00\", \"yhat\": 9.667596458569419, \"yhat_lower\": 9.419155140501758, \"yhat_upper\": 9.91603777663708, \"fact\": 9.616577898394782, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:11:00\", \"yhat\": 9.667655573059132, \"yhat_lower\": 9.311984154344719, \"yhat_upper\": 10.023326991773546, \"fact\": 9.573703532341133, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:12:00\", \"yhat\": 9.66765448989437, \"yhat_lower\": 9.230362175366896, \"yhat_upper\": 10.104946804421843, \"fact\": 9.467645765284308, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:13:00\", \"yhat\": 9.66765450974138, \"yhat_lower\": 9.161741457375207, \"yhat_upper\": 10.173567562107554, \"fact\": 9.486973369882458, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:14:00\", \"yhat\": 9.667654509377721, \"yhat_lower\": 9.101375915622476, \"yhat_upper\": 10.233933103132966, \"fact\": 9.442311708770832, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:15:00\", \"yhat\": 9.44122218833253, \"yhat_lower\": 9.193177968471263, \"yhat_upper\": 9.689266408193797, \"fact\": 9.395669890818453, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:16:00\", \"yhat\": 9.44113286559513, \"yhat_lower\": 9.085966931506842, \"yhat_upper\": 9.796298799683417, \"fact\": 9.456601403941736, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:17:00\", \"yhat\": 9.441125542601327, \"yhat_lower\": 9.004071181073382, \"yhat_upper\": 9.878179904129272, \"fact\": 9.564992092172044, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:18:00\", \"yhat\": 9.441124942236405, \"yhat_lower\": 8.93524821565893, \"yhat_upper\": 9.94700166881388, \"fact\": 9.63165317584744, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:19:00\", \"yhat\": 9.441124893016365, \"yhat_lower\": 8.874725971869882, \"yhat_upper\": 10.007523814162848, \"fact\": 9.578406412111097, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:20:00\", \"yhat\": 9.577010257908446, \"yhat_lower\": 9.329278857373401, \"yhat_upper\": 9.824741658443491, \"fact\": 9.46403283204649, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:22:00\", \"yhat\": 9.576967340378145, \"yhat_lower\": 9.140204222374976, \"yhat_upper\": 10.013730458381314, \"fact\": 9.323236419089412, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:23:00\", \"yhat\": 9.576967303248832, \"yhat_lower\": 9.071487232808513, \"yhat_upper\": 10.082447373689151, \"fact\": 9.391465325298743, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:24:00\", \"yhat\": 9.576967302140565, \"yhat_lower\": 9.011053642401437, \"yhat_upper\": 10.142880961879692, \"fact\": 9.50366014614707, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:25:00\", \"yhat\": 9.506830532297522, \"yhat_lower\": 9.258337076208072, \"yhat_upper\": 9.755323988386973, \"fact\": 9.592600239141852, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:26:00\", \"yhat\": 9.50678636797026, \"yhat_lower\": 9.15023908783813, \"yhat_upper\": 9.86333364810239, \"fact\": 9.355788749450348, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:27:00\", \"yhat\": 9.506786983191155, \"yhat_lower\": 9.068093834829146, \"yhat_upper\": 9.945480131553165, \"fact\": 9.222799348520082, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:28:00\", \"yhat\": 9.506786974620963, \"yhat_lower\": 8.999068442700635, \"yhat_upper\": 10.014505506541292, \"fact\": 9.034232188045483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:29:00\", \"yhat\": 9.506786974740349, \"yhat_lower\": 8.93836413305676, \"yhat_upper\": 10.075209816423937, \"fact\": 8.988900736784247, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:30:00\", \"yhat\": 8.9873429545356, \"yhat_lower\": 8.737903393522299, \"yhat_upper\": 9.236782515548903, \"fact\": 8.940239461563786, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:31:00\", \"yhat\": 8.987286699369655, \"yhat_lower\": 8.628465373826847, \"yhat_upper\": 9.346108024912462, \"fact\": 8.867726672403123, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:32:00\", \"yhat\": 8.98728466786384, \"yhat_lower\": 8.545194369056874, \"yhat_upper\": 9.429374966670805, \"fact\": 8.750332311139447, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:33:00\", \"yhat\": 8.987284594501405, \"yhat_lower\": 8.475287869821173, \"yhat_upper\": 9.499281319181637, \"fact\": 8.749543232452918, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:34:00\", \"yhat\": 8.987284591852116, \"yhat_lower\": 8.413840900963045, \"yhat_upper\": 9.560728282741188, \"fact\": 8.714350103767188, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:35:00\", \"yhat\": 8.71309938082775, \"yhat_lower\": 8.46400152406582, \"yhat_upper\": 8.96219723758968, \"fact\": 8.70989589254306, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:36:00\", \"yhat\": 8.712982433292986, \"yhat_lower\": 8.354472945290455, \"yhat_upper\": 9.071491921295516, \"fact\": 8.93646758528286, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:37:00\", \"yhat\": 8.712971498236582, \"yhat_lower\": 8.270896445100064, \"yhat_upper\": 9.1550465513731, \"fact\": 9.012239346556045, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:38:00\", \"yhat\": 8.71297047576562, \"yhat_lower\": 8.200748670193134, \"yhat_upper\": 9.225192281338105, \"fact\": 9.039800746733981, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:39:00\", \"yhat\": 8.712970380160545, \"yhat_lower\": 8.139110031273379, \"yhat_upper\": 9.286830729047711, \"fact\": 8.977564792960163, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:40:00\", \"yhat\": 8.97530631701115, \"yhat_lower\": 8.726024972419532, \"yhat_upper\": 9.224587661602767, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:41:00\", \"yhat\": 8.975146983066967, \"yhat_lower\": 8.61604763877353, \"yhat_upper\": 9.334246327360404, \"fact\": 8.798698884079773, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:42:00\", \"yhat\": 8.97513574216543, \"yhat_lower\": 8.532304690128239, \"yhat_upper\": 9.41796679420262, \"fact\": 8.757817163308653, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:43:00\", \"yhat\": 8.975134949127462, \"yhat_lower\": 8.462036451662238, \"yhat_upper\": 9.488233446592686, \"fact\": 8.739247557388522, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:44:00\", \"yhat\": 8.975134893179172, \"yhat_lower\": 8.400293637216713, \"yhat_upper\": 9.549976149141632, \"fact\": 8.70356646824997, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:45:00\", \"yhat\": 8.702234387513121, \"yhat_lower\": 8.453219710059951, \"yhat_upper\": 8.95124906496629, \"fact\": 8.782616489057622, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:46:00\", \"yhat\": 8.702291586140268, \"yhat_lower\": 8.343246994978601, \"yhat_upper\": 9.061336177301934, \"fact\": 8.479925780652454, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:47:00\", \"yhat\": 8.702289130070708, \"yhat_lower\": 8.260018108495998, \"yhat_upper\": 9.144560151645418, \"fact\": 8.273358954380925, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:48:00\", \"yhat\": 8.702289235532639, \"yhat_lower\": 8.190133517405952, \"yhat_upper\": 9.214444953659326, \"fact\": 8.447199865827617, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:49:00\", \"yhat\": 8.702289231004176, \"yhat_lower\": 8.128701479841103, \"yhat_upper\": 9.275876982167249, \"fact\": 8.523194953304365, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:50:00\", \"yhat\": 8.525177179581291, \"yhat_lower\": 8.274455920180683, \"yhat_upper\": 8.7758984389819, \"fact\": 8.530052782649555, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:51:00\", \"yhat\": 8.524988491194868, \"yhat_lower\": 8.163243232052801, \"yhat_upper\": 8.886733750336935, \"fact\": 8.396411307804495, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:52:00\", \"yhat\": 8.5250064524678, \"yhat_lower\": 8.079629754584783, \"yhat_upper\": 8.970383150350816, \"fact\": 8.314908428588723, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:53:00\", \"yhat\": 8.52500474273181, \"yhat_lower\": 8.009341604555459, \"yhat_upper\": 9.04066788090816, \"fact\": 8.244009975240218, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:54:00\", \"yhat\": 8.52500490548181, \"yhat_lower\": 7.947551844132463, \"yhat_upper\": 9.102457966831155, \"fact\": 8.180232114481395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:55:00\", \"yhat\": 8.177851481912983, \"yhat_lower\": 7.927338642087731, \"yhat_upper\": 8.428364321738234, \"fact\": 7.997073407217911, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:56:00\", \"yhat\": 8.178025809157027, \"yhat_lower\": 7.816203313556452, \"yhat_upper\": 8.539848304757603, \"fact\": 7.997788244170042, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:57:00\", \"yhat\": 8.17801304364738, \"yhat_lower\": 7.732287565953062, \"yhat_upper\": 8.6237385213417, \"fact\": 8.027379343471765, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:58:00\", \"yhat\": 8.178013978430911, \"yhat_lower\": 7.66181986206173, \"yhat_upper\": 8.694208094800093, \"fact\": 7.891617442415619, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:59:00\", \"yhat\": 8.178013909979258, \"yhat_lower\": 7.599879521588968, \"yhat_upper\": 8.756148298369547, \"fact\": 7.993391171167953, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:00:00\", \"yhat\": 7.998191386002311, \"yhat_lower\": 7.747442178929054, \"yhat_upper\": 8.248940593075568, \"fact\": 7.839794824705354, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:01:00\", \"yhat\": 7.997879276145051, \"yhat_lower\": 7.635887285235066, \"yhat_upper\": 8.359871267055036, \"fact\": 7.730599469753859, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:02:00\", \"yhat\": 7.997899569520735, \"yhat_lower\": 7.551972521576454, \"yhat_upper\": 8.443826617465016, \"fact\": 7.6509477022655386, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:03:00\", \"yhat\": 7.997898250045918, \"yhat_lower\": 7.481481352421691, \"yhat_upper\": 8.514315147670144, \"fact\": 7.6005718066277375, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:04:00\", \"yhat\": 7.997898335838141, \"yhat_lower\": 7.419520939210173, \"yhat_upper\": 8.576275732466108, \"fact\": 7.616974853712176, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:05:00\", \"yhat\": 7.617759735970455, \"yhat_lower\": 7.367069397810061, \"yhat_upper\": 7.868450074130848, \"fact\": 7.452726173004684, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:06:00\", \"yhat\": 7.617756450656629, \"yhat_lower\": 7.255661234840034, \"yhat_upper\": 7.979851666473225, \"fact\": 7.4873100141103475, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:07:00\", \"yhat\": 7.617756464408102, \"yhat_lower\": 7.171262249539907, \"yhat_upper\": 8.064250679276297, \"fact\": 7.355716834977905, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:08:00\", \"yhat\": 7.617756464350542, \"yhat_lower\": 7.100454502782307, \"yhat_upper\": 8.135058425918777, \"fact\": 7.304617707670855, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:09:00\", \"yhat\": 7.617756464350783, \"yhat_lower\": 7.038234631657517, \"yhat_upper\": 8.197278297044049, \"fact\": 7.489866921022014, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:10:00\", \"yhat\": 7.497407115272219, \"yhat_lower\": 7.246233501575262, \"yhat_upper\": 7.748580728969176, \"fact\": 7.457128971331552, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:11:00\", \"yhat\": 7.497434203651614, \"yhat_lower\": 7.134986811930751, \"yhat_upper\": 7.859881595372477, \"fact\": 7.49124494359832, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:12:00\", \"yhat\": 7.4974343009674485, \"yhat_lower\": 7.05059309781191, \"yhat_upper\": 7.944275504122987, \"fact\": 7.746174323894706, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:13:00\", \"yhat\": 7.497434301317059, \"yhat_lower\": 6.979779900920512, \"yhat_upper\": 8.015088701713605, \"fact\": 7.728164560761447, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:14:00\", \"yhat\": 7.4974343013183145, \"yhat_lower\": 6.917550609611226, \"yhat_upper\": 8.077317993025403, \"fact\": 7.57497190780261, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:15:00\", \"yhat\": 7.569166103804073, \"yhat_lower\": 7.317435117697556, \"yhat_upper\": 7.82089708991059, \"fact\": 7.629350721280201, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:16:00\", \"yhat\": 7.569802525660964, \"yhat_lower\": 7.2066005957845, \"yhat_upper\": 7.933004455537428, \"fact\": 7.670839399995044, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:17:00\", \"yhat\": 7.569732762234566, \"yhat_lower\": 7.122647542703057, \"yhat_upper\": 8.016817981766076, \"fact\": 7.8020911978599985, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:18:00\", \"yhat\": 7.569740409576671, \"yhat_lower\": 7.052132506340897, \"yhat_upper\": 8.087348312812445, \"fact\": 7.688201610108968, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:19:00\", \"yhat\": 7.569739571288698, \"yhat_lower\": 6.99013301459613, \"yhat_upper\": 8.149346127981268, \"fact\": 7.491134163279598, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:20:00\", \"yhat\": 7.49399729718513, \"yhat_lower\": 7.2430228531460195, \"yhat_upper\": 7.744971741224241, \"fact\": 7.541546760013012, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:21:00\", \"yhat\": 7.491215997489166, \"yhat_lower\": 7.131984413800495, \"yhat_upper\": 7.850447581177837, \"fact\": 7.322022918010769, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:22:00\", \"yhat\": 7.493917801964262, \"yhat_lower\": 7.055600226737752, \"yhat_upper\": 7.932235377190771, \"fact\": 7.235580785625353, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:23:00\", \"yhat\": 7.491293220574403, \"yhat_lower\": 6.983262477196419, \"yhat_upper\": 7.999323963952387, \"fact\": 7.270589900870376, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:24:00\", \"yhat\": 7.493842786072384, \"yhat_lower\": 6.927051679030923, \"yhat_upper\": 8.060633893113845, \"fact\": 7.166069908720111, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:25:00\", \"yhat\": 7.161707794897096, \"yhat_lower\": 6.90934625121356, \"yhat_upper\": 7.414069338580632, \"fact\": 7.084649033319625, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:26:00\", \"yhat\": 7.162216050773891, \"yhat_lower\": 6.798255200110867, \"yhat_upper\": 7.526176901436915, \"fact\": 6.953837567532185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:27:00\", \"yhat\": 7.162156830852821, \"yhat_lower\": 6.7142227533336225, \"yhat_upper\": 7.610090908372019, \"fact\": 6.9788882663663205, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:28:00\", \"yhat\": 7.162163730918736, \"yhat_lower\": 6.643615198702406, \"yhat_upper\": 7.6807122631350655, \"fact\": 7.166048798085546, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:29:00\", \"yhat\": 7.162162926950936, \"yhat_lower\": 6.581532200234819, \"yhat_upper\": 7.742793653667053, \"fact\": 7.397644550791485, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:30:00\", \"yhat\": 7.406943270228067, \"yhat_lower\": 7.15383589316496, \"yhat_upper\": 7.660050647291174, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:31:00\", \"yhat\": 7.405949313812806, \"yhat_lower\": 7.039755535771491, \"yhat_upper\": 7.7721430918541206, \"fact\": 7.244896929081159, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:32:00\", \"yhat\": 7.4060555595558, \"yhat_lower\": 6.954966374894545, \"yhat_upper\": 7.857144744217055, \"fact\": 7.163683211087717, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:33:00\", \"yhat\": 7.406044202762151, \"yhat_lower\": 6.883612905722169, \"yhat_upper\": 7.928475499802133, \"fact\": 6.997342471102844, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:34:00\", \"yhat\": 7.406045416709725, \"yhat_lower\": 6.820912915723485, \"yhat_upper\": 7.991177917695965, \"fact\": 6.910312134996908, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:35:00\", \"yhat\": 6.905890360459139, \"yhat_lower\": 6.653573468113107, \"yhat_upper\": 7.1582072528051714, \"fact\": 6.920281767120731, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:36:00\", \"yhat\": 6.910181518066455, \"yhat_lower\": 6.549041348685839, \"yhat_upper\": 7.271321687447071, \"fact\": 7.005098218639339, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:37:00\", \"yhat\": 6.906017119033094, \"yhat_lower\": 6.465362549098307, \"yhat_upper\": 7.346671688967881, \"fact\": 7.073528376327899, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:38:00\", \"yhat\": 6.910058503875145, \"yhat_lower\": 6.399328462451917, \"yhat_upper\": 7.4207885452983735, \"fact\": 7.092071643143026, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:39:00\", \"yhat\": 6.906136499448884, \"yhat_lower\": 6.336325469273886, \"yhat_upper\": 7.475947529623882, \"fact\": 7.2003894873370955, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:40:00\", \"yhat\": 7.2067355773258965, \"yhat_lower\": 6.954710206056364, \"yhat_upper\": 7.458760948595429, \"fact\": 7.29287665449782, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:41:00\", \"yhat\": 7.200577522453847, \"yhat_lower\": 6.839813565421762, \"yhat_upper\": 7.561341479485932, \"fact\": 7.219469085171615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:42:00\", \"yhat\": 7.206553113703592, \"yhat_lower\": 6.766372744896895, \"yhat_upper\": 7.646733482510289, \"fact\": 7.191066675166035, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:43:00\", \"yhat\": 7.200754579665499, \"yhat_lower\": 6.690556591285611, \"yhat_upper\": 7.7109525680453865, \"fact\": 7.150610552736501, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:44:00\", \"yhat\": 7.206381302710246, \"yhat_lower\": 6.637174685582005, \"yhat_upper\": 7.775587919838486, \"fact\": 7.173786787560158, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:45:00\", \"yhat\": 7.1753581125262365, \"yhat_lower\": 6.922817727992856, \"yhat_upper\": 7.4278984970596165, \"fact\": 7.165902938765192, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:46:00\", \"yhat\": 7.175068918309635, \"yhat_lower\": 6.80910021880904, \"yhat_upper\": 7.54103761781023, \"fact\": 7.184761105184088, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:47:00\", \"yhat\": 7.175122143006449, \"yhat_lower\": 6.724686207158312, \"yhat_upper\": 7.625558078854587, \"fact\": 7.095968849846142, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:48:00\", \"yhat\": 7.175112347276838, \"yhat_lower\": 6.653507608159348, \"yhat_upper\": 7.696717086394328, \"fact\": 7.189463215776056, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:49:00\", \"yhat\": 7.175114150130106, \"yhat_lower\": 6.59098227615027, \"yhat_upper\": 7.759246024109943, \"fact\": 7.2416172252622815, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:50:00\", \"yhat\": 7.2428212046653195, \"yhat_lower\": 6.990628098786309, \"yhat_upper\": 7.49501431054433, \"fact\": 7.289594697210025, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:51:00\", \"yhat\": 7.242596179389664, \"yhat_lower\": 6.877242083286759, \"yhat_upper\": 7.607950275492569, \"fact\": 7.287819788227195, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:52:00\", \"yhat\": 7.242638236898751, \"yhat_lower\": 6.793005616434362, \"yhat_upper\": 7.692270857363139, \"fact\": 7.252759139403707, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:53:00\", \"yhat\": 7.242630376297023, \"yhat_lower\": 6.721978678552502, \"yhat_upper\": 7.763282074041544, \"fact\": 7.312186655332198, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:54:00\", \"yhat\": 7.2426318454534435, \"yhat_lower\": 6.659583635828087, \"yhat_upper\": 7.8256800550788, \"fact\": 7.417825510401695, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:55:00\", \"yhat\": 7.422223649962312, \"yhat_lower\": 7.17041192998206, \"yhat_upper\": 7.6740353699425645, \"fact\": 7.537862680510393, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:56:00\", \"yhat\": 7.421412635525187, \"yhat_lower\": 7.056493585622967, \"yhat_upper\": 7.786331685427408, \"fact\": 7.474088346812236, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:57:00\", \"yhat\": 7.42156218612679, \"yhat_lower\": 6.972419203481223, \"yhat_upper\": 7.870705168772357, \"fact\": 7.353827173698256, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:58:00\", \"yhat\": 7.42153460908079, \"yhat_lower\": 6.901426747209679, \"yhat_upper\": 7.9416424709519005, \"fact\": 7.203553863120317, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:59:00\", \"yhat\": 7.42153969427241, \"yhat_lower\": 6.839084117630604, \"yhat_upper\": 8.003995270914217, \"fact\": 7.1667714268010965, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:00:00\", \"yhat\": 7.166259548584659, \"yhat_lower\": 6.91438449994657, \"yhat_upper\": 7.418134597222748, \"fact\": 7.199926729249083, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:01:00\", \"yhat\": 7.166339966490083, \"yhat_lower\": 6.800752396262416, \"yhat_upper\": 7.531927536717751, \"fact\": 7.017751526939817, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:02:00\", \"yhat\": 7.166327332548444, \"yhat_lower\": 6.716015404099314, \"yhat_upper\": 7.616639260997574, \"fact\": 7.082192901082215, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:03:00\", \"yhat\": 7.1663293173860305, \"yhat_lower\": 6.644718779784825, \"yhat_upper\": 7.687939854987236, \"fact\": 7.060415319852113, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:04:00\", \"yhat\": 7.16632900556092, \"yhat_lower\": 6.582079464193524, \"yhat_upper\": 7.750578546928316, \"fact\": 7.068729453386899, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:05:00\", \"yhat\": 7.069589447303465, \"yhat_lower\": 6.817788963137929, \"yhat_upper\": 7.321389931469001, \"fact\": 7.039528369282021, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:06:00\", \"yhat\": 7.069453590168522, \"yhat_lower\": 6.704401730869556, \"yhat_upper\": 7.434505449467489, \"fact\": 7.033655777722624, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:07:00\", \"yhat\": 7.069475052135589, \"yhat_lower\": 6.619940229984988, \"yhat_upper\": 7.51900987428619, \"fact\": 7.062204617401134, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:08:00\", \"yhat\": 7.069471661691424, \"yhat_lower\": 6.548833462782674, \"yhat_upper\": 7.590109860600175, \"fact\": 6.993569720043028, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:09:00\", \"yhat\": 7.069472197295249, \"yhat_lower\": 6.48635916371062, \"yhat_upper\": 7.652585230879877, \"fact\": 6.9882948401110525, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:10:00\", \"yhat\": 6.988801942242213, \"yhat_lower\": 6.737509924834264, \"yhat_upper\": 7.240093959650162, \"fact\": 6.8390032876923215, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:11:00\", \"yhat\": 6.988721462241647, \"yhat_lower\": 6.62443884182381, \"yhat_upper\": 7.353004082659483, \"fact\": 6.691998504671839, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:12:00\", \"yhat\": 6.98873423487677, \"yhat_lower\": 6.540160301382951, \"yhat_upper\": 7.437308168370588, \"fact\": 6.752681942577438, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:13:00\", \"yhat\": 6.988732207786724, \"yhat_lower\": 6.469213736960752, \"yhat_upper\": 7.508250678612697, \"fact\": 6.73868451382265, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:14:00\", \"yhat\": 6.988732529497477, \"yhat_lower\": 6.406878381852167, \"yhat_upper\": 7.570586677142787, \"fact\": 6.680331145067498, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:15:00\", \"yhat\": 6.677716616136112, \"yhat_lower\": 6.426397813028462, \"yhat_upper\": 6.929035419243762, \"fact\": 6.6180921787104054, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:16:00\", \"yhat\": 6.678137044072399, \"yhat_lower\": 6.313601508891899, \"yhat_upper\": 7.042672579252899, \"fact\": 6.6895657202333645, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:17:00\", \"yhat\": 6.678069437381385, \"yhat_lower\": 6.2291442965141615, \"yhat_upper\": 7.126994578248609, \"fact\": 6.72316112495938, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:18:00\", \"yhat\": 6.678080308839429, \"yhat_lower\": 6.158124454089077, \"yhat_upper\": 7.198036163589781, \"fact\": 6.738952790095521, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:19:00\", \"yhat\": 6.678078560660392, \"yhat_lower\": 6.095715600963967, \"yhat_upper\": 7.260441520356817, \"fact\": 6.664365358351624, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:20:00\", \"yhat\": 6.6604405759630625, \"yhat_lower\": 6.409513371531347, \"yhat_upper\": 6.911367780394778, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:21:00\", \"yhat\": 6.661092647072432, \"yhat_lower\": 6.297104663813606, \"yhat_upper\": 7.025080630331258, \"fact\": 6.724600878108458, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:22:00\", \"yhat\": 6.660984310688506, \"yhat_lower\": 6.212767927102645, \"yhat_upper\": 7.109200694274367, \"fact\": 6.580937541938436, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:23:00\", \"yhat\": 6.661002309909624, \"yhat_lower\": 6.141875399592989, \"yhat_upper\": 7.180129220226259, \"fact\": 6.555562177433832, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:24:00\", \"yhat\": 6.660999319483425, \"yhat_lower\": 6.0795726605945335, \"yhat_upper\": 7.242425978372316, \"fact\": 6.659379361607502, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:27:00\", \"yhat\": 6.6679498488655256, \"yhat_lower\": 6.231325786160343, \"yhat_upper\": 7.104573911570708, \"fact\": 6.35302739173681, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:28:00\", \"yhat\": 6.659876975554334, \"yhat_lower\": 6.1538465329416345, \"yhat_upper\": 7.165907418167033, \"fact\": 6.189166144427423, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:29:00\", \"yhat\": 6.6677153862021, \"yhat_lower\": 6.1031311579030945, \"yhat_upper\": 7.232299614501105, \"fact\": 6.260671502798964, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:30:00\", \"yhat\": 6.257265877742868, \"yhat_lower\": 6.006083353559222, \"yhat_upper\": 6.508448401926514, \"fact\": 6.171678268702035, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:31:00\", \"yhat\": 6.260569470640141, \"yhat_lower\": 5.900964436772674, \"yhat_upper\": 6.620174504507609, \"fact\": 6.186759614812712, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:32:00\", \"yhat\": 6.257364853029232, \"yhat_lower\": 5.8186152883602515, \"yhat_upper\": 6.696114417698213, \"fact\": 6.140920120718393, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:33:00\", \"yhat\": 6.2604734606426655, \"yhat_lower\": 5.75191441393562, \"yhat_upper\": 6.769032507349711, \"fact\": 6.2395658921642525, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:34:00\", \"yhat\": 6.2574579865775535, \"yhat_lower\": 5.690091236395257, \"yhat_upper\": 6.82482473675985, \"fact\": 6.243797647964152, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:35:00\", \"yhat\": 6.241172156995438, \"yhat_lower\": 5.9903530005877, \"yhat_upper\": 6.491991313403175, \"fact\": 6.470077371588114, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:36:00\", \"yhat\": 6.243718293358708, \"yhat_lower\": 5.884568154177088, \"yhat_upper\": 6.602868432540329, \"fact\": 6.60046767084194, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:37:00\", \"yhat\": 6.241249113133898, \"yhat_lower\": 5.8030782060790145, \"yhat_upper\": 6.679420020188781, \"fact\": 6.625989069250561, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:38:00\", \"yhat\": 6.243643663194352, \"yhat_lower\": 5.735727929713654, \"yhat_upper\": 6.7515593966750505, \"fact\": 6.7475051661190895, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:40:00\", \"yhat\": 6.848414326779806, \"yhat_lower\": 6.596058314494082, \"yhat_upper\": 7.10077033906553, \"fact\": 6.859763545701101, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:41:00\", \"yhat\": 6.847968056284806, \"yhat_lower\": 6.482445945075264, \"yhat_upper\": 7.213490167494348, \"fact\": 6.807310091228302, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:42:00\", \"yhat\": 6.848022137271187, \"yhat_lower\": 6.397735959816673, \"yhat_upper\": 7.2983083147257, \"fact\": 6.841886616435936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:43:00\", \"yhat\": 6.8480155835036385, \"yhat_lower\": 6.326477329113023, \"yhat_upper\": 7.369553837894254, \"fact\": 6.85893746778489, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:44:00\", \"yhat\": 6.848016377717501, \"yhat_lower\": 6.263862842769224, \"yhat_upper\": 7.4321699126657785, \"fact\": 6.846026479115778, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:45:00\", \"yhat\": 6.8453303282550175, \"yhat_lower\": 6.593491778657855, \"yhat_upper\": 7.09716887785218, \"fact\": 6.883238199122709, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:46:00\", \"yhat\": 6.845421008692728, \"yhat_lower\": 6.480649724798994, \"yhat_upper\": 7.210192292586463, \"fact\": 6.809841352593101, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:47:00\", \"yhat\": 6.8454091966815005, \"yhat_lower\": 6.3961121817684425, \"yhat_upper\": 7.2947062115945585, \"fact\": 6.751200710300513, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:48:00\", \"yhat\": 6.84541073531114, \"yhat_lower\": 6.325040862707935, \"yhat_upper\": 7.3657806079143455, \"fact\": 6.805567687218024, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:49:00\", \"yhat\": 6.845410534889626, \"yhat_lower\": 6.262583097140611, \"yhat_upper\": 7.428237972638641, \"fact\": 6.772889900582233, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:50:00\", \"yhat\": 6.774927971137638, \"yhat_lower\": 6.524557406600048, \"yhat_upper\": 7.025298535675228, \"fact\": 6.728335674496716, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:51:00\", \"yhat\": 6.772952338160717, \"yhat_lower\": 6.414311751818976, \"yhat_upper\": 7.131592924502459, \"fact\": 6.747618665608875, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:52:00\", \"yhat\": 6.774867446373799, \"yhat_lower\": 6.3373666484705895, \"yhat_upper\": 7.212368244277008, \"fact\": 6.555395135552946, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:53:00\", \"yhat\": 6.773011008710196, \"yhat_lower\": 6.265815902140084, \"yhat_upper\": 7.280206115280307, \"fact\": 6.593569618569199, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:54:00\", \"yhat\": 6.774810573233653, \"yhat_lower\": 6.209016140605826, \"yhat_upper\": 7.34060500586148, \"fact\": 6.537512510098631, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:55:00\", \"yhat\": 6.534465477256504, \"yhat_lower\": 6.283044278135245, \"yhat_upper\": 6.785886676377762, \"fact\": 6.511672421125268, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:56:00\", \"yhat\": 6.534792647826327, \"yhat_lower\": 6.1709929870391464, \"yhat_upper\": 6.898592308613508, \"fact\": 6.631520179746892, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:57:00\", \"yhat\": 6.534757518378335, \"yhat_lower\": 6.086607022918886, \"yhat_upper\": 6.9829080138377835, \"fact\": 6.75546745691182, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:58:00\", \"yhat\": 6.534761290349992, \"yhat_lower\": 6.015726543862899, \"yhat_upper\": 7.053796036837085, \"fact\": 6.765024078734705, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:59:00\", \"yhat\": 6.534760885340207, \"yhat_lower\": 5.953428104244104, \"yhat_upper\": 7.11609366643631, \"fact\": 6.798885033129787, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:00:00\", \"yhat\": 6.800542387966737, \"yhat_lower\": 6.549330083029052, \"yhat_upper\": 7.051754692904422, \"fact\": 6.74534060560366, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:01:00\", \"yhat\": 6.800347818992969, \"yhat_lower\": 6.436595992369229, \"yhat_upper\": 7.164099645616709, \"fact\": 6.872906486758738, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:02:00\", \"yhat\": 6.800370660864069, \"yhat_lower\": 6.352271964013913, \"yhat_upper\": 7.248469357714225, \"fact\": 6.914632913487516, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:03:00\", \"yhat\": 6.800367979290202, \"yhat_lower\": 6.281373686137165, \"yhat_upper\": 7.3193622724432394, \"fact\": 7.086807423198176, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:04:00\", \"yhat\": 6.800368294099719, \"yhat_lower\": 6.219070039761726, \"yhat_upper\": 7.381666548437713, \"fact\": 7.073886368734035, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:05:00\", \"yhat\": 7.072402435618398, \"yhat_lower\": 6.82114743998009, \"yhat_upper\": 7.323657431256705, \"fact\": 7.020129069863576, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:06:00\", \"yhat\": 7.072498655578617, \"yhat_lower\": 6.708782407486071, \"yhat_upper\": 7.4362149036711624, \"fact\": 7.101131503472381, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:07:00\", \"yhat\": 7.072492416563767, \"yhat_lower\": 6.624105838501655, \"yhat_upper\": 7.520878994625879, \"fact\": 7.010405102545185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:08:00\", \"yhat\": 7.072492821108793, \"yhat_lower\": 6.553034062815197, \"yhat_upper\": 7.591951579402389, \"fact\": 6.951266834994014, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:09:00\", \"yhat\": 7.07249279487762, \"yhat_lower\": 6.490579912604701, \"yhat_upper\": 7.65440567715054, \"fact\": 6.963550333967537, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:10:00\", \"yhat\": 6.964407393020498, \"yhat_lower\": 6.713454556882263, \"yhat_upper\": 7.215360229158734, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:11:00\", \"yhat\": 6.9643273051951216, \"yhat_lower\": 6.601128255251094, \"yhat_upper\": 7.327526355139149, \"fact\": 7.031916357257972, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:12:00\", \"yhat\": 6.9643347889965606, \"yhat_lower\": 6.516806535482838, \"yhat_upper\": 7.411863042510283, \"fact\": 6.966991581251915, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:13:00\", \"yhat\": 6.96433408967324, \"yhat_lower\": 6.445968847124983, \"yhat_upper\": 7.482699332221498, \"fact\": 7.1046647071880225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:14:00\", \"yhat\": 6.964334155021461, \"yhat_lower\": 6.38371503864915, \"yhat_upper\": 7.544953271393771, \"fact\": 7.040671190034965, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:15:00\", \"yhat\": 7.037103658043733, \"yhat_lower\": 6.78622124459446, \"yhat_upper\": 7.287986071493007, \"fact\": 7.190168047613055, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:16:00\", \"yhat\": 7.037372346409672, \"yhat_lower\": 6.674709529418991, \"yhat_upper\": 7.400035163400353, \"fact\": 7.253047411598573, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:17:00\", \"yhat\": 7.037352110168436, \"yhat_lower\": 6.590503787582585, \"yhat_upper\": 7.484200432754288, \"fact\": 7.2720044758545415, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:18:00\", \"yhat\": 7.037353634259209, \"yhat_lower\": 6.519806429875265, \"yhat_upper\": 7.554900838643153, \"fact\": 7.381451693947673, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:19:00\", \"yhat\": 7.037353519472443, \"yhat_lower\": 6.45766882928098, \"yhat_upper\": 7.617038209663907, \"fact\": 7.473923616291, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:20:00\", \"yhat\": 7.477776029845417, \"yhat_lower\": 7.226905603509754, \"yhat_upper\": 7.728646456181081, \"fact\": 7.377898618253228, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:21:00\", \"yhat\": 7.477741887624239, \"yhat_lower\": 7.114988128822711, \"yhat_upper\": 7.840495646425767, \"fact\": 7.4365645152964674, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:22:00\", \"yhat\": 7.4777421902115, \"yhat_lower\": 7.030313048141197, \"yhat_upper\": 7.925171332281803, \"fact\": 7.424375555436707, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:23:00\", \"yhat\": 7.477742187529804, \"yhat_lower\": 6.959286940125583, \"yhat_upper\": 7.996197434934025, \"fact\": 7.322828741550124, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:24:00\", \"yhat\": 7.477742187553571, \"yhat_lower\": 6.896881751749428, \"yhat_upper\": 8.058602623357714, \"fact\": 7.259170692504289, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:25:00\", \"yhat\": 7.2567168944616505, \"yhat_lower\": 7.006072985654786, \"yhat_upper\": 7.507360803268515, \"fact\": 7.123867211441125, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:26:00\", \"yhat\": 7.256795716763838, \"yhat_lower\": 6.89448958475306, \"yhat_upper\": 7.619101848774616, \"fact\": 7.120132713051596, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:27:00\", \"yhat\": 7.256793184788829, \"yhat_lower\": 6.810111202536724, \"yhat_upper\": 7.703475167040933, \"fact\": 7.0565544845028185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:28:00\", \"yhat\": 7.256793266122376, \"yhat_lower\": 6.73930918935305, \"yhat_upper\": 7.774277342891701, \"fact\": 7.139838404300698, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:29:00\", \"yhat\": 7.256793263509733, \"yhat_lower\": 6.677091136469581, \"yhat_upper\": 7.836495390549885, \"fact\": 7.20277666346131, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:30:00\", \"yhat\": 7.205440170563385, \"yhat_lower\": 6.954965903978387, \"yhat_upper\": 7.455914437148383, \"fact\": 7.040986511007052, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:31:00\", \"yhat\": 7.20547266192142, \"yhat_lower\": 6.843328144897782, \"yhat_upper\": 7.567617178945058, \"fact\": 7.006594977513499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:32:00\", \"yhat\": 7.205473058274164, \"yhat_lower\": 6.7586725713629106, \"yhat_upper\": 7.652273545185417, \"fact\": 7.105131073775493, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:33:00\", \"yhat\": 7.205473063109157, \"yhat_lower\": 6.687676228385733, \"yhat_upper\": 7.72326989783258, \"fact\": 6.966567283612587, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:34:00\", \"yhat\": 7.205473063168137, \"yhat_lower\": 6.625303726230022, \"yhat_upper\": 7.785642400106252, \"fact\": 7.067989237821224, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:35:00\", \"yhat\": 7.0725971521236275, \"yhat_lower\": 6.821858508890813, \"yhat_upper\": 7.323335795356442, \"fact\": 7.134185474168518, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:36:00\", \"yhat\": 7.072435948838359, \"yhat_lower\": 6.710504487097107, \"yhat_upper\": 7.43436741057961, \"fact\": 7.0416050260755325, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:37:00\", \"yhat\": 7.072441588374486, \"yhat_lower\": 6.626424199974522, \"yhat_upper\": 7.5184589767744505, \"fact\": 6.980618485802484, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:38:00\", \"yhat\": 7.0724413910809405, \"yhat_lower\": 6.555841749444252, \"yhat_upper\": 7.589041032717629, \"fact\": 7.066809141768836, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:39:00\", \"yhat\": 7.0724413979830585, \"yhat_lower\": 6.493806245637723, \"yhat_upper\": 7.651076550328394, \"fact\": 7.191769766968483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:40:00\", \"yhat\": 7.205842636225949, \"yhat_lower\": 6.955967151116606, \"yhat_upper\": 7.455718121335292, \"fact\": 7.352789477352357, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:41:00\", \"yhat\": 7.192147882634176, \"yhat_lower\": 6.834786599538338, \"yhat_upper\": 7.549509165730013, \"fact\": 7.435857234044891, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:42:00\", \"yhat\": 7.205474679928187, \"yhat_lower\": 6.769332347019433, \"yhat_upper\": 7.641617012836941, \"fact\": 7.224490309562595, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:43:00\", \"yhat\": 7.1925059525301, \"yhat_lower\": 6.6871202996102985, \"yhat_upper\": 7.697891605449901, \"fact\": 7.123376652717213, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:44:00\", \"yhat\": 7.20512623080217, \"yhat_lower\": 6.641212190679784, \"yhat_upper\": 7.769040270924556, \"fact\": 7.0722055728658, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:45:00\", \"yhat\": 7.05674553395191, \"yhat_lower\": 6.8064854427037345, \"yhat_upper\": 7.307005625200085, \"fact\": 7.0742890656413255, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:46:00\", \"yhat\": 7.071798459896775, \"yhat_lower\": 6.713948014641266, \"yhat_upper\": 7.429648905152284, \"fact\": 7.242089094524295, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:47:00\", \"yhat\": 7.057141926315996, \"yhat_lower\": 6.620381184092856, \"yhat_upper\": 7.493902668539136, \"fact\": 7.124376062669945, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:48:00\", \"yhat\": 7.071412505829328, \"yhat_lower\": 6.565335109644032, \"yhat_upper\": 7.577489902014625, \"fact\": 7.211386630870367, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:49:00\", \"yhat\": 7.05751771696101, \"yhat_lower\": 6.492817374714798, \"yhat_upper\": 7.622218059207222, \"fact\": 7.327778305274825, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:50:00\", \"yhat\": 7.337577152494852, \"yhat_lower\": 7.0872324450297235, \"yhat_upper\": 7.58792185995998, \"fact\": 7.114185757892747, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:51:00\", \"yhat\": 7.328048551617149, \"yhat_lower\": 6.969873950564092, \"yhat_upper\": 7.686223152670206, \"fact\": 7.13394669208722, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:52:00\", \"yhat\": 7.337314359384924, \"yhat_lower\": 6.900231028184155, \"yhat_upper\": 7.774397690585692, \"fact\": 6.998725732620053, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:53:00\", \"yhat\": 7.3283040970503714, \"yhat_lower\": 6.821768213297846, \"yhat_upper\": 7.834839980802897, \"fact\": 6.999429650181499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:54:00\", \"yhat\": 7.337065861741822, \"yhat_lower\": 6.771904475511329, \"yhat_upper\": 7.902227247972315, \"fact\": 6.88988017320615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:55:00\", \"yhat\": 6.885315580374561, \"yhat_lower\": 6.633676344887812, \"yhat_upper\": 7.13695481586131, \"fact\": 7.011925284409866, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:56:00\", \"yhat\": 6.8857629900837525, \"yhat_lower\": 6.522592321076656, \"yhat_upper\": 7.248933659090849, \"fact\": 7.0993986854425275, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:57:00\", \"yhat\": 6.885719136128917, \"yhat_lower\": 6.438572737407546, \"yhat_upper\": 7.332865534850288, \"fact\": 7.271220399150457, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:58:00\", \"yhat\": 6.885723434581354, \"yhat_lower\": 6.367999465344272, \"yhat_upper\": 7.4034474038184355, \"fact\": 7.264494897726525, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:59:00\", \"yhat\": 6.885723013258045, \"yhat_lower\": 6.305954704749167, \"yhat_upper\": 7.4654913217669225, \"fact\": 7.044423132287613, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:00:00\", \"yhat\": 7.0536403608448035, \"yhat_lower\": 6.802129077409046, \"yhat_upper\": 7.305151644280561, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:01:00\", \"yhat\": 7.0450296877754335, \"yhat_lower\": 6.683772977201631, \"yhat_upper\": 7.406286398349236, \"fact\": 7.021339661711941, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:02:00\", \"yhat\": 7.053073720778145, \"yhat_lower\": 6.612593066972749, \"yhat_upper\": 7.493554374583542, \"fact\": 7.317534903185268, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:03:00\", \"yhat\": 7.04555903912348, \"yhat_lower\": 6.534655074519172, \"yhat_upper\": 7.556463003727789, \"fact\": 7.10716948495657, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:04:00\", \"yhat\": 7.052579204300814, \"yhat_lower\": 6.482696754452679, \"yhat_upper\": 7.62246165414895, \"fact\": 7.215310153650435, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:05:00\", \"yhat\": 7.218657222721772, \"yhat_lower\": 6.965159052125586, \"yhat_upper\": 7.472155393317958, \"fact\": 7.220570452422764, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:06:00\", \"yhat\": 7.218825197379227, \"yhat_lower\": 6.85453385789717, \"yhat_upper\": 7.583116536861283, \"fact\": 7.103080980776757, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:07:00\", \"yhat\": 7.218833627287587, \"yhat_lower\": 6.77009253188357, \"yhat_upper\": 7.6675747226916044, \"fact\": 7.050846940115519, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:08:00\", \"yhat\": 7.218834050347565, \"yhat_lower\": 6.69918062118574, \"yhat_upper\": 7.7384874795093905, \"fact\": 6.939961443394882, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:09:00\", \"yhat\": 7.218834071579082, \"yhat_lower\": 6.636844947591255, \"yhat_upper\": 7.80082319556691, \"fact\": 6.998102784901203, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:10:00\", \"yhat\": 6.9999817303214, \"yhat_lower\": 6.7466685023181485, \"yhat_upper\": 7.253294958324651, \"fact\": 7.099749789012837, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:11:00\", \"yhat\": 7.000050533044942, \"yhat_lower\": 6.63593108238495, \"yhat_upper\": 7.364169983704935, \"fact\": 7.235330438059645, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:12:00\", \"yhat\": 7.00005305244477, \"yhat_lower\": 6.551548330818587, \"yhat_upper\": 7.448557774070952, \"fact\": 7.338052774675268, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:13:00\", \"yhat\": 7.000053144699482, \"yhat_lower\": 6.480692200798091, \"yhat_upper\": 7.519414088600873, \"fact\": 7.288772432558911, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:14:00\", \"yhat\": 7.00005314807764, \"yhat_lower\": 6.418404364929072, \"yhat_upper\": 7.581701931226209, \"fact\": 7.324544402704568, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:15:00\", \"yhat\": 7.325769054774548, \"yhat_lower\": 7.072539439260948, \"yhat_upper\": 7.578998670288147, \"fact\": 7.121821576872811, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:16:00\", \"yhat\": 7.325825187062364, \"yhat_lower\": 6.96142838736375, \"yhat_upper\": 7.690221986760978, \"fact\": 7.287459513397984, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:17:00\", \"yhat\": 7.325827759902285, \"yhat_lower\": 6.876766102452637, \"yhat_upper\": 7.774889417351933, \"fact\": 7.314871558542801, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:18:00\", \"yhat\": 7.32582787782916, \"yhat_lower\": 6.805695758803259, \"yhat_upper\": 7.84595999685506, \"fact\": 7.415176143796352, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:19:00\", \"yhat\": 7.325827883234373, \"yhat_lower\": 6.743231183005246, \"yhat_upper\": 7.9084245834635, \"fact\": 7.516025127146469, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:20:00\", \"yhat\": 7.519557228738009, \"yhat_lower\": 7.2658402512386475, \"yhat_upper\": 7.77327420623737, \"fact\": 7.6050364669125985, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:21:00\", \"yhat\": 7.5200651268529075, \"yhat_lower\": 7.155587980315242, \"yhat_upper\": 7.884542273390573, \"fact\": 7.566205083257227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:22:00\", \"yhat\": 7.520138160000011, \"yhat_lower\": 7.07078897294257, \"yhat_upper\": 7.969487347057451, \"fact\": 7.729722886759445, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:23:00\", \"yhat\": 7.520148661792436, \"yhat_lower\": 6.999502660143899, \"yhat_upper\": 8.040794663440973, \"fact\": 7.763741051140791, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:24:00\", \"yhat\": 7.520150171896389, \"yhat_lower\": 6.9368472798164476, \"yhat_upper\": 8.10345306397633, \"fact\": 7.791223704044699, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:25:00\", \"yhat\": 7.792077741431366, \"yhat_lower\": 7.5384821135383, \"yhat_upper\": 8.045673369324433, \"fact\": 8.00363971231057, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:26:00\", \"yhat\": 7.792046415790713, \"yhat_lower\": 7.427452208344807, \"yhat_upper\": 8.156640623236619, \"fact\": 7.849663097795245, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:27:00\", \"yhat\": 7.792047564798681, \"yhat_lower\": 7.343286305202935, \"yhat_upper\": 8.240808824394428, \"fact\": 7.787666292025311, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:28:00\", \"yhat\": 7.792047522653675, \"yhat_lower\": 7.272576366136444, \"yhat_upper\": 8.311518679170907, \"fact\": 7.948607630624028, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:29:00\", \"yhat\": 7.792047524199532, \"yhat_lower\": 7.2104001387265395, \"yhat_upper\": 8.373694909672524, \"fact\": 8.10370677263385, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:30:00\", \"yhat\": 8.108906777967789, \"yhat_lower\": 7.854506878107899, \"yhat_upper\": 8.36330667782768, \"fact\": 7.939931606789101, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:31:00\", \"yhat\": 8.109344041835927, \"yhat_lower\": 7.743795814893018, \"yhat_upper\": 8.474892268778836, \"fact\": 8.01138413900431, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:32:00\", \"yhat\": 8.109380810969437, \"yhat_lower\": 7.658947956791965, \"yhat_upper\": 8.55981366514691, \"fact\": 8.024263331132907, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:33:00\", \"yhat\": 8.109383902853486, \"yhat_lower\": 7.58767118817815, \"yhat_upper\": 8.63109661752882, \"fact\": 8.02728778518364, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:34:00\", \"yhat\": 8.109384162847292, \"yhat_lower\": 7.525020326847561, \"yhat_upper\": 8.693747998847023, \"fact\": 8.145123103951551, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:35:00\", \"yhat\": 8.14854852027868, \"yhat_lower\": 7.894151313038731, \"yhat_upper\": 8.40294572751863, \"fact\": 8.346190638990999, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:36:00\", \"yhat\": 8.148650456129728, \"yhat_lower\": 7.783611913723136, \"yhat_upper\": 8.513688998536319, \"fact\": 8.422543666781964, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:37:00\", \"yhat\": 8.148653489605584, \"yhat_lower\": 7.699316635721408, \"yhat_upper\": 8.59799034348976, \"fact\": 8.459908928046268, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:38:00\", \"yhat\": 8.148653579877806, \"yhat_lower\": 7.628502149125702, \"yhat_upper\": 8.668805010629908, \"fact\": 8.455258423436057, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:39:00\", \"yhat\": 8.148653582564187, \"yhat_lower\": 7.566234905239464, \"yhat_upper\": 8.731072259888908, \"fact\": 8.556138297516846, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:40:00\", \"yhat\": 8.559337743941045, \"yhat_lower\": 8.304869568143616, \"yhat_upper\": 8.813805919738474, \"fact\": 8.519475678661328, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:41:00\", \"yhat\": 8.55967801435906, \"yhat_lower\": 8.194048587272157, \"yhat_upper\": 8.925307441445963, \"fact\": 8.41012741828165, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:42:00\", \"yhat\": 8.55971420310612, \"yhat_lower\": 8.109083983864776, \"yhat_upper\": 9.010344422347464, \"fact\": 8.331208792762425, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:43:00\", \"yhat\": 8.559718051884458, \"yhat_lower\": 8.037704203579201, \"yhat_upper\": 9.081731900189714, \"fact\": 8.236846240515225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:44:00\", \"yhat\": 8.55971846121321, \"yhat_lower\": 7.974966853533057, \"yhat_upper\": 9.144470068893364, \"fact\": 8.256041617140585, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:45:00\", \"yhat\": 8.256446300367262, \"yhat_lower\": 8.00220595361776, \"yhat_upper\": 8.510686647116763, \"fact\": 8.380900569385801, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:46:00\", \"yhat\": 8.25648753757218, \"yhat_lower\": 7.8909641420738295, \"yhat_upper\": 8.622010933070532, \"fact\": 8.283185908846015, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:47:00\", \"yhat\": 8.256491739641744, \"yhat_lower\": 7.805907930809316, \"yhat_upper\": 8.707075548474172, \"fact\": 8.19681328000246, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:48:00\", \"yhat\": 8.256492167832468, \"yhat_lower\": 7.734486380502248, \"yhat_upper\": 8.778497955162686, \"fact\": 8.268775956135276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:49:00\", \"yhat\": 8.256492211465085, \"yhat_lower\": 7.671719615563745, \"yhat_upper\": 8.841264807366425, \"fact\": 8.42869425982205, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:50:00\", \"yhat\": 8.433972931515521, \"yhat_lower\": 8.179597249012575, \"yhat_upper\": 8.688348614018468, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:51:00\", \"yhat\": 8.433627570176709, \"yhat_lower\": 8.067584238141595, \"yhat_upper\": 8.799670902211822, \"fact\": 8.475701630597108, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:52:00\", \"yhat\": 8.43365016571992, \"yhat_lower\": 7.983134418564238, \"yhat_upper\": 8.884165912875602, \"fact\": 8.648756666874846, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:53:00\", \"yhat\": 8.433648687388342, \"yhat_lower\": 7.912149860957917, \"yhat_upper\": 8.955147513818767, \"fact\": 8.687765792214106, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:54:00\", \"yhat\": 8.433648784109373, \"yhat_lower\": 7.849734138461978, \"yhat_upper\": 9.017563429756768, \"fact\": 8.748978959879818, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:55:00\", \"yhat\": 8.75110640865237, \"yhat_lower\": 8.496762290379833, \"yhat_upper\": 9.005450526924909, \"fact\": 8.799798123977336, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:56:00\", \"yhat\": 8.751178623062, \"yhat_lower\": 8.385174407151624, \"yhat_upper\": 9.117182838972376, \"fact\": 8.712653545197707, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:57:00\", \"yhat\": 8.751181074317685, \"yhat_lower\": 8.30019841735437, \"yhat_upper\": 9.202163731281, \"fact\": 8.7413195426343, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:58:00\", \"yhat\": 8.75118115752344, \"yhat_lower\": 8.228862291362258, \"yhat_upper\": 9.273500023684623, \"fact\": 8.735522823807608, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:59:00\", \"yhat\": 8.751181160347787, \"yhat_lower\": 8.166160800611303, \"yhat_upper\": 9.336201520084272, \"fact\": 8.755033678541, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:00:00\", \"yhat\": 8.755706054193782, \"yhat_lower\": 8.5017529542068, \"yhat_upper\": 9.009659154180763, \"fact\": 8.697623905237386, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:01:00\", \"yhat\": 8.755727367222551, \"yhat_lower\": 8.39034787932722, \"yhat_upper\": 9.121106855117883, \"fact\": 8.732542420245244, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:02:00\", \"yhat\": 8.755728042805009, \"yhat_lower\": 8.305552665700095, \"yhat_upper\": 9.205903419909923, \"fact\": 8.667663294380052, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:03:00\", \"yhat\": 8.755728064219687, \"yhat_lower\": 8.234366202103606, \"yhat_upper\": 9.277089926335767, \"fact\": 8.74224875192919, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:04:00\", \"yhat\": 8.755728064898491, \"yhat_lower\": 8.17179428537325, \"yhat_upper\": 9.339661844423732, \"fact\": 8.813368356071924, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:05:00\", \"yhat\": 8.815798951545332, \"yhat_lower\": 8.562149112061316, \"yhat_upper\": 9.069448791029348, \"fact\": 8.763653819520787, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:06:00\", \"yhat\": 8.815900890152937, \"yhat_lower\": 8.451056396831643, \"yhat_upper\": 9.180745383474232, \"fact\": 8.727719225687869, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:07:00\", \"yhat\": 8.81590516543438, \"yhat_lower\": 8.366378747035252, \"yhat_upper\": 9.265431583833507, \"fact\": 8.757287262181396, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:08:00\", \"yhat\": 8.815905344738686, \"yhat_lower\": 8.295286060182855, \"yhat_upper\": 9.336524629294518, \"fact\": 8.58461198633341, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:09:00\", \"yhat\": 8.815905352258667, \"yhat_lower\": 8.23279711945526, \"yhat_upper\": 9.399013585062075, \"fact\": 8.580523889099103, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:10:00\", \"yhat\": 8.580362723804022, \"yhat_lower\": 8.326853112002222, \"yhat_upper\": 8.833872335605822, \"fact\": 8.729985918072733, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:11:00\", \"yhat\": 8.580356656980483, \"yhat_lower\": 8.215837046984399, \"yhat_upper\": 8.944876266976566, \"fact\": 8.715254942693004, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:12:00\", \"yhat\": 8.580356428604095, \"yhat_lower\": 8.131303956753406, \"yhat_upper\": 9.029408900454783, \"fact\": 8.657186335028134, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:13:00\", \"yhat\": 8.580356420007211, \"yhat_lower\": 8.060329538582451, \"yhat_upper\": 9.100383301431972, \"fact\": 8.715123818586068, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:14:00\", \"yhat\": 8.580356419683595, \"yhat_lower\": 7.99794073657419, \"yhat_upper\": 9.162772102793, \"fact\": 8.803699468934434, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:15:00\", \"yhat\": 8.806450034302976, \"yhat_lower\": 8.553075118765864, \"yhat_upper\": 9.059824949840088, \"fact\": 8.770428664936265, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:16:00\", \"yhat\": 8.806158991074216, \"yhat_lower\": 8.441572581831046, \"yhat_upper\": 9.170745400317386, \"fact\": 8.68461158678178, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:17:00\", \"yhat\": 8.806189786983296, \"yhat_lower\": 8.357679472774645, \"yhat_upper\": 9.254700101191947, \"fact\": 8.571580251558387, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:18:00\", \"yhat\": 8.80618652840202, \"yhat_lower\": 8.28709972157471, \"yhat_upper\": 9.325273335229328, \"fact\": 8.629115838099489, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:19:00\", \"yhat\": 8.806186873199502, \"yhat_lower\": 8.225036902210283, \"yhat_upper\": 9.387336844188722, \"fact\": 8.680104200208032, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:20:00\", \"yhat\": 8.68140738640574, \"yhat_lower\": 8.428265245907497, \"yhat_upper\": 8.934549526903982, \"fact\": 8.720381281982103, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:21:00\", \"yhat\": 8.681206473157925, \"yhat_lower\": 8.316765266710705, \"yhat_upper\": 9.045647679605144, \"fact\": 8.674145386553628, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:22:00\", \"yhat\": 8.6812374481124, \"yhat_lower\": 8.233101914538715, \"yhat_upper\": 9.129372981686085, \"fact\": 8.645195557966613, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:23:00\", \"yhat\": 8.681232672679146, \"yhat_lower\": 8.162633055588254, \"yhat_upper\": 9.199832289770038, \"fact\": 8.542567468006013, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:24:00\", \"yhat\": 8.68123340891147, \"yhat_lower\": 8.100674721536304, \"yhat_upper\": 9.261792096286637, \"fact\": 8.614450952639153, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:25:00\", \"yhat\": 8.617623322347557, \"yhat_lower\": 8.364769013424496, \"yhat_upper\": 8.870477631270617, \"fact\": 8.600759594883009, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:26:00\", \"yhat\": 8.617158210772903, \"yhat_lower\": 8.253204853244553, \"yhat_upper\": 8.981111568301253, \"fact\": 8.344461174673786, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:27:00\", \"yhat\": 8.617226402313221, \"yhat_lower\": 8.169671192639882, \"yhat_upper\": 9.064781611986561, \"fact\": 8.345833211443853, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:28:00\", \"yhat\": 8.61721640452683, \"yhat_lower\": 8.09928858505197, \"yhat_upper\": 9.135144224001692, \"fact\": 8.308939856017505, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:29:00\", \"yhat\": 8.617217870335232, \"yhat_lower\": 8.037409169683444, \"yhat_upper\": 9.197026570987019, \"fact\": 8.288296800857225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:30:00\", \"yhat\": 8.298189492177734, \"yhat_lower\": 8.046133045695523, \"yhat_upper\": 8.550245938659945, \"fact\": 8.200204061185255, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:31:00\", \"yhat\": 8.28859806674758, \"yhat_lower\": 7.927798800188566, \"yhat_upper\": 8.649397333306595, \"fact\": 8.316763381802183, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:32:00\", \"yhat\": 8.297897400852088, \"yhat_lower\": 7.857667635206764, \"yhat_upper\": 8.738127166497414, \"fact\": 8.213260542060581, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:33:00\", \"yhat\": 8.28888126290502, \"yhat_lower\": 7.778633272272173, \"yhat_upper\": 8.799129253537867, \"fact\": 8.100444362690379, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:34:00\", \"yhat\": 8.297622828974912, \"yhat_lower\": 7.728353759755649, \"yhat_upper\": 8.866891898194176, \"fact\": 8.166018118282045, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:35:00\", \"yhat\": 8.154120802005647, \"yhat_lower\": 7.902030261934824, \"yhat_upper\": 8.40621134207647, \"fact\": 8.133296418077531, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:36:00\", \"yhat\": 8.165645749740973, \"yhat_lower\": 7.804782187374016, \"yhat_upper\": 8.52650931210793, \"fact\": 8.2170409947153, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:37:00\", \"yhat\": 8.154481515957805, \"yhat_lower\": 7.7141761672328455, \"yhat_upper\": 8.594786864682764, \"fact\": 8.174451684276958, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:38:00\", \"yhat\": 8.1652963256062, \"yhat_lower\": 7.654957313392368, \"yhat_upper\": 8.675635337820031, \"fact\": 8.145406367187972, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:39:00\", \"yhat\": 8.154820003629915, \"yhat_lower\": 7.585449337442692, \"yhat_upper\": 8.724190669817139, \"fact\": 8.179618234404483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:40:00\", \"yhat\": 8.189034354851302, \"yhat_lower\": 7.937347911562023, \"yhat_upper\": 8.44072079814058, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:41:00\", \"yhat\": 8.179912033639834, \"yhat_lower\": 7.819595429633585, \"yhat_upper\": 8.540228637646083, \"fact\": 8.079524030680783, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:42:00\", \"yhat\": 8.188749722659978, \"yhat_lower\": 7.749123912990297, \"yhat_upper\": 8.628375532329658, \"fact\": 8.044864923024296, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:43:00\", \"yhat\": 8.180187784814752, \"yhat_lower\": 7.670622315253084, \"yhat_upper\": 8.68975325437642, \"fact\": 7.985665500760242, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:44:00\", \"yhat\": 8.1884825753984, \"yhat_lower\": 7.619984009050429, \"yhat_upper\": 8.75698114174637, \"fact\": 8.046488503559157, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:45:00\", \"yhat\": 8.03966137384912, \"yhat_lower\": 7.788116975729213, \"yhat_upper\": 8.291205771969027, \"fact\": 7.987912077062759, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:46:00\", \"yhat\": 8.046277520746237, \"yhat_lower\": 7.686355874633648, \"yhat_upper\": 8.406199166858826, \"fact\": 7.950148874417816, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:47:00\", \"yhat\": 8.039865836535832, \"yhat_lower\": 7.600650929721418, \"yhat_upper\": 8.479080743350245, \"fact\": 8.068015846901767, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:48:00\", \"yhat\": 8.046079376690429, \"yhat_lower\": 7.537072389939165, \"yhat_upper\": 8.555086363441692, \"fact\": 8.09246969731638, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:49:00\", \"yhat\": 8.040057857229108, \"yhat_lower\": 7.472131541821604, \"yhat_upper\": 8.607984172636613, \"fact\": 8.019705123658905, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:50:00\", \"yhat\": 8.026120815909106, \"yhat_lower\": 7.774834628100456, \"yhat_upper\": 8.277407003717757, \"fact\": 8.06028447175568, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:51:00\", \"yhat\": 8.019905304885793, \"yhat_lower\": 7.660308585562578, \"yhat_upper\": 8.379502024209009, \"fact\": 8.006729199085527, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:52:00\", \"yhat\": 8.025926880699336, \"yhat_lower\": 7.587124219673318, \"yhat_upper\": 8.464729541725355, \"fact\": 7.884033492434073, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:53:00\", \"yhat\": 8.020093188965506, \"yhat_lower\": 7.511545701134459, \"yhat_upper\": 8.528640676796552, \"fact\": 8.046823619428089, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:54:00\", \"yhat\": 8.025744858943458, \"yhat_lower\": 7.458341932307344, \"yhat_upper\": 8.593147785579571, \"fact\": 7.942622275786526, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:55:00\", \"yhat\": 7.930438435577516, \"yhat_lower\": 7.679024411472945, \"yhat_upper\": 8.181852459682087, \"fact\": 8.107336569826192, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:56:00\", \"yhat\": 7.942220305414503, \"yhat_lower\": 7.582371615541745, \"yhat_upper\": 8.302068995287263, \"fact\": 8.118646844437311, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:57:00\", \"yhat\": 7.9308271441062095, \"yhat_lower\": 7.491736755447252, \"yhat_upper\": 8.369917532765166, \"fact\": 8.101259000219994, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:58:00\", \"yhat\": 7.941844421193188, \"yhat_lower\": 7.432940380162401, \"yhat_upper\": 8.450748462223974, \"fact\": 7.975741033032815, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:59:00\", \"yhat\": 7.931190627120871, \"yhat_lower\": 7.363399774895639, \"yhat_upper\": 8.498981479346103, \"fact\": 7.988226254020678, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:00:00\", \"yhat\": 7.9895145920203285, \"yhat_lower\": 7.737215683345835, \"yhat_upper\": 8.241813500694823, \"fact\": 8.062133599963992, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:01:00\", \"yhat\": 7.989216732186696, \"yhat_lower\": 7.627231990466299, \"yhat_upper\": 8.351201473907093, \"fact\": 8.023293650410814, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:02:00\", \"yhat\": 7.989285596475815, \"yhat_lower\": 7.54482985514088, \"yhat_upper\": 8.433741337810751, \"fact\": 7.840974331834362, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:03:00\", \"yhat\": 7.989269675261269, \"yhat_lower\": 7.475217578888254, \"yhat_upper\": 8.503321771634285, \"fact\": 7.651628623492227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:04:00\", \"yhat\": 7.98927335619773, \"yhat_lower\": 7.414024034866996, \"yhat_upper\": 8.564522677528464, \"fact\": 7.656945468320031, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:05:00\", \"yhat\": 7.643592413729259, \"yhat_lower\": 7.391920684220081, \"yhat_upper\": 7.895264143238436, \"fact\": 7.567227283798734, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:06:00\", \"yhat\": 7.656488931048908, \"yhat_lower\": 7.29624973678623, \"yhat_upper\": 8.016728125311586, \"fact\": 7.485420053891467, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:07:00\", \"yhat\": 7.6440333421163995, \"yhat_lower\": 7.204470399576512, \"yhat_upper\": 8.083596284656286, \"fact\": 7.453326960684346, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:08:00\", \"yhat\": 7.656063077882291, \"yhat_lower\": 7.146606635186908, \"yhat_upper\": 8.165519520577675, \"fact\": 7.5675711212537005, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:09:00\", \"yhat\": 7.644444635480143, \"yhat_lower\": 7.07603733791208, \"yhat_upper\": 8.212851933048206, \"fact\": 7.59136442192483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:10:00\", \"yhat\": 7.601231367687085, \"yhat_lower\": 7.349792115994011, \"yhat_upper\": 7.8526706193801585, \"fact\": 7.819711007934736, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:12:00\", \"yhat\": 7.600906803165737, \"yhat_lower\": 7.161709042345346, \"yhat_upper\": 8.040104563986128, \"fact\": 7.958116508233395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:13:00\", \"yhat\": 7.592013940621235, \"yhat_lower\": 7.082959110317633, \"yhat_upper\": 8.101068770924837, \"fact\": 7.968943931383387, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:14:00\", \"yhat\": 7.6006039675590795, \"yhat_lower\": 7.0326585898450915, \"yhat_upper\": 8.168549345273068, \"fact\": 8.088943997843543, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:15:00\", \"yhat\": 8.09295495298188, \"yhat_lower\": 7.84015514230051, \"yhat_upper\": 8.345754763663251, \"fact\": 7.94868555720843, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:16:00\", \"yhat\": 8.092441012973348, \"yhat_lower\": 7.728750091851999, \"yhat_upper\": 8.456131934094696, \"fact\": 8.031676300784632, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:17:00\", \"yhat\": 8.092506866198642, \"yhat_lower\": 7.645231639764697, \"yhat_upper\": 8.539782092632587, \"fact\": 7.919155930994936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:18:00\", \"yhat\": 8.092498428156828, \"yhat_lower\": 7.574895046589965, \"yhat_upper\": 8.610101809723691, \"fact\": 7.860433362299011, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:19:00\", \"yhat\": 8.092499509357474, \"yhat_lower\": 7.513049859018121, \"yhat_upper\": 8.671949159696826, \"fact\": 7.887708781348885, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:20:00\", \"yhat\": 7.8886960043342444, \"yhat_lower\": 7.635907084081201, \"yhat_upper\": 8.141484924587289, \"fact\": 7.95518511616727, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:21:00\", \"yhat\": 7.888623551243643, \"yhat_lower\": 7.525580131570147, \"yhat_upper\": 8.251666970917139, \"fact\": 8.031980714285634, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:22:00\", \"yhat\": 7.88862886863436, \"yhat_lower\": 7.442085010522148, \"yhat_upper\": 8.335172726746572, \"fact\": 7.986336725108602, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:23:00\", \"yhat\": 7.888628478386769, \"yhat_lower\": 7.371884718252424, \"yhat_upper\": 8.405372238521114, \"fact\": 7.9750917218656125, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:24:00\", \"yhat\": 7.888628507027354, \"yhat_lower\": 7.310143235182004, \"yhat_upper\": 8.467113778872704, \"fact\": 7.88889753640553, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:25:00\", \"yhat\": 7.886225983596472, \"yhat_lower\": 7.633721357153316, \"yhat_upper\": 8.138730610039628, \"fact\": 7.99517540935556, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:26:00\", \"yhat\": 7.886430544223814, \"yhat_lower\": 7.523719838510416, \"yhat_upper\": 8.249141249937212, \"fact\": 8.048314544065995, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:27:00\", \"yhat\": 7.886414881029691, \"yhat_lower\": 7.440269559661288, \"yhat_upper\": 8.332560202398096, \"fact\": 7.831803761276401, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:28:00\", \"yhat\": 7.886416080359461, \"yhat_lower\": 7.370125224943679, \"yhat_upper\": 8.402706935775244, \"fact\": 7.813286153136449, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:29:00\", \"yhat\": 7.886415988526857, \"yhat_lower\": 7.308432417340612, \"yhat_upper\": 8.464399559713103, \"fact\": 7.800293226728714, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:30:00\", \"yhat\": 7.800363237210505, \"yhat_lower\": 7.548781480111039, \"yhat_upper\": 8.051944994309972, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:31:00\", \"yhat\": 7.800295502411265, \"yhat_lower\": 7.44003859776619, \"yhat_upper\": 8.16055240705634, \"fact\": 7.568500650268759, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:32:00\", \"yhat\": 7.800361035498751, \"yhat_lower\": 7.360837236990321, \"yhat_upper\": 8.239884834007182, \"fact\": 7.485083521432123, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:33:00\", \"yhat\": 7.800297632556636, \"yhat_lower\": 7.29081644950358, \"yhat_upper\": 8.309778815609693, \"fact\": 7.562902259069609, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:34:00\", \"yhat\": 7.800358974593507, \"yhat_lower\": 7.231972256014665, \"yhat_upper\": 8.36874569317235, \"fact\": 7.774237559343768, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:35:00\", \"yhat\": 7.775403417312147, \"yhat_lower\": 7.523244807904434, \"yhat_upper\": 8.027562026719862, \"fact\": 7.84399038958902, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:36:00\", \"yhat\": 7.774275535880446, \"yhat_lower\": 7.413359727516846, \"yhat_upper\": 8.135191344244047, \"fact\": 7.703560195883743, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:37:00\", \"yhat\": 7.775366677819242, \"yhat_lower\": 7.334976144092362, \"yhat_upper\": 8.215757211546121, \"fact\": 7.580990260422031, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:38:00\", \"yhat\": 7.774311078624916, \"yhat_lower\": 7.263897936878491, \"yhat_upper\": 8.284724220371341, \"fact\": 7.536262826528088, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:39:00\", \"yhat\": 7.775332292840447, \"yhat_lower\": 7.205860173211591, \"yhat_upper\": 8.344804412469301, \"fact\": 7.479715123694341, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:40:00\", \"yhat\": 7.479944326746334, \"yhat_lower\": 7.227851320738915, \"yhat_upper\": 7.732037332753753, \"fact\": 7.547983789043043, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:41:00\", \"yhat\": 7.479722800843295, \"yhat_lower\": 7.1188015306397014, \"yhat_upper\": 7.840644071046889, \"fact\": 7.661272545133261, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:42:00\", \"yhat\": 7.479936906743241, \"yhat_lower\": 7.039573654917003, \"yhat_upper\": 7.9203001585694786, \"fact\": 7.799921735142088, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:43:00\", \"yhat\": 7.4797299723136215, \"yhat_lower\": 6.9693090116155645, \"yhat_upper\": 7.9901509330116784, \"fact\": 7.90744271501311, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:44:00\", \"yhat\": 7.479929975481087, \"yhat_lower\": 6.910471365675477, \"yhat_upper\": 8.049388585286698, \"fact\": 7.9914944717499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:45:00\", \"yhat\": 7.992831826320691, \"yhat_lower\": 7.740697630989267, \"yhat_upper\": 8.244966021652115, \"fact\": 8.078038554719182, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:46:00\", \"yhat\": 7.991538971212558, \"yhat_lower\": 7.630528262305753, \"yhat_upper\": 8.352549680119363, \"fact\": 7.887233092209016, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:47:00\", \"yhat\": 7.992788807544024, \"yhat_lower\": 7.552328612089921, \"yhat_upper\": 8.433249002998126, \"fact\": 7.727544853299987, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:48:00\", \"yhat\": 7.991580558571942, \"yhat_lower\": 7.481033163607713, \"yhat_upper\": 8.50212795353617, \"fact\": 7.797725220766124, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:49:00\", \"yhat\": 7.9927486039725935, \"yhat_lower\": 7.423158304049574, \"yhat_upper\": 8.562338903895613, \"fact\": 7.873085248908442, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:50:00\", \"yhat\": 7.874290611601964, \"yhat_lower\": 7.621878341554407, \"yhat_upper\": 8.126702881649521, \"fact\": 7.980822066822155, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:51:00\", \"yhat\": 7.873127035735559, \"yhat_lower\": 7.5115791361467075, \"yhat_upper\": 8.23467493532441, \"fact\": 7.734172080818521, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:52:00\", \"yhat\": 7.874250273416762, \"yhat_lower\": 7.433181494062872, \"yhat_upper\": 8.315319052770652, \"fact\": 7.599489257353818, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:53:00\", \"yhat\": 7.873165975499538, \"yhat_lower\": 7.361858717422135, \"yhat_upper\": 8.384473233576943, \"fact\": 7.722687896015395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:54:00\", \"yhat\": 7.874212683594335, \"yhat_lower\": 7.30380482480906, \"yhat_upper\": 8.44462054237961, \"fact\": 7.77275116820956, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:55:00\", \"yhat\": 7.774825652182994, \"yhat_lower\": 7.521869810970636, \"yhat_upper\": 8.027781493395352, \"fact\": 7.558314501085786, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:56:00\", \"yhat\": 7.77282178658255, \"yhat_lower\": 7.410478614218573, \"yhat_upper\": 8.135164958946527, \"fact\": 7.60533623053003, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:57:00\", \"yhat\": 7.774757437759453, \"yhat_lower\": 7.332727010862397, \"yhat_upper\": 8.216787864656508, \"fact\": 7.564962022147053, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:58:00\", \"yhat\": 7.772887678890487, \"yhat_lower\": 7.260455842600711, \"yhat_upper\": 8.285319515180262, \"fact\": 7.507104599166352, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:59:00\", \"yhat\": 7.774693788519015, \"yhat_lower\": 7.203039183116839, \"yhat_upper\": 8.34634839392119, \"fact\": 7.394733417407842, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:00:00\", \"yhat\": 7.385688797667205, \"yhat_lower\": 7.132552822126157, \"yhat_upper\": 7.6388247732082535, \"fact\": 7.209009286177776, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:01:00\", \"yhat\": 7.394455328793662, \"yhat_lower\": 7.032092706828553, \"yhat_upper\": 7.756817950758772, \"fact\": 7.296538174554642, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:02:00\", \"yhat\": 7.385958336084743, \"yhat_lower\": 6.9438268074600105, \"yhat_upper\": 7.828089864709475, \"fact\": 7.206584493381573, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:03:00\", \"yhat\": 7.394194077685835, \"yhat_lower\": 6.881735123874807, \"yhat_upper\": 7.906653031496863, \"fact\": 7.160033858921166, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:04:00\", \"yhat\": 7.386211554686991, \"yhat_lower\": 6.814479224515522, \"yhat_upper\": 7.95794388485846, \"fact\": 7.254636375974447, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:05:00\", \"yhat\": 7.259141253237945, \"yhat_lower\": 7.005935555482245, \"yhat_upper\": 7.512346950993645, \"fact\": 7.383418162205393, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:06:00\", \"yhat\": 7.254784853775417, \"yhat_lower\": 6.892094207516899, \"yhat_upper\": 7.617475500033936, \"fact\": 7.412786701811927, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:07:00\", \"yhat\": 7.258997669167945, \"yhat_lower\": 6.816543482107363, \"yhat_upper\": 7.701451856228527, \"fact\": 7.410993240415173, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:08:00\", \"yhat\": 7.254923705408612, \"yhat_lower\": 6.742000635756372, \"yhat_upper\": 7.767846775060852, \"fact\": 7.311113765840335, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:09:00\", \"yhat\": 7.2588633939935425, \"yhat_lower\": 6.686663753839192, \"yhat_upper\": 7.831063034147893, \"fact\": 7.3759026127290195, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:10:00\", \"yhat\": 7.377722826500255, \"yhat_lower\": 7.124707059929779, \"yhat_upper\": 7.630738593070731, \"fact\": 7.429606304723798, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:11:00\", \"yhat\": 7.375965698815666, \"yhat_lower\": 7.0133952128731885, \"yhat_upper\": 7.738536184758143, \"fact\": 7.49942313491552, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:12:00\", \"yhat\": 7.37766192688994, \"yhat_lower\": 6.935404606005896, \"yhat_upper\": 7.819919247773983, \"fact\": 7.391456931311621, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:13:00\", \"yhat\": 7.3760244877298895, \"yhat_lower\": 6.863271155694184, \"yhat_upper\": 7.888777819765595, \"fact\": 7.285664791754202, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:14:00\", \"yhat\": 7.377605175518006, \"yhat_lower\": 6.8056266157813665, \"yhat_upper\": 7.949583735254646, \"fact\": 7.115643401562619, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:15:00\", \"yhat\": 7.109097062740931, \"yhat_lower\": 6.855988233676483, \"yhat_upper\": 7.362205891805379, \"fact\": 7.054269618633998, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:16:00\", \"yhat\": 7.115410784128555, \"yhat_lower\": 6.75263313980147, \"yhat_upper\": 7.478188428455639, \"fact\": 7.060118316641897, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:17:00\", \"yhat\": 7.109321414353122, \"yhat_lower\": 6.666835479886579, \"yhat_upper\": 7.551807348819665, \"fact\": 7.161535062516319, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:18:00\", \"yhat\": 7.115194404620739, \"yhat_lower\": 6.602147999712708, \"yhat_upper\": 7.628240809528771, \"fact\": 7.255915033132671, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:19:00\", \"yhat\": 7.1095301050371145, \"yhat_lower\": 6.537239550961617, \"yhat_upper\": 7.681820659112612, \"fact\": 7.426012747469036, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:20:00\", \"yhat\": 7.435183771218641, \"yhat_lower\": 7.182046143669651, \"yhat_upper\": 7.6883213987676315, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:21:00\", \"yhat\": 7.42634269186817, \"yhat_lower\": 7.06348758950777, \"yhat_upper\": 7.78919779422857, \"fact\": 7.317126681220951, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:22:00\", \"yhat\": 7.434865697174387, \"yhat_lower\": 6.992296996412565, \"yhat_upper\": 7.8774343979362085, \"fact\": 7.437457589321834, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:23:00\", \"yhat\": 7.426649322615331, \"yhat_lower\": 6.913493322803598, \"yhat_upper\": 7.939805322427064, \"fact\": 7.411908464884772, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:24:00\", \"yhat\": 7.4345700980307186, \"yhat_lower\": 6.862164486094167, \"yhat_upper\": 8.00697570996727, \"fact\": 7.524143393749286, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:25:00\", \"yhat\": 7.522268346908923, \"yhat_lower\": 7.2690560658477485, \"yhat_upper\": 7.775480627970098, \"fact\": 7.496314903881952, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:26:00\", \"yhat\": 7.524076742141832, \"yhat_lower\": 7.161329417566667, \"yhat_upper\": 7.886824066716998, \"fact\": 7.573752510226136, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:27:00\", \"yhat\": 7.52233262927595, \"yhat_lower\": 7.079817227671923, \"yhat_upper\": 7.964848030879977, \"fact\": 7.541365430808015, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:28:00\", \"yhat\": 7.5240147447967045, \"yhat_lower\": 7.011011068682215, \"yhat_upper\": 8.037018420911194, \"fact\": 7.502722693475748, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:29:00\", \"yhat\": 7.522392422824019, \"yhat_lower\": 6.950101678549461, \"yhat_upper\": 8.094683167098578, \"fact\": 7.432187339829274, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:30:00\", \"yhat\": 7.429892489954869, \"yhat_lower\": 7.177032281079992, \"yhat_upper\": 7.682752698829747, \"fact\": 7.367743829771953, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:31:00\", \"yhat\": 7.432107393596378, \"yhat_lower\": 7.069869225372073, \"yhat_upper\": 7.794345561820683, \"fact\": 7.2855991505679105, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:32:00\", \"yhat\": 7.429969651081765, \"yhat_lower\": 6.988076253242481, \"yhat_upper\": 7.87186304892105, \"fact\": 7.3253574361749, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:33:00\", \"yhat\": 7.43203292055008, \"yhat_lower\": 6.91974943317916, \"yhat_upper\": 7.944316407921001, \"fact\": 7.612270582135634, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:34:00\", \"yhat\": 7.430041529692772, \"yhat_lower\": 6.858556735252098, \"yhat_upper\": 8.001526324133446, \"fact\": 7.591724855148331, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:35:00\", \"yhat\": 7.587698807782413, \"yhat_lower\": 7.334433116303468, \"yhat_upper\": 7.840964499261358, \"fact\": 7.518090746071456, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:36:00\", \"yhat\": 7.59157874538491, \"yhat_lower\": 7.228613493569347, \"yhat_upper\": 7.9545439972004734, \"fact\": 7.676593906453708, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:37:00\", \"yhat\": 7.587839615059046, \"yhat_lower\": 7.145108066981556, \"yhat_upper\": 8.030571163136536, \"fact\": 7.676014289757855, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:38:00\", \"yhat\": 7.591443048161889, \"yhat_lower\": 7.078131122512384, \"yhat_upper\": 8.104754973811392, \"fact\": 7.662263279799936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:39:00\", \"yhat\": 7.587970387678022, \"yhat_lower\": 7.015369487278913, \"yhat_upper\": 8.160571288077131, \"fact\": 7.744231691853355, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:40:00\", \"yhat\": 7.74470804214502, \"yhat_lower\": 7.491578873673213, \"yhat_upper\": 7.997837210616827, \"fact\": 7.535410761101995, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:41:00\", \"yhat\": 7.744248862463998, \"yhat_lower\": 7.381445018164147, \"yhat_upper\": 8.107052706763849, \"fact\": 7.555415160113135, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:42:00\", \"yhat\": 7.744691490469382, \"yhat_lower\": 7.302170483729033, \"yhat_upper\": 8.18721249720973, \"fact\": 7.735896999116704, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:43:00\", \"yhat\": 7.744264817514877, \"yhat_lower\": 7.231181223432841, \"yhat_upper\": 8.257348411596913, \"fact\": 7.847623077982126, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:44:00\", \"yhat\": 7.744676110537215, \"yhat_lower\": 7.17234040639972, \"yhat_upper\": 8.317011814674709, \"fact\": 7.7968137342359105, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:45:00\", \"yhat\": 7.790966825013142, \"yhat_lower\": 7.537462835422848, \"yhat_upper\": 8.044470814603436, \"fact\": 7.784207158858803, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:46:00\", \"yhat\": 7.796596808255675, \"yhat_lower\": 7.433149220333608, \"yhat_upper\": 8.160044396177742, \"fact\": 7.853358920798734, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:47:00\", \"yhat\": 7.791175702829961, \"yhat_lower\": 7.347904842006693, \"yhat_upper\": 8.23444656365323, \"fact\": 7.9176391649767295, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:48:00\", \"yhat\": 7.796395680007634, \"yhat_lower\": 7.282401556501674, \"yhat_upper\": 8.310389803513594, \"fact\": 7.831808587137508, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:49:00\", \"yhat\": 7.791369369025712, \"yhat_lower\": 7.218040405546062, \"yhat_upper\": 8.364698332505363, \"fact\": 7.74727118708158, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:50:00\", \"yhat\": 7.752406772961804, \"yhat_lower\": 7.499159830772723, \"yhat_upper\": 8.005653715150885, \"fact\": 7.749417906852305, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:51:00\", \"yhat\": 7.747462479312985, \"yhat_lower\": 7.384341056107206, \"yhat_upper\": 8.110583902518766, \"fact\": 7.788491835544637, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:52:00\", \"yhat\": 7.752222606055269, \"yhat_lower\": 7.309364637946218, \"yhat_upper\": 8.195080574164319, \"fact\": 7.682725698948679, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:53:00\", \"yhat\": 7.747639786301426, \"yhat_lower\": 7.234106931023541, \"yhat_upper\": 8.26117264157931, \"fact\": 7.663473876690589, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:54:00\", \"yhat\": 7.752051903464116, \"yhat_lower\": 7.179247861790422, \"yhat_upper\": 8.32485594513781, \"fact\": 7.650759642073896, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:55:00\", \"yhat\": 7.642282915223809, \"yhat_lower\": 7.389362135013348, \"yhat_upper\": 7.895203695434271, \"fact\": 7.643660841766507, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:56:00\", \"yhat\": 7.650442234015386, \"yhat_lower\": 7.2877785547753495, \"yhat_upper\": 8.013105913255421, \"fact\": 7.740792599980338, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:57:00\", \"yhat\": 7.642588438049094, \"yhat_lower\": 7.20029162120723, \"yhat_upper\": 8.084885254890958, \"fact\": 7.729485101072052, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:58:00\", \"yhat\": 7.650148151384946, \"yhat_lower\": 7.137262626369366, \"yhat_upper\": 8.163033676400527, \"fact\": 7.809879193660448, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:59:00\", \"yhat\": 7.642871508858766, \"yhat_lower\": 7.070791030071477, \"yhat_upper\": 8.214951987646055, \"fact\": 7.870193732739887, \"anomaly\": 0}], \"data-6901ae1c11c8ca95bc6f676e09993d85\": [{\"ds\": \"2021-08-23T04:56:00\", \"yhat\": 4.473766151591606, \"yhat_lower\": 4.131916534542009, \"yhat_upper\": 4.815615768641203, \"fact\": 4.840059501436562, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:28:00\", \"yhat\": 7.811028598630542, \"yhat_lower\": 7.302984694464954, \"yhat_upper\": 8.31907250279613, \"fact\": 7.22636705323483, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:29:00\", \"yhat\": 7.816239009807493, \"yhat_lower\": 7.249410032610338, \"yhat_upper\": 8.383067987004647, \"fact\": 7.215400231065601, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:42:00\", \"yhat\": 7.9635309998693184, \"yhat_lower\": 7.523847532664423, \"yhat_upper\": 8.403214467074214, \"fact\": 7.514024098971325, \"anomaly\": 1}, {\"ds\": \"2021-08-23T11:19:00\", \"yhat\": 8.247542407544156, \"yhat_lower\": 7.67141697409807, \"yhat_upper\": 8.823667840990241, \"fact\": 7.602800054795464, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:38:00\", \"yhat\": 8.617398730145023, \"yhat_lower\": 8.105510751766866, \"yhat_upper\": 9.12928670852318, \"fact\": 8.098826371466577, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:21:00\", \"yhat\": 9.576968584288453, \"yhat_lower\": 9.221979994094195, \"yhat_upper\": 9.931957174482712, \"fact\": 9.216432465535892, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:25:00\", \"yhat\": 6.668198547811226, \"yhat_lower\": 6.418155337927641, \"yhat_upper\": 6.918241757694811, \"fact\": 6.375346888821504, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:26:00\", \"yhat\": 6.659635499640006, \"yhat_lower\": 6.301818416867237, \"yhat_upper\": 7.0174525824127745, \"fact\": 6.228907112687021, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:39:00\", \"yhat\": 6.241321487625956, \"yhat_lower\": 5.674688968869951, \"yhat_upper\": 6.80795400638196, \"fact\": 6.844731750554106, \"anomaly\": 1}, {\"ds\": \"2021-08-23T22:11:00\", \"yhat\": 7.591700428749495, \"yhat_lower\": 7.231745188327408, \"yhat_upper\": 7.951655669171582, \"fact\": 7.983399267364478, \"anomaly\": 1}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## plot SARIMAX\n",
    "\n",
    "tf1 = pd.DataFrame({\"ds\" : mydf.index, \"yhat\" : fcall, \"yhat_lower\" : lowerall, \"yhat_upper\" : upperall, \"fact\" : mydf})\n",
    "detected_anomalies = detect_anomalies(tf1)\n",
    "plot_anomalies(detected_anomalies, mytitle=\"SARIMAX Anomaly Detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83964e33-5a46-4e9f-9b95-50c73f91f7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e4279d24-4cb0-4ed8-b29f-73b4e36142a3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:132: FutureWarning: The 'freq' argument in Timestamp is deprecated and will be removed in a future version.\n",
      "  date_key = Timestamp(key, freq=base_index.freq)\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tybalex/.pyenv/versions/3.8.6/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Holt-Winters Exponential Smoothing model fit\n",
    "\n",
    "print(n_loops)\n",
    "total_forecast = None\n",
    "mses = []\n",
    "fcast_total2 = None\n",
    "fcast_upper = None\n",
    "fcast_lower = None\n",
    "\n",
    "for i1 in range(10, n_loops): # 39 for normal period and 59 for all\n",
    "    i = i1 * one_step_len\n",
    "    mydf1, df_val1 = mydf[0:i+one_step_len].copy(), mydf[i+one_step_len: i + one_step_len*2].copy().reset_index() # no max interval\n",
    "    fit2 = Holt(mydf1, initialization_method=\"estimated\").fit()\n",
    "    fcast2 = fit2.forecast(one_step_len).rename(\"Holt's\")\n",
    "      \n",
    "#     fit2 = ExponentialSmoothing(\n",
    "#     mydf1,\n",
    "#     seasonal_periods=365,\n",
    "#     trend=\"add\",\n",
    "#     seasonal=\"add\",\n",
    "#     damped_trend=True,\n",
    "#     use_boxcox=True,\n",
    "#     initialization_method=\"estimated\",\n",
    "#     ).fit()\n",
    "#     fcast2 = fit2.forecast(one_step_len).rename(\"Holt-Winters (add-mul-seasonal)\")\n",
    "\n",
    "    \n",
    "#     fit2 = Holt(mydf1, exponential=True, initialization_method=\"estimated\").fit()\n",
    "#     fcast2 = fit2.forecast(one_step_len).rename(\"Exponential\")\n",
    "\n",
    "#     fit2 = Holt(mydf1, damped_trend=True, initialization_method=\"estimated\").fit(\n",
    "#         damping_trend=0.98\n",
    "#     )\n",
    "#     fcast2 = fit2.forecast(one_step_len).rename(\"Additive Damped\")\n",
    "    \n",
    "#     fit2 = Holt(\n",
    "#         mydf1, exponential=True, damped_trend=True, initialization_method=\"estimated\"\n",
    "#     ).fit()\n",
    "#     fcast2 = fit2.forecast(one_step_len).rename(\"Multiplicative Damped\")\n",
    "    \n",
    "    std2 = confidence_interval_level * np.sqrt(fit2.sse / len(mydf1))\n",
    "    fcast2lower = fcast2 - std2\n",
    "    fcast2upper = fcast2 + std2\n",
    "    fcast2lower, fcast2upper\n",
    "    if fcast_total2 is None:\n",
    "        fcast_total2 = fcast2.copy()\n",
    "        fcast_lower = fcast2lower.copy()\n",
    "        fcast_upper = fcast2upper.copy()\n",
    "    else:\n",
    "        fcast_total2 = pd.concat([fcast_total2, fcast2.copy()])\n",
    "        fcast_lower = pd.concat([fcast_lower, fcast2lower.copy()])\n",
    "        fcast_upper = pd.concat([fcast_upper, fcast2upper.copy()])\n",
    "        \n",
    "    \n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.plot(mydf, marker=\"o\", color=\"black\")\n",
    "# plt.plot(fcast_total2, color=\"blue\")\n",
    "# plt.plot(fcast_upper, color=\"red\")\n",
    "# plt.plot(fcast_lower, color=\"green\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b536e67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-4ce8c03ffa9d4cbf9fa524fe3fd3bb4c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-4ce8c03ffa9d4cbf9fa524fe3fd3bb4c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-4ce8c03ffa9d4cbf9fa524fe3fd3bb4c\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"title\": {\"fontSize\": 20}}, \"layer\": [{\"data\": {\"name\": \"data-f100b2afcf83259294af24d5eae069fe\"}, \"mark\": {\"type\": \"area\", \"color\": \"#7FC97F\", \"interpolate\": \"basis\"}, \"encoding\": {\"tooltip\": [{\"type\": \"temporal\", \"field\": \"ds\"}, {\"type\": \"quantitative\", \"field\": \"fact\"}, {\"type\": \"quantitative\", \"field\": \"yhat_lower\"}, {\"type\": \"quantitative\", \"field\": \"yhat_upper\"}], \"x\": {\"type\": \"temporal\", \"axis\": {\"format\": \"%H:%M\"}, \"field\": \"ds\", \"title\": \"date\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"yhat_upper\"}, \"y2\": {\"field\": \"yhat_lower\"}}, \"selection\": {\"selector028\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"title\": \"Holt-Winters Anomaly Detection\"}, {\"data\": {\"name\": \"data-f100b2afcf83259294af24d5eae069fe\"}, \"mark\": {\"type\": \"circle\", \"color\": \"Black\", \"opacity\": 0.7, \"size\": 15}, \"encoding\": {\"tooltip\": [{\"type\": \"temporal\", \"field\": \"ds\"}, {\"type\": \"quantitative\", \"field\": \"fact\"}, {\"type\": \"quantitative\", \"field\": \"yhat_lower\"}, {\"type\": \"quantitative\", \"field\": \"yhat_upper\"}], \"x\": {\"type\": \"temporal\", \"field\": \"ds\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"fact\", \"title\": \"CPU Utilization Percentage\"}}, \"selection\": {\"selector029\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}}, {\"data\": {\"name\": \"data-d751713988987e9331980363e24189ce\"}, \"mark\": {\"type\": \"circle\", \"color\": \"Red\", \"size\": 30}, \"encoding\": {\"tooltip\": [{\"type\": \"temporal\", \"field\": \"ds\"}, {\"type\": \"quantitative\", \"field\": \"fact\"}, {\"type\": \"quantitative\", \"field\": \"yhat_lower\"}, {\"type\": \"quantitative\", \"field\": \"yhat_upper\"}], \"x\": {\"type\": \"temporal\", \"field\": \"ds\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"fact\", \"title\": \"CPU Utilization Percentage\"}}, \"selection\": {\"selector030\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}}], \"height\": 450, \"width\": 870, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-f100b2afcf83259294af24d5eae069fe\": [{\"ds\": \"2021-08-23T00:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.082844108170518, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.1674626685853957, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.2000638083637936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.2814511443512329, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.3429855599321083, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.2755731156274361, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.3259830242634005, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.4015225334641455, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.4579557754303325, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.4239244375389235, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.4248304660409077, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5154668939682374, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5347447133251277, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5788794305034655, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5726670357289692, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6529094883797053, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5430597588849078, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7045537848463952, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.725605597123208, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8969706823799903, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8337969714925286, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6294768866812936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.567784829262433, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5549744824391043, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.4655315966944646, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5393699211046206, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5668600641982584, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6655541826966052, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7580343014578879, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7003402751751524, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7381733427541626, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8166089669392944, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8202484912521655, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7872173390481985, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7582781883694865, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6414662620123128, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.570877626485185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6024371681340028, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7349602229944048, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7985687642651969, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8061596609015358, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6931954985336808, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.760725739200367, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7189225397241747, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7880738117048671, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8704947902250355, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.967249743848884, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8691529633007926, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8629364499573176, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7756583985416396, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7897277717701854, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6222619168405523, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7314104084301887, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.9129068757687002, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8975244367609747, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7613237273260038, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7500453495271577, \"anomaly\": 0}, {\"ds\": \"2021-08-23T00:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.762571819220517, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6311805915464404, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6367814595846615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.4275645069609109, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5905556060578103, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6655632693644886, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.546791983263702, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8056647493831086, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7934579666991242, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.705101463531864, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.7224407924287297, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6633223909604884, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.6588597657693875, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.5859053445587559, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.8477342784230981, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 1.892257718603778, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.065957311209133, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.0592974557159858, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.060554824830489, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.1274093355782053, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.033973783734165, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.039052392155165, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.2018149811854757, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.1549872175178706, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.1714092548496255, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.392593747792554, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.369397260991428, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.553716627751497, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.48438777779565, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.523275431247673, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.541655645961276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.5946662175765676, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.6388582691705813, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.6823768968397044, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.9349245206759322, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.9313232387612618, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.7479986630107325, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.890996166493898, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.102050247761979, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.2153245723915553, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.351469110459854, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.263568933965749, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.1765726494156343, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.03359878070924, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.0229695218101025, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.1900447587564402, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.124001365720735, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.0901049942288012, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.008162397059522, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.0342427632947664, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.9627319946168917, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.9569461503037706, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.0267749492582157, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.07180359176354, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.1560782394784286, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.997043850204673, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.009950987266252, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.0938716467439757, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.0880073603636, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.11206377340535, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.071783339491452, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.9694802366080912, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.1296100628743804, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.002978165799547, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.961692345489058, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.988327400999106, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.817236951076069, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.7591756473744242, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.7415743889488313, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.634959930239999, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.684944460100623, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.7044345238588345, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.6484580732244156, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.7494103531133773, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.8828342883822207, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.8354131880299063, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.8000865445536682, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.7125150434931227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.5930717283678337, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.608611290894402, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.630785813099688, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.4460733245935717, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.3347403540561436, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.262071173411276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.298347870588908, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.3476057569157662, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.135029126951106, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.1239990673356894, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.0556779001073835, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.0694340149175385, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.162436461794182, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.2670705003332525, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.29288072551883, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.3569619929709806, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.410609579163354, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.3144117890462743, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.4445136543567934, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.465681531052395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.534376307983406, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.6272076036465988, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.5816446195896057, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.6662380206684615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.7168521403799497, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.8538032872934025, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.854838809029115, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.8618450419844574, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.9749993982224634, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.9242167077789762, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.046298158099033, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.2619941973050857, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.2881410304426844, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.17823623114512, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.2035656084512185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.2670646744239535, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.141727652556658, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.9955668695370674, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.9382006257672204, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.1072176080352674, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.2265123861605005, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.193007278757366, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 2.9939694331844597, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.0510071595638975, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.0843334587124414, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.017355148653572, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.0840789077005564, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.2646089479518845, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.165542668097864, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.0844463441003063, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.1069823468616202, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.219189334092936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.253827606819794, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.2185308345572, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.155315043321703, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.3632975565070162, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.343103013230474, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.2149037491158556, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.3955861520011412, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.198464588834615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.1356264595407213, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.216974287061278, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.265503557337653, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.282716546203024, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.2557944933176817, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.253280546730072, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.2468023667661132, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.2013389472410476, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.303433319153471, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.282481127060928, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.2652271356713536, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.1595061912084845, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.150058882565577, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.2408736119745805, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.1901242584634275, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.305247070725088, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.1486164121920943, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.3311019146556613, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.2369006752018885, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.4338477225305613, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.5746933953177287, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.668791853750908, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.692430901451204, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.7236669409703915, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.8603194598248907, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.9691359848159276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.962226709383252, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.9138960369194913, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.866906827861522, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.8996568831849046, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.931161464982215, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.9222762574162413, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.9522308518159854, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.9672379603949333, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.949120794105074, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.011080429852479, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.9773963745259766, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.063919451853195, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.041478475360821, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.062740372256043, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.0505187731741525, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.1897089265414085, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.284031357825327, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.343010092731889, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.185387068316425, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.0414341396536315, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.158591747922278, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.11021899046745, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.381527688619375, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.3351854149025995, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.184798061879761, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.217342874859245, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.134349504828188, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.00615462019463, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.174443032790151, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.158682107023693, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.039980382510705, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.963354168012908, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.013776178380292, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.8392000488227365, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 3.9196928506772672, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.026390515550767, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.1533871249773675, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.189958026263005, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.126055761269775, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.19189206344511, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.22553102867423, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.210411801001582, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.182752319021494, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.217524711732356, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.130474550476257, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.17480129452376, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.320493820499588, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.185929353510199, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.20876999105369, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.205431875057931, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.267783231196223, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.243656661707888, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.277196878166224, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.3318998015163706, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.363011737742668, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.180371396839616, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.168647619776069, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.175629966333796, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.05020272321786, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.1803453970069935, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.324238542138023, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.332892480853049, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.291603988308282, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.307690348837449, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.235240633659249, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.317974290661283, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.332980571066018, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.487906802061469, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.685148103114914, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.840059501436562, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.799561104428719, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.795506399361607, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.742588279703727, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.798220230319819, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.829701886057892, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.883016949588336, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.8937347142287, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 4.938648459724199, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.17809129022616, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.2277973565851275, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.060179684851194, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.1297403620303, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.15313317767182, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.300808308865612, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.26705268243037, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.18963904990192, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.127358854626321, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.29558515008685, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.426325324638567, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.398406115283306, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.538297490098523, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.653105045264966, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.765696569733555, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.666272705776069, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.567606762643266, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.677067547194454, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.952771138793346, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.893822573112458, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.956312217973574, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.867959474518728, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.924113424681968, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.755143754694852, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.748453921221867, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.688476020659092, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.746675485986374, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.843299988713007, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.834770667584292, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.867216105273556, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.877789831818705, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.788247198986482, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.855276906622282, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 5.952180412895244, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.064808083145066, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.090622739284995, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.088539270842496, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.180880255586056, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.0829197927436836, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.153305438466777, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.245424626413475, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.270181897393748, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.304686334947228, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.2486697214488025, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.23101000200763, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.230694728169978, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.157703819607037, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.301928313075152, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.4061636350278155, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.462931053129455, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.586302157616276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.590380090978745, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.598384601991288, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.6087284233126855, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.519586448521761, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.585441774813497, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.612122789230208, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.713398361671289, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.822549277291775, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.97551658913424, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.0245338623762, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.011984857308559, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.939497193677334, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.010406398571905, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.931851888092667, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.879178023131081, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.109475269891421, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.284680664017118, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.395090828652547, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.371434651213532, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.245236231448149, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.344627723533745, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.362549605351548, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.316384307810927, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.4436762713471, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.586315011635683, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.84596167034078, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.810708032610894, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.869544211046324, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.588004256487661, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.4272223763164, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.22636705323483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.215400231065601, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.212214491649582, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.351039971128483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.376476250774716, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.335800040585095, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.448679719340017, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.483511703168986, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.414570983492366, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.334626120276795, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.3049778908374945, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.278459085454509, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.413871916691975, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.306328534468085, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.135863705449194, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.296605351643508, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.432244315830181, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.395988175550756, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.278183825443562, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.250066035906667, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.282209302585056, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.2156324032840775, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.196476313520412, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.113119567118843, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.162704804924952, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.221109884038875, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.28587585791872, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.33450767010157, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.2076185280683, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.200436641971628, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.174060851045539, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.262444992057902, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.34306802733499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.316689086557331, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.435901366061946, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.519301570079593, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.444483463234448, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.558503416641305, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.502724062217367, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.543900869874692, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.61793683008212, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.576099179026605, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.474889511780991, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.493594475005889, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.394645478479456, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.358314631980785, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.414394947365127, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.362071254261016, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.2610336329398955, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.397969492007248, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.175585543122942, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.132322801642127, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.1510859667762, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.086966133877971, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.091083736255178, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.047475782418074, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.009527254558687, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.115014684339309, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.158507807273718, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.223216693033921, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.414873061673024, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.2522816003485655, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.362085934503852, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.467224271777104, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.364294904567715, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.459430953032399, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.452578150899747, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.5133858350161615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.4258638789745675, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.3737932149732766, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.598358267725344, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.492834789309395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.522201737971649, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.302638063120661, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.279557282830666, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.363046511604048, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.326486104423132, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.246927464543807, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.41642187662266, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.502878653438836, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.651020501300728, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.73101396367219, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.7908900897128355, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.721905539978192, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.676797763099813, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.49859598323504, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.476065058965288, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.482103132721876, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.533694637573916, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.520250704663931, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.430552773592014, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.425522429366651, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.19210405586305, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.28277232480738, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.175360535016683, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.262163774530336, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.203036103460411, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.104577394867066, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.146838037080654, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.1098713925408195, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.964204225280627, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.8317439585381985, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.846925861641189, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.8792347865250285, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.918101973663316, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.946297846175937, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.91741109605579, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.792759709575465, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.781526290147463, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.527562112720121, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.342845929573227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.295282891714099, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.416976346172642, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.474370432036268, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.601555135123274, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.565698424868521, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.58040116897878, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.482049789735297, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.390248110625829, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.32894900581122, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.342132763662364, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.431054046458639, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.373515189094005, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.205522054823765, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.316785939738493, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.333618541503614, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.445636379481378, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.591432527622528, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.518538014853173, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.403509692296891, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.514920639375976, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.698467040888667, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.759388401607078, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.716490662775344, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.5987942999302085, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.65333830003684, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.556226307271936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.631915596619567, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.7418854984709515, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.90468821514332, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.92379664141639, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.946555214531447, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.930459476706841, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.022422718896414, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.053346772430454, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.097472113550277, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.192623177672057, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.258527915260533, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.282872270839376, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.242022079132392, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.261334072336341, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.264136729062933, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.286273159581655, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.357895750482174, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.330285522164443, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.421393852719808, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.5620596009564744, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.565735575531843, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.58361194350413, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.610778235091248, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.521885308219655, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.716909631502675, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.747519051979066, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.785511706436309, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.930365226719392, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.967473463214496, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.999580916809377, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.92745812562292, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.055342945626094, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.069067375478213, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.155734179368574, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.011806921777461, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.092111510811511, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.220078277501383, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.267900885640357, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.340179387722713, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.360308596655782, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.356915788188523, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.288188793887379, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.371033308450802, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.296495018073724, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.267777641850003, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.144346886350423, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.061674389304113, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.101904105964518, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.049382116624201, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.9510567258113305, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.962974507940454, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.805239859715092, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.663667118812604, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.514024098971325, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.471366107835003, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.445667100893326, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.456711779886499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.444329373125276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.468336779368962, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.585589594686708, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.750432747546225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.789461459883152, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.849428734659802, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.945508717131604, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.897018421083583, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.790206365474418, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.839967858463782, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.8667860803525524, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.7525973626559095, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.70504444156228, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.801695429233526, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.652667153528996, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.578881723592664, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.491151863279462, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.503454922925876, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.599057949270826, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.540289550698573, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.709498641608279, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.830648777977522, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.833850854121761, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.896527014556835, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.740317372019487, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.734078442460585, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.68652453910119, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.654062933595664, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.7323556114676295, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.823575479244249, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.961063693882232, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.66166136402624, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.735994319948233, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.8172661459687465, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.800477360464126, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.726932237108902, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.811868370741103, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.658004719265347, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.670100990217529, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.45312553026062, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.57061971942359, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.584558764339831, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.736367838262079, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.883967912330481, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.9454144774542215, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.9815247789264765, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.828608211241088, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.8866167493939185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.718286285065371, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.764341416031271, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.840706888425015, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.938059917879748, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.761060058402809, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.6946908748491, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.672013085482828, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.749640954645437, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.74351636626246, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.758280802421245, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.9905599789244945, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.870475361188625, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.972400000133551, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.089531300610558, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.097777022768552, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.031589183895466, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.148437931838542, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.221370040659716, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.333189126475943, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.511437080644786, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.530259401373554, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.464149676702108, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.510761154617697, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.588384748465963, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.596579830973859, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.665254766764672, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.571601855976125, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.483149022444422, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.392816789809771, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.289463311811762, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.293193709584163, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.201046712843748, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.074013353443654, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.060346196714583, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.129960019946706, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.093286965059585, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.207114051737939, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.174797102772132, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.244861920292358, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.004603702913197, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.962191492988927, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.82693977677464, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.780715623518733, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.602800054795464, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.7126592728826395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.7702415551012605, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.755515291272416, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.893932649872157, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.9497835809896715, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.8758994800134285, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.882184263103129, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.064546783500113, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.081645734366429, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.172757664947504, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.098672806113793, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.151170322208227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.26088485879859, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.191009434921096, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.194555208030412, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.360453709951065, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.396733578661529, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.457129588862593, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.320222281734633, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.38706323868159, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.47380305154199, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.471000521610067, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.583404963654896, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.531063469573645, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.471403101314356, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.409649600014262, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.370469524136148, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.48614212062726, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.64617716198996, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.53530065692971, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.526391763137674, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.4747311830338, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.369368219481078, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.560972818522371, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.506389603340054, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.481984739041978, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.485287372932227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.509799875799924, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.462839177620474, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.500847291856171, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.407545286261158, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.435490902768226, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.405689339518776, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.404404408484888, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.370573940680746, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.356621268629302, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.273825661013671, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.417744225285109, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.333018409415137, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.395519857078213, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.329430969980034, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.393907016426743, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.505097929522941, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.511009348963547, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.485964064563397, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.532367389569465, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.527169421117446, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.770144851734896, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.941922134099055, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.83656128758854, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.75134541259338, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.663598406050742, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.672674873252237, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.52103640042284, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.52272103376713, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.645248319087003, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.674972483541307, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.76474826986135, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.811453323118272, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.485875363354573, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.399451833349502, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.457620981862641, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.612568848026724, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.514394842156392, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.387880106011288, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.223871883913581, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.098826371466577, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.05572889460056, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.956979270891584, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.811500666817628, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.690415462062634, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.717134221024015, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.835378833401439, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.711894191123989, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.7229591895282015, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.669836539613878, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.717692584250162, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.761794676176121, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.780476902942309, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.977593528807279, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.918981702230322, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.014169824247498, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.002420669187153, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.151076376650083, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.979406800773713, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.92353421269369, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.068779742758723, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.078786779675173, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.191788462425002, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.000415544530842, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.071115630032562, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.081479750948631, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.098170821285184, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.267139845953881, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.212596119789714, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.230590163089623, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.318860440882997, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.392351095262217, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.398247511408044, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.545377931691302, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.553662460728718, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.539053365383428, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.738610081903111, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.789728699261456, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.672292432735887, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.583695199589734, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.545572696616933, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.53469919243193, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.619454458907168, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.64014873041566, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.773110778116337, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.842045243191007, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.779304562733579, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.715667021210756, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.95869877998149, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.131002557332641, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.110278629189814, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.026194022516984, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.996799590069418, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.89038427307193, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.845887105325563, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.940727418078595, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.890937823525107, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.689691616597951, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.859131071315861, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.75225132967224, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.745441955414979, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.792889390472723, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.787700796349098, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.865140236693664, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.873378150594053, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.0222393846978, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.065340509014483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.08761005037332, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.21261808729404, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.171105600168334, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.2291796823891, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.306666947502116, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.262624362293195, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.242218868074156, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.33795232275775, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.323311197520256, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.224541361617664, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.235951852873002, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.183230028411051, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.303308572775062, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.41516862839868, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.344349304080247, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.418666704403686, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.318795523294629, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.361514185397724, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.455447864087226, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.401919535507847, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.38713489217632, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.455945295107508, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.609159720517681, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.614996053596242, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.556691781795077, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.643000959964645, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.718788895128835, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.638302318559198, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.86400121471953, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.832149494497711, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.8378481484009, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.86632383278163, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.892267601353337, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.931774604936024, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.954188808547201, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.817695310369409, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.84172254699343, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.80607724404463, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.634992469023846, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.719664071742129, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.803939082783222, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.800414529471565, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.82701899851565, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.77933964253321, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.756520180732126, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.850925560836, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.804925591815215, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.619049334366524, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.600139673643671, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.654070612123258, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.81409008687884, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.86346342581928, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.857124185840512, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.983032579376141, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.037199180536911, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.993484385678066, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.0400027689603, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.034298117029037, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.076049094922666, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.0988034535548, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.03315333035482, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.989417587885512, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.142657199531792, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.255063743963055, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.289207345135177, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.290051522452643, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.208202234151164, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.20744863055363, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.102381099087888, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.187155935748017, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.126046394947553, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.077830439271654, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.112502220252225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.2942943861814, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.205446118651967, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.271409386655742, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.256522349950478, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.17902731704118, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.223078359670582, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.289101894089889, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.452816223055665, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.530367461184968, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.515200566630206, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.462488799078955, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.536617371571872, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.582085913026225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.453705254361472, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.481826344423022, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.353428837573519, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.342528897524867, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.289505252298003, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.233404516009793, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.398350843814256, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.413367861232464, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.465737097515472, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.540956107018431, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.419642110204657, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.38830467957498, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.337534746596601, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.446651275126646, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.514004036753205, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.507311180202013, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.600130615972407, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.608687106522943, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.484335112185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.621271569245923, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.639575926010757, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.596954129260547, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.62736816641365, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.668971329410926, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.960130410890418, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 11.0, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.944748604963694, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.762400197925471, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.633397214168852, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.508366912453496, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.747813043137848, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.616517623097478, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.519134892650595, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.505485347067411, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.370020036709334, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.252602215750233, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.239477262630865, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.27736285358397, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.253281566040584, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.045963893343206, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.974512039077938, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.041043064809825, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.047700947811453, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 10.004137092919867, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.966989635494258, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.988342774645961, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.964268279658732, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.838689442516403, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.773522635065854, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.868386927448714, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.830469543424808, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.788865576129703, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.914847367291713, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.807562371531388, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.670822674017861, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.616577898394782, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.573703532341133, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.467645765284308, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.486973369882458, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.442311708770832, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.395669890818453, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.456601403941736, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.564992092172044, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.63165317584744, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.578406412111097, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.46403283204649, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.216432465535892, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.323236419089412, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.391465325298743, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.50366014614707, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.592600239141852, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.355788749450348, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.222799348520082, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.034232188045483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.988900736784247, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.940239461563786, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.867726672403123, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.750332311139447, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.749543232452918, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.714350103767188, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.70989589254306, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.93646758528286, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.012239346556045, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 9.039800746733981, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.977564792960163, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.798698884079773, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.757817163308653, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.739247557388522, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.70356646824997, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.782616489057622, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.479925780652454, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.273358954380925, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.447199865827617, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.523194953304365, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.530052782649555, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.396411307804495, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.314908428588723, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.244009975240218, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.180232114481395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.997073407217911, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.997788244170042, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.027379343471765, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.891617442415619, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.993391171167953, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.839794824705354, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.730599469753859, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.6509477022655386, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.6005718066277375, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.616974853712176, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.452726173004684, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.4873100141103475, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.355716834977905, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.304617707670855, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.489866921022014, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.457128971331552, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.49124494359832, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.746174323894706, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.728164560761447, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.57497190780261, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.629350721280201, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.670839399995044, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.8020911978599985, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.688201610108968, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.491134163279598, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.541546760013012, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.322022918010769, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.235580785625353, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.270589900870376, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.166069908720111, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.084649033319625, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.953837567532185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.9788882663663205, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.166048798085546, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.397644550791485, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.244896929081159, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.163683211087717, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.997342471102844, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.910312134996908, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.920281767120731, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.005098218639339, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.073528376327899, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.092071643143026, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.2003894873370955, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.29287665449782, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.219469085171615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.191066675166035, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.150610552736501, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.173786787560158, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.165902938765192, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.184761105184088, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.095968849846142, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.189463215776056, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.2416172252622815, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.289594697210025, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.287819788227195, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.252759139403707, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.312186655332198, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.417825510401695, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.537862680510393, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.474088346812236, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.353827173698256, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.203553863120317, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.1667714268010965, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.199926729249083, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.017751526939817, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.082192901082215, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.060415319852113, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.068729453386899, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.039528369282021, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.033655777722624, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.062204617401134, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.993569720043028, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.9882948401110525, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.8390032876923215, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.691998504671839, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.752681942577438, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.73868451382265, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.680331145067498, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.6180921787104054, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.6895657202333645, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.72316112495938, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.738952790095521, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.664365358351624, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.724600878108458, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.580937541938436, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.555562177433832, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.659379361607502, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.375346888821504, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.228907112687021, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.35302739173681, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.189166144427423, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.260671502798964, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.171678268702035, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.186759614812712, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.140920120718393, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.2395658921642525, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.243797647964152, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.470077371588114, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.60046767084194, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.625989069250561, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.7475051661190895, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.844731750554106, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.859763545701101, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.807310091228302, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.841886616435936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.85893746778489, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.846026479115778, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.883238199122709, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.809841352593101, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.751200710300513, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.805567687218024, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.772889900582233, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.728335674496716, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.747618665608875, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.555395135552946, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.593569618569199, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.537512510098631, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.511672421125268, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.631520179746892, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.75546745691182, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.765024078734705, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.798885033129787, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.74534060560366, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.872906486758738, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.914632913487516, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.086807423198176, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.073886368734035, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.020129069863576, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.101131503472381, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.010405102545185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.951266834994014, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.963550333967537, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.031916357257972, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.966991581251915, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.1046647071880225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.040671190034965, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.190168047613055, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.253047411598573, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.2720044758545415, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.381451693947673, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.473923616291, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.377898618253228, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.4365645152964674, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.424375555436707, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.322828741550124, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.259170692504289, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.123867211441125, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.120132713051596, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.0565544845028185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.139838404300698, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.20277666346131, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.040986511007052, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.006594977513499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.105131073775493, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.966567283612587, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.067989237821224, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.134185474168518, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.0416050260755325, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.980618485802484, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.066809141768836, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.191769766968483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.352789477352357, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.435857234044891, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.224490309562595, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.123376652717213, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.0722055728658, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.0742890656413255, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.242089094524295, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.124376062669945, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.211386630870367, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.327778305274825, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.114185757892747, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.13394669208722, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.998725732620053, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.999429650181499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.88988017320615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.011925284409866, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.0993986854425275, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.271220399150457, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.264494897726525, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.044423132287613, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.021339661711941, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.317534903185268, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.10716948495657, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.215310153650435, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.220570452422764, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.103080980776757, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.050846940115519, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.939961443394882, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 6.998102784901203, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.099749789012837, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.235330438059645, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.338052774675268, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.288772432558911, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.324544402704568, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.121821576872811, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.287459513397984, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.314871558542801, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.415176143796352, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.516025127146469, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.6050364669125985, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.566205083257227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.729722886759445, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.763741051140791, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.791223704044699, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.00363971231057, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.849663097795245, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.787666292025311, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.948607630624028, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.10370677263385, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.939931606789101, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.01138413900431, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.024263331132907, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.02728778518364, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.145123103951551, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.346190638990999, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.422543666781964, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.459908928046268, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.455258423436057, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.556138297516846, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.519475678661328, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.41012741828165, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.331208792762425, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.236846240515225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.256041617140585, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.380900569385801, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.283185908846015, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.19681328000246, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.268775956135276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.42869425982205, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.475701630597108, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.648756666874846, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.687765792214106, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.748978959879818, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.799798123977336, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.712653545197707, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.7413195426343, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.735522823807608, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.755033678541, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.697623905237386, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.732542420245244, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.667663294380052, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.74224875192919, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.813368356071924, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.763653819520787, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.727719225687869, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.757287262181396, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.58461198633341, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.580523889099103, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.729985918072733, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.715254942693004, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.657186335028134, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.715123818586068, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.803699468934434, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.770428664936265, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.68461158678178, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.571580251558387, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.629115838099489, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.680104200208032, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.720381281982103, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.674145386553628, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.645195557966613, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.542567468006013, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.614450952639153, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.600759594883009, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.344461174673786, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.345833211443853, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.308939856017505, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.288296800857225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.200204061185255, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.316763381802183, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.213260542060581, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.100444362690379, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.166018118282045, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.133296418077531, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.2170409947153, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.174451684276958, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.145406367187972, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.179618234404483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.079524030680783, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.044864923024296, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.985665500760242, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.046488503559157, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.987912077062759, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.950148874417816, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.068015846901767, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.09246969731638, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.019705123658905, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.06028447175568, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.006729199085527, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.884033492434073, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.046823619428089, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.942622275786526, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.107336569826192, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.118646844437311, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.101259000219994, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.975741033032815, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.988226254020678, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.062133599963992, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.023293650410814, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.840974331834362, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.651628623492227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.656945468320031, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.567227283798734, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.485420053891467, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.453326960684346, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.5675711212537005, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.59136442192483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.819711007934736, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.983399267364478, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.958116508233395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.968943931383387, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.088943997843543, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.94868555720843, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.031676300784632, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.919155930994936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.860433362299011, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.887708781348885, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.95518511616727, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.031980714285634, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.986336725108602, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.9750917218656125, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.88889753640553, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.99517540935556, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.048314544065995, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.831803761276401, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.813286153136449, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.800293226728714, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.568500650268759, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.485083521432123, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.562902259069609, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.774237559343768, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.84399038958902, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.703560195883743, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.580990260422031, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.536262826528088, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.479715123694341, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.547983789043043, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.661272545133261, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.799921735142088, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.90744271501311, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.9914944717499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 8.078038554719182, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.887233092209016, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.727544853299987, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.797725220766124, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.873085248908442, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.980822066822155, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.734172080818521, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.599489257353818, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.722687896015395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.77275116820956, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.558314501085786, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.60533623053003, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.564962022147053, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.507104599166352, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.394733417407842, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:00:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.209009286177776, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:01:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.296538174554642, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:02:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.206584493381573, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:03:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.160033858921166, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:04:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.254636375974447, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:05:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.383418162205393, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:06:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.412786701811927, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:07:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.410993240415173, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:08:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.311113765840335, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:09:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.3759026127290195, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:10:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.429606304723798, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:11:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.49942313491552, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:12:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.391456931311621, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:13:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.285664791754202, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:14:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.115643401562619, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:15:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.054269618633998, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:16:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.060118316641897, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:17:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.161535062516319, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:18:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.255915033132671, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:19:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.426012747469036, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:20:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:21:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.317126681220951, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:22:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.437457589321834, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:23:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.411908464884772, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:24:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.524143393749286, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:25:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.496314903881952, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:26:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.573752510226136, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:27:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.541365430808015, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:28:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.502722693475748, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:29:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.432187339829274, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:30:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.367743829771953, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:31:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.2855991505679105, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:32:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.3253574361749, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:33:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.612270582135634, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:34:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.591724855148331, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:35:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.518090746071456, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:36:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.676593906453708, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:37:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.676014289757855, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:38:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.662263279799936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:39:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.744231691853355, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:40:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.535410761101995, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:41:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.555415160113135, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:42:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.735896999116704, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:43:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.847623077982126, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:44:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.7968137342359105, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:45:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.784207158858803, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:46:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.853358920798734, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:47:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.9176391649767295, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:48:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.831808587137508, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:49:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.74727118708158, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:50:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.749417906852305, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:51:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.788491835544637, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:52:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.682725698948679, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:53:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.663473876690589, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:54:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.650759642073896, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:55:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.643660841766507, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:56:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.740792599980338, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:57:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.729485101072052, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:58:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.809879193660448, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:59:00\", \"yhat\": null, \"yhat_lower\": null, \"yhat_upper\": null, \"fact\": 7.870193732739887, \"anomaly\": 0}], \"data-d751713988987e9331980363e24189ce\": []}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## plot results\n",
    "total_forecast = pd.DataFrame({\"ds\" : mydf.index, \"yhat\" : fcast_total2, \"yhat_lower\" : fcast_lower, \"yhat_upper\" : fcast_upper, \"fact\" : mydf})\n",
    "detected_anomalies = detect_anomalies(total_forecast)\n",
    "plot_anomalies(detected_anomalies, mytitle=\"Holt-Winters Anomaly Detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479dee11-37b9-44d9-ad05-936cba508751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3d999e80-f451-477a-a28b-9e2720744e0b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287\n",
      "Initial log joint probability = -2.52171\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      64       271.345   0.000570192       65.9479   1.933e-05       0.001      118  LS failed, Hessian reset \n",
      "      99       274.393    0.00391478       39.5395      0.4617           1      163   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     164       275.167   0.000390198         63.33   9.008e-06       0.001      300  LS failed, Hessian reset \n",
      "     199       275.265   0.000314725       43.3694      0.1712           1      351   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     229       275.565   0.000364276       60.0034   8.103e-06       0.001      431  LS failed, Hessian reset \n",
      "     299       275.881   2.92121e-06       31.9661     0.00485           1      527   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       276.045    0.00014803       36.0027      0.3003           1      655   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     426       276.117   0.000211289       33.4207   5.361e-06       0.001      729  LS failed, Hessian reset \n",
      "     445       276.195   0.000377086       24.8288   2.107e-05       0.001      781  LS failed, Hessian reset \n",
      "     482       276.207   2.98757e-05       19.1891   8.218e-07       0.001      874  LS failed, Hessian reset \n",
      "     499       276.208   8.74342e-07       31.0484      0.5938      0.5938      895   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     529       276.208   2.55622e-06        32.264   7.784e-08       0.001      966  LS failed, Hessian reset \n",
      "     570       276.209   2.99495e-08        35.585       0.294       0.294     1025   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.46058\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      70       274.658   0.000443929       31.8952    4.63e-06       0.001      155  LS failed, Hessian reset \n",
      "      99       275.437   0.000527381       52.7203      0.5417      0.5417      196   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     154       276.208    0.00133307       93.7656   3.444e-05       0.001      289  LS failed, Hessian reset \n",
      "     199       276.654   0.000183918       30.6039      0.4282           1      349   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       276.665    0.00030868       29.9667           1           1      503   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     307       276.731    0.00114616       40.7237   2.752e-05       0.001      561  LS failed, Hessian reset \n",
      "     385        276.78   1.08084e-05        33.735     3.7e-07       0.001      704  LS failed, Hessian reset \n",
      "     399       276.781   5.70714e-06       21.7459      0.6733      0.6733      719   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     422       276.781   1.09198e-07       22.5473       0.261      0.7479      757   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.48397\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        277.05     0.0145665       47.5538      0.4823      0.4823      130   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     123       277.851    0.00100678       65.8108   3.522e-05       0.001      201  LS failed, Hessian reset \n",
      "     199        278.33    0.00363368       37.5415           1           1      303   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       278.689   5.48596e-06       31.4692       5.183      0.5183      447   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     359       279.016   0.000420467       40.4517   1.653e-05       0.001      561  LS failed, Hessian reset \n",
      "     399       279.264   0.000550135       32.1356       2.491      0.2491      616   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     418       279.278   4.00407e-05        34.826   1.482e-06       0.001      681  LS failed, Hessian reset \n",
      "     439       279.279   1.34923e-06       24.6618   3.926e-08       0.001      753  LS failed, Hessian reset \n",
      "     452       279.279   6.20604e-09       29.3607      0.1435      0.1435      774   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "Initial log joint probability = -2.41708\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       291.548     0.0117148       28.1742           1           1      142   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     154       294.633   0.000434349       62.0114   1.079e-05       0.001      241  LS failed, Hessian reset \n",
      "     199       294.952   0.000851929       46.5241      0.8441      0.8441      300   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     212       295.722    0.00274588       81.6569   3.415e-05       0.001      367  LS failed, Hessian reset \n",
      "     299       296.631   0.000698683        33.189           1           1      480   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     384       296.885   2.53598e-05       23.1103   8.028e-07       0.001      635  LS failed, Hessian reset \n",
      "     399       296.885   1.93655e-06       37.0467           1           1      654   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     476       296.888   2.88328e-05       30.5988    1.06e-06       0.001      798  LS failed, Hessian reset \n",
      "     499       296.889   4.66625e-07       25.6916       1.282      0.1282      833   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     505       296.889   2.82872e-07       26.8879   1.243e-08       0.001      875  LS failed, Hessian reset \n",
      "     509       296.889   2.17957e-08       29.9224      0.1843           1      880   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.44201\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       313.901    0.00546009       126.543      0.7645      0.7645      123   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     150       316.134   0.000173967       38.9053   4.051e-06       0.001      232  LS failed, Hessian reset \n",
      "     199       317.415    0.00987805       60.8291           1           1      294   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     260        319.35   0.000980063       86.7689   2.376e-05       0.001      405  LS failed, Hessian reset \n",
      "     297       319.981    0.00029174       42.9421    1.05e-05       0.001      492  LS failed, Hessian reset \n",
      "     299       319.986   0.000124612       18.9778           1           1      494   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     354        320.54   0.000289658       56.2343    3.03e-06       0.001      610  LS failed, Hessian reset \n",
      "     399       321.231   4.06008e-05       42.9674      0.5179      0.5179      669   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     456       321.794   0.000178413       34.8674   2.518e-06       0.001      781  LS failed, Hessian reset \n",
      "     499       322.002   0.000170794        43.139   3.105e-06       0.001      878  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     527       322.015   4.66012e-05       21.1306    1.41e-06       0.001      947  LS failed, Hessian reset \n",
      "     559       322.016   9.38165e-06       23.8136   2.951e-07       0.001     1037  LS failed, Hessian reset \n",
      "     599       322.016   3.58121e-06       17.1433     0.07245           1     1091   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     612       322.022   5.06263e-05       32.4623    2.02e-06       0.001     1148  LS failed, Hessian reset \n",
      "     643       322.026   1.59992e-05       22.1269   4.081e-07       0.001     1230  LS failed, Hessian reset \n",
      "     682       322.026   6.31901e-07       26.5556   2.482e-08       0.001     1330  LS failed, Hessian reset \n",
      "     699       322.026   3.10715e-07       24.0845      0.1565           1     1354   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     700       322.026   7.71347e-08       25.4862   3.203e-09       0.001     1389  LS failed, Hessian reset \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.92219\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       319.996     0.0458199       317.126           1           1      134   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     106        320.66   0.000260106       33.9981    2.48e-06       0.001      184  LS failed, Hessian reset \n",
      "     199       324.309    0.00628745       57.7884      0.2164           1      302   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     259       325.543    0.00176975       95.8293   5.116e-05       0.001      427  LS failed, Hessian reset \n",
      "     299       325.884   2.42597e-05       25.7751      0.9801      0.9801      477   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     331       325.938   3.09665e-05       25.9016   1.392e-06       0.001      554  LS failed, Hessian reset \n",
      "     343       325.939   1.24577e-05       29.7475   3.669e-07       0.001      607  LS failed, Hessian reset \n",
      "     358       325.939   3.83728e-08       24.6367      0.3018       0.986      631   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.64323\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       330.777    0.00674267       103.467      0.9016      0.9016      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     114       332.045   0.000375907        70.903   6.801e-06       0.001      174  LS failed, Hessian reset \n",
      "     174       334.104   0.000229533       41.7266   2.903e-06       0.001      303  LS failed, Hessian reset \n",
      "     185       334.607   0.000284964       49.7276   9.046e-06       0.001      351  LS failed, Hessian reset \n",
      "     198       334.645   0.000159693       31.6752   3.337e-06       0.001      396  LS failed, Hessian reset \n",
      "     199       334.646   6.02944e-05       26.5986           1           1      397   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     256        335.61   0.000283886       56.9372   2.932e-06       0.001      507  LS failed, Hessian reset \n",
      "     299        336.47   0.000102968       21.0679           1           1      576   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       336.618   0.000126443        24.009           1           1      713   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     431       336.673    0.00019069       42.3611   3.163e-06       0.001      793  LS failed, Hessian reset \n",
      "     467       336.732   2.16491e-05        22.485   8.638e-07       0.001      878  LS failed, Hessian reset \n",
      "     499       336.734   2.56581e-05       33.1416      0.4583           1      926   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       336.908     0.0133116       36.8948           1           1     1063   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     614       337.057   0.000179345       41.7274   3.133e-06       0.001     1124  LS failed, Hessian reset \n",
      "     687       337.145   5.32747e-05       23.0961   1.547e-06       0.001     1255  LS failed, Hessian reset \n",
      "     699       337.146   2.81514e-06       26.3578           1           1     1275   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     723       337.146   4.30473e-08       22.7696      0.5728      0.5728     1313   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.23685\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       342.231     0.0271767       105.878        0.72        0.72      140   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     112       343.418   0.000505602       81.0609   9.474e-06       0.001      194  LS failed, Hessian reset \n",
      "     199       348.306     0.0224018        132.76           1           1      305   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       349.821     0.0401922       105.665           1           1      445   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     306       349.968   0.000170427       37.9551   3.186e-06       0.001      522  LS failed, Hessian reset \n",
      "     399       350.454   0.000647353       26.9579           1           1      647   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     418       350.461   1.79922e-05        33.504   7.297e-07       0.001      746  LS failed, Hessian reset \n",
      "     475       350.476   1.80196e-05        31.844   5.638e-07       0.001      861  LS failed, Hessian reset \n",
      "     491       350.477    2.3729e-08       24.8935      0.2594           1      887   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.34368\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       348.562     0.0102916        63.495           1           1      133   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     141       351.478    0.00338546       198.187   7.315e-05       0.001      225  LS failed, Hessian reset \n",
      "     199       353.363   0.000893542       25.4458           1           1      301   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     236       353.511   2.86948e-06       23.9231   1.182e-07       0.001      392  LS failed, Hessian reset \n",
      "     257       353.511   1.83632e-05       28.7545   7.107e-07       0.001      463  LS failed, Hessian reset \n",
      "     274       353.512   5.74872e-06       17.4152   2.156e-07       0.001      527  LS failed, Hessian reset \n",
      "     292       353.512   5.94181e-08       21.2579      0.8566      0.2151      561   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.47796\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       357.168    0.00958703       130.467           1           1      121   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     109       357.992   0.000245988       29.7957   2.553e-06       0.001      175  LS failed, Hessian reset \n",
      "     178       359.788   0.000160149       33.9092   4.307e-06       0.001      306  LS failed, Hessian reset \n",
      "     199       360.184   0.000625517       28.2657      0.5338      0.5338      329   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       365.623   0.000868969       35.7971      0.4261      0.4261      460   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     339       366.226   0.000154832       28.8219   2.441e-06       0.001      559  LS failed, Hessian reset \n",
      "     380       366.434    7.5925e-05        22.006   2.321e-06       0.001      655  LS failed, Hessian reset \n",
      "     399       366.436   7.85247e-05        26.366       5.786      0.5786      687   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     427       366.509   9.64309e-05       34.2743   2.907e-06       0.001      753  LS failed, Hessian reset \n",
      "     495       366.544   4.97337e-05       25.1589    1.36e-06       0.001      881  LS failed, Hessian reset \n",
      "     499       366.544   6.43324e-06       26.7495      0.2846           1      888   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       367.698     0.0011841       220.493      0.6347      0.6347     1015   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     608        368.09   0.000206789       47.9652   4.682e-06       0.001     1061  LS failed, Hessian reset \n",
      "     686       368.546    0.00101347       32.2879   2.609e-05       0.001     1202  LS failed, Hessian reset \n",
      "     699       368.604   0.000260838       35.4589     0.03086           1     1222   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     770       368.632   0.000169204       39.4068   2.738e-06       0.001     1355  LS failed, Hessian reset \n",
      "     799       368.638   9.56449e-06       26.9645      0.9431      0.9431     1396   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     827       368.639   1.42253e-05       29.4554   4.039e-07       0.001     1480  LS failed, Hessian reset \n",
      "     899        368.64   1.43981e-05       27.3697           1           1     1580   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     918       368.661   0.000590411       30.7582   1.366e-05       0.001     1637  LS failed, Hessian reset \n",
      "     985       368.672   7.81378e-06       32.5405   2.321e-07       0.001     1769  LS failed, Hessian reset \n",
      "     999       368.672   3.65782e-06       40.0506      0.6271      0.6271     1788   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1028       368.672   2.18977e-06       27.3437   5.857e-08       0.001     1870  LS failed, Hessian reset \n",
      "    1060       368.673   4.19557e-08       27.0804      0.7271      0.7271     1917   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.44763\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      78       363.038   0.000166177       31.6919   4.392e-06       0.001      156  LS failed, Hessian reset \n",
      "      99       364.812    0.00166419       104.028           1           1      188   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       370.081   0.000562322       33.6199           1           1      337   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     224       370.213   4.23446e-05       17.2207    1.46e-06       0.001      417  LS failed, Hessian reset \n",
      "     299       370.903    0.00204206       24.3714           1           1      523   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     341       371.854   0.000110739       24.7749   5.653e-06       0.001      621  LS failed, Hessian reset \n",
      "     352        371.86   0.000124492       27.1043   4.688e-06       0.001      671  LS failed, Hessian reset \n",
      "     379       371.862   2.89503e-08       21.8235      0.2488      0.8842      714   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.02702\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       365.706    0.00251595       97.4714      0.4303      0.4303      142   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     127       366.815    0.00115748       85.3543    4.38e-05       0.001      217  LS failed, Hessian reset \n",
      "     164       367.572   0.000291243       47.7687   5.456e-06       0.001      300  LS failed, Hessian reset \n",
      "     199       368.276    0.00011194        42.432      0.1029      0.1029      344   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     244       369.578   0.000236343       39.1386   3.822e-06       0.001      447  LS failed, Hessian reset \n",
      "     299       370.368   5.29352e-06       22.5234      0.3408           1      539   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     304       370.368   4.65398e-06       23.2356   2.268e-07       0.001      580  LS failed, Hessian reset \n",
      "     354       370.376   7.43225e-09       30.8914    0.002051           1      656   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "Initial log joint probability = -3.45399\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      92       352.671   0.000513968       40.5019   5.908e-06       0.001      152  LS failed, Hessian reset \n",
      "      99       354.089     0.0149634       101.641      0.9785      0.9785      160   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     103       354.166    0.00184866       71.6268   7.522e-05       0.001      199  LS failed, Hessian reset \n",
      "     126       354.911    0.00227249       97.6922   7.824e-05       0.001      253  LS failed, Hessian reset \n",
      "     159       355.377    0.00159003       94.6874   3.853e-05       0.001      333  LS failed, Hessian reset \n",
      "     186       355.634   0.000395011       37.8403   1.124e-05       0.001      404  LS failed, Hessian reset \n",
      "     199       355.649   0.000393225       42.6606           1           1      418   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     241       356.869   0.000357822       42.1838   6.085e-06       0.001      510  LS failed, Hessian reset \n",
      "     299       357.518   0.000393191       24.0507       0.181           1      584   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        357.75   0.000500199       21.7545      0.4643      0.4643      714   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     436       357.817   9.98712e-05       30.5472   3.065e-06       0.001      801  LS failed, Hessian reset \n",
      "     499       357.954   2.20949e-05       24.8124      0.9062      0.5179      888   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     577       357.976    0.00010962       24.0627   2.674e-06       0.001     1041  LS failed, Hessian reset \n",
      "     599       357.978   7.31126e-07       28.4131      0.7417      0.7417     1072   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     620       357.978   7.04973e-07       25.3801    1.91e-08       0.001     1138  LS failed, Hessian reset \n",
      "     630       357.978   2.66232e-08       26.7387      0.2949           1     1153   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.30377\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       341.773     0.0210915       93.3368           1           1      128   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     131       343.312    0.00100591       49.0267   6.634e-06       0.001      206  LS failed, Hessian reset \n",
      "     199       343.974   3.81451e-05       27.6627      0.7017      0.7017      298   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     240       344.115   0.000827206       64.4456   1.766e-05       0.001      383  LS failed, Hessian reset \n",
      "     299         344.2   0.000636923       34.5934      0.2077           1      471   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     327       344.211   1.24081e-05       29.2649   4.554e-07       0.001      552  LS failed, Hessian reset \n",
      "     361       344.212   1.26227e-08       26.8665      0.1308      0.4279      601   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.24642\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        336.48     0.0120156       48.7804      0.2922      0.2922      133   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     169       339.937   0.000839242       57.8629    2.55e-05       0.001      306  LS failed, Hessian reset \n",
      "     199       340.179   8.53573e-05       24.9417      0.8687      0.8687      345   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     228       340.207   0.000150612       28.2034   5.066e-06       0.001      427  LS failed, Hessian reset \n",
      "     269       340.278   0.000117413       32.4014   3.879e-06       0.001      521  LS failed, Hessian reset \n",
      "     292       340.281   1.94684e-06       26.1232   6.372e-08       0.001      589  LS failed, Hessian reset \n",
      "     299       340.281   2.25916e-07       23.4956       2.336      0.5602      599   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     310       340.281   3.53694e-07       23.4536   1.119e-08       0.001      651  LS failed, Hessian reset \n",
      "     314       340.281   2.59235e-09       28.3768    0.005683     0.09942      659   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "Initial log joint probability = -3.27614\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       351.531     0.0812441       76.6096      0.9729      0.9729      118   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       363.232    0.00528038       62.2202           1           1      258   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     231        364.85    0.00234087       111.435   5.513e-05       0.001      341  LS failed, Hessian reset \n",
      "     284       365.418   0.000204332       31.2594   5.134e-06       0.001      458  LS failed, Hessian reset \n",
      "     299       365.422   1.37644e-05       35.4185      0.6493      0.6493      480   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     312       365.425   2.94428e-05       35.9018   8.893e-07       0.001      537  LS failed, Hessian reset \n",
      "     375         365.5   0.000447527       47.7968   7.711e-06       0.001      647  LS failed, Hessian reset \n",
      "     399       365.535   1.58925e-05       33.2994       0.329           1      681   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     413       365.538   2.28739e-05       31.0043   7.769e-07       0.001      744  LS failed, Hessian reset \n",
      "     452        365.54   1.01738e-05       26.1084   2.627e-07       0.001      841  LS failed, Hessian reset \n",
      "     469        365.54   3.28992e-06       26.6081   8.482e-08       0.001      902  LS failed, Hessian reset \n",
      "     481        365.54   9.50891e-08       29.9909      0.3799           1      921   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.57023\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       379.723     0.0482508       60.0928           1           1      122   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     140       385.651   0.000249366       36.8765   4.588e-06       0.001      217  LS failed, Hessian reset \n",
      "     196        390.35   0.000258749       42.2901   7.859e-06       0.001      331  LS failed, Hessian reset \n",
      "     199       390.589    0.00321758       34.1417      0.3882           1      336   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     292       395.151   0.000494289       58.5498    1.95e-05       0.001      493  LS failed, Hessian reset \n",
      "     299       395.172   0.000980673        75.395           1           1      500   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     323        395.42    0.00036131       30.1443     2.9e-06       0.001      572  LS failed, Hessian reset \n",
      "     351       395.567   0.000737981       95.2934    1.73e-05       0.001      642  LS failed, Hessian reset \n",
      "     399       395.629    1.6763e-05       25.8006      0.9141      0.9141      711   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     481       395.821    0.00164634       108.481   2.218e-05       0.001      867  LS failed, Hessian reset \n",
      "     499       395.883   4.92887e-05       28.7339      0.9673      0.9673      891   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     522       395.885   1.33917e-05       24.7327   4.788e-07       0.001      967  LS failed, Hessian reset \n",
      "     541       395.885   4.23932e-07       20.6204   1.771e-08       0.001     1031  LS failed, Hessian reset \n",
      "     547       395.885   5.25418e-08       22.8697      0.4206      0.4206     1038   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.5123\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      87       394.963   0.000706332        90.496   1.334e-05       0.001      161  LS failed, Hessian reset \n",
      "      99       395.761     0.0112801       81.8971           1           1      174   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     106       395.948   0.000241494       37.2302   4.204e-06       0.001      218  LS failed, Hessian reset \n",
      "     153       400.553   0.000971541       103.213    1.82e-05       0.001      353  LS failed, Hessian reset \n",
      "     167       401.801    0.00234344       101.687   6.467e-05       0.001      412  LS failed, Hessian reset \n",
      "     199        402.51    0.00159332        40.051     0.08393           1      457   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     200       402.519   0.000447885        61.592   1.118e-05       0.001      490  LS failed, Hessian reset \n",
      "     299       403.289    0.00114714       23.2078           1           1      612   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     326       404.075    0.00367749       63.4418   9.827e-05       0.001      683  LS failed, Hessian reset \n",
      "     366       404.723   0.000346492       40.6656   1.382e-05       0.001      767  LS failed, Hessian reset \n",
      "     399       404.837   4.98513e-05       34.0367      0.3351           1      816   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       405.264   4.47401e-05       20.5266   1.618e-06       0.001     1023  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       405.368     0.0030725       41.0037       0.294           1     1156   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     647       405.519   3.22988e-05       22.5788   1.004e-06       0.001     1273  LS failed, Hessian reset \n",
      "     675        405.52   5.62108e-09       30.7391    0.003706           1     1318   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "Initial log joint probability = -3.30507\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       406.476     0.0108229        176.49      0.0695           1      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     131       412.308   0.000212393       36.3002   5.696e-06       0.001      205  LS failed, Hessian reset \n",
      "     199       413.168    0.00606264       59.8873           1           1      303   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     237       414.532   0.000705196        110.88   8.233e-06       0.001      385  LS failed, Hessian reset \n",
      "     269       415.727    0.00107084       78.5783   2.512e-05       0.001      456  LS failed, Hessian reset \n",
      "     299       415.945    0.00400025       45.9972           1           1      499   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     324       416.109    0.00106997       44.3006   3.445e-05       0.001      568  LS failed, Hessian reset \n",
      "     369       416.128   6.29902e-06       26.4974   1.676e-07       0.001      688  LS failed, Hessian reset \n",
      "     399       416.129   5.71327e-06       35.9909           1           1      734   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       417.973      0.251858       344.195           1           1      853   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     508       418.801   0.000891319       91.2611   2.393e-05       0.001      916  LS failed, Hessian reset \n",
      "     578       421.091   0.000340218       61.8028   5.802e-06       0.001     1041  LS failed, Hessian reset \n",
      "     599       421.275   0.000178126       28.9392      0.3041      0.7911     1071   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     669       421.529   0.000238001       33.0057   3.469e-06       0.001     1201  LS failed, Hessian reset \n",
      "     699       421.595   9.36891e-05        24.019       0.678       0.678     1243   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     770       421.681   2.20388e-06       21.0519    6.55e-08       0.001     1382  LS failed, Hessian reset \n",
      "     782       421.681   1.34534e-08       26.6568      0.1616           1     1399   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.61849\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       415.902     0.0101655       64.2271           1           1      121   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        426.65   5.28052e-05       29.4947       1.281       0.186      267   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     244        427.24    0.00020458       39.7209   4.716e-06       0.001      362  LS failed, Hessian reset \n",
      "     299       427.258    0.00116748       38.4912           1           1      439   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     311       427.409   0.000685262       45.9084   2.036e-05       0.001      510  LS failed, Hessian reset \n",
      "     383       427.532   0.000569113       47.3696   1.396e-05       0.001      644  LS failed, Hessian reset \n",
      "     399       427.551    2.9016e-05       41.2614      0.2668      0.8533      665   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       427.574   1.00612e-06       33.0677           1           1      817   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       428.918     0.0014326       43.0552       0.581       0.581      937   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     658       429.156   0.000178184       29.0254   5.909e-06       0.001     1049  LS failed, Hessian reset \n",
      "     699       429.214   0.000751799       43.5205           1           1     1105   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       429.311   0.000584318       36.6063           1           1     1236   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     898       430.207   0.000304454       39.3831   1.325e-05       0.001     1386  LS failed, Hessian reset \n",
      "     899       430.211   0.000186026       29.0526           1           1     1387   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       430.576   5.33507e-05       32.6096      0.6617      0.6617     1517   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1080       430.653   7.00915e-05       31.2375   2.218e-06       0.001     1663  LS failed, Hessian reset \n",
      "    1099       430.656   2.52995e-06       26.9374       0.893      0.2538     1691   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       430.891   2.41278e-06       31.1931           1           1     1821   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1216       430.891    4.7212e-08       23.8096     0.04591           1     1853   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.50033\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        424.61     0.0278078       39.8325       0.518           1      128   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     154       431.207   0.000301277       45.3135    5.11e-06       0.001      263  LS failed, Hessian reset \n",
      "     185       432.826   0.000357894       55.1779   7.887e-06       0.001      344  LS failed, Hessian reset \n",
      "     199       433.066   0.000678259       42.3557      0.5211      0.5211      364   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     229       434.372   0.000425131       64.1683   6.372e-06       0.001      472  LS failed, Hessian reset \n",
      "     299       435.917     0.0282484       57.1107           1           1      564   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     303       435.963   0.000906905       66.2404   2.345e-05       0.001      609  LS failed, Hessian reset \n",
      "     360       436.323   0.000347685       55.7006   7.484e-06       0.001      720  LS failed, Hessian reset \n",
      "     399       436.346   7.83779e-07       27.7679      0.7112      0.7112      776   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     438       436.381   0.000373315       69.8417   7.357e-06       0.001      884  LS failed, Hessian reset \n",
      "     472       436.402   4.55844e-05       34.8795   1.373e-06       0.001      960  LS failed, Hessian reset \n",
      "     499       436.404   5.01713e-06       27.1747           1           1      995   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     565       436.405   1.12832e-07       24.7721      0.1208      0.3443     1091   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.54368\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      80       434.542    0.00467754       205.537   0.0001096       0.001      138  LS failed, Hessian reset \n",
      "      99       436.399     0.0211253       101.961           1           1      159   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     103       436.524    0.00081647       88.9193   2.264e-05       0.001      201  LS failed, Hessian reset \n",
      "     134       438.304    0.00377171       61.7085   0.0001599       0.001      272  LS failed, Hessian reset \n",
      "     168       439.131      0.001512       103.744   2.655e-05       0.001      352  LS failed, Hessian reset \n",
      "     199       439.865    0.00323771       30.5661           1           1      397   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     241       441.503     0.0017383       123.566   3.858e-05       0.001      486  LS failed, Hessian reset \n",
      "     299       442.795     0.0207908       39.9663           1           1      575   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       444.482   0.000800517       37.1016      0.6064           1      713   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     467       445.454   0.000535424       58.6853   2.794e-06       0.001      837  LS failed, Hessian reset \n",
      "     499       445.978    0.00475909       91.0492           1           1      880   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     522       446.236   0.000948025       31.1825   3.223e-05       0.001      958  LS failed, Hessian reset \n",
      "     599       446.408   7.53284e-05       30.3525           1           1     1053   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     645       446.435   4.15718e-05       29.3549   1.083e-06       0.001     1172  LS failed, Hessian reset \n",
      "     699       446.437   7.05031e-05       36.2508      0.2847      0.8437     1248   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     715       446.446   0.000182669       39.5305   4.136e-06       0.001     1303  LS failed, Hessian reset \n",
      "     767       446.453   5.77396e-06        33.507   1.819e-07       0.001     1415  LS failed, Hessian reset \n",
      "     799       446.454   2.44818e-06        22.395      0.6454      0.6454     1463   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     813       446.454   3.11234e-06       31.4485   1.039e-07       0.001     1528  LS failed, Hessian reset \n",
      "     855       446.454   1.81271e-07       30.3969     0.06669           1     1582   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.84026\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       439.619    0.00996879       295.623      0.6648      0.6648      113   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       449.154     0.0156797        307.94      0.6526      0.6526      241   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       454.266   0.000491703       29.1051      0.5652      0.5652      380   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       460.334    0.00399159       45.1524           1           1      512   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499         463.4     0.0031484       32.9309      0.3198      0.3198      647   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     510       463.471    0.00130736       107.009   5.273e-05       0.001      728  LS failed, Hessian reset \n",
      "     548       464.288   0.000192971       36.2415   2.419e-06       0.001      809  LS failed, Hessian reset \n",
      "     599       465.067   0.000163332       27.5232       3.925      0.3925      887   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     642       466.194    0.00014754       38.6709   2.556e-06       0.001      990  LS failed, Hessian reset \n",
      "     699       466.597   8.58768e-05       31.4295      0.7761      0.7761     1062   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     755       466.929   0.000182319       49.5092    2.69e-06       0.001     1184  LS failed, Hessian reset \n",
      "     792       466.941   7.23096e-06       31.6925   2.239e-07       0.001     1276  LS failed, Hessian reset \n",
      "     799       466.941   9.65766e-07       27.2594      0.8239      0.8239     1288   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     812       466.941   3.83196e-08       24.5127      0.2608           1     1311   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.45551\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       464.356      0.003979       205.322      0.5359      0.5359      121   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       473.895     0.0008875       73.5488       3.983      0.3983      256   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     260       477.893   0.000425856       65.1866   1.881e-06       0.001      370  LS failed, Hessian reset \n",
      "     299       480.542   0.000609412       31.6646           1           1      428   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     307       480.691   0.000265493        59.678   2.409e-06       0.001      475  LS failed, Hessian reset \n",
      "     343       481.073   0.000196045       52.4232   3.043e-06       0.001      566  LS failed, Hessian reset \n",
      "     399       481.331    0.00016985       21.2114      0.8587      0.8587      635   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     450       481.676   0.000401948       77.6311   1.158e-05       0.001      778  LS failed, Hessian reset \n",
      "     479       481.799   0.000133707       31.4681   2.184e-06       0.001      856  LS failed, Hessian reset \n",
      "     499        481.81   1.35672e-05       22.9247       1.203      0.1203      891   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     526       481.811   9.11253e-08       26.7731           1           1      926   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.13007\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      97       502.249   0.000196809       38.0019   3.177e-06       0.001      174  LS failed, Hessian reset \n",
      "      99       502.412    0.00540643       41.9202           1           1      177   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       513.188    0.00470952       72.9907           1           1      311   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     208       514.447   0.000330367       41.0127     1.9e-06       0.001      363  LS failed, Hessian reset \n",
      "     299       517.554    0.00475193       81.9595           1           1      483   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     352       518.613   0.000730682       111.439   2.089e-05       0.001      597  LS failed, Hessian reset \n",
      "     399       518.752    0.00039145       29.6943      0.7851      0.7851      652   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     441        518.77   0.000360402       37.4766   1.083e-05       0.001      753  LS failed, Hessian reset \n",
      "     463       518.776   5.45093e-06       28.5939   1.983e-07       0.001      819  LS failed, Hessian reset \n",
      "     475       518.776   3.14006e-08       27.2704      0.1305      0.5425      842   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.05378\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       515.035    0.00315973       39.7834           1           1      135   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     124        517.28   0.000726918       118.133   9.503e-06       0.001      217  LS failed, Hessian reset \n",
      "     199        521.69    0.00323412       118.305      0.8349      0.8349      311   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     228       523.702   0.000569651        115.41   8.262e-06       0.001      403  LS failed, Hessian reset \n",
      "     299       525.308    0.00122092       46.4649           1           1      500   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     333       525.822   0.000280032       63.3787   5.085e-06       0.001      577  LS failed, Hessian reset \n",
      "     377       525.912   5.20387e-05       25.3351   1.327e-06       0.001      674  LS failed, Hessian reset \n",
      "     399       525.913   1.70259e-07        30.504       0.279       0.279      711   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     415       525.915   2.78502e-05       24.4025   7.039e-07       0.001      771  LS failed, Hessian reset \n",
      "     448       525.916   1.46799e-07       34.3114           1           1      814   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.04681\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       523.528      0.046955        41.642           1           1      117   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       532.139     0.0317915       187.474           1           1      254   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       535.612   4.95626e-05       28.1115       0.127       0.127      384   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     323       535.768    0.00143102       104.696   3.079e-05       0.001      448  LS failed, Hessian reset \n",
      "     366       535.824    6.4304e-05       30.7368   1.887e-06       0.001      549  LS failed, Hessian reset \n",
      "     399       535.825   3.32536e-05       34.6307           1           1      597   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     410       535.826   2.20436e-06       23.4793   8.461e-08       0.001      646  LS failed, Hessian reset \n",
      "     432       535.826   1.43581e-06        36.311    3.94e-08       0.001      710  LS failed, Hessian reset \n",
      "     443       535.826   6.87505e-08       22.0445      0.1668      0.8246      725   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.03314\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       542.177     0.0176862       68.8042           1           1      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     167       549.857   0.000293079        36.685   2.285e-06       0.001      251  LS failed, Hessian reset \n",
      "     199       551.828   0.000368988       29.4103           1           1      307   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     207       551.879   0.000534554       70.3519   1.872e-05       0.001      354  LS failed, Hessian reset \n",
      "     273       552.842   0.000233233       28.8712   7.881e-06       0.001      484  LS failed, Hessian reset \n",
      "     286        552.85   4.92036e-05       25.8623   1.584e-06       0.001      539  LS failed, Hessian reset \n",
      "     299       552.853   3.44887e-06       30.5154      0.2734           1      559   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     333       553.031   0.000530365       90.5862   9.547e-06       0.001      641  LS failed, Hessian reset \n",
      "     385       553.317   0.000224771       45.6366   5.513e-06       0.001      762  LS failed, Hessian reset \n",
      "     399       553.328    1.2267e-05       31.8511           1           1      778   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499        554.68    0.00735676        33.704       0.924       0.924      903   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     539       554.945   0.000246668       66.9245   4.839e-06       0.001     1007  LS failed, Hessian reset \n",
      "     569       554.983   3.30362e-05       32.5631   1.092e-06       0.001     1083  LS failed, Hessian reset \n",
      "     599       554.984   3.18901e-07       33.5717           1           1     1135   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     606       554.984   3.09984e-06       31.7814   1.005e-07       0.001     1181  LS failed, Hessian reset \n",
      "     625       554.984   8.46254e-08       31.0095           1           1     1213   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.95339\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       575.475    0.00926421       84.5296     0.05239           1      131   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     142       580.766    0.00752406       252.405   0.0002339       0.001      223  LS failed, Hessian reset \n",
      "     199       582.443   0.000561471        28.766      0.1908           1      311   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     280       588.081   0.000190374       52.1079   2.277e-06       0.001      457  LS failed, Hessian reset \n",
      "     299       589.178     0.0044968       119.441      0.1597           1      483   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       591.752     0.0012001       38.8432           1           1      606   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     476       592.247   0.000637834       64.8456   1.943e-05       0.001      746  LS failed, Hessian reset \n",
      "     499        592.31   0.000534374       38.7172           1           1      772   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     575       593.056   0.000499016       108.234   9.802e-06       0.001      913  LS failed, Hessian reset \n",
      "     599       593.459   0.000211315       33.4236      0.2059           1      946   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     650       593.668   0.000422708       44.9733   1.041e-05       0.001     1048  LS failed, Hessian reset \n",
      "     699       593.691   0.000770146       41.7633      0.1342           1     1113   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     729        593.74   0.000104854        30.098   3.286e-06       0.001     1237  LS failed, Hessian reset \n",
      "     799       593.757   0.000109613       33.9033           1           1     1341   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       593.849    0.00217355       37.9389      0.6619      0.6619     1476   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       594.599    0.00529293       48.4863           1           1     1600   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099        594.76    0.00146415       34.9532           1           1     1717   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1151       594.878   0.000203034       48.0021   6.057e-06       0.001     1815  LS failed, Hessian reset \n",
      "    1199       594.919   0.000173871        27.385      0.8907      0.8907     1878   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1219        594.93   8.36017e-05       37.1275   1.753e-06       0.001     1940  LS failed, Hessian reset \n",
      "    1299       594.943    7.2772e-06       25.4415           1           1     2052   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1340       594.943   2.28557e-07       35.6415      0.0262      0.6326     2118   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.02865\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       590.549     0.0149564       121.393      0.4547           1      120   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     147       598.957    0.00070891       154.082   1.927e-06       0.001      221  LS failed, Hessian reset \n",
      "     178        601.81   0.000898487       157.044    1.03e-05       0.001      293  LS failed, Hessian reset \n",
      "     199       602.686    0.00170382       49.4434      0.9683      0.9683      323   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     229       603.146    0.00017868       24.7155   6.944e-06       0.001      403  LS failed, Hessian reset \n",
      "     289       603.685   0.000136362       35.4279   2.029e-06       0.001      520  LS failed, Hessian reset \n",
      "     299       603.866    0.00165353       43.7608      0.5731      0.5731      534   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       605.595     0.0119829       92.6225      0.7634      0.7634      662   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     475       606.551    9.5994e-05       37.1917    2.12e-06       0.001      799  LS failed, Hessian reset \n",
      "     499       606.673   0.000202225       28.2886           1           1      832   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     533       606.759    0.00042893       66.8613   8.803e-06       0.001      929  LS failed, Hessian reset \n",
      "     599       606.808   0.000952721       30.4828        0.83        0.83     1017   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       607.459   7.50135e-05       24.6565       1.951      0.6376     1146   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     744        607.46    5.5913e-07       27.5253      0.3508           1     1219   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.87685\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       605.948     0.0157856       51.9618      0.8202      0.8202      139   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       614.401     0.0195802       130.778           1           1      281   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       617.328     0.0100696       50.3544           1           1      407   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       619.285   0.000432239       27.8152      0.6707      0.6707      526   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       619.501     0.0044326       61.7652           1           1      645   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     501       619.509    0.00011245       44.8994   2.271e-06       0.001      705  LS failed, Hessian reset \n",
      "     524       619.518   9.40209e-05        28.592    2.64e-06       0.001      774  LS failed, Hessian reset \n",
      "     559        619.52   4.17782e-06       27.4164   1.332e-07       0.001      860  LS failed, Hessian reset \n",
      "     585        619.52   1.96782e-08       29.0352     0.08082       0.257      894   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.9064\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       612.612    0.00221741       85.4192       0.336       0.336      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     163       617.242   0.000338522       83.1604   2.337e-06       0.001      248  LS failed, Hessian reset \n",
      "     199       619.193   0.000936564       51.7074      0.1888           1      296   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       626.652    0.00333503        93.423           1           1      432   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       628.191   0.000324193       33.2266           1           1      557   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     487       629.705   0.000136197        45.755   2.153e-06       0.001      721  LS failed, Hessian reset \n",
      "     499       630.089    0.00121003       35.4929           1           1      739   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       630.638   3.63509e-06       23.9543       0.112       0.112      887   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     664        630.65   2.63781e-06       31.2391   8.933e-08       0.001     1023  LS failed, Hessian reset \n",
      "     686        630.65   3.22059e-08       29.7057      0.2161           1     1055   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.86336\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       616.728     0.0314279       113.678     0.07619           1      130   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     189       625.831   0.000192325       42.0581   2.292e-06       0.001      282  LS failed, Hessian reset \n",
      "     199       626.359    0.00203483        33.863           1           1      297   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299        627.23   0.000408211       34.7005           1           1      433   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     371       628.121   0.000278331       60.3918   2.051e-06       0.001      575  LS failed, Hessian reset \n",
      "     399       628.784    0.00167522       45.6251           1           1      610   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     418       628.871   0.000155161       36.3666   3.053e-06       0.001      672  LS failed, Hessian reset \n",
      "     452       628.912   0.000418302       77.6893   1.251e-05       0.001      756  LS failed, Hessian reset \n",
      "     491       628.924   3.22646e-05       30.5456   8.101e-07       0.001      850  LS failed, Hessian reset \n",
      "     499       628.924   1.99733e-06       29.1348      0.0665           1      863   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     522       628.924    2.2617e-08       27.8933     0.03843           1      905   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.88066\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       632.016    0.00785591       135.539      0.1812           1      138   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     159       635.413   0.000245334        59.191    2.83e-06       0.001      246  LS failed, Hessian reset \n",
      "     199       636.141    0.00121615       45.6441      0.7034      0.7034      294   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     215       636.456   0.000192478        39.432    2.34e-06       0.001      353  LS failed, Hessian reset \n",
      "     299       638.828   0.000396527       94.9475     0.07518     0.07518      467   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        640.87    0.00382521       55.6886           1           1      598   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       641.572    0.00100186       55.8974      0.9341      0.9341      720   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       643.482    0.00321746       54.2103      0.4548      0.4548      842   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     642        643.97   0.000494163       96.1345   1.397e-05       0.001      940  LS failed, Hessian reset \n",
      "     699       644.046    1.0447e-06       26.2549           1           1     1020   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     733       644.217   0.000283055       63.1071   7.231e-06       0.001     1105  LS failed, Hessian reset \n",
      "     799       644.404   8.17304e-06       28.1667      0.4041      0.4041     1192   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     829       644.404   7.32505e-07       37.0184   2.177e-08       0.001     1273  LS failed, Hessian reset \n",
      "     837       644.404   2.87282e-08       34.1835         0.2           1     1284   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.90994\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        641.89    0.00342425       65.8473       1.695      0.1695      129   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     189       647.822     0.0010901       104.306     4.5e-05       0.001      283  LS failed, Hessian reset \n",
      "     199       647.891   0.000666945       77.8919      0.5986      0.5986      293   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     215       648.262   0.000381497       83.0536   6.926e-06       0.001      356  LS failed, Hessian reset \n",
      "     257       649.035   0.000173089       34.9446   1.984e-06       0.001      446  LS failed, Hessian reset \n",
      "     299       649.251      0.001884       44.6494      0.1888      0.6104      504   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     391       653.035   0.000216034       60.4262   4.219e-06       0.001      679  LS failed, Hessian reset \n",
      "     399       653.208   0.000502644       34.4455      0.3591      0.5461      690   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       656.385    0.00214413       46.1697       0.177           1      815   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     529       656.505   0.000253155       60.3846   6.338e-06       0.001      893  LS failed, Hessian reset \n",
      "     599       656.621    0.00228079       56.3657           1           1      979   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     601       656.687    0.00032612       45.0992   1.752e-06       0.001     1025  LS failed, Hessian reset \n",
      "     699       657.164    0.00253943       40.1657      0.9947      0.9947     1148   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     720       657.646   0.000181398       52.6972   2.737e-06       0.001     1224  LS failed, Hessian reset \n",
      "     799       658.336    0.00221161       44.3394           1           1     1329   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     889       658.491   6.91115e-05       38.9813   1.404e-06       0.001     1491  LS failed, Hessian reset \n",
      "     899       658.492    2.9144e-06       24.2348           1           1     1506   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     916       658.493   3.83531e-09       29.3022     0.04146     0.04146     1531   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "Initial log joint probability = -2.89117\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       652.619     0.0653736       653.696           1           1      125   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       663.374     0.0111176       88.5156           1           1      257   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     211       664.872    0.00020609       47.2643   2.135e-06       0.001      320  LS failed, Hessian reset \n",
      "     267       665.806   0.000212396       38.3588   1.874e-06       0.001      439  LS failed, Hessian reset \n",
      "     299       665.872   2.12705e-05       34.0349           1           1      491   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     334       665.895   0.000256262       54.7781    5.97e-06       0.001      572  LS failed, Hessian reset \n",
      "     399       665.916    0.00059263       40.9716           1           1      660   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     456       666.144   0.000350082       53.7752   1.152e-05       0.001      815  LS failed, Hessian reset \n",
      "     499       666.299   4.16655e-06       24.8106        1.03      0.2547      874   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       666.351   2.56812e-07       29.6981      0.3249      0.3249     1000   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       666.357   1.39749e-06       32.9047        2.35      0.7819     1135   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     705       666.357   1.57577e-06       37.4633   4.881e-08       0.001     1185  LS failed, Hessian reset \n",
      "     713       666.357   1.23566e-07        27.526      0.7373      0.7373     1195   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.02643\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       663.192     0.0640067       51.2198      0.7576      0.7576      119   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     115       667.106   0.000570768        114.74   1.235e-05       0.001      177  LS failed, Hessian reset \n",
      "     199        676.52    0.00639933       44.5624           1           1      284   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     245       678.627   0.000131516        39.372   3.196e-06       0.001      394  LS failed, Hessian reset \n",
      "     299       679.048    0.00109998       31.5708      0.8214      0.8214      462   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       679.508    0.00338057       45.4968      0.3757           1      593   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     486       681.222   0.000194395       51.7712   5.002e-06       0.001      742  LS failed, Hessian reset \n",
      "     499        681.24    1.8443e-05        32.135      0.1944      0.1944      758   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     518       681.244    5.6564e-05       40.6457    1.81e-06       0.001      824  LS failed, Hessian reset \n",
      "     555       681.246   9.89867e-06       33.2028   2.539e-07       0.001      915  LS failed, Hessian reset \n",
      "     590       681.246   1.60311e-07       24.2578   5.429e-09       0.001      999  LS failed, Hessian reset \n",
      "     591       681.246   5.35203e-08       28.5333      0.3556           1     1001   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.96327\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        674.18     0.0110367       56.9377           1           1      129   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       685.464      0.010693       123.438       2.499      0.2499      249   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     238       691.419   0.000158729       52.6236   2.516e-06       0.001      341  LS failed, Hessian reset \n",
      "     299       695.464    0.00514619       36.4233           1           1      418   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       698.942    0.00192263        140.06      0.3492      0.3492      539   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     446       700.354   0.000188924       52.8467    1.55e-06       0.001      643  LS failed, Hessian reset \n",
      "     480        701.43   0.000291047       72.8238   7.387e-06       0.001      725  LS failed, Hessian reset \n",
      "     499       701.549    7.4743e-05        54.069      0.1381      0.1381      747   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     569       702.283   0.000139664       49.9115   3.155e-06       0.001      874  LS failed, Hessian reset \n",
      "     599       702.294   4.91088e-06       34.3123           1           1      922   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       702.862    0.00016968       50.7492      0.5114      0.5114     1044   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       704.735    0.00204159        61.449      0.4138           1     1171   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       705.523   0.000915248       44.6566           1           1     1292   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     912        705.67   0.000215685       74.2396   5.708e-06       0.001     1344  LS failed, Hessian reset \n",
      "     949       705.773   8.45605e-05       30.1532   2.959e-06       0.001     1420  LS failed, Hessian reset \n",
      "     999       705.792   1.18832e-05        30.233     0.06384           1     1484   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       706.286   1.37903e-05       25.9323      0.3132           1     1621   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       706.392   1.62348e-06       27.0587           1           1     1758   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1202       706.392   3.98937e-06       34.6157   1.065e-07       0.001     1802  LS failed, Hessian reset \n",
      "    1220       706.392   4.32462e-08       25.4017      0.3992           1     1827   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.84701\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       702.338     0.0101264       177.433           1           1      126   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     179       711.912   0.000163094       37.6512   1.597e-06       0.001      268  LS failed, Hessian reset \n",
      "     199       712.418   0.000977977       49.8005       0.341       0.341      293   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     242       715.758    0.00044283       148.762   1.988e-06       0.001      387  LS failed, Hessian reset \n",
      "     299        720.45    0.00102111       45.0663       4.497      0.4497      464   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     318       720.758   0.000149528       55.5756   2.806e-06       0.001      529  LS failed, Hessian reset \n",
      "     379       721.494   0.000194004       61.2037   1.585e-06       0.001      643  LS failed, Hessian reset \n",
      "     399       722.039    0.00142996       38.3737      0.2467           1      667   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       723.776     0.0714189       242.293           1           1      791   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     550       725.825   9.41734e-05       39.7071   1.376e-06       0.001      889  LS failed, Hessian reset \n",
      "     599       726.656      0.017763        70.365       1.331      0.1331      957   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699        727.27    7.9141e-05       26.0424      0.3856           1     1092   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     725         727.3   4.25182e-05       28.1561   1.424e-06       0.001     1161  LS failed, Hessian reset \n",
      "     799       727.345    0.00031681       42.2436       4.001      0.4001     1264   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899        728.08    0.00337766       37.6462      0.8048      0.8048     1389   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999        728.31     0.0012828       36.5451           1           1     1511   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       728.551   0.000409136       50.9806           1           1     1635   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       728.593    3.5407e-06       28.2205      0.4877      0.4877     1777   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299       728.771   0.000599881       58.2257           1           1     1915   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1325        728.79    1.1789e-05       34.2671   4.345e-07       0.001     1988  LS failed, Hessian reset \n",
      "    1399       728.833   1.15915e-06        31.128           1           1     2088   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1409       728.834   9.94565e-06       28.6354    3.71e-07       0.001     2140  LS failed, Hessian reset \n",
      "    1437       728.834   4.95424e-09       36.3585    0.001427           1     2180   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "Initial log joint probability = -2.77705\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       728.103      0.012134       130.603      0.1562      0.1562      129   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       746.771   0.000172072       57.7393   1.821e-06       0.001      296  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     262        750.15   0.000205713       75.8785    4.12e-06       0.001      418  LS failed, Hessian reset \n",
      "     299       750.601   0.000175725       33.0786      0.8501     0.08501      465   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       754.272    0.00201637       55.5749     0.04532     0.08597      601   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     479       755.203   0.000151015       69.7517    2.44e-06       0.001      757  LS failed, Hessian reset \n",
      "     490       755.363   0.000104597       37.2191   1.415e-06       0.001      803  LS failed, Hessian reset \n",
      "     499       755.427   0.000191196       31.7377      0.7591      0.7591      814   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       755.502   1.18122e-05       35.6395           1           1      962   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     641       755.514   1.06704e-05       26.2861   3.114e-07       0.001     1057  LS failed, Hessian reset \n",
      "     659       755.514   5.41402e-08       29.7758      0.3367           1     1084   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.83044\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       744.253     0.0131144       129.374           1           1      129   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       756.512   0.000955935       107.651      0.4933      0.4933      269   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       759.295       0.02358       316.739       1.888      0.4408      400   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        763.39   0.000795045       77.5903      0.5785      0.5785      524   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     446        766.24   9.78851e-05       34.0047   1.438e-06       0.001      616  LS failed, Hessian reset \n",
      "     499       766.566    0.00334711       92.7884      0.2831           1      690   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     500       766.574   0.000183638       71.7245   1.979e-06       0.001      728  LS failed, Hessian reset \n",
      "     599       766.865    0.00136006       42.9812      0.2782           1      862   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     689       767.302   0.000114444       42.3758   1.466e-06       0.001     1013  LS failed, Hessian reset \n",
      "     699       767.336   8.83182e-05       29.0397      0.4408           1     1030   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       767.428   3.17448e-06       28.6727           1           1     1168   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     874       767.485   0.000111942        45.043   3.325e-06       0.001     1294  LS failed, Hessian reset \n",
      "     899       767.489   3.08468e-06        32.118       1.797      0.1797     1327   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     911       767.489   1.14539e-07        35.379      0.4224      0.4224     1346   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.92487\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       777.336    0.00487858        263.38      0.3885     0.03885      136   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       784.518   0.000353154       76.9633       0.454       0.454      259   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       788.145     0.0118468       60.1258           1           1      383   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       794.756   0.000453017       41.0782      0.3706      0.3706      520   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     450       795.199   0.000865753       85.1163   2.128e-05       0.001      624  LS failed, Hessian reset \n",
      "     499         795.4    0.00119556       37.5834      0.1305           1      683   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     583       796.119   0.000107454       52.4477   2.427e-06       0.001      834  LS failed, Hessian reset \n",
      "     599       796.215   0.000708434       46.4344      0.2686           1      856   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     620        796.27   0.000306336       91.0494   7.399e-06       0.001      919  LS failed, Hessian reset \n",
      "     678       796.296   3.39898e-06       34.1845   1.093e-07       0.001     1044  LS failed, Hessian reset \n",
      "     699       796.297   6.66765e-06       30.1034           1           1     1077   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     793       796.308   6.33125e-07       29.7307      0.0568           1     1208   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.81598\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       786.628    0.00310123       138.198      0.3168      0.3168      128   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        797.73    0.00338713       50.3626      0.2628           1      254   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     258       800.726   0.000145014       56.5439   2.735e-06       0.001      370  LS failed, Hessian reset \n",
      "     299       802.181      0.017216       129.163           1           1      425   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     305       802.349    0.00018616       67.1322   1.765e-06       0.001      502  LS failed, Hessian reset \n",
      "     399       803.347   0.000496564       30.3309           1           1      630   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     497       803.747   0.000951018       137.105   1.126e-05       0.001      794  LS failed, Hessian reset \n",
      "     499       803.769   0.000156656       57.1732      0.6671      0.6671      796   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       804.171   2.94264e-05       37.9999       0.277           1      928   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     614       804.184   0.000145775        53.421   2.986e-06       0.001      995  LS failed, Hessian reset \n",
      "     699       804.205   4.44065e-05       33.0439           1           1     1109   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       804.479    0.00136177        45.802           1           1     1234   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     892       804.504   1.27047e-05       34.6313   3.917e-07       0.001     1397  LS failed, Hessian reset \n",
      "     899       804.505   9.88964e-07       27.3236      0.3074           1     1407   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     913       804.505   9.49345e-08       32.9104      0.7122      0.7122     1426   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.49773\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       813.381     0.0192164       545.862           1           1      130   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       824.934     0.0482083       308.521           1           1      265   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       827.619    0.00037811       39.2233      0.5598      0.5598      398   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     390       828.769   0.000201079        38.548   1.182e-06       0.001      554  LS failed, Hessian reset \n",
      "     399       829.044   0.000721498        45.046           1           1      565   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     489       829.471   3.92813e-05       33.5413   9.286e-07       0.001      718  LS failed, Hessian reset \n",
      "     499       829.472   1.95461e-06       39.4371      0.3402      0.3402      732   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     521       829.472   7.06944e-08       40.3215      0.3001      0.3001      765   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.91991\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       831.255       0.01061       167.871           1           1      122   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       850.206    0.00220222       119.747      0.3716           1      259   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       852.543   0.000693455       40.8333           1           1      392   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     397       853.517   0.000478448       121.639   1.194e-05       0.001      553  LS failed, Hessian reset \n",
      "     399        853.53   0.000543136       38.1373           1           1      555   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     457       853.686   0.000104189       28.0861    2.93e-06       0.001      676  LS failed, Hessian reset \n",
      "     499       853.781    0.00064905       32.3047           1           1      727   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     528       854.178   0.000168874        53.314   1.136e-06       0.001      827  LS failed, Hessian reset \n",
      "     599       854.993   3.08586e-05       30.1478        2.18       0.648      926   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     685       855.428   0.000191055       39.9533   5.886e-06       0.001     1063  LS failed, Hessian reset \n",
      "     699       855.434   4.79456e-05       37.5955   1.556e-06       0.001     1114  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799        856.09      0.020722       78.9347           1           1     1235   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     807       856.772   0.000142717       53.7304   1.092e-06       0.001     1294  LS failed, Hessian reset \n",
      "     868        857.05   8.15726e-05       42.1576   1.583e-06       0.001     1423  LS failed, Hessian reset \n",
      "     895       857.055   8.07696e-06       35.5309   2.593e-07       0.001     1513  LS failed, Hessian reset \n",
      "     899       857.055   4.02721e-06       26.7365       1.784      0.1784     1519   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     937       857.057   6.46605e-06       36.1855   2.652e-07       0.001     1603  LS failed, Hessian reset \n",
      "     974       857.058   4.09863e-08       31.3193      0.2366           1     1651   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.26746\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       856.555      0.117347       214.454           1           1      129   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       862.798    0.00783101       102.961           1           1      256   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       869.707     0.0155874       51.3076           1           1      388   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       871.883     0.0800449       132.724           1           1      519   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     433       873.117   0.000316908       137.682   3.294e-06       0.001      599  LS failed, Hessian reset \n",
      "     499       874.461   0.000169973        65.267      0.5791      0.5791      684   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       874.806    0.00204396       57.4439           1           1      816   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     696        875.15   7.24058e-05       39.2963   2.333e-06       0.001     1001  LS failed, Hessian reset \n",
      "     699       875.152   6.80959e-05        35.523           1           1     1004   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       875.315   0.000392284       27.9241      0.3701           1     1130   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       875.497   0.000443937       38.8151           1           1     1258   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       875.587     0.0005026       33.0774      0.7168      0.7168     1387   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1070       875.664   9.46312e-05       55.7278   1.664e-06       0.001     1529  LS failed, Hessian reset \n",
      "    1099       875.668   4.62224e-07       31.1315           1           1     1572   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1104       875.668   2.27902e-07       27.8076           1           1     1582   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.2845\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       876.437     0.0416646       385.009      0.5336           1      134   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     151       885.247    0.00263129       266.522   5.182e-05       0.001      235  LS failed, Hessian reset \n",
      "     199       886.735     0.0102117       167.236           1           1      295   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     279       892.118   7.73148e-05        34.742    9.17e-07       0.001      428  LS failed, Hessian reset \n",
      "     299       892.339    0.00155994       53.0066      0.4458           1      451   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       894.591     0.0893073       71.0982           1           1      591   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       896.903   0.000311919        107.04      0.4862      0.4862      720   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     584       898.928    0.00012356       60.1194   7.668e-07       0.001      878  LS failed, Hessian reset \n",
      "     599       899.698    0.00375916       37.0719           1           1      898   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     620       899.929   6.58104e-05       46.7793   1.605e-06       0.001      962  LS failed, Hessian reset \n",
      "     679       900.864   0.000781595       112.967   1.763e-05       0.001     1061  LS failed, Hessian reset \n",
      "     699       901.136    0.00104053       36.5697       2.943      0.2943     1089   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       901.501   6.23712e-05        29.446           1           1     1218   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     816        901.61   0.000179304       103.504   3.483e-06       0.001     1281  LS failed, Hessian reset \n",
      "     850       901.727   0.000130196       26.1448   3.528e-06       0.001     1364  LS failed, Hessian reset \n",
      "     871       901.728   3.90751e-08       25.5595      0.2293           1     1410   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.37801\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       890.515      0.017281       112.955           1           1      130   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        911.98    0.00830226       122.704      0.8771      0.8771      263   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     246       914.612   9.98601e-05       41.5034   8.422e-07       0.001      376  LS failed, Hessian reset \n",
      "     299       915.743     0.0154099       184.461           1           1      446   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     302       915.795   7.95357e-05       50.5917   1.184e-06       0.001      487  LS failed, Hessian reset \n",
      "     399       916.912     0.0163818       68.3466           1           1      609   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       920.885     0.0182019       91.2682      0.1564           1      740   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       921.558   0.000518145       28.0263           1           1      874   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       922.044   3.68322e-05       25.8378      0.5448       0.411      996   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     742       922.132   5.15078e-05       42.8564   1.226e-06       0.001     1088  LS failed, Hessian reset \n",
      "     799       922.231    3.3842e-06       23.3599      0.8038      0.8038     1164   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     809       922.231   3.38234e-07       25.2181     0.08142           1     1180   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.39749\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       928.949    0.00492303       43.5412      0.7557      0.7557      134   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       955.199    0.00509771       96.6045      0.6876      0.6876      262   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       961.245   0.000128112       64.3715        0.23           1      421   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       965.865    0.00865414       30.3898           1           1      550   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     402       965.877   3.58682e-05       31.5868   5.983e-07       0.001      594  LS failed, Hessian reset \n",
      "     499       966.673   2.26023e-05       26.8373      0.1614      0.4427      732   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     529       966.721   4.79772e-05       44.8717    6.07e-07       0.001      810  LS failed, Hessian reset \n",
      "     570       966.754   4.64337e-06       29.8216    1.72e-07       0.001      906  LS failed, Hessian reset \n",
      "     584       966.754   6.43009e-09       23.7309    0.009156           1      926   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "Initial log joint probability = -3.53792\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       947.742     0.0171239       313.626      0.4368           1      123   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       967.907      0.035338       84.7118      0.9368      0.9368      256   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       984.466     0.0554316       173.123      0.4093           1      380   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       994.538      0.020253       518.589           1           1      511   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     440       996.707   6.85843e-05        59.316   4.784e-07       0.001      623  LS failed, Hessian reset \n",
      "     499       999.059   0.000723859       151.404      0.2462      0.2462      708   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     516       999.344   6.50591e-05       37.5461   4.263e-07       0.001      763  LS failed, Hessian reset \n",
      "     578       999.731   4.58439e-05        50.556   5.585e-07       0.001      894  LS failed, Hessian reset \n",
      "     599       999.902    0.00021698       52.3198           1           1      920   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     601       999.905   4.29903e-05       50.7439    1.45e-06       0.001      959  LS failed, Hessian reset \n",
      "     612       999.909   1.98507e-05       30.4255   7.243e-07       0.001     1011  LS failed, Hessian reset \n",
      "     650       999.928   3.21291e-05       26.9841   4.754e-07       0.001     1107  LS failed, Hessian reset \n",
      "     695       999.935   1.01942e-07       25.1195      0.4421           1     1178   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.49334\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       971.879    0.00645204       151.323      0.3181           1      129   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       997.321    0.00570551       114.626           1           1      259   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299        1004.9   0.000138158       87.3822      0.1916      0.1916      400   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     326       1006.14   7.81966e-05       55.2954    4.99e-07       0.001      475  LS failed, Hessian reset \n",
      "     369       1008.71   6.91089e-05       59.3897   5.237e-07       0.001      571  LS failed, Hessian reset \n",
      "     399       1009.36    0.00161835       59.8231      0.5744      0.5744      609   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     415       1010.44   0.000163183       173.418    7.34e-07       0.001      670  LS failed, Hessian reset \n",
      "     452       1013.07   2.69787e-05       24.6942   5.191e-07       0.001      760  LS failed, Hessian reset \n",
      "     495        1013.9   0.000128953       134.345   6.859e-07       0.001      858  LS failed, Hessian reset \n",
      "     499       1013.97    0.00175701       117.826           1           1      863   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     596       1016.08   7.10116e-05       49.8953   4.606e-07       0.001     1021  LS failed, Hessian reset \n",
      "     599       1016.24    0.00367956       157.661           1           1     1025   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1017.66   0.000875455       35.3683           1           1     1171   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     700       1017.66    4.2234e-05       45.2478   1.194e-06       0.001     1207  LS failed, Hessian reset \n",
      "     727       1017.69   4.08839e-05       43.3424   1.056e-06       0.001     1293  LS failed, Hessian reset \n",
      "     765       1017.85   7.54189e-05       58.5819   2.448e-06       0.001     1376  LS failed, Hessian reset \n",
      "     785       1017.87   4.53198e-05       46.9185   1.511e-06       0.001     1443  LS failed, Hessian reset \n",
      "     799       1017.88   6.29461e-05       18.8832           1           1     1460   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     817       1017.92   4.06066e-05       54.4423   8.582e-07       0.001     1527  LS failed, Hessian reset \n",
      "     871       1018.26     6.419e-05       68.4232   6.093e-07       0.001     1645  LS failed, Hessian reset \n",
      "     899       1018.54    0.00202707       54.7464      0.5432           1     1679   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     937       1018.62   0.000105043       62.4436   3.679e-06       0.001     1781  LS failed, Hessian reset \n",
      "     999       1018.76    0.00409218       214.703      0.1503           1     1880   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1008       1018.82   5.21919e-05       59.5195   1.185e-06       0.001     1934  LS failed, Hessian reset \n",
      "    1099          1019   0.000126514       32.2272       2.583      0.5569     2053   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1119          1019   7.08803e-06       27.6906   2.613e-07       0.001     2120  LS failed, Hessian reset \n",
      "    1128          1019   3.38204e-07       24.4387   1.405e-08       0.001     2170  LS failed, Hessian reset \n",
      "    1129          1019   2.21056e-07       25.6707      0.9721      0.9721     2171   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.85494\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1007.34     0.0182662       264.743      0.4529      0.4529      119   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1029.89     0.0147292       440.552      0.3617      0.3617      249   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299        1041.8     0.0750431       294.206           1           1      380   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     310       1043.47   0.000103103       132.509   6.198e-07       0.001      439  LS failed, Hessian reset \n",
      "     399       1051.22     0.0245477       136.506           1           1      541   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     451        1054.3   0.000219194       104.751   4.855e-06       0.001      658  LS failed, Hessian reset \n",
      "     499       1057.05    0.00311289       26.5664           1           1      721   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1058.22   0.000774651       51.9272           1           1      854   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     648       1059.51   2.96692e-05       31.1546   4.522e-07       0.001      970  LS failed, Hessian reset \n",
      "     699       1059.88   4.32189e-05       39.2339      0.5259      0.5259     1035   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     741       1060.13   0.000118527       75.1968    4.23e-06       0.001     1130  LS failed, Hessian reset \n",
      "     768       1060.14   7.99922e-05        69.951   2.111e-06       0.001     1202  LS failed, Hessian reset \n",
      "     799       1060.14   0.000103413       32.4478           1           1     1244   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     811       1060.19   4.26437e-05       51.3983   4.882e-07       0.001     1296  LS failed, Hessian reset \n",
      "     899        1060.4   0.000875606        98.381       2.842      0.2842     1405   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     925       1060.66   3.83637e-05       53.9327   7.846e-07       0.001     1473  LS failed, Hessian reset \n",
      "     999        1060.9   1.21346e-05       37.8891      0.5038      0.5038     1576   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1026        1060.9   1.51973e-05       34.1738   3.733e-07       0.001     1654  LS failed, Hessian reset \n",
      "    1054        1060.9   4.33372e-08       24.0426      0.1742      0.7409     1698   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.88495\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99          1028     0.0628819       951.634      0.1578           1      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1051.55    0.00998999       99.4734           1           1      244   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1059.95    0.00705364        66.525           1           1      366   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1065.49    0.00539919       110.689      0.6073      0.6073      490   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     440       1067.49   0.000127872       123.365   1.463e-06       0.001      582  LS failed, Hessian reset \n",
      "     499       1068.39     0.0509649       475.551           1           1      657   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1071.83    0.00673226       88.8043           1           1      791   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     603       1071.91   5.50165e-05        58.801   4.711e-07       0.001      850  LS failed, Hessian reset \n",
      "     699       1072.86   0.000628411       53.7209      0.3287      0.3287      975   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     738       1074.43    6.6635e-05       86.9712   1.075e-06       0.001     1094  LS failed, Hessian reset \n",
      "     799       1076.22   1.89641e-05       38.3925     0.05156           1     1184   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1076.81    0.00304139       118.218      0.7488      0.7488     1310   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1077.83    0.00247183       63.3359           1           1     1433   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1056       1078.93   4.04207e-05       38.1023   3.757e-07       0.001     1552  LS failed, Hessian reset \n",
      "    1099       1079.16   0.000693542       72.1749      0.1981           1     1608   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1116       1079.22   0.000615491       193.449   1.872e-05       0.001     1680  LS failed, Hessian reset \n",
      "    1167       1079.25   1.76065e-08       31.4508     0.04219           1     1752   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.08061\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1051.54     0.0707138       213.734           1           1      141   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1083.26    0.00354172       145.004      0.4817      0.4817      266   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1092.86     0.0110643       215.996           1           1      377   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     356       1096.39   7.26214e-05       66.7935   4.077e-07       0.001      483  LS failed, Hessian reset \n",
      "     399       1098.46   0.000804762       47.2279           1           1      538   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     417       1098.68    0.00335755       253.566   7.209e-05       0.001      605  LS failed, Hessian reset \n",
      "     467       1099.32   0.000175836       113.663   5.802e-06       0.001      700  LS failed, Hessian reset \n",
      "     499        1099.9   0.000484237       158.359           1           1      738   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     513       1099.97   2.75262e-05       36.8973   1.025e-06       0.001      823  LS failed, Hessian reset \n",
      "     599       1101.98    0.00587483       91.7812      0.4428      0.4428      936   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     638       1103.02   5.52349e-05       77.5658   9.704e-07       0.001     1039  LS failed, Hessian reset \n",
      "     681       1104.23   2.51239e-05        33.604   4.459e-07       0.001     1180  LS failed, Hessian reset \n",
      "     699       1104.67   0.000270568       33.8607      0.3558      0.9448     1204   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1105.29   0.000692234       249.121      0.2006      0.5788     1335   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     839       1105.64    2.2558e-05       28.3345   4.122e-07       0.001     1437  LS failed, Hessian reset \n",
      "     881       1105.94   9.85193e-05       93.4689   2.177e-06       0.001     1549  LS failed, Hessian reset \n",
      "     899       1105.98   2.27262e-05       27.0225      0.3634           1     1571   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999        1106.3    0.00131687       60.0449           1           1     1690   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1106.75    0.00317502       45.8245           1           1     1815   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1157       1107.38   0.000123847        126.61    1.43e-06       0.001     1960  LS failed, Hessian reset \n",
      "    1199       1107.62   6.13873e-05         49.78     0.07549     0.07549     2019   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299       1107.87    0.00163367       46.0957      0.8743      0.8743     2143   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1367       1108.03   1.99209e-05       22.5077   3.709e-07       0.001     2295  LS failed, Hessian reset \n",
      "    1399       1108.08   3.64623e-05       83.5108      0.1603      0.1603     2348   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1450       1108.12    0.00014085       109.623   3.126e-06       0.001     2452  LS failed, Hessian reset \n",
      "    1499       1108.13   3.41672e-07       20.2798           1           1     2516   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1500       1108.13   2.77792e-07       29.5373      0.4894           1     2518   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.6449\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1067.33    0.00234321       129.272           1           1      136   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1115.07     0.0416083       82.5115           1           1      250   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1128.97     0.0117784       276.415      0.2491      0.7742      371   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     334       1130.26   3.91395e-05       60.9316   7.906e-07       0.001      450  LS failed, Hessian reset \n",
      "     399       1132.12    0.00568399       88.7929      0.2076           1      536   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     401       1132.15   6.89749e-05       100.662     6.6e-07       0.001      577  LS failed, Hessian reset \n",
      "     499       1133.72    0.00258157       48.1402           1           1      710   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     507       1133.89   0.000225297       188.765   1.793e-06       0.001      763  LS failed, Hessian reset \n",
      "     584       1134.83    2.9105e-05        36.219    3.67e-07       0.001      909  LS failed, Hessian reset \n",
      "     599       1134.85   0.000132236       19.3766           1           1      931   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     638       1135.13   2.50486e-05       39.5448    4.71e-07       0.001     1020  LS failed, Hessian reset \n",
      "     699       1135.39   0.000241763       26.6569      0.3461           1     1107   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     730       1135.58    5.8951e-05       89.8495   6.215e-07       0.001     1185  LS failed, Hessian reset \n",
      "     775        1135.8   1.41552e-05       21.7626   4.297e-07       0.001     1283  LS failed, Hessian reset \n",
      "     799       1135.82   2.55793e-05        26.244           1           1     1319   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1136.58     0.0021485        57.876      0.4086      0.4086     1448   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     934          1137   2.59894e-05       41.5606   7.279e-07       0.001     1529  LS failed, Hessian reset \n",
      "     976       1137.14   2.37379e-05       42.4308     9.2e-07       0.001     1645  LS failed, Hessian reset \n",
      "     987       1137.14   1.07816e-05       22.1729   3.466e-07       0.001     1696  LS failed, Hessian reset \n",
      "     999       1137.14   2.13737e-07       22.9608       0.253           1     1715   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1001       1137.14    3.3401e-08       22.6278     0.04577           1     1721   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.55211\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1121.52      0.027168       1520.12           1           1      130   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1147.11     0.0178961       77.8221           1           1      263   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1153.66    0.00680881       64.9948      0.2672      0.0604      394   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1157.17     0.0042513       322.593     0.05151      0.8437      526   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     453       1158.76   6.96726e-05       26.2585   2.636e-07       0.001      646  LS failed, Hessian reset \n",
      "     499       1159.68   0.000820468       208.331           1           1      704   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     508       1159.76   0.000229572       95.0148   5.162e-06       0.001      748  LS failed, Hessian reset \n",
      "     529        1159.9   3.89788e-05       58.8482   3.455e-07       0.001      841  LS failed, Hessian reset \n",
      "     599        1160.4     0.0026439       100.741      0.8294      0.8294      932   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     611       1160.54   3.82857e-05       51.3227   3.169e-07       0.001      984  LS failed, Hessian reset \n",
      "     661       1160.91   2.38767e-05       43.8245   4.678e-07       0.001     1126  LS failed, Hessian reset \n",
      "     699       1161.06   9.28542e-05       25.8034        3.89       0.389     1181   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     723       1161.07   5.26791e-06       26.5458   3.123e-07       0.001     1252  LS failed, Hessian reset \n",
      "     784       1161.21   2.78885e-05       47.6546   8.686e-07       0.001     1378  LS failed, Hessian reset \n",
      "     799       1161.35    0.00115327       32.2493      0.7757      0.7757     1401   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     860       1161.46    1.8515e-05       33.1423   4.271e-07       0.001     1536  LS failed, Hessian reset \n",
      "     899        1161.5   4.33819e-05       35.9557      0.6171      0.6171     1590   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     969       1161.86   7.29514e-05        94.882   1.622e-06       0.001     1716  LS failed, Hessian reset \n",
      "     999       1162.13   5.62158e-05       30.8722      0.2703           1     1761   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1006       1162.14    2.3558e-05       35.6862    4.13e-07       0.001     1816  LS failed, Hessian reset \n",
      "    1099       1162.24   0.000609005       29.1113      0.3164           1     1931   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1191       1162.38   1.57731e-05       27.7109   4.385e-07       0.001     2139  LS failed, Hessian reset \n",
      "    1199       1162.39    0.00130908       65.8292           1           1     2149   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299       1162.46   3.80972e-05       28.4793           1           1     2283   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1363       1162.47   2.54475e-05       45.0395   5.355e-07       0.001     2406  LS failed, Hessian reset \n",
      "    1399       1162.48   1.86032e-06       16.5566      0.4673      0.4673     2456   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.30901\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        1149.2     0.0470313       193.568           1           1      137   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1180.95      0.016199       874.113      0.6173      0.6173      262   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1194.89    0.00255911       239.446           1           1      382   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1199.87    0.00133386       140.428      0.6484      0.6484      508   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1205.98    0.00899726       27.1565           1           1      630   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     585       1208.42   7.60159e-05         71.28    3.09e-06       0.001      782  LS failed, Hessian reset \n",
      "     599       1208.44   0.000369752       43.4901           1           1      797   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     659       1208.99   3.94086e-05       56.9064   2.726e-07       0.001      943  LS failed, Hessian reset \n",
      "     691       1209.63   1.39522e-05       31.2019   3.972e-07       0.001     1027  LS failed, Hessian reset \n",
      "     699       1209.64   0.000382196       32.1645      0.2108           1     1039   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     731       1209.78   4.63469e-05       61.0506   2.061e-06       0.001     1124  LS failed, Hessian reset \n",
      "     799       1210.45    2.2629e-05       31.6157   2.674e-07       0.001     1249  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     815        1210.7   6.68619e-05       17.8236    2.73e-06       0.001     1313  LS failed, Hessian reset \n",
      "     831       1210.75   3.62747e-05       53.4429   2.758e-07       0.001     1374  LS failed, Hessian reset \n",
      "     869       1210.83   4.03155e-05       73.3344   8.418e-07       0.001     1474  LS failed, Hessian reset \n",
      "     899       1210.88   3.69884e-05       30.2681           1           1     1510   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     981       1211.05   8.69135e-06       21.9675   2.826e-07       0.001     1653  LS failed, Hessian reset \n",
      "     999       1211.05   2.42642e-05       28.9367     0.09108           1     1674   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1018       1211.07   1.73342e-05       30.6515   2.943e-07       0.001     1733  LS failed, Hessian reset \n",
      "    1094       1211.39   6.82687e-05       88.4399   2.603e-07       0.001     1885  LS failed, Hessian reset \n",
      "    1099       1211.45    0.00028891       32.4919           1           1     1891   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1190       1211.68   0.000120311       114.553   3.028e-06       0.001     2046  LS failed, Hessian reset \n",
      "    1199       1211.69   1.03505e-05       33.6971           1           1     2063   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1294       1211.71   1.70128e-05       33.1074   6.486e-07       0.001     2230  LS failed, Hessian reset \n",
      "    1299       1211.71   1.71972e-05       35.6191           1           1     2235   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399       1211.74   5.05212e-05       26.3769           1           1     2362   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1499       1212.42    0.00384595       89.9909           1           1     2491   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1525       1212.48   1.27868e-05        25.553   3.021e-07       0.001     2565  LS failed, Hessian reset \n",
      "    1583        1212.6   3.08021e-05        66.515   4.549e-07       0.001     2691  LS failed, Hessian reset \n",
      "    1599       1212.64   6.42553e-05       27.1836           1           1     2710   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1608       1212.64   2.31337e-05       51.8312   7.785e-07       0.001     2758  LS failed, Hessian reset \n",
      "    1653       1212.64   2.02283e-05       40.5853   4.049e-07       0.001     2859  LS failed, Hessian reset \n",
      "    1684       1212.65   1.32964e-05       38.0453   4.973e-07       0.001     2936  LS failed, Hessian reset \n",
      "    1699       1212.65   1.56958e-06        26.175           1           1     2956   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1709       1212.65   1.96912e-06       25.5509   6.334e-08       0.001     3009  LS failed, Hessian reset \n",
      "    1717       1212.65   2.65582e-08       31.0634     0.06001           1     3022   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.60051\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1161.78     0.0110741       458.846      0.8345     0.08345      126   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1184.98     0.0103758        173.96           1           1      248   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1201.93    0.00201009        362.89      0.1306           1      372   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     379       1212.66   3.44975e-05       59.9602   4.484e-07       0.001      514  LS failed, Hessian reset \n",
      "     397       1213.88   5.46193e-05       37.3734    2.75e-07       0.001      576  LS failed, Hessian reset \n",
      "     399       1213.96    0.00283355        62.609           1           1      580   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1218.64    0.00576027       218.493      0.5635      0.5635      704   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     518       1219.95   4.95531e-05       52.0798   2.703e-07       0.001      779  LS failed, Hessian reset \n",
      "     529       1220.73    2.4265e-05       31.7744   2.883e-07       0.001      836  LS failed, Hessian reset \n",
      "     599       1221.94   0.000262742       42.7626       0.597       0.597      923   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1224.03    0.00091677       205.048      0.6632      0.6632     1046   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     725       1224.23   3.91067e-05       49.6385   2.564e-07       0.001     1114  LS failed, Hessian reset \n",
      "     799       1224.68   0.000188957       36.3777       0.302       0.302     1204   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     857       1224.93   2.32979e-05       49.5263   5.042e-07       0.001     1322  LS failed, Hessian reset \n",
      "     898       1224.98   1.57821e-05       28.2916    4.09e-07       0.001     1419  LS failed, Hessian reset \n",
      "     899       1224.98   1.27608e-05        28.018           1           1     1420   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     931       1224.98   1.06723e-05       29.5028   3.194e-07       0.001     1505  LS failed, Hessian reset \n",
      "     947       1224.98   1.64955e-07       24.3537           1           1     1532   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.89654\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1165.49    0.00630827       444.535           1           1      132   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1199.63    0.00494594       518.108      0.1076           1      251   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1209.51    0.00649928       155.381      0.9101      0.9101      379   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1213.38    0.00751511       157.439           1           1      524   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1217.51   0.000995206       64.5303      0.5702      0.5702      664   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1221.35     0.0146119       152.572      0.7374     0.07374      793   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1223.11    0.00069599       172.415      0.2766      0.2766      922   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1223.73   0.000256523        119.85      0.6513      0.6513     1053   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     856       1224.18   6.18011e-05       92.1899   1.111e-06       0.001     1156  LS failed, Hessian reset \n",
      "     899       1224.58    0.00045966       74.8447       2.041      0.2041     1211   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     918       1224.61   2.21931e-05       43.5372   4.896e-07       0.001     1272  LS failed, Hessian reset \n",
      "     951       1224.62    2.8126e-06       21.4003   1.002e-07       0.001     1348  LS failed, Hessian reset \n",
      "     999       1224.67   0.000805531       32.8901           1           1     1408   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1072       1224.82   1.92455e-05        35.152   7.288e-07       0.001     1564  LS failed, Hessian reset \n",
      "    1099       1224.84   1.93004e-05       23.8794      0.3531      0.3531     1598   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1130       1224.84   4.95235e-07       19.0803      0.2789           1     1638   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.44718\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1174.38     0.0628514       964.383           1           1      126   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1191.66     0.0568545       400.826           1           1      250   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     284       1211.38   6.13426e-05       47.9895   3.862e-07       0.001      404  LS failed, Hessian reset \n",
      "     299       1211.51   0.000267522       48.3243      0.1642           1      426   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1215.05   0.000125025       28.7233           1           1      561   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     486       1215.59   0.000170884       111.014   5.831e-06       0.001      714  LS failed, Hessian reset \n",
      "     499       1215.67    0.00040728       114.421      0.3436      0.3436      728   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     542          1216   6.94224e-05       97.3899   5.565e-07       0.001      822  LS failed, Hessian reset \n",
      "     583       1216.07   2.02352e-05       34.7921   7.133e-07       0.001      925  LS failed, Hessian reset \n",
      "     599       1216.07   8.90488e-05       37.0137           1           1      943   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     608       1216.07   1.36333e-05       29.3672    5.69e-07       0.001     1008  LS failed, Hessian reset \n",
      "     664        1216.1   7.27355e-05       45.0207   2.095e-06       0.001     1123  LS failed, Hessian reset \n",
      "     699       1216.11   0.000120572        28.858      0.4523           1     1170   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     701       1216.11   2.08659e-05       37.5587   7.069e-07       0.001     1214  LS failed, Hessian reset \n",
      "     799       1216.83     0.0482338       143.497       5.258      0.5258     1333   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1217.63   0.000239913       48.2642      0.3899           1     1465   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     975       1217.72   2.60734e-05       41.0072   4.758e-07       0.001     1614  LS failed, Hessian reset \n",
      "     999       1217.79   6.16772e-05       25.8601      0.7018      0.7018     1642   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1061        1217.8   3.73057e-07       30.1912      0.3118           1     1733   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.36144\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1171.62    0.00830067       251.481           1           1      135   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     194       1198.66     0.0001064       123.326   8.622e-07       0.001      296  LS failed, Hessian reset \n",
      "     199        1199.1    0.00718745       383.674           1           1      301   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     267       1205.34   0.000116802       143.493   8.303e-07       0.001      420  LS failed, Hessian reset \n",
      "     299       1207.87    0.00157986       134.878      0.5749      0.5749      457   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     363        1209.4   7.83146e-05       80.5769   1.936e-06       0.001      579  LS failed, Hessian reset \n",
      "     399       1209.72    0.00129424        106.19           1           1      626   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     403       1209.82   4.42184e-05       55.0678   5.968e-07       0.001      670  LS failed, Hessian reset \n",
      "     499       1211.12   4.48413e-05       58.9786   7.785e-07       0.001      844  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     596       1211.65   6.39922e-05       38.3673   3.848e-07       0.001     1013  LS failed, Hessian reset \n",
      "     599       1211.67    0.00138915       41.7745           1           1     1017   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1212.95   9.09369e-05       25.7875       0.766       0.766     1158   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     716       1212.98   7.31545e-05       91.1049     8.1e-07       0.001     1213  LS failed, Hessian reset \n",
      "     778       1213.26   6.80047e-05       41.7213   3.837e-07       0.001     1343  LS failed, Hessian reset \n",
      "     799       1213.45   0.000498753       28.0377           1           1     1373   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1213.68   6.82256e-06       22.0005      0.8257      0.8257     1502   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1214.67    0.00513192       57.6801           1           1     1620   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1082       1215.56   4.37777e-05       40.4213   3.817e-07       0.001     1767  LS failed, Hessian reset \n",
      "    1099       1215.59    2.4488e-05       28.4171       0.641       0.641     1789   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1215.82   8.45099e-06       35.6785     0.05781     0.05781     1924   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1238       1215.83   3.20057e-05       38.3885   9.367e-07       0.001     2013  LS failed, Hessian reset \n",
      "    1251       1215.83   8.60049e-07       23.8874           1           1     2037   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.24576\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1171.16     0.0660729       518.573           1           1      132   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1198.37     0.0212349       82.9434          10           1      265   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     234       1199.63   4.55171e-05       44.4096    5.77e-07       0.001      347  LS failed, Hessian reset \n",
      "     299       1204.59      0.115526       218.965      0.6927           1      435   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     302       1204.73   0.000172649       100.458   4.663e-07       0.001      475  LS failed, Hessian reset \n",
      "     347        1207.1   7.27093e-05       69.6277   2.078e-06       0.001      574  LS failed, Hessian reset \n",
      "     372       1207.46   0.000457801       192.333   1.059e-05       0.001      647  LS failed, Hessian reset \n",
      "     399       1207.81   0.000797109       43.5098      0.4515           1      685   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1212.33    0.00449049       107.004           1           1      814   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1213.88   0.000493031       81.0716      0.6607      0.6607      939   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     655       1214.03   8.84433e-05        71.634   2.806e-06       0.001     1037  LS failed, Hessian reset \n",
      "     699       1214.11   0.000153205       59.1497           1           1     1097   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     795       1215.11    0.00010604       40.2814   3.544e-06       0.001     1240  LS failed, Hessian reset \n",
      "     799       1215.11   6.35364e-05       33.1454      0.8692      0.8692     1244   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     880       1215.31   5.17624e-05       59.3339    1.19e-06       0.001     1398  LS failed, Hessian reset \n",
      "     899       1215.38   2.37265e-05       37.8871       0.603       0.603     1426   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     958       1215.51   5.38142e-05       59.5835   1.534e-06       0.001     1540  LS failed, Hessian reset \n",
      "     990       1215.53      4.28e-05       52.1691   8.383e-07       0.001     1624  LS failed, Hessian reset \n",
      "     999       1215.54    3.5865e-05       27.7742      0.1266      0.8164     1635   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1021       1215.54   8.46659e-06       28.8365   2.469e-07       0.001     1701  LS failed, Hessian reset \n",
      "    1035       1215.54   6.94791e-08       26.4665      0.3096           1     1719   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.10708\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1168.63     0.0263225       209.445      0.4323      0.4323      126   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1187.54      0.008953       411.838      0.3073     0.03073      250   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299        1196.1     0.0236597       267.872          10           1      359   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1201.75   0.000122434       78.4266      0.1101      0.1101      500   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     447       1203.06   4.90375e-05       49.7478   8.398e-07       0.001      625  LS failed, Hessian reset \n",
      "     499       1203.81   0.000505486        38.297      0.1612      0.1612      695   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     532       1205.14   7.88869e-05       77.2035   1.588e-06       0.001      773  LS failed, Hessian reset \n",
      "     599       1205.97   1.68197e-05       35.6335       0.263           1      870   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     653       1208.24   0.000118319       59.9679   4.656e-07       0.001     1016  LS failed, Hessian reset \n",
      "     699       1209.93    0.00240223       75.9484      0.4144           1     1080   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     763       1210.32   3.83061e-05       37.7298   5.642e-07       0.001     1209  LS failed, Hessian reset \n",
      "     785       1210.36   4.80557e-05        59.518   1.071e-06       0.001     1287  LS failed, Hessian reset \n",
      "     799       1210.37   5.76324e-05       27.7558       0.448           1     1306   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1210.56   0.000377552       29.1782           1           1     1430   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     947       1210.63   3.26852e-05       29.9687   9.409e-07       0.001     1539  LS failed, Hessian reset \n",
      "     979       1210.63   3.89672e-06       27.6361    1.17e-07       0.001     1624  LS failed, Hessian reset \n",
      "     999       1210.63   1.84974e-07       26.6212      0.4413      0.9643     1659   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1000       1210.63   1.35645e-07        29.473      0.4262      0.4262     1660   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.0192\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        1174.5     0.0101618       122.253           1           1      131   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1189.45    0.00597409       251.219      0.7929      0.7929      263   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     283       1199.11   5.81015e-05       45.2887   6.405e-07       0.001      415  LS failed, Hessian reset \n",
      "     299       1199.47   0.000381168       84.1752      0.5755      0.5755      433   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1205.68    0.00114836       170.953           1           1      568   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1207.43     0.0113173       76.6845       1.762      0.1762      698   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     548       1208.79   8.15653e-05       40.3958    5.02e-07       0.001      800  LS failed, Hessian reset \n",
      "     599       1208.99   0.000187068       68.7281      0.1859           1      875   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     663       1209.23   5.91531e-05       43.8603   5.497e-07       0.001     1000  LS failed, Hessian reset \n",
      "     699       1209.23   1.02708e-06       28.7813      0.2131           1     1051   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     741       1209.31   6.67773e-05       65.9107   7.227e-07       0.001     1154  LS failed, Hessian reset \n",
      "     799       1209.38   1.17526e-05       34.8156      0.2962      0.9601     1242   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     826       1209.38   3.32845e-05       33.6754    6.91e-07       0.001     1314  LS failed, Hessian reset \n",
      "     854       1209.39   1.14068e-07        23.538      0.3411           1     1349   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.26039\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1187.13    0.00507774       159.319           1           1      133   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1206.01     0.0207803       102.919           1           1      259   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1213.49     0.0168112       223.606           1           1      389   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     317       1214.74   0.000315056       265.197   1.569e-06       0.001      457  LS failed, Hessian reset \n",
      "     365       1217.66   3.67164e-05        39.617   7.009e-07       0.001      554  LS failed, Hessian reset \n",
      "     399       1218.71    0.00223617       91.8179      0.8543      0.8543      600   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     403       1218.82   7.22602e-05       64.1265   5.756e-07       0.001      644  LS failed, Hessian reset \n",
      "     481       1220.48   4.03523e-05       40.3898   6.704e-07       0.001      805  LS failed, Hessian reset \n",
      "     499       1220.59   0.000683975       36.7136           1           1      828   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     550       1220.92   9.10738e-05       57.1147   4.966e-07       0.001      929  LS failed, Hessian reset \n",
      "     569       1221.22   6.23699e-05       35.6057   4.971e-07       0.001      990  LS failed, Hessian reset \n",
      "     599       1221.33   0.000208146       37.7228      0.2905           1     1032   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     617       1221.36   3.96008e-05       38.9833   7.071e-07       0.001     1096  LS failed, Hessian reset \n",
      "     699       1221.42   1.18386e-05       34.5926           1           1     1208   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     703       1221.42   1.83166e-05       39.7194   4.982e-07       0.001     1249  LS failed, Hessian reset \n",
      "     723       1221.42   8.34225e-08       28.4861      0.5684      0.5684     1273   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.28787\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1202.71     0.0501977       279.174           1           1      131   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        1222.7     0.0180422       411.935      0.1809           1      252   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1232.82     0.0277326       247.878           1           1      382   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1237.27   0.000901023       33.5616           1           1      507   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     460       1237.99   0.000313298       140.842   6.526e-06       0.001      629  LS failed, Hessian reset \n",
      "     499       1238.19   0.000492325       49.8467           1           1      681   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     505       1238.26   6.44713e-05       54.5988   5.881e-07       0.001      731  LS failed, Hessian reset \n",
      "     599       1238.91   0.000249317       44.3162      0.7338      0.7338      851   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     617       1238.95   9.52969e-05       43.0235    2.86e-06       0.001      907  LS failed, Hessian reset \n",
      "     632       1238.99   0.000303988       62.9697   8.924e-06       0.001      958  LS failed, Hessian reset \n",
      "     675          1239   1.26883e-07       29.4694           1           1     1025   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.00748\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1213.35     0.0182942       186.707           1           1      130   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     127       1219.07   0.000165673       108.752   2.466e-06       0.001      197  LS failed, Hessian reset \n",
      "     199       1234.84     0.0294247       314.275           1           1      283   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299          1245     0.0105437       147.808           1           1      412   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        1247.7    0.00119341       84.9527      0.7687      0.7687      555   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     430       1248.31   0.000189164       104.826   4.471e-06       0.001      638  LS failed, Hessian reset \n",
      "     499       1248.67   0.000316962       36.7069      0.3516           1      733   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     574        1251.2   5.89379e-05       62.4351   8.687e-07       0.001      911  LS failed, Hessian reset \n",
      "     599       1251.79   0.000373255       33.6962           1           1      941   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     617       1251.95   8.32713e-05       72.6502   6.261e-07       0.001      999  LS failed, Hessian reset \n",
      "     660       1252.21   4.59091e-05       38.8509   5.805e-07       0.001     1110  LS failed, Hessian reset \n",
      "     699       1252.29    5.2422e-05       36.7814           1           1     1167   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     702        1252.3   6.46198e-05        42.301   1.761e-06       0.001     1207  LS failed, Hessian reset \n",
      "     726        1252.3   5.06332e-06       33.0257   1.899e-07       0.001     1276  LS failed, Hessian reset \n",
      "     771       1252.35   4.29575e-05       46.6793   9.269e-07       0.001     1391  LS failed, Hessian reset \n",
      "     799       1252.41   0.000181935       33.0044           1           1     1430   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     853       1252.43   2.55085e-05       34.3021   6.961e-07       0.001     1537  LS failed, Hessian reset \n",
      "     897       1252.43   2.92325e-07       37.1402      0.2751           1     1588   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.96743\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1227.66     0.0271725       114.514       0.332      0.8888      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1252.33    0.00070475       213.561      0.2374           1      243   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     264       1257.04   9.90843e-05        83.718   2.055e-06       0.001      360  LS failed, Hessian reset \n",
      "     299        1258.6    0.00742654       222.598       6.953      0.6953      407   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1260.19   0.000225503       47.8498      0.7572      0.7572      540   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     473       1261.21   4.37508e-05       34.3489   5.592e-07       0.001      668  LS failed, Hessian reset \n",
      "     499       1261.48   4.50757e-05       70.7265      0.1098      0.1098      704   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     585       1261.98   5.09573e-05       53.2021   1.025e-06       0.001      856  LS failed, Hessian reset \n",
      "     599       1262.01   3.99999e-05       39.8798       0.937      0.3385      876   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     635       1262.02    4.7205e-05       42.5762   1.219e-06       0.001      958  LS failed, Hessian reset \n",
      "     661       1262.02   3.51014e-08       39.6783     0.09601     0.09601      996   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.03895\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1228.04     0.0102295       505.537           1           1      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1262.46    0.00197916       82.3216      0.6327      0.6327      249   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299        1269.1   0.000468171       76.6989           1           1      380   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     312       1269.37   6.46223e-05       46.8848    5.62e-07       0.001      429  LS failed, Hessian reset \n",
      "     329       1269.54   0.000295474       125.792   7.576e-06       0.001      489  LS failed, Hessian reset \n",
      "     399        1270.1    0.00133696       63.0688           1           1      575   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     477       1270.63    5.7923e-05       55.7614   6.463e-07       0.001      712  LS failed, Hessian reset \n",
      "     499       1270.97   0.000423706       61.7148           1           1      742   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     547        1271.1   0.000507655       42.6479   1.631e-05       0.001      843  LS failed, Hessian reset \n",
      "     599       1271.13   3.71231e-05       29.8162      0.4695      0.4695      908   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1271.58    0.00051029       42.4383           1           1     1035   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     734       1273.92   0.000117811       32.9816   4.577e-07       0.001     1179  LS failed, Hessian reset \n",
      "     787       1275.22   3.94903e-05       43.7508   9.414e-07       0.001     1302  LS failed, Hessian reset \n",
      "     799       1275.33   0.000713874       37.5092           1           1     1319   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1275.68   3.98737e-05       41.2744   6.433e-07       0.001     1498  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1275.85     5.349e-05       32.5029       1.105       0.209     1630   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1013       1275.85   1.28729e-05       29.5724   3.842e-07       0.001     1688  LS failed, Hessian reset \n",
      "    1033       1275.85   2.87307e-07       25.1365   8.563e-09       0.001     1751  LS failed, Hessian reset \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.97003\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1243.48     0.0125088       404.888      0.5853      0.5853      132   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1273.06    0.00991227       235.595           1           1      257   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     248          1285   9.86187e-05       94.6769   1.093e-06       0.001      362  LS failed, Hessian reset \n",
      "     299       1287.66    0.00354308       176.444      0.3894           1      437   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1292.09    0.00102184       63.8196      0.3562      0.3562      569   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1296.18    0.00235401       66.5446      0.3304           1      697   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1297.13   0.000528017       44.7337           1           1      831   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     626       1297.22   3.36575e-05       38.8577   7.783e-07       0.001      907  LS failed, Hessian reset \n",
      "     699       1297.28   1.60227e-06       33.9963      0.4737      0.4737     1006   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1297.56    0.00351674       49.0421           1           1     1121   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     829       1297.75   0.000121602       101.332   2.631e-06       0.001     1196  LS failed, Hessian reset \n",
      "     899       1298.11    0.00034884       56.1345           1           1     1282   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     931       1298.21   0.000187463       110.847   5.805e-06       0.001     1361  LS failed, Hessian reset \n",
      "     999       1298.22   8.30885e-07       43.6434     0.02009           1     1453   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1010       1298.22   2.78472e-07       34.7257      0.2379           1     1467   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.97278\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1259.94     0.0498409       369.085           1           1      116   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1304.74      0.068697       325.562           1           1      234   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     285       1313.63   4.05503e-05       47.7808   5.724e-07       0.001      385  LS failed, Hessian reset \n",
      "     299       1314.62     0.0220097       155.886           1           1      402   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1318.07    0.00599625        88.731           1           1      545   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1319.66     0.0211607       60.9004           1           1      671   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     589       1323.82   0.000240832       115.917    5.88e-06       0.001      823  LS failed, Hessian reset \n",
      "     599       1323.89   0.000782113       83.7437           1           1      834   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     620       1324.04   3.73938e-05       33.9608   4.703e-07       0.001      902  LS failed, Hessian reset \n",
      "     699       1324.94    0.00150893       53.0308           1           1     1010   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     792       1325.79   8.18955e-05       76.8586   4.722e-07       0.001     1163  LS failed, Hessian reset \n",
      "     799       1325.97    0.00328419       351.583           1           1     1172   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1326.33    0.00086001       40.0096           1           1     1307   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     969       1326.48   0.000134692       105.503   3.904e-06       0.001     1424  LS failed, Hessian reset \n",
      "     999       1326.51   0.000113173        26.907           1           1     1460   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1326.64    0.00229081       49.1074           1           1     1580   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1116       1326.75   3.39729e-05       41.9026   5.774e-07       0.001     1647  LS failed, Hessian reset \n",
      "    1191       1326.93   4.02583e-05       52.3898   1.034e-06       0.001     1794  LS failed, Hessian reset \n",
      "    1199       1326.93   3.07301e-05       32.9111      0.4437      0.4437     1803   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1210       1326.93   9.04221e-06       28.3124   2.914e-07       0.001     1855  LS failed, Hessian reset \n",
      "    1224       1326.93   4.76436e-08       30.0776     0.04746      0.7324     1874   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.98732\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1297.39      0.161259       310.896           1           1      121   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1340.63     0.0495163       313.725           1           1      240   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     281       1348.76   0.000155289       179.067   9.981e-07       0.001      384  LS failed, Hessian reset \n",
      "     299       1350.61    0.00770154       42.5011           1           1      407   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1353.14    0.00216857       189.244       0.276           1      536   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1359.64    0.00207566       52.6213     0.08634      0.9207      670   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1360.35    0.00521724       148.437           1           1      798   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1360.95     0.0156532       73.4522        2.56       0.256      927   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     709       1361.04   5.86672e-05       68.1784   1.291e-06       0.001      981  LS failed, Hessian reset \n",
      "     799       1361.26   0.000223062       36.6965      0.9123      0.9123     1109   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     880       1361.46   2.96661e-05       45.8268   7.006e-07       0.001     1267  LS failed, Hessian reset \n",
      "     899       1361.47   8.47162e-06       25.6743       2.006      0.4631     1294   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1361.58   0.000216069       35.7626        1.86       0.186     1415   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099          1362    0.00855032       112.231      0.3112           1     1538   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1362.62   0.000257815       28.8915      0.6965      0.6965     1666   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1256       1362.66   1.50258e-05        32.608   5.228e-07       0.001     1775  LS failed, Hessian reset \n",
      "    1299       1362.69   8.72457e-06        28.367     0.05429           1     1828   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1313       1362.69   6.55022e-08       26.7463     0.03572           1     1852   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.07075\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1301.13    0.00276228       316.545      0.3301      0.3301      125   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1351.37     0.0167596       445.277      0.9458      0.9458      253   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1370.28    0.00396628       184.879      0.7169      0.7169      374   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1382.57    0.00921133         84.99      0.2443           1      505   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     485       1391.56   3.19504e-05       49.3731   6.002e-07       0.001      650  LS failed, Hessian reset \n",
      "     499          1392    0.00128676       127.035           1           1      667   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     529       1392.76   0.000120912        106.11   2.956e-06       0.001      754  LS failed, Hessian reset \n",
      "     577       1393.16   6.45795e-05       93.9042   6.522e-07       0.001      850  LS failed, Hessian reset \n",
      "     599       1393.26   0.000391427       44.8995      0.1822           1      881   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     607        1393.3   5.35762e-05       67.2976   1.255e-06       0.001      929  LS failed, Hessian reset \n",
      "     621       1393.36   1.64422e-05       26.4326   4.544e-07       0.001      986  LS failed, Hessian reset \n",
      "     660       1393.57   2.78478e-05        39.313   4.193e-07       0.001     1084  LS failed, Hessian reset \n",
      "     699       1393.69   0.000535117        40.256       4.424      0.4424     1134   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     732       1394.74   0.000150954       122.906   2.952e-06       0.001     1215  LS failed, Hessian reset \n",
      "     791       1395.25   5.19629e-05       77.0097   7.637e-07       0.001     1344  LS failed, Hessian reset \n",
      "     799       1395.31   0.000143227       96.6299      0.5344      0.5344     1353   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     835       1395.43   3.09944e-05        28.722   3.342e-07       0.001     1444  LS failed, Hessian reset \n",
      "     899       1395.57   0.000229165       38.7081           1           1     1530   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1396.72    0.00596265       52.7882      0.1901      0.7011     1652   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1398.45    0.00175674        70.004           1           1     1785   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1116       1398.69   4.32064e-05       62.8049   1.158e-06       0.001     1845  LS failed, Hessian reset \n",
      "    1168       1398.76   2.66995e-05        38.046   7.932e-07       0.001     1965  LS failed, Hessian reset \n",
      "    1191       1398.76    3.9379e-07        31.084      0.2761           1     1999   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.992\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1342.17     0.0369124       89.8044      0.4916           1      122   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1390.36    0.00985486       412.696      0.6422      0.6422      247   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1408.69     0.0340379       275.095           1           1      375   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     309       1409.19   6.25483e-05       66.0485   3.604e-07       0.001      431  LS failed, Hessian reset \n",
      "     399       1419.14     0.0017339        240.22      0.7054      0.7054      539   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     432       1420.45   8.34155e-05       99.6392   1.246e-06       0.001      622  LS failed, Hessian reset \n",
      "     499       1422.35       0.01403        459.01      0.3137           1      708   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599          1427     0.0111304       199.331       2.325      0.2325      855   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     605       1427.12   0.000176083        135.91   3.362e-06       0.001      904  LS failed, Hessian reset \n",
      "     624       1427.39   2.93322e-05       36.9087   3.416e-07       0.001      962  LS failed, Hessian reset \n",
      "     699       1427.87    0.00116668       95.6651       4.523           1     1055   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1429.55      0.015892       75.3851      0.4098           1     1190   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     878       1431.68   0.000281233       145.054   7.118e-06       0.001     1329  LS failed, Hessian reset \n",
      "     899       1432.06     0.0064297       118.949           1           1     1353   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     948       1432.69   1.81722e-05       35.1368   5.152e-07       0.001     1467  LS failed, Hessian reset \n",
      "     999       1432.77   7.18461e-06       28.8215      0.5255     0.05255     1541   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1020       1432.78   2.60123e-05       51.0131   9.357e-07       0.001     1611  LS failed, Hessian reset \n",
      "    1051       1432.79   2.33588e-07       26.7217      0.2617        0.87     1654   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.9733\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1344.69    0.00409566       1236.13      0.5461      0.5461      120   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1402.62     0.0718249        549.83      0.1539           1      235   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1421.23     0.0113949       75.5645           1           1      358   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1432.52    0.00646526       76.6042           1           1      477   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1436.18    0.00152839       72.7709      0.5432      0.5432      610   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     516       1436.62   2.81061e-05       41.3284   3.967e-07       0.001      675  LS failed, Hessian reset \n",
      "     599        1437.7    0.00692957       218.804       1.824      0.1824      778   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     641       1438.84   3.65629e-07       126.025   1.326e-05           1      844   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative change in objective function was below tolerance\n",
      "Initial log joint probability = -3.04987\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1369.67     0.0741167        762.36           1           1      119   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1415.24    0.00760273       121.861           1           1      240   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1436.79     0.0143836       332.616        1.59       0.159      361   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1444.08   0.000298923       38.6554           1           1      476   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1447.66    0.00272383        55.592           1           1      598   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1451.07    0.00320605       107.125      0.1269      0.7505      734   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1452.06   0.000129439       194.039      0.2349    0.002349      886   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     751        1452.3   3.27123e-05       40.2823   3.431e-07       0.001      995  LS failed, Hessian reset \n",
      "     799       1452.39    0.00199063       106.913           1           1     1061   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     825       1452.73   0.000222117       157.593   2.745e-06       0.001     1135  LS failed, Hessian reset \n",
      "     899       1453.12    0.00334267       27.3396      0.5399           1     1239   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     901       1453.12   2.15106e-05        37.215    5.53e-07       0.001     1278  LS failed, Hessian reset \n",
      "     947        1453.2   6.36446e-05       100.108   4.719e-07       0.001     1382  LS failed, Hessian reset \n",
      "     999       1453.26   5.83019e-06       22.8472           1           1     1458   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099        1453.9    0.00515021       104.202           1           1     1600   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1111       1454.05   6.72659e-05        90.501   1.543e-06       0.001     1650  LS failed, Hessian reset \n",
      "    1199       1454.35    0.00120111        121.26           1           1     1759   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1204       1454.37   2.84669e-05       47.4064   4.186e-07       0.001     1808  LS failed, Hessian reset \n",
      "    1262       1454.41   1.11698e-05       26.2667   3.724e-07       0.001     1921  LS failed, Hessian reset \n",
      "    1275       1454.41   1.16912e-07        22.795     0.07104           1     1946   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.51324\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1388.16     0.0131999       181.661           1           1      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1432.95      0.012429       358.717           1           1      252   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1448.55      0.048637       277.396           1           1      384   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1452.83   0.000459557       235.758      0.5423      0.5423      514   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1454.24    0.00197264       54.0647           1           1      651   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1455.05    0.00453425       23.1913          10           1      793   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     616       1455.28   4.91567e-05       30.7182   3.233e-07       0.001      869  LS failed, Hessian reset \n",
      "     693       1455.64   4.41808e-05       64.0179   7.684e-07       0.001     1014  LS failed, Hessian reset \n",
      "     699       1455.68   8.20513e-05       48.3182     0.02123           1     1022   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     719        1455.7   5.82582e-05       51.4819   2.145e-06       0.001     1094  LS failed, Hessian reset \n",
      "     742       1455.71   1.70902e-05       26.1771   4.709e-07       0.001     1178  LS failed, Hessian reset \n",
      "     799       1455.81    0.00400498        272.64      0.4244      0.4244     1255   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1456.08   8.19313e-05       50.0225           1           1     1396   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     937        1456.1   2.59993e-05       22.6497   9.305e-07       0.001     1483  LS failed, Hessian reset \n",
      "     999       1456.11   7.76531e-05       26.8523           1           1     1552   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1015       1456.12   6.83445e-05       21.8353   1.599e-06       0.001     1615  LS failed, Hessian reset \n",
      "    1099       1457.42    0.00710543       421.887           1           1     1729   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1148       1458.34   2.83213e-05       42.4951   4.238e-07       0.001     1827  LS failed, Hessian reset \n",
      "    1168       1458.39   0.000204146       35.5485   4.326e-06       0.001     1889  LS failed, Hessian reset \n",
      "    1190       1458.41   4.06377e-05       47.3695   1.049e-06       0.001     1963  LS failed, Hessian reset \n",
      "    1199       1458.41   2.44674e-06       22.7901           1           1     1973   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1206       1458.41   1.66668e-08        23.504    0.006711           1     1987   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.74372\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1392.65    0.00291022       176.636           1           1      126   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1441.25     0.0370156       332.595           1           1      245   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1458.88     0.0118346       291.306           1           1      365   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1464.34    0.00609553       195.754      0.6486      0.6486      490   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     478       1467.26   4.06843e-05        52.637   4.074e-07       0.001      633  LS failed, Hessian reset \n",
      "     499       1467.85   0.000977195       138.063      0.3335           1      663   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1468.82    0.00089658       54.4011           1           1      797   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     616       1468.88   3.92227e-05       57.5111   9.315e-07       0.001      877  LS failed, Hessian reset \n",
      "     699        1469.5   0.000276697       131.322      0.6534      0.6534      994   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1471.74    0.00257688       233.672      0.2347           1     1129   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     802       1471.79   4.89451e-05        38.821    3.27e-07       0.001     1164  LS failed, Hessian reset \n",
      "     853        1472.1    6.0226e-05       92.3049   5.889e-07       0.001     1295  LS failed, Hessian reset \n",
      "     899       1472.26     2.409e-05       30.3265   5.893e-07       0.001     1410  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     940       1472.28    4.0813e-05        61.445    7.26e-07       0.001     1510  LS failed, Hessian reset \n",
      "     997       1472.29   1.14932e-07       30.7649      0.1899           1     1599   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.31604\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1406.79    0.00633554       509.024      0.1784           1      132   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1453.27      0.019476       111.939      0.8636      0.8636      257   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1466.77    0.00419359         83.62           1           1      379   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1472.57      0.133978       148.037           1           1      495   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1475.56   5.70957e-05       27.7963      0.3565           1      628   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1478.45   5.61689e-05       45.4471       0.368           1      763   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     662       1478.95   3.48098e-05       56.8492   6.059e-07       0.001      886  LS failed, Hessian reset \n",
      "     699       1479.16   0.000207265       35.3007           1           1      934   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1480.16    0.00238084       49.4054      0.1897      0.9202     1059   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     870       1481.61      3.76e-05       61.1074   6.174e-07       0.001     1226  LS failed, Hessian reset \n",
      "     899       1482.06   0.000135765       49.9499      0.3213      0.3213     1264   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     910        1482.1   0.000107287       79.8406   3.462e-06       0.001     1310  LS failed, Hessian reset \n",
      "     940       1482.31   3.79004e-05       54.1948   4.114e-07       0.001     1381  LS failed, Hessian reset \n",
      "     980       1482.51   2.65105e-05       43.6816   6.165e-07       0.001     1480  LS failed, Hessian reset \n",
      "     999       1482.52   3.08278e-05       26.2663           1           1     1507   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1027       1482.59   5.46944e-05       37.6709   3.153e-07       0.001     1585  LS failed, Hessian reset \n",
      "    1099       1482.69    0.00655467       43.5688           1           1     1677   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1136       1482.84   3.29689e-05       54.1005    6.15e-07       0.001     1759  LS failed, Hessian reset \n",
      "    1199       1482.89   9.31607e-07       31.5251      0.8145      0.8145     1846   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1256       1482.93   2.93297e-05       46.2173   7.248e-07       0.001     1956  LS failed, Hessian reset \n",
      "    1292       1482.94   5.62167e-05       51.1728   1.507e-06       0.001     2044  LS failed, Hessian reset \n",
      "    1299       1482.94   1.69828e-06        22.182     0.03182           1     2053   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1318       1482.94   1.53338e-07       30.2137      0.1998           1     2086   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.72707\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        1413.3     0.0626609       407.302           1           1      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1452.17    0.00344967       150.616      0.3012           1      243   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1466.92    0.00750225       251.033           1           1      369   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1478.43    0.00310519       259.882           1           1      489   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     492       1480.84   6.75791e-05       95.1686   5.639e-07       0.001      674  LS failed, Hessian reset \n",
      "     499       1481.09     0.0016634       98.8207       0.585       0.585      681   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     550       1481.83   0.000354715       145.025    1.43e-05       0.001      788  LS failed, Hessian reset \n",
      "     599       1482.61    0.00621037       103.463      0.2511      0.8609      848   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1486.79    0.00156281       174.536      0.3596           1      968   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     720       1487.15   4.44289e-05       49.6791    3.84e-07       0.001     1038  LS failed, Hessian reset \n",
      "     799       1487.74     0.0145465        149.91      0.9431      0.9431     1135   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     859       1488.61   4.43453e-05       50.6751   3.741e-07       0.001     1264  LS failed, Hessian reset \n",
      "     899       1488.97    0.00164662       74.3508       1.835      0.1835     1318   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     953       1489.39   0.000100097       97.6778   3.016e-06       0.001     1429  LS failed, Hessian reset \n",
      "     999        1489.5   0.000197437       34.1533      0.5522           1     1494   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1068        1489.6   5.27603e-05        48.199   3.489e-07       0.001     1620  LS failed, Hessian reset \n",
      "    1099       1489.63   4.82633e-05       39.5421      0.8394      0.8394     1658   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1489.86    0.00755696       57.7013           1           1     1783   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1291       1490.55   6.15396e-05       42.0894   3.277e-07       0.001     1956  LS failed, Hessian reset \n",
      "    1299       1490.58   0.000224943       75.4955      0.6113      0.6113     1968   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399       1490.72    3.7827e-05       33.2183           1           1     2101   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1403       1490.73   3.06289e-05       51.9055   6.448e-07       0.001     2144  LS failed, Hessian reset \n",
      "    1432       1490.73   1.24867e-06        31.449   3.553e-08       0.001     2225  LS failed, Hessian reset \n",
      "    1440       1490.73   1.94336e-08       27.3107     0.08475           1     2238   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.14058\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1404.23      0.075531       611.299           1           1      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        1440.4      0.032826       648.071           1           1      257   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     214       1445.28   0.000118447       138.872   1.104e-06       0.001      313  LS failed, Hessian reset \n",
      "     299       1451.42    0.00578129       118.516           1           1      419   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1457.87     0.0114218       272.414      0.3846           1      556   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1461.69    0.00776337       166.097           1           1      682   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1465.03   0.000761227       137.356      0.3925           1      820   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     629       1465.15   7.56968e-05       79.4954   1.853e-06       0.001      907  LS failed, Hessian reset \n",
      "     699       1466.07     0.0059954       69.1801      0.9829      0.9829      997   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1467.43   0.000592854       44.6028      0.5339      0.5339     1125   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1468.05    0.00082531       84.7245           1           1     1243   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1468.79   0.000303217       34.3074           1           1     1374   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1064       1468.85   2.29793e-05       33.3941   7.347e-07       0.001     1505  LS failed, Hessian reset \n",
      "    1099       1468.86   5.54813e-05       32.7396      0.2241           1     1549   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1469.19     0.0120138       209.427      0.9694      0.9694     1668   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1232       1469.58   0.000360162       124.952   1.097e-05       0.001     1744  LS failed, Hessian reset \n",
      "    1299       1469.87   0.000122403       63.4927      0.5358      0.5358     1836   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1316       1469.89   6.67184e-05       63.9122   2.071e-06       0.001     1902  LS failed, Hessian reset \n",
      "    1358       1469.91   5.40169e-05       47.9058   1.563e-06       0.001     1983  LS failed, Hessian reset \n",
      "    1399       1469.92   1.28803e-06       23.7913           1           1     2040   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1403       1469.92    1.6247e-07       30.1636      0.2417           1     2047   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.7073\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1404.79     0.0138341       382.072      0.9019      0.9019      125   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1432.83    0.00829489       314.372      0.7932      0.7932      247   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1450.75      0.017629       240.006           1           1      369   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     352       1452.79   0.000139073       103.497   2.357e-06       0.001      472  LS failed, Hessian reset \n",
      "     399       1453.62    0.00243759       42.2711           1           1      528   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1461.13    0.00274709        215.39       0.219           1      667   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     526       1461.45   0.000485227        71.819   7.358e-06       0.001      738  LS failed, Hessian reset \n",
      "     570       1462.24   0.000103504       83.9887   4.866e-07       0.001      847  LS failed, Hessian reset \n",
      "     599       1462.87   0.000260749        74.866      0.3865      0.3865      884   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1464.71      0.110589       200.689           1           1     1008   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     725       1465.61   0.000953471       114.607     1.5e-05       0.001     1085  LS failed, Hessian reset \n",
      "     799       1467.01    0.00414871       47.6001       2.186      0.2186     1187   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     823       1467.21   5.53518e-05        43.282   4.263e-07       0.001     1258  LS failed, Hessian reset \n",
      "     862       1467.43   3.95681e-05       36.5539   4.536e-07       0.001     1341  LS failed, Hessian reset \n",
      "     899       1467.48   0.000448956       79.2302     0.06108           1     1388   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     950       1467.57   0.000181201       105.277   5.079e-06       0.001     1515  LS failed, Hessian reset \n",
      "     987       1467.59   2.04379e-07        28.845      0.5727      0.1484     1577   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -7.79058\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1416.63     0.0172331       90.7444           1           1      119   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1443.61    0.00215919       113.311      0.5583     0.05583      238   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1453.13     0.0391442       409.631           1           1      366   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     377       1463.01   0.000971736       131.525   2.291e-05       0.001      506  LS failed, Hessian reset \n",
      "     399       1464.05    0.00119109       104.549           1           1      534   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1465.69      0.010045       116.756           1           1      661   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     509       1466.07   6.91298e-05       74.7155   6.544e-07       0.001      713  LS failed, Hessian reset \n",
      "     599       1467.13    0.00418224       64.6311           1           1      838   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     633       1467.18   5.08434e-05       60.5372   7.941e-07       0.001      925  LS failed, Hessian reset \n",
      "     699        1467.2    0.00109498       80.0628      0.4624      0.4624     1008   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     792       1467.46   6.87494e-05       33.2755   1.991e-06       0.001     1153  LS failed, Hessian reset \n",
      "     799       1467.46   5.53562e-06       37.0395      0.4347      0.4347     1164   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     812       1467.46   1.86399e-07       31.6576           1           1     1184   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.60929\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1427.34      0.103013       554.984           1           1      117   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1459.55    0.00562404       183.665       3.542      0.3542      247   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1464.45    0.00747994       288.942           1           1      363   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        1473.7     0.0100454         165.5           1           1      489   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     449       1478.89   0.000158651       84.4132   4.534e-07       0.001      589  LS failed, Hessian reset \n",
      "     499       1480.08   0.000236037       100.876      0.5457      0.5457      649   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599        1483.4    0.00468786       96.5893           1           1      772   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1485.15    0.00627846       128.269       6.897      0.6897      902   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     723       1485.28   5.20639e-05       62.2243   1.105e-06       0.001      973  LS failed, Hessian reset \n",
      "     799       1485.39   2.16591e-05       41.4705      0.2674      0.9404     1066   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     812        1485.4   5.41124e-05       40.9367   1.208e-06       0.001     1120  LS failed, Hessian reset \n",
      "     899       1485.41   1.64453e-05       34.1857           1           1     1230   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1485.94   0.000163686       66.9769      0.5228      0.5228     1369   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1027       1485.99   8.63454e-05       57.2049   2.365e-06       0.001     1439  LS failed, Hessian reset \n",
      "    1068       1485.99   1.09032e-05       43.9544   3.123e-07       0.001     1535  LS failed, Hessian reset \n",
      "    1083          1486   4.13157e-08       33.9602      0.0497           1     1558   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.04248\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1438.36    0.00894979       791.088           1           1      122   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1471.29    0.00481147       86.1184           1           1      248   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1479.17   0.000602743       151.986      0.4023      0.4023      378   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     315       1480.26    6.3181e-05       55.7104   5.863e-07       0.001      451  LS failed, Hessian reset \n",
      "     399       1490.83    0.00154047        54.529           1           1      557   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     452        1493.3   0.000788405       264.031    1.75e-05       0.001      680  LS failed, Hessian reset \n",
      "     499       1495.52   0.000433633       60.8103           1           1      741   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     544       1497.51   5.18782e-05        56.454   6.675e-07       0.001      840  LS failed, Hessian reset \n",
      "     599       1498.62      0.010232       792.182      0.5819      0.5819      913   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     640       1501.61   5.47495e-05       55.3591   4.962e-07       0.001     1007  LS failed, Hessian reset \n",
      "     699       1502.41    0.00159316       40.9111           1           1     1087   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     759       1502.81   0.000453289       72.8139   1.252e-05       0.001     1208  LS failed, Hessian reset \n",
      "     799       1502.84   0.000267441       41.0697           1           1     1257   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     820       1503.31   0.000115499       121.654   1.197e-06       0.001     1335  LS failed, Hessian reset \n",
      "     899       1503.97   0.000384731       49.9791      0.4039           1     1438   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1504.53    0.00506707       84.7979           1           1     1562   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1064       1505.05   0.000107809       57.8653   3.022e-06       0.001     1685  LS failed, Hessian reset \n",
      "    1099       1505.06   5.62602e-07       33.0043      0.7253      0.7253     1733   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1108       1505.06   1.28462e-06       34.8385   4.055e-08       0.001     1785  LS failed, Hessian reset \n",
      "    1122       1505.06   1.47201e-07        30.891      0.3886           1     1808   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.14854\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1455.75     0.0217604       345.398       1.261      0.1261      120   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1490.14     0.0335991       198.684           1           1      247   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     286        1508.3   6.16899e-05       64.2833   6.395e-07       0.001      407  LS failed, Hessian reset \n",
      "     299       1509.95     0.0141155       141.957           1           1      422   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     317       1511.66   9.03782e-05       76.0148   4.904e-07       0.001      492  LS failed, Hessian reset \n",
      "     399       1515.66   0.000167068       98.6609     0.04085           1      612   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     479       1516.57   0.000250973       130.683   4.849e-06       0.001      752  LS failed, Hessian reset \n",
      "     499       1516.77   0.000673939        57.034      0.9424      0.9424      774   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     560       1518.83   0.000148386       172.684   5.984e-07       0.001      890  LS failed, Hessian reset \n",
      "     599       1520.15   0.000205975       51.0339      0.8764      0.8764      950   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     672       1520.87    0.00031121       104.305   1.172e-05       0.001     1076  LS failed, Hessian reset \n",
      "     699       1520.94    0.00029075       30.3367      0.4677      0.4677     1110   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     723       1521.01    6.3854e-05       56.4126   4.563e-07       0.001     1174  LS failed, Hessian reset \n",
      "     799       1521.08    0.00382466       57.4906           1           1     1271   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     814       1521.12   0.000228558       32.5731   5.003e-06       0.001     1331  LS failed, Hessian reset \n",
      "     885        1521.2     7.623e-07       29.5487      0.2108      0.7157     1422   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.37941\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1473.38    0.00839599       484.503     0.08538           1      125   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1512.13    0.00656873       129.647       0.492      0.0492      254   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299        1521.9     0.0219214       434.948      0.9039      0.9039      380   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1525.62    0.00243405       55.5798           1           1      513   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     454       1529.44   6.24336e-05        76.169   8.048e-07       0.001      619  LS failed, Hessian reset \n",
      "     499       1531.08   0.000746694       45.1895           1           1      677   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1531.82   2.33881e-05       36.9943      0.2853           1      815   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699          1533   0.000138248       42.6999           1           1      945   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     703       1533.01   0.000348218       99.8644   7.205e-06       0.001      985  LS failed, Hessian reset \n",
      "     799       1533.23   0.000554953       38.9085           1           1     1109   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     826        1533.3   0.000196023       34.8534   5.404e-06       0.001     1181  LS failed, Hessian reset \n",
      "     836       1533.32   0.000194684       75.7698   4.554e-06       0.001     1228  LS failed, Hessian reset \n",
      "     858       1533.33   5.24263e-05       49.4587   1.453e-06       0.001     1291  LS failed, Hessian reset \n",
      "     877       1533.33   1.53896e-07       34.9875       0.371       0.371     1318   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.81453\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        1485.5    0.00314713       410.172     0.06143      0.3892      136   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1514.86     0.0134943       251.608      0.3351      0.3351      267   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     258       1520.15   0.000166932       147.913   1.376e-06       0.001      372  LS failed, Hessian reset \n",
      "     299        1521.7    0.00170872       62.5666        1.95       0.195      421   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     386       1523.65   0.000377603       222.944   4.602e-06       0.001      568  LS failed, Hessian reset \n",
      "     399       1524.07    0.00175717       42.8655           1           1      581   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1526.14    0.00247406       76.7901      0.8359      0.8359      703   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     583       1528.21   9.94844e-05       99.5336   1.726e-06       0.001      888  LS failed, Hessian reset \n",
      "     599       1530.18    0.00849932       112.978           1           1      908   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     698       1532.43    0.00138954       135.469   3.147e-05       0.001     1066  LS failed, Hessian reset \n",
      "     699       1532.43   0.000172587       111.547      0.2643           1     1068   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     743       1532.69   0.000136163       101.447   4.743e-07       0.001     1167  LS failed, Hessian reset \n",
      "     799       1533.06    0.00010128       41.7183           1           1     1243   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     865       1533.21   9.80069e-05       93.5492   1.678e-06       0.001     1381  LS failed, Hessian reset \n",
      "     899        1533.3   3.72034e-05        38.489       2.956      0.2956     1427   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     911       1533.31   0.000100292       34.9776   2.787e-06       0.001     1479  LS failed, Hessian reset \n",
      "     937       1533.31   3.33819e-07        37.806           1           1     1519   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.77269\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        1480.2     0.0428308       130.141           1           1      120   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1505.24    0.00455438       101.362           1           1      242   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1517.89   0.000491633       86.7589      0.7335      0.7335      375   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     352       1519.51   0.000117141       88.3705   2.645e-06       0.001      491  LS failed, Hessian reset \n",
      "     376       1519.79     8.009e-05        76.465   1.164e-06       0.001      571  LS failed, Hessian reset \n",
      "     399       1519.96   0.000509911       44.9187      0.2313           1      600   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1527.69     0.0461668       241.255           1           1      729   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     593       1529.45   0.000191044       131.542   3.879e-06       0.001      909  LS failed, Hessian reset \n",
      "     599       1529.56   0.000285805       72.7334      0.1171           1      917   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699        1529.8   6.84269e-05       41.7756      0.8504      0.8504     1041   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     723       1529.87   5.45509e-05       57.0727   6.599e-07       0.001     1118  LS failed, Hessian reset \n",
      "     795       1529.94   1.34554e-07       32.8373      0.1621           1     1214   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.41448\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1481.22     0.0677476       274.907           1           1      126   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     174       1493.85   0.000785842       244.787   1.213e-05       0.001      256  LS failed, Hessian reset \n",
      "     199       1496.68     0.0264572       836.224      0.8051      0.8051      284   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     214       1499.36   9.86661e-05       66.7406   7.343e-07       0.001      346  LS failed, Hessian reset \n",
      "     299       1505.28    0.00442428       67.3152           1           1      458   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     371       1506.43   5.42182e-05       48.1175   1.369e-06       0.001      592  LS failed, Hessian reset \n",
      "     399       1506.62    0.00109806       65.9905           1           1      631   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1512.87     0.0135115       97.7397           1           1      755   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     559       1514.24   5.03895e-05       48.0507   8.785e-07       0.001      876  LS failed, Hessian reset \n",
      "     594       1514.44   6.36987e-05       55.5773   1.882e-06       0.001      954  LS failed, Hessian reset \n",
      "     599       1514.44   7.02844e-05       34.2735           1           1      960   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     685       1514.86   6.30399e-05       58.0913   1.206e-06       0.001     1129  LS failed, Hessian reset \n",
      "     699       1515.16   0.000280525       72.1468      0.8515      0.8515     1145   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     762       1515.46   4.34019e-05       44.7744   7.345e-07       0.001     1260  LS failed, Hessian reset \n",
      "     799       1515.47   4.54231e-07       34.2394      0.3287           1     1309   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     803       1515.47   5.56976e-08       32.9551      0.2579           1     1315   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.2344\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1473.67     0.0141912       116.299       3.789      0.3789      134   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1485.86    0.00718509       736.747      0.5701      0.5701      251   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1492.51   0.000674817       52.8055       2.538      0.2538      397   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     310       1492.91   0.000142977       61.0223   7.081e-07       0.001      451  LS failed, Hessian reset \n",
      "     399       1496.14    0.00293008       116.021      0.7221      0.7221      564   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1499.25    0.00318494        170.44           1           1      692   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     565       1501.03   0.000304436       135.843   7.367e-06       0.001      818  LS failed, Hessian reset \n",
      "     599       1501.77    0.00015497       51.2868      0.5527      0.5527      862   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1502.07    0.00176821       60.1616           1           1      981   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     785       1503.74   0.000141095       108.042   7.804e-07       0.001     1125  LS failed, Hessian reset \n",
      "     799       1504.08   0.000269736       50.7489      0.7523      0.7523     1139   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1504.63   1.58388e-05       32.7406           1           1     1261   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     949       1504.67   9.40125e-05       36.0977   2.415e-06       0.001     1365  LS failed, Hessian reset \n",
      "     986       1504.67   1.88063e-07       29.6621           1           1     1417   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.00203\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1471.93     0.0268462       205.567      0.8706      0.8706      134   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1481.36     0.0268008        141.53           1           1      255   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1490.47    0.00384526       51.8609           1           1      388   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1493.19    0.00432654       202.059      0.1541           1      526   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     405       1493.32   7.74095e-05       48.4754   8.602e-07       0.001      573  LS failed, Hessian reset \n",
      "     499       1493.84   0.000610195       42.7328           1           1      693   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     586       1494.82   7.29244e-05       49.4673   9.054e-07       0.001      855  LS failed, Hessian reset \n",
      "     599       1495.01   0.000617787       105.777      0.2963           1      875   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     676       1495.24    3.8301e-08       32.5503      0.1434      0.3493      985   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.82473\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1469.87     0.0106955       301.516      0.1992      0.6033      128   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     180       1475.66   0.000366498       146.953   6.439e-06       0.001      274  LS failed, Hessian reset \n",
      "     199       1478.17    0.00397849       73.7652           1           1      296   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     252       1481.53   0.000169559       106.779    1.81e-06       0.001      423  LS failed, Hessian reset \n",
      "     299          1485    0.00564901       125.127           1           1      482   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     386       1486.69   0.000109167       72.9474    1.45e-06       0.001      640  LS failed, Hessian reset \n",
      "     399       1487.03   0.000261587       69.6523      0.8555      0.8555      656   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     443       1487.65   0.000278634       175.461   1.261e-06       0.001      741  LS failed, Hessian reset \n",
      "     499       1488.53   0.000380624       34.1948      0.8533      0.8533      816   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     545       1489.08   8.49259e-05        52.372   9.984e-07       0.001      921  LS failed, Hessian reset \n",
      "     599       1489.69   0.000158069       37.0436           1           1      989   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     622       1489.76   9.22928e-05       55.8568   9.206e-07       0.001     1063  LS failed, Hessian reset \n",
      "     699       1489.95     0.0100988       48.8794           1           1     1154   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     718       1490.49   0.000184297       47.1733   7.274e-07       0.001     1230  LS failed, Hessian reset \n",
      "     795       1491.38   0.000202133       98.6535       5e-06       0.001     1380  LS failed, Hessian reset \n",
      "     799       1491.39   8.55098e-05       62.3205      0.9234      0.9234     1384   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     840       1491.43   7.15038e-08       35.2296      0.2843      0.2843     1438   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.62834\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1467.59     0.0310975       264.621           1           1      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1480.35    0.00728885       125.638      0.6784           1      254   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299        1485.1    0.00624255       135.527      0.5158           1      385   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        1486.4    0.00260751       42.2128           1           1      517   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     461       1488.63   0.000154039       93.9775   1.161e-06       0.001      643  LS failed, Hessian reset \n",
      "     499       1488.97   0.000278527        38.572         0.3           1      693   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1489.29     0.0256263       171.229      0.3308           1      817   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     615        1489.7   7.15803e-05       46.2746   1.185e-06       0.001      890  LS failed, Hessian reset \n",
      "     692       1490.74   0.000133711       83.7403   2.881e-06       0.001     1044  LS failed, Hessian reset \n",
      "     699       1490.75   0.000190546       57.5315           1           1     1051   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     758        1490.8    7.5431e-08       37.4108      0.2853      0.2853     1128   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.79963\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1471.33     0.0346592       125.025           1           1      135   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1479.07     0.0121376       189.578      0.9858      0.9858      256   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     256       1481.01   7.31874e-05       35.0903   9.814e-07       0.001      372  LS failed, Hessian reset \n",
      "     299       1481.91    0.00115582       41.4032      0.4962      0.4962      435   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1483.83   0.000666917       107.169      0.4151           1      572   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499        1486.3    0.00150419       65.8266           1           1      692   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     508       1486.56   0.000150438       94.2638   1.484e-06       0.001      734  LS failed, Hessian reset \n",
      "     579       1488.01   8.38586e-05       39.2623   8.765e-07       0.001      855  LS failed, Hessian reset \n",
      "     599       1488.06   2.08846e-05       33.5881      0.2893      0.2893      884   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1488.46   0.000561678       44.2278      0.6671      0.6671     1014   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1489.03    0.00508353       58.6598      0.6768      0.6768     1130   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1490.41     0.0132451       92.4407      0.2991           1     1250   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999        1491.1    0.00082013        45.931           1           1     1376   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1082       1491.82   6.32755e-05       44.4242   1.058e-06       0.001     1521  LS failed, Hessian reset \n",
      "    1099       1491.83   1.27542e-05       31.9226      0.4734      0.4734     1541   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1108       1491.83   1.55106e-05       32.0512   3.752e-07       0.001     1587  LS failed, Hessian reset \n",
      "    1162       1491.84   0.000130439        47.148     4.1e-06       0.001     1705  LS failed, Hessian reset \n",
      "    1199       1491.84    2.7338e-07       32.6592      0.4598      0.4598     1759   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1207       1491.84   3.46508e-07        32.213           1           1     1770   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.11915\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1477.27    0.00401314       209.036      0.1964      0.1964      118   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1490.38    0.00563789        63.554      0.4296      0.4296      247   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     245        1492.8   0.000353131       115.788   7.883e-06       0.001      346  LS failed, Hessian reset \n",
      "     274       1493.03   0.000125692       75.8635    1.85e-06       0.001      423  LS failed, Hessian reset \n",
      "     299       1493.12   0.000525146       64.2439           1           1      454   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     374       1494.43   0.000132889       68.3297   9.844e-07       0.001      596  LS failed, Hessian reset \n",
      "     399       1494.95   0.000269072       42.7828           1           1      629   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     424       1494.97   0.000149697       95.8662   2.859e-06       0.001      693  LS failed, Hessian reset \n",
      "     499        1495.2   4.78805e-05       41.3902      0.2584      0.2584      806   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     520       1495.23    0.00012335       37.2096   3.857e-06       0.001      868  LS failed, Hessian reset \n",
      "     599       1495.27   0.000689593       38.1029      0.8232      0.8232      981   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699        1498.7   0.000851708       85.2218      0.3916           1     1099   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     733       1499.03   6.84141e-05       40.1499    9.89e-07       0.001     1184  LS failed, Hessian reset \n",
      "     799       1499.33   0.000955202       75.4963      0.3733      0.5456     1265   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     814        1499.4   9.14578e-05       44.2962   8.532e-07       0.001     1320  LS failed, Hessian reset \n",
      "     845       1499.42    5.8513e-06        35.573   1.935e-07       0.001     1399  LS failed, Hessian reset \n",
      "     872       1499.42   9.56523e-07       28.3324           1           1     1432   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.49983\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1496.04     0.0198433       127.674           1           1      131   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        1510.6   0.000167825       108.407   1.984e-06       0.001      316  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299          1513   8.13181e-05       52.5203   1.347e-06       0.001      472  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     353       1513.82   0.000105592       35.4384   8.072e-07       0.001      581  LS failed, Hessian reset \n",
      "     399       1514.23   0.000355466       56.7175      0.4971           1      639   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     444       1514.35   8.39194e-05       52.8664   1.155e-06       0.001      732  LS failed, Hessian reset \n",
      "     499        1514.4   4.17513e-06       36.7704      0.6324      0.6324      807   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     591       1517.12    7.0766e-05       44.9558   1.018e-06       0.001     1004  LS failed, Hessian reset \n",
      "     599       1517.26   0.000511783       93.3548      0.4054      0.4054     1014   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1518.54   4.28206e-05       40.0801      0.3443      0.3443     1136   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     713       1518.65   8.62737e-05       57.0538   1.521e-06       0.001     1192  LS failed, Hessian reset \n",
      "     797       1518.88   2.32391e-07       29.0132      0.6425      0.6425     1306   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.79979\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1517.29     0.0059434       179.891      0.9896      0.9896      138   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1526.38    0.00105853       52.2271      0.4987      0.4987      252   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1532.59    0.00318989       32.2467           1           1      392   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     314       1532.87   7.57081e-05       51.0658   1.249e-06       0.001      458  LS failed, Hessian reset \n",
      "     366       1533.52   9.84368e-05       50.5874   9.234e-07       0.001      557  LS failed, Hessian reset \n",
      "     399       1533.77    0.00309566       55.5796           1           1      597   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1536.84    0.00108661       67.2881           1           1      714   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     523       1537.49    0.00011663       46.4692    7.85e-07       0.001      793  LS failed, Hessian reset \n",
      "     599       1537.98    0.00142969       146.379           1           1      889   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     641       1538.46   0.000751199       158.717   2.258e-05       0.001      973  LS failed, Hessian reset \n",
      "     699       1538.54   2.02721e-06       35.9008      0.5131      0.5131     1048   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799        1538.6    0.00236219       54.1379           1           1     1176   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1538.73    0.00195539       43.9461           1           1     1305   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1538.77   2.58059e-07       27.9772      0.3524      0.3524     1426   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1005       1538.77    1.8688e-07       28.1121           1           1     1438   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.84202\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1532.42      0.118326       334.524           1           1      129   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1546.06    0.00177466       92.8986      0.2879           1      268   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1549.44    0.00748124         95.44           1           1      410   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1555.54    0.00177331       124.195       0.323           1      536   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1557.96    0.00167775        55.718      0.4862           1      689   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     594       1558.74    8.5906e-05       47.9295   8.241e-07       0.001      857  LS failed, Hessian reset \n",
      "     599       1559.15    0.00347201       276.444           1           1      866   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     631       1559.39   0.000175213        95.847   3.997e-06       0.001      940  LS failed, Hessian reset \n",
      "     699       1559.59   1.72297e-05       27.9367      0.7743      0.7743     1028   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     703       1559.59   2.45243e-05        26.649   6.279e-07       0.001     1068  LS failed, Hessian reset \n",
      "     742       1559.59   1.70608e-07       29.4652      0.6722      0.6722     1113   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.95635\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1555.85    0.00589029       113.188           1           1      130   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        1568.8    0.00634734       115.924           1           1      252   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1573.87   0.000971883       113.651           1           1      377   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1577.78    0.00221704       54.7851      0.6017      0.6017      513   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1582.28    0.00176456       36.9372           1           1      643   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1582.92   0.000614421       44.9508           1           1      770   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     668       1583.53   5.32232e-05       44.8431   1.223e-06       0.001      945  LS failed, Hessian reset \n",
      "     699       1583.79   8.88448e-05       50.4058      0.3402      0.3402      986   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     791       1584.03   6.28833e-08       32.7917     0.04922      0.2602     1101   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.62084\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1561.16    0.00658477        362.97      0.1863           1      120   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1576.25    0.00158376       85.1477      0.2763      0.2763      246   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     290       1580.74    0.00011135        81.287    1.79e-06       0.001      398  LS failed, Hessian reset \n",
      "     299        1581.7    0.00296004        61.801           1           1      410   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1585.33    0.00661741       352.333      0.6381      0.6381      557   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1587.14    0.00288801       197.124      0.1782           1      698   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599          1590    0.00190276        61.291     0.06853           1      826   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     622       1590.63     0.0001402       102.377   1.661e-06       0.001      905  LS failed, Hessian reset \n",
      "     699       1591.43   0.000174493        62.504           1           1      999   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1592.27    0.00120529       42.7619      0.1484           1     1126   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     829       1592.33   0.000150765       60.3963   3.468e-06       0.001     1200  LS failed, Hessian reset \n",
      "     870       1592.34   1.59059e-07       32.0459      0.0632           1     1259   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.80106\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1569.82     0.0107984       357.535      0.1172           1      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1588.47    0.00368525       152.609      0.1384      0.4056      258   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     297       1591.92   0.000132311       84.0315   3.126e-06       0.001      422  LS failed, Hessian reset \n",
      "     299       1592.11     0.0116618       119.879           1           1      425   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     393       1595.13   0.000105008       66.4349   2.277e-06       0.001      584  LS failed, Hessian reset \n",
      "     399       1595.35    0.00225782       101.158      0.2653           1      592   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     464       1595.87    4.8824e-05       38.0497   9.152e-07       0.001      722  LS failed, Hessian reset \n",
      "     499       1596.04     0.0276397       350.737           1           1      764   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     523       1598.57   9.51575e-05        52.442    6.48e-07       0.001      851  LS failed, Hessian reset \n",
      "     599       1600.31    0.00018561       45.5178           1           1      952   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1600.93      0.002061       40.8097           1           1     1073   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1601.05   1.85315e-06       31.8129      0.9438      0.9438     1198   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     887       1601.26   9.09059e-05       56.2184   6.315e-07       0.001     1349  LS failed, Hessian reset \n",
      "     899       1601.51    0.00116216       128.626      0.1768           1     1364   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     930       1601.59   8.12071e-05       60.8096   2.053e-06       0.001     1446  LS failed, Hessian reset \n",
      "     958        1601.6   2.13379e-05       31.5632   6.734e-07       0.001     1522  LS failed, Hessian reset \n",
      "     982        1601.6   6.35268e-07       32.0003   2.006e-08       0.001     1600  LS failed, Hessian reset \n",
      "     985        1601.6   1.99788e-07       27.0637      0.3394           1     1604   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.29042\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        1578.7     0.0715763       274.707        2.31       0.231      135   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199          1594    0.00249655       99.9737      0.3447      0.3447      266   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1604.13    0.00146854        219.89      0.0822      0.9881      405   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     390       1612.86   0.000102795       70.5666   6.244e-07       0.001      573  LS failed, Hessian reset \n",
      "     399       1613.99    0.00153439       91.3815      0.8868      0.8868      584   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     434       1615.14   6.28876e-05       51.1383   2.005e-06       0.001      671  LS failed, Hessian reset \n",
      "     499       1615.84   0.000132498       29.5652           1           1      757   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1617.07    0.00234153       137.477      0.4571           1      890   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     608       1618.82   0.000310883       258.067   6.765e-07       0.001      936  LS failed, Hessian reset \n",
      "     699       1620.95    0.00146046       37.1115      0.2495           1     1062   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     717       1621.09   0.000154976       131.987   7.132e-07       0.001     1136  LS failed, Hessian reset \n",
      "     769       1621.24   4.83022e-05       43.0589   6.221e-07       0.001     1249  LS failed, Hessian reset \n",
      "     799       1621.25   2.19181e-06       29.0655      0.3336           1     1292   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     818       1621.25   1.62017e-07       29.3398      0.2791      0.2791     1321   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.9633\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1581.76      0.122741       190.232           1           1      123   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1605.22    0.00260797       285.352      0.5232      0.5232      244   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1612.13     0.0223149       489.378       0.576       0.576      375   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1627.53    0.00267968        87.802           1           1      503   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     462       1628.96   8.08738e-05        77.979   8.591e-07       0.001      626  LS failed, Hessian reset \n",
      "     499        1629.4   0.000128644       49.8644           1           1      678   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     509        1629.5   0.000325532       147.181   7.952e-06       0.001      731  LS failed, Hessian reset \n",
      "     599       1631.84     0.0113844       50.6943           1           1      840   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     610       1632.09   0.000149606       119.727   1.581e-06       0.001      918  LS failed, Hessian reset \n",
      "     699       1633.49    0.00431034       224.268           1           1     1019   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     750       1634.09   5.18926e-05       49.2762    6.95e-07       0.001     1131  LS failed, Hessian reset \n",
      "     799       1634.22   0.000732959       47.7743      0.2033      0.3761     1200   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     800       1634.22   4.92256e-05       52.3337    1.03e-06       0.001     1246  LS failed, Hessian reset \n",
      "     899       1634.28   2.02288e-06       33.1765           1           1     1372   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     933       1634.44   4.73321e-05       51.9324   1.054e-06       0.001     1454  LS failed, Hessian reset \n",
      "     999       1634.49   1.22347e-06       31.8645      0.4186      0.4186     1540   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1008       1634.49   1.73442e-07       33.9045      0.2151           1     1551   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.9456\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1592.26     0.0115901       107.739           1           1      117   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1618.86    0.00248376        189.77      0.4727     0.04727      247   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299        1626.4    0.00299662       80.6613      0.1671      0.1671      379   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     330       1627.72   0.000128352       82.4006   5.953e-07       0.001      456  LS failed, Hessian reset \n",
      "     388       1630.62   0.000250966       124.547   5.931e-06       0.001      568  LS failed, Hessian reset \n",
      "     399       1630.75    0.00225816        48.859      0.5964           1      582   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     446       1631.28   7.45594e-05       67.6592   8.555e-07       0.001      680  LS failed, Hessian reset \n",
      "     499       1631.81     0.0611712       711.708           1           1      748   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1634.46   0.000124182       28.8686      0.5324      0.5324      884   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1636.67   0.000383805       51.4188      0.8569      0.8569     1004   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1637.22   0.000610313       39.5423           1           1     1135   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1638.61     0.0036421       136.595           1           1     1261   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     916       1638.89   4.73003e-05       36.9967   5.931e-07       0.001     1331  LS failed, Hessian reset \n",
      "     999        1639.3   4.62901e-05       34.2106           1           1     1440   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1008        1639.3   4.87577e-05       48.9574   1.162e-06       0.001     1484  LS failed, Hessian reset \n",
      "    1037       1639.31   2.30227e-07       39.9741      0.9351      0.9351     1522   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.52812\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1589.45    0.00286785       164.213      0.0546           1      131   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        1614.4     0.0155147       372.836      0.3359           1      271   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299        1623.3     0.0115707       123.418           1           1      403   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1626.49   0.000200713       67.2654           1           1      527   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     481       1626.66   0.000238202       37.0895   5.442e-06       0.001      656  LS failed, Hessian reset \n",
      "     499       1626.66   3.13708e-06       31.4402      0.2949           1      681   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     523       1626.66   1.02615e-07       29.1738      0.3226           1      717   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.23665\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1587.56     0.0136253       206.514           1           1      118   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1608.23     0.0197567       141.147      0.4395           1      244   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     256       1616.67   0.000220951        39.859   5.613e-07       0.001      349  LS failed, Hessian reset \n",
      "     299       1618.83    0.00553859       76.0724           1           1      404   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     368       1622.83   7.13889e-05       45.1314   6.393e-07       0.001      541  LS failed, Hessian reset \n",
      "     399       1624.38    0.00255261       160.507       0.123           1      581   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     450       1625.56   0.000114008       90.4017   1.989e-06       0.001      686  LS failed, Hessian reset \n",
      "     499          1626    0.00125708       120.492           1           1      744   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1628.45   0.000650659       64.0312           1           1      870   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1628.91    0.00110624       40.7438           1           1      999   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1629.84   0.000292186       80.3525     0.06052           1     1132   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     891        1631.3    5.7257e-05        43.549   6.594e-07       0.001     1296  LS failed, Hessian reset \n",
      "     899       1631.36     0.0027927       45.8468      0.2543           1     1306   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     982       1631.67   5.38109e-05       47.1303   9.316e-07       0.001     1471  LS failed, Hessian reset \n",
      "     999       1631.68    6.8127e-06       27.7937       1.592      0.1592     1496   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1022       1631.69   1.24596e-05       32.3652   3.421e-07       0.001     1560  LS failed, Hessian reset \n",
      "    1039       1631.69   4.30192e-07       31.1025           1           1     1582   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.76301\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1575.41    0.00601644       130.284           1           1      125   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1599.98    0.00960389       287.618           1           1      243   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1607.63    0.00650176       260.196      0.1473           1      374   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     389       1617.21   0.000122871       83.9596   6.739e-07       0.001      529  LS failed, Hessian reset \n",
      "     399        1618.2    0.00636608       67.4705           1           1      540   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1620.28   0.000404704        48.144           1           1      678   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1621.04   3.52529e-05       32.3978           1           1      818   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1621.38    0.00288458       67.7592           1           1      942   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1621.83   0.000432585       49.0291      0.7508      0.7508     1067   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     835       1622.83   0.000326039       126.508   6.034e-07       0.001     1206  LS failed, Hessian reset \n",
      "     899       1623.99    0.00119638       35.2841      0.6405      0.6405     1286   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     954        1624.1   0.000547803       57.9919   1.446e-05       0.001     1389  LS failed, Hessian reset \n",
      "     988       1624.12   3.63758e-05       45.7503   9.561e-07       0.001     1481  LS failed, Hessian reset \n",
      "     999       1624.12   1.03163e-06       24.3586      0.8462      0.8462     1494   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1011       1624.12   1.67974e-09       34.3456   0.0004267     0.09609     1517   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "Initial log joint probability = -6.04624\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1580.43      0.030092       881.744      0.6791     0.06791      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     166       1601.24   0.000181255        119.78   2.292e-06       0.001      258  LS failed, Hessian reset \n",
      "     199       1605.68    0.00512913        205.66      0.1744           1      297   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     251       1609.59   8.46277e-05        70.651   1.079e-06       0.001      399  LS failed, Hessian reset \n",
      "     299       1611.33     0.0644091       86.5209           1           1      457   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1616.23     0.0153043       175.727      0.4943           1      595   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1617.82    0.00249711       168.786           1           1      729   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1619.98    0.00209206       38.0103           1           1      850   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1621.72    0.00508325       54.1256      0.9088      0.9088      977   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     707       1621.95   7.47307e-05       62.1886   7.703e-07       0.001     1047  LS failed, Hessian reset \n",
      "     799       1623.45   0.000348988       39.3408       2.974      0.2974     1171   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1623.55   0.000523357       33.1615           1           1     1291   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     932       1623.55   7.76316e-08       27.3211      0.2747           1     1337   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.3403\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1589.28     0.0864833       693.516           1           1      142   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1605.34     0.0175236       289.653           1           1      263   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1617.11    0.00904615       341.738       0.121       0.121      384   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     388        1621.4    5.9551e-05       41.7224   6.944e-07       0.001      540  LS failed, Hessian reset \n",
      "     399       1621.76     0.0011538       44.4715           1           1      553   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1623.77    0.00274508       91.3833       0.427      0.0427      686   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1627.11     0.0320417       48.4879           1           1      809   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     660       1630.55   5.50254e-05       30.8148   5.374e-07       0.001      928  LS failed, Hessian reset \n",
      "     699       1631.11    0.00835871       95.9705           1           1      978   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     701       1631.15   0.000107808       97.7108   7.571e-07       0.001     1015  LS failed, Hessian reset \n",
      "     799       1632.74     0.0208789       192.503           1           1     1138   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     885        1634.1   6.33198e-05        45.569   5.633e-07       0.001     1309  LS failed, Hessian reset \n",
      "     899       1634.27   0.000527207       124.835           1           1     1327   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1634.96   0.000438477       28.7606           1           1     1455   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1635.32   2.67023e-05       35.6075           1           1     1580   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1150       1635.35   1.94559e-07       34.2591           1           1     1645   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.77804\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99          1578     0.0552097       498.624           1           1      128   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1609.28     0.0488818         426.1           1           1      247   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1624.91     0.0283007       163.179           1           1      361   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1634.17    0.00407511       119.247           1           1      484   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     496       1639.13   0.000254188       240.279    6.62e-07       0.001      649  LS failed, Hessian reset \n",
      "     499       1639.32    0.00255269       158.814          10           1      653   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     594       1641.82    0.00015497       82.0324   4.576e-06       0.001      818  LS failed, Hessian reset \n",
      "     599       1641.83   0.000316894       37.6122           1           1      823   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     629       1641.99   6.58039e-05       55.3985   5.551e-07       0.001      898  LS failed, Hessian reset \n",
      "     699        1643.2    0.00115354       62.4727      0.8311      0.8311      993   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1646.59     0.0121373        174.25      0.5618           1     1117   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     810       1646.77    0.00159307       222.307   3.997e-05       0.001     1175  LS failed, Hessian reset \n",
      "     837       1647.08   3.48901e-05       39.6425   9.673e-07       0.001     1252  LS failed, Hessian reset \n",
      "     899       1647.28    0.00370423       75.1649       2.009      0.2009     1334   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     906        1647.3     3.784e-05       49.2375    7.48e-07       0.001     1381  LS failed, Hessian reset \n",
      "     999       1649.33     0.0250266       82.9166           1           1     1488   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1652.38    0.00408871       58.6913       0.346           1     1616   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1107       1652.51   4.80316e-05       55.5977   5.484e-07       0.001     1670  LS failed, Hessian reset \n",
      "    1171       1652.72   3.50444e-05       34.7371   8.163e-07       0.001     1796  LS failed, Hessian reset \n",
      "    1199       1652.72   1.02002e-07       36.5501      0.2945           1     1838   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.84427\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1596.24     0.0355446       192.923           1           1      126   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1640.82    0.00546264       969.194           1           1      250   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1658.47    0.00992458       125.593      0.8659      0.8659      376   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     304       1658.66   0.000100168       64.7733   4.045e-07       0.001      430  LS failed, Hessian reset \n",
      "     399       1666.08    0.00882896       448.958           1           1      549   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1669.38   0.000631547       207.602      0.2792     0.02792      676   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     506       1670.09   5.43319e-05        68.715   8.075e-07       0.001      731  LS failed, Hessian reset \n",
      "     518       1670.88   3.93654e-05       47.1245   5.345e-07       0.001      794  LS failed, Hessian reset \n",
      "     599       1672.12      0.030349       109.374          10           1      901   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     695       1675.74   0.000659407       90.4576   6.723e-06       0.001     1053  LS failed, Hessian reset \n",
      "     699       1675.89    0.00014974       57.9935      0.9149      0.9149     1057   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1677.47     0.0049393       81.5809           1           1     1186   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1677.93   0.000627637       45.1028       4.234           1     1317   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1678.87      0.013086       85.0845           1           1     1441   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1681.52    0.00142642       177.715           1           1     1574   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1682.25   0.000464215       61.0188           1           1     1706   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1245       1682.32   5.17461e-05       68.6372   8.549e-07       0.001     1803  LS failed, Hessian reset \n",
      "    1275       1682.33   1.90794e-07       29.5452      0.4962      0.4962     1844   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.64839\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1595.99     0.0427892       512.731           1           1      126   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1618.73     0.0163583       358.328      0.1218           1      253   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1647.43     0.0277408        242.95      0.1039           1      383   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1670.98   0.000973315       59.0998           1           1      512   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1678.52    0.00166475       164.719           1           1      649   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1682.43   0.000608974       69.7998           1           1      782   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1683.75   0.000401068       68.7158      0.1356           1      909   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     760       1684.66   4.14546e-05       55.4051   5.634e-07       0.001     1027  LS failed, Hessian reset \n",
      "     799       1685.33    0.00190957       68.9664      0.6134      0.6134     1076   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     865       1685.46   3.28522e-05       43.7255   4.331e-07       0.001     1213  LS failed, Hessian reset \n",
      "     899       1685.47   0.000184276       43.1481           1           1     1256   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1686.77    0.00322185       178.898      0.4753           1     1376   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099        1688.4   0.000487186       46.6897      0.4533      0.4533     1500   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1689.92     0.0096211       135.058           1           1     1631   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299        1690.2    0.00112956       46.3126           1           1     1761   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1397       1690.29   3.79063e-05       31.7724   1.003e-06       0.001     1921  LS failed, Hessian reset \n",
      "    1399       1690.29    2.9116e-05       32.6965           1           1     1923   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1424       1690.29   1.18414e-07       33.2534      0.6282      0.6282     1961   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.60656\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1621.91    0.00454471       113.259      0.1196      0.8313      126   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        1664.8     0.0067226       200.224           1           1      245   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1685.03     0.0148505       276.124      0.6593      0.6593      359   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1702.67    0.00320631        68.457      0.8622      0.8622      492   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     496       1707.93   0.000493409       218.979   6.457e-06       0.001      673  LS failed, Hessian reset \n",
      "     499       1708.02    0.00125773       121.996           1           1      677   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     557        1709.2   7.24312e-05       97.3522    4.41e-07       0.001      788  LS failed, Hessian reset \n",
      "     599        1710.2    0.00180589       52.2566      0.3749      0.3749      842   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     671       1714.67   0.000138283       172.518   3.877e-07       0.001      974  LS failed, Hessian reset \n",
      "     699       1716.71    0.00181257       124.216       0.639       0.639     1008   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1718.43     0.0329166       144.467      0.2832           1     1142   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     851       1720.72   0.000138993       218.918   6.115e-07       0.001     1244  LS failed, Hessian reset \n",
      "     899       1722.17    0.00375435       55.3446           1           1     1300   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1722.78    0.00153535       44.5754           1           1     1428   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099        1723.2   7.87816e-06       31.3538       0.525       0.525     1550   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1723.67    0.00980436       90.8326           1           1     1668   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1232       1723.87   3.18085e-05       38.2198    3.22e-07       0.001     1748  LS failed, Hessian reset \n",
      "    1299       1723.93    7.7335e-05       34.0872           1           1     1842   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399          1724   4.95197e-05       34.1684      0.4463      0.4463     1964   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1460       1724.01   9.61152e-08       34.2921     0.08916           1     2043   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.32555\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1636.31     0.0329615       119.381           1           1      152   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1681.34    0.00541016        192.43           1           1      271   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1710.41     0.0147909       125.655           1           1      396   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1736.53     0.0551848       681.951           1           1      520   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1744.16    0.00324356       604.954      0.2931           1      652   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1746.16   0.000278652       64.6512      0.2724      0.2724      773   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1746.47     0.0011205       35.7147           1           1      911   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     706       1746.49   0.000108387       98.0774   3.654e-06       0.001      963  LS failed, Hessian reset \n",
      "     799       1746.75    0.00100369        68.521      0.9099      0.9099     1075   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1747.12   0.000195224        33.344           1           1     1190   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     930       1747.13   3.05846e-05       51.3831   6.436e-07       0.001     1271  LS failed, Hessian reset \n",
      "     959       1747.14   1.60092e-07         34.76           1           1     1312   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -7.90412\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1666.74      0.137314       2172.27           1           1      131   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1707.01    0.00698271       1513.33      0.6932      0.6932      263   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     218       1711.49   4.29827e-05       62.3866   6.255e-07       0.001      324  LS failed, Hessian reset \n",
      "     299       1716.33   0.000768748       58.2586      0.8567      0.8567      429   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1721.04    0.00438886       204.952           1           1      558   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1723.82   0.000223887       52.7121           1           1      683   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1725.06   0.000435198       65.7952      0.7274      0.7274      811   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     673       1726.87   4.12975e-05        55.926   4.444e-07       0.001      943  LS failed, Hessian reset \n",
      "     699       1726.96   6.87517e-05       52.1856           1           1      981   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     777       1727.46   3.28475e-05       43.2022   4.113e-07       0.001     1115  LS failed, Hessian reset \n",
      "     799       1727.48   0.000213576       58.5598      0.7304      0.7304     1143   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1727.72    0.00358829       39.6345      0.4734           1     1273   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1728.41    0.00676061        47.041           1           1     1400   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1069       1728.54    2.6452e-07       32.1116      0.2957           1     1504   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.02405\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1658.86     0.0077611       242.009           1           1      120   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1713.35    0.00610157       207.485      0.4587           1      245   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1725.73    0.00360723       90.9059           1           1      367   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1729.24   0.000541234       92.6238           1           1      493   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     458       1730.17   5.14004e-05       48.6374   3.914e-07       0.001      606  LS failed, Hessian reset \n",
      "     499       1730.63    0.00122779       75.1807      0.3508           1      661   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     538       1730.79   0.000129784       130.412    1.58e-06       0.001      761  LS failed, Hessian reset \n",
      "     599       1730.92   2.50509e-05       37.4036      0.5927      0.5927      837   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     624       1731.07   8.02913e-05       61.4874   3.624e-07       0.001      903  LS failed, Hessian reset \n",
      "     699       1731.26   1.18007e-05       35.6792           1           1     1005   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1731.48    0.00191984       55.3283      0.8146      0.8146     1124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1731.85   0.000586348       58.7155           1           1     1255   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     996       1731.96    5.8022e-06       37.4326   1.592e-07       0.001     1448  LS failed, Hessian reset \n",
      "     999       1731.96   1.32472e-06       30.0722      0.3912      0.3912     1452   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1014       1731.96   1.60166e-07       35.1604      0.6948      0.1717     1476   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.21548\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1638.88     0.0236649       154.361           1           1      122   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1708.79      0.178593       358.363      0.9309     0.09309      239   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1735.03    0.00115673       91.4984           1           1      373   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     338       1736.86   4.26766e-05       65.3405   6.254e-07       0.001      460  LS failed, Hessian reset \n",
      "     399       1742.65    0.00409506       187.284           1           1      535   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     490       1749.09   0.000201775       229.326   3.999e-07       0.001      677  LS failed, Hessian reset \n",
      "     499       1749.96    0.00104823       125.166           1           1      686   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     553       1752.89   3.53814e-05       38.8134   3.719e-07       0.001      801  LS failed, Hessian reset \n",
      "     599       1753.88    0.00103619       110.218      0.3214      0.3214      857   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1756.81    0.00308338       99.3836      0.4165      0.4165      991   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1758.98     0.0023938       175.283           1           1     1113   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1760.68     0.0122442        80.689      0.1842           1     1243   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     952       1761.91   0.000530389       127.453   1.074e-05       0.001     1356  LS failed, Hessian reset \n",
      "     999       1762.73    0.00172992       96.3728      0.1152           1     1414   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1763.41   2.63818e-05       32.8346           1           1     1554   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1136       1763.42   0.000167147       53.5682   5.249e-06       0.001     1645  LS failed, Hessian reset \n",
      "    1191       1763.43   1.74211e-07       35.2803      0.3585           1     1729   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.12968\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1667.19     0.0347455       566.918           1           1      129   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1705.69     0.0278121       285.003           1           1      251   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1731.21    0.00615921       241.422      0.8024      0.8024      372   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     353       1739.02   7.20442e-05       62.5018   3.557e-07       0.001      495  LS failed, Hessian reset \n",
      "     378       1742.61   6.05384e-05       87.1611    6.59e-07       0.001      585  LS failed, Hessian reset \n",
      "     399        1744.6    0.00643649       100.119           1           1      612   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     453       1750.85   0.000118755       169.344   4.353e-07       0.001      726  LS failed, Hessian reset \n",
      "     499       1754.97    0.00268192       88.9116           1           1      786   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     545       1756.93   4.32992e-05       66.7417   8.269e-07       0.001      885  LS failed, Hessian reset \n",
      "     572       1757.99   4.77732e-05       75.2974   5.906e-07       0.001      957  LS failed, Hessian reset \n",
      "     599       1758.34   2.27005e-05       104.362      0.3471      0.3471      988   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1767.81    0.00207864       168.891           1           1     1118   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1770.29    0.00860235       129.164           1           1     1243   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     806        1770.7   6.90514e-05       105.684   4.084e-07       0.001     1287  LS failed, Hessian reset \n",
      "     899       1772.17   5.54746e-05       34.6429           1           1     1411   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1773.59    0.00714577       125.211      0.8229      0.8229     1536   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1007       1773.94    9.3182e-05       103.283   3.125e-07       0.001     1602  LS failed, Hessian reset \n",
      "    1022        1774.4   7.64345e-05       88.3369   1.425e-06       0.001     1665  LS failed, Hessian reset \n",
      "    1099       1775.46   0.000748175       88.9169      0.7225     0.07225     1765   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199        1776.1    0.00137713       40.6881      0.4898           1     1890   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1232       1776.31   0.000163152       98.6232   2.518e-06       0.001     1972  LS failed, Hessian reset \n",
      "    1299       1776.42   8.19485e-05       35.7995           1           1     2048   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1332       1776.51   6.75311e-05       87.2712   1.508e-06       0.001     2134  LS failed, Hessian reset \n",
      "    1399       1776.54   2.18595e-05       39.7645           1           1     2227   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1499       1776.57   0.000241224        36.028           1           1     2351   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1556       1776.59   7.95573e-08       30.4047      0.2734      0.7265     2425   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.61692\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1665.56     0.0642706       827.891           1           1      130   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1720.77    0.00560759       285.293           1           1      249   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1745.07     0.0241171       290.914           1           1      370   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     379       1750.95   8.10385e-05       122.133   4.337e-07       0.001      501  LS failed, Hessian reset \n",
      "     399       1752.07    0.00163377       54.7858       0.756       0.756      526   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     420        1752.7   2.85777e-05       43.6504   4.272e-07       0.001      590  LS failed, Hessian reset \n",
      "     499       1753.87    0.00513336       196.981           1           1      695   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1754.68   3.83578e-05       38.3488           1           1      827   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     657       1755.26   4.48359e-05       53.5936   3.376e-07       0.001      966  LS failed, Hessian reset \n",
      "     699       1755.58   0.000683507       52.9289       0.241           1     1019   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     717       1755.62    5.6076e-05       79.0308    1.41e-06       0.001     1082  LS failed, Hessian reset \n",
      "     799       1755.77   0.000931532       28.8015      0.3129           1     1186   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1755.84   0.000767624       34.6505           1           1     1305   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1756.45     0.0180283       79.2997           1           1     1427   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1756.82    1.0052e-05       36.9853      0.8672      0.8672     1562   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1756.92    2.4702e-07       32.7603      0.5379      0.5379     1687   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1249       1756.95   4.02298e-05       47.2199   1.041e-06       0.001     1793  LS failed, Hessian reset \n",
      "    1299       1756.96   2.95361e-07       36.9864      0.6592      0.6592     1855   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1301       1756.96   1.91655e-07       32.9264           1           1     1858   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.48206\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1645.72      0.022124       662.565      0.9355      0.9355      141   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1708.94    0.00897843       1075.14      0.1074           1      255   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1736.95     0.0182593        624.91           1           1      377   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1746.54     0.0126897       118.253           1           1      501   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     403       1746.57   0.000346033       174.535   1.042e-05       0.001      544  LS failed, Hessian reset \n",
      "     499       1749.52     0.0010551       66.3228      0.4111           1      670   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     589       1755.55   3.00178e-05       48.4076    4.26e-07       0.001      823  LS failed, Hessian reset \n",
      "     599       1756.54    0.00179688       78.6831      0.2772       0.946      836   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     621        1757.9   8.90526e-05       66.0573   3.014e-07       0.001      898  LS failed, Hessian reset \n",
      "     699       1759.68   0.000321812       106.037      0.5012      0.5012      998   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     772       1760.66   0.000247597       148.574   6.933e-06       0.001     1127  LS failed, Hessian reset \n",
      "     799        1760.7   5.74933e-05       46.7621     0.07998           1     1163   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1761.25    0.00537598       78.3055           1           1     1287   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1763.36    0.00184007       44.6345      0.5619      0.5619     1404   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1764.23   0.000124738       43.0429           1           1     1537   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1147       1764.29   2.32594e-05       45.7358   4.454e-07       0.001     1634  LS failed, Hessian reset \n",
      "    1199       1764.31   4.78425e-07       36.6806           1           1     1704   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1203       1764.31   2.53028e-07       32.4502           1           1     1708   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.48237\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1654.01     0.0216086       222.718      0.4032           1      132   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1703.56     0.0619929       956.337           1           1      244   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1728.73    0.00247814       64.2812           1           1      357   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1756.36     0.0307856       430.586           1           1      485   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1778.29      0.023473       657.198       1.453      0.1453      610   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1784.77    0.00194618       56.4367      0.8381      0.8381      734   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     692       1787.73   2.48046e-05       49.6642   7.232e-07       0.001      903  LS failed, Hessian reset \n",
      "     699       1787.78   0.000109818       114.691      0.5476      0.5476      913   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     740       1788.27   2.40153e-05       49.1744   3.824e-07       0.001     1019  LS failed, Hessian reset \n",
      "     799       1788.67     0.0212234       108.252           1           1     1096   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     809       1789.26   0.000309706       60.2571   3.014e-06       0.001     1156  LS failed, Hessian reset \n",
      "     899       1790.32   0.000312076       63.9274      0.1001           1     1276   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     941       1791.77   0.000143011       131.417   2.384e-07       0.001     1367  LS failed, Hessian reset \n",
      "     999       1792.32   5.52375e-05        47.656           1           1     1436   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1792.74   0.000163455       93.4849      0.1126      0.1126     1576   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1198       1793.03   4.46089e-05       82.0842   7.287e-07       0.001     1745  LS failed, Hessian reset \n",
      "    1199       1793.03   3.60264e-05       66.3219           1           1     1746   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299       1793.25   2.13075e-05       62.0457   4.461e-07       0.001     1911  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1337       1793.25   1.48637e-07       38.8374     0.09583           1     1964   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.69142\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1649.07     0.0131666       230.538           1           1      129   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1715.78     0.0250859       266.773           1           1      246   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1746.59     0.0182004       115.289           1           1      381   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        1760.8     0.0102927       171.906           1           1      496   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1767.75    0.00167905       267.379     0.04297           1      636   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     550       1769.93   2.54817e-05       52.0211   4.573e-07       0.001      742  LS failed, Hessian reset \n",
      "     599       1770.77    0.00335391       91.1167           1           1      813   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     622       1770.88   0.000134102       129.522   2.518e-06       0.001      882  LS failed, Hessian reset \n",
      "     693       1771.55   0.000152645       144.619   2.504e-06       0.001     1023  LS failed, Hessian reset \n",
      "     699       1771.67     0.0015063       137.049           1           1     1029   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     755       1772.16   9.80785e-05       89.8824   2.718e-06       0.001     1143  LS failed, Hessian reset \n",
      "     799       1772.22   0.000235467       43.3624           1           1     1195   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     879        1773.9   4.99414e-05       67.4697   2.822e-07       0.001     1348  LS failed, Hessian reset \n",
      "     899       1774.32    0.00459988       186.441           1           1     1377   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1774.99   0.000179264       48.9977      0.5263      0.5263     1514   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1775.27    0.00121878       156.887           1           1     1638   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1775.36   0.000144351       38.4824           1           1     1765   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299       1776.11     0.0010644       48.5831      0.1961      0.7081     1895   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399       1776.28   9.00508e-06       32.9404       0.535       0.535     2033   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1429       1776.29   3.56323e-05       58.6579   8.973e-07       0.001     2107  LS failed, Hessian reset \n",
      "    1466        1776.3   1.51335e-07       29.7436      0.2004      0.2004     2155   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.9281\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1672.22     0.0142465       830.366      0.0634           1      123   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1723.17     0.0291673       293.634           1           1      255   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1738.89    0.00411461       99.4553           1           1      384   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        1753.2     0.0023151       177.706      0.7134      0.7134      516   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     480       1757.07   0.000104007       161.182   7.691e-07       0.001      689  LS failed, Hessian reset \n",
      "     499       1757.44   0.000458903       104.821           1           1      716   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     534       1757.82   2.25152e-05       40.4326   6.079e-07       0.001      812  LS failed, Hessian reset \n",
      "     599       1758.04   6.50386e-05       36.4146      0.4082      0.4082      908   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     688       1760.65   5.36717e-05       43.0818    2.85e-07       0.001     1065  LS failed, Hessian reset \n",
      "     699       1761.21   0.000836825       37.2755      0.8496      0.8496     1078   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1762.86    0.00107754       73.3541      0.6734      0.6734     1222   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     848       1763.17    3.4246e-05       48.4784   3.304e-07       0.001     1332  LS failed, Hessian reset \n",
      "     884       1763.27      0.000255       75.7347   7.511e-06       0.001     1419  LS failed, Hessian reset \n",
      "     899       1763.27   1.26221e-05       33.8811      0.4444      0.4444     1437   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1763.39   0.000338192         54.12      0.9527      0.9527     1558   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1013       1763.75   0.000122767       187.535   9.444e-07       0.001     1653  LS failed, Hessian reset \n",
      "    1072        1764.4    2.3476e-05       42.3964   3.939e-07       0.001     1775  LS failed, Hessian reset \n",
      "    1099       1764.42    0.00015314       61.6171           1           1     1814   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1132       1764.42   1.63064e-07       29.8441      0.6204      0.1385     1865   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.31436\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1682.74     0.0120015       205.619       0.995       0.995      130   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1755.92    0.00622045       273.427           1           1      248   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     288       1766.65   0.000537078       132.178   1.072e-05       0.001      404  LS failed, Hessian reset \n",
      "     299       1767.98   0.000297177       63.8713           1           1      419   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1778.43   0.000705297       227.152      0.2237       0.523      554   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     438       1780.13   2.47828e-05       40.4346   3.699e-07       0.001      650  LS failed, Hessian reset \n",
      "     499       1781.06   0.000787394       77.6971           1           1      733   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1782.11   0.000322255        41.589      0.3479           1      868   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     658       1783.93   7.92252e-05       102.603   3.275e-07       0.001      988  LS failed, Hessian reset \n",
      "     699        1785.5   0.000730774       84.7671       1.704      0.1704     1036   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1786.04   0.000340748       51.6733      0.6173      0.6173     1183   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1786.18   0.000271744       33.9818      0.3944           1     1304   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     923       1786.23   0.000219397       177.691   5.132e-06       0.001     1365  LS failed, Hessian reset \n",
      "     958       1786.28   8.73143e-05       40.3813   2.826e-06       0.001     1459  LS failed, Hessian reset \n",
      "     999       1786.29   6.33705e-07       31.6592           1           1     1515   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1003       1786.29   1.57978e-07        26.914      0.8043      0.8043     1520   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.35243\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99          1692     0.0160499       314.374           1           1      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1746.98    0.00865507       245.054           1           1      245   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1775.47    0.00554903       911.532      0.4728      0.4728      363   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1789.08    0.00694355       169.427           1           1      488   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1795.33    0.00135827       78.1614      0.5387      0.5387      615   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1798.02   0.000391974       174.767      0.1655           1      743   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1800.19   0.000855692       113.858           1           1      879   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     794       1801.09   3.36616e-05       54.9599   3.153e-07       0.001     1030  LS failed, Hessian reset \n",
      "     799        1801.1   0.000107028       59.3233           1           1     1038   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1801.78    0.00254328       214.516      0.6687      0.6687     1165   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1803.45    0.00324393       72.7578           1           1     1290   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1006       1804.01   6.53317e-05       72.8699   2.621e-07       0.001     1346  LS failed, Hessian reset \n",
      "    1099       1806.34   0.000558757       56.3049           1           1     1463   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1122       1806.44   0.000151346       150.745   3.643e-06       0.001     1527  LS failed, Hessian reset \n",
      "    1199       1806.54    0.00106277       66.4418       0.478       0.478     1627   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1216       1806.71   7.42329e-05       101.431   1.611e-06       0.001     1702  LS failed, Hessian reset \n",
      "    1299       1806.97   2.36727e-05       35.3908      0.2059      0.8825     1806   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1315       1806.97   2.23505e-05       45.1064   6.456e-07       0.001     1861  LS failed, Hessian reset \n",
      "    1354       1806.98   2.14249e-06       29.1592   6.268e-08       0.001     1947  LS failed, Hessian reset \n",
      "    1366       1806.98   4.43491e-07       33.1063       1.376      0.3566     1963   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.73108\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1681.98    0.00970851       125.574           1           1      126   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1748.33     0.0126274       833.538           1           1      245   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     222       1758.79   6.19307e-05       101.185   4.747e-07       0.001      314  LS failed, Hessian reset \n",
      "     299       1776.64    0.00220938       387.299      0.7018      0.7018      414   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1785.18    0.00321518       43.4892      0.7019           1      540   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     400       1785.18   3.20243e-05       55.7089   7.364e-07       0.001      574  LS failed, Hessian reset \n",
      "     499       1789.14    0.00881957        209.77           1           1      713   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1791.38   0.000344024       78.0971           1           1      843   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     612       1792.43   0.000102117       157.157   1.047e-06       0.001      917  LS failed, Hessian reset \n",
      "     649       1793.84    0.00010128        117.44   2.101e-06       0.001     1002  LS failed, Hessian reset \n",
      "     699       1794.14   6.52687e-05       62.2044      0.6683      0.6683     1061   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     708       1794.21   0.000149342       102.496   3.076e-06       0.001     1113  LS failed, Hessian reset \n",
      "     799       1796.47     0.0295328       172.553           1           1     1229   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     802       1796.55   4.52541e-05       72.5678   3.367e-07       0.001     1278  LS failed, Hessian reset \n",
      "     899       1799.29   0.000199237       30.9135        1.11       0.111     1417   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     925       1799.33   3.35852e-05       63.1862   5.161e-07       0.001     1488  LS failed, Hessian reset \n",
      "     999       1800.07     0.0245054       217.002      0.5542           1     1583   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1007       1800.16   4.47767e-05        74.265   9.872e-07       0.001     1660  LS failed, Hessian reset \n",
      "    1065       1800.61   4.23765e-05       74.7057    5.62e-07       0.001     1774  LS failed, Hessian reset \n",
      "    1099       1800.68   5.06936e-05       31.2877      0.5201      0.5201     1817   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1115       1800.69   5.69497e-05       74.0718   1.915e-06       0.001     1869  LS failed, Hessian reset \n",
      "    1153       1800.71   2.45377e-05       40.0814   3.343e-07       0.001     1954  LS failed, Hessian reset \n",
      "    1199       1800.73   6.50532e-06       36.1941      0.7099      0.7099     2017   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299       1801.24    0.00215587       44.7033           1           1     2139   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1361       1801.36   5.08437e-05       54.9166   1.916e-06       0.001     2261  LS failed, Hessian reset \n",
      "    1399       1801.37   2.52114e-06       27.6707      0.8856      0.8856     2316   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1499       1801.69   0.000994562       44.0715           1           1     2435   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1599       1802.51    0.00146076       84.2233           1           1     2559   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1660        1803.6   2.80086e-05       44.9218    3.21e-07       0.001     2678  LS failed, Hessian reset \n",
      "    1699       1803.84   0.000348594       70.8564           1           1     2740   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1799       1804.12   0.000249245       37.5491           1           1     2873   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1811       1804.13   4.04822e-05       70.6999   9.336e-07       0.001     2934  LS failed, Hessian reset \n",
      "    1899       1804.15   1.74875e-05       34.2954      0.8122      0.8122     3060   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1905       1804.15   2.33154e-05       43.9852   3.563e-07       0.001     3107  LS failed, Hessian reset \n",
      "    1940       1804.15   1.46173e-06       30.2402   4.819e-08       0.001     3194  LS failed, Hessian reset \n",
      "    1949       1804.15   3.76018e-07       31.2762           1           1     3206   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.25405\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1711.65      0.023175       254.824           1           1      129   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1767.93    0.00972223       933.019      0.3276           1      241   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299        1798.3      0.106823       1213.02           1           1      361   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1814.19    0.00264377        330.47     0.09528           1      491   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1816.46    0.00107867       80.9036           1           1      622   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     554       1822.09    0.00016473       155.926   2.573e-07       0.001      735  LS failed, Hessian reset \n",
      "     599       1824.33    0.00148183       547.233      0.2482      0.2482      790   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1826.11   0.000285526       76.3732      0.4117      0.4117      934   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     745       1826.31   4.95505e-05       78.1262   1.271e-06       0.001     1042  LS failed, Hessian reset \n",
      "     799       1826.37   9.80756e-05       41.7291           1           1     1106   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     803       1826.37   2.67834e-05       50.1588   7.138e-07       0.001     1155  LS failed, Hessian reset \n",
      "     833       1826.38   3.73881e-07       33.0804      0.2905           1     1201   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -7.45582\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        1726.4    0.00798717       133.756           1           1      118   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199          1791    0.00591879       410.203      0.1917      0.6208      243   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1816.82    0.00557884        581.96     0.01658           1      375   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1827.99    0.00142255       322.349           1           1      506   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     435       1829.08   2.15967e-05       42.9565   3.361e-07       0.001      610  LS failed, Hessian reset \n",
      "     499       1830.88    0.00141196       58.2702           1           1      691   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1834.43    0.00173179       111.031      0.8754      0.8754      808   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699          1837   0.000377837       249.807     0.02471           1      931   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     781       1837.97   2.07306e-05       46.7211   4.389e-07       0.001     1078  LS failed, Hessian reset \n",
      "     799       1838.09    0.00216795       115.488           1           1     1100   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1839.41     0.0329492       81.2797           1           1     1233   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     914       1840.53   3.36618e-05       59.2803   2.636e-07       0.001     1313  LS failed, Hessian reset \n",
      "     935       1841.53    4.1197e-05        54.201   2.375e-07       0.001     1380  LS failed, Hessian reset \n",
      "     997       1842.32   2.33787e-05       36.7275   2.382e-07       0.001     1518  LS failed, Hessian reset \n",
      "     999       1842.33   0.000220019       52.1371           1           1     1521   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1037       1842.56    1.6083e-05       26.0981   2.492e-07       0.001     1617  LS failed, Hessian reset \n",
      "    1071       1842.71   3.73698e-05       49.3475   2.364e-07       0.001     1700  LS failed, Hessian reset \n",
      "    1099       1842.83   0.000148502       40.5259           1           1     1745   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1142       1842.89    1.9716e-05       44.7682   3.723e-07       0.001     1845  LS failed, Hessian reset \n",
      "    1190       1842.94   1.70337e-05       36.7472   3.401e-07       0.001     1943  LS failed, Hessian reset \n",
      "    1199       1842.94   2.37615e-06       28.9001      0.2861      0.2861     1953   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1234       1842.95   5.41052e-06       28.6768   1.826e-07       0.001     2035  LS failed, Hessian reset \n",
      "    1277       1842.95   3.93948e-07       32.6648      0.4482      0.4482     2097   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -7.69088\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1705.71    0.00621054       501.548           1           1      129   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1760.57    0.00182716       145.523      0.2512      0.2512      247   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1811.98     0.0272367       222.341           1           1      368   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1828.21    0.00885028       459.987      0.2999      0.2999      492   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499        1842.9    0.00306129       253.775           1           1      618   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     548       1846.01   3.96263e-05       88.4767   2.891e-07       0.001      720  LS failed, Hessian reset \n",
      "     599        1847.7     0.0102918       385.707      0.4424           1      786   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1849.43   0.000101987       102.395      0.2384      0.2384      931   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     737       1849.63   3.90667e-05        51.017   2.221e-07       0.001     1026  LS failed, Hessian reset \n",
      "     799       1850.37    0.00642745       276.793           1           1     1100   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899        1852.1   4.33261e-05        60.783      0.3898      0.3898     1239   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     970       1852.83   2.74243e-05       61.5493   5.885e-07       0.001     1369  LS failed, Hessian reset \n",
      "     999          1853   0.000383396       64.6457      0.4558           1     1408   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1021       1853.12   3.05511e-05       34.3689   2.102e-07       0.001     1476  LS failed, Hessian reset \n",
      "    1099       1853.27    0.00106253       40.2439      0.9591      0.9591     1576   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1138       1853.96   0.000210577       79.6482   2.929e-06       0.001     1706  LS failed, Hessian reset \n",
      "    1199       1854.52    0.00035492       94.1014       0.484       0.484     1784   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1243        1854.6   0.000139086       95.3739   2.608e-06       0.001     1879  LS failed, Hessian reset \n",
      "    1266       1854.61    2.7236e-05       62.6186   7.295e-07       0.001     1948  LS failed, Hessian reset \n",
      "    1299       1854.61   3.25515e-07       31.8038           1           1     1994   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1309       1854.61   5.79444e-07       33.2916      0.6165      0.6165     2008   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -7.64838\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1742.22    0.00385166       185.115      0.3086      0.9637      128   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1774.78      0.010776       466.363      0.4172      0.4172      250   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1812.91      0.080291        1527.6      0.5032           1      375   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1826.77     0.0151167       129.328      0.4273           1      501   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1831.52     0.0101535       79.9919           1           1      631   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1835.72   0.000648045       62.1689           1           1      756   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1837.17    0.00157794       90.4723           1           1      884   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1839.61     0.0476781       255.404           1           1     1005   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     859       1840.59   1.79074e-05       39.6809   3.577e-07       0.001     1122  LS failed, Hessian reset \n",
      "     899        1840.8   0.000194672       31.4968      0.6202      0.6202     1176   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1841.74   0.000939005       51.8737           1           1     1316   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1841.86    0.00048263        63.167      0.6318      0.6318     1440   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1176       1842.61   2.97977e-05       59.9002   8.057e-07       0.001     1580  LS failed, Hessian reset \n",
      "    1199       1842.75    0.00064987       90.4367       1.371      0.3062     1612   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299       1843.26   0.000438649       100.256           1           1     1739   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1353       1843.39   2.11687e-05       42.7959   3.046e-07       0.001     1862  LS failed, Hessian reset \n",
      "    1399       1843.48    0.00188677       44.7652      0.4041           1     1921   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1499       1843.66    0.00212524       130.656           1           1     2066   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1599       1845.39     0.0631831        206.92      0.3082           1     2188   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1699       1846.81    0.00344647       122.524           1           1     2309   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1721       1846.87   2.37593e-05       51.6374   6.125e-07       0.001     2373  LS failed, Hessian reset \n",
      "    1799       1847.03   4.59446e-05       57.2939      0.5206      0.5206     2473   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1855       1847.04   1.02215e-05        32.198   3.355e-07       0.001     2598  LS failed, Hessian reset \n",
      "    1882       1847.05   1.10515e-06       23.7021           1           1     2635   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -9.28701\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1732.33     0.0128687       348.595           1           1      120   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1779.47     0.0845455       586.904           1           1      239   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     262       1806.15   5.91277e-05       98.8048   4.014e-07       0.001      363  LS failed, Hessian reset \n",
      "     299       1809.12   0.000694167       152.044           1           1      408   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1815.94     0.0143982       639.417          10           1      527   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1823.06    0.00157318       339.834      0.2955           1      661   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     511        1825.2    0.00015628       243.275   1.335e-06       0.001      740  LS failed, Hessian reset \n",
      "     551       1827.41   2.70792e-05       49.7696   7.738e-07       0.001      836  LS failed, Hessian reset \n",
      "     599       1827.65     0.0013374       95.1714           1           1      895   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     614       1827.72   2.80732e-05       43.7843   2.881e-07       0.001      959  LS failed, Hessian reset \n",
      "     641       1827.75   1.45981e-05       20.6175   2.698e-07       0.001     1043  LS failed, Hessian reset \n",
      "     675       1827.77   7.83947e-05       95.2191   2.168e-06       0.001     1129  LS failed, Hessian reset \n",
      "     699       1827.78   6.55564e-06       23.6297      0.6088      0.6088     1157   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     705       1827.79   1.77296e-05       26.1949   5.863e-07       0.001     1209  LS failed, Hessian reset \n",
      "     721       1827.79   4.53805e-06       32.3152   1.863e-07       0.001     1268  LS failed, Hessian reset \n",
      "     729       1827.79    9.2433e-08       28.3073      0.0653      0.2285     1280   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -9.71034\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1699.47    0.00399118       159.048      0.1691      0.1691      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1762.39     0.0686357       869.362           1           1      241   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1781.07    0.00607912       149.735      0.8067      0.8067      365   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1788.09     0.0101306       122.646       8.679      0.8679      510   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1793.58   0.000299563       97.6671      0.1277      0.1277      628   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     566       1795.63   7.24267e-05       60.1698   2.802e-07       0.001      764  LS failed, Hessian reset \n",
      "     599       1796.45   0.000965552        32.098       0.592       0.592      812   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1797.08     0.0120489       102.852      0.9815      0.9815      936   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     752       1800.19   5.16879e-05       83.4641   3.223e-07       0.001     1046  LS failed, Hessian reset \n",
      "     799       1801.73   0.000298739       58.7617      0.3463           1     1106   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     880       1802.28   5.03017e-05       60.1925   2.769e-07       0.001     1265  LS failed, Hessian reset \n",
      "     899       1802.41   0.000115662       39.1421      0.2691           1     1289   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     990       1802.88   4.78435e-05       87.3101   3.407e-07       0.001     1456  LS failed, Hessian reset \n",
      "     999       1803.04   0.000175399       127.632      0.4113      0.4113     1468   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1094       1803.29   2.93068e-05       56.3412   5.677e-07       0.001     1640  LS failed, Hessian reset \n",
      "    1099       1803.29   9.67838e-06       34.9041           1           1     1646   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1125       1803.29   2.70349e-07       30.4595           1           1     1681   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -8.77884\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1691.96     0.0199336       423.747           1           1      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1735.46    0.00773074       83.9875      0.5761      0.5761      251   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1745.51    0.00579128       145.643      0.1258      0.7455      380   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1754.42    0.00599536       37.1463      0.1422           1      510   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     403       1754.44   4.51472e-05         34.48   3.342e-07       0.001      565  LS failed, Hessian reset \n",
      "     458       1759.33   0.000412398       111.978   6.062e-06       0.001      665  LS failed, Hessian reset \n",
      "     483       1760.72     6.341e-05       93.5151   4.083e-07       0.001      739  LS failed, Hessian reset \n",
      "     499       1761.51   0.000108711       165.233      0.6182      0.6182      758   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1764.71    0.00999316       70.6293      0.6838      0.6838      885   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     601       1764.74   0.000752392       279.398   2.028e-05       0.001      923  LS failed, Hessian reset \n",
      "     699       1768.85    0.00649547         157.5           1           1     1037   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1769.38    0.00626951       141.422           1           1     1169   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     811       1770.01   4.67111e-05       41.3783    3.13e-07       0.001     1243  LS failed, Hessian reset \n",
      "     868       1770.71   3.92385e-05       63.8127   6.121e-07       0.001     1356  LS failed, Hessian reset \n",
      "     899       1770.74    1.6347e-05       31.7353      0.4323      0.4323     1396   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     995        1771.3   4.96683e-05       75.2284   3.824e-07       0.001     1561  LS failed, Hessian reset \n",
      "     999       1771.42    0.00149915        120.95           1           1     1566   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1069       1771.98    0.00012576       111.859   3.639e-06       0.001     1685  LS failed, Hessian reset \n",
      "    1099       1772.01    1.6913e-06       29.9219      0.1646      0.1646     1725   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1116       1772.01   2.23415e-05       27.0427   5.894e-07       0.001     1783  LS failed, Hessian reset \n",
      "    1139       1772.01    7.9994e-08        34.367      0.3122           1     1813   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -8.49345\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        1676.8     0.0507985       795.625           1           1      128   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1729.91     0.0405304       215.563       1.915      0.1915      255   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1743.09     0.0139742       124.783           1           1      379   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1746.15    0.00126556       53.1512      0.7984      0.7984      507   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499          1749    0.00241592       137.335           1           1      638   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1751.86    0.00522605       96.9997           1           1      758   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     604       1751.97   3.71695e-05       58.8214   4.336e-07       0.001      804  LS failed, Hessian reset \n",
      "     669       1755.03   3.56654e-05       59.9333   7.837e-07       0.001      937  LS failed, Hessian reset \n",
      "     699       1755.21   0.000119802       73.3788      0.1567           1      982   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1756.01   0.000171327       34.1418           1           1     1117   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     811       1756.06   4.58884e-05       68.9382   1.092e-06       0.001     1175  LS failed, Hessian reset \n",
      "     899       1756.67   0.000169907       43.1876      0.5834      0.5834     1289   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999        1758.7     0.0286021       399.835        5.83           1     1407   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1039       1759.46    3.3916e-05       36.9276   3.326e-07       0.001     1504  LS failed, Hessian reset \n",
      "    1081       1759.53   4.84068e-05       28.0715   1.598e-06       0.001     1603  LS failed, Hessian reset \n",
      "    1099       1759.54   1.54978e-06       29.2403       4.265      0.4265     1634   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1124       1759.55   2.68895e-05       46.9001   6.348e-07       0.001     1709  LS failed, Hessian reset \n",
      "    1149       1759.55   1.11113e-05       28.8533   2.791e-07       0.001     1778  LS failed, Hessian reset \n",
      "    1167       1759.56    2.2104e-07        27.283       0.297           1     1806   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -8.30601\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1683.09     0.0282605       866.456           1           1      130   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1719.93     0.0667541       274.966       0.338           1      247   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1743.52     0.0252798       353.207           1           1      377   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     370       1749.52   3.83498e-05       46.8905   3.759e-07       0.001      512  LS failed, Hessian reset \n",
      "     399       1751.19     0.0017973       43.7294           1           1      552   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1755.25     0.0058541       313.865      0.3503           1      687   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1757.49   0.000372111       48.2654           1           1      817   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     686        1757.9   0.000165632       124.805    3.28e-06       0.001      990  LS failed, Hessian reset \n",
      "     699       1758.03   0.000227973       52.6337      0.0447      0.3313     1006   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     738       1758.26   3.18871e-05       52.1418   6.857e-07       0.001     1109  LS failed, Hessian reset \n",
      "     790       1758.28   6.08703e-05       69.2319   1.447e-06       0.001     1212  LS failed, Hessian reset \n",
      "     799       1758.29   0.000152709       43.1215      0.6509      0.6509     1222   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     849       1758.29   1.42616e-08       30.5783    0.008371      0.1691     1297   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -9.00834\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1663.01    0.00527029       234.352       0.839       0.839      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1715.74     0.0605352       363.009      0.4732      0.4732      253   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1744.99     0.0470245       169.781           1           1      389   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1755.15    0.00177775       499.805      0.3545      0.3545      506   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     486       1760.69   5.06225e-05       85.2672   7.354e-07       0.001      648  LS failed, Hessian reset \n",
      "     499       1761.72    0.00881853       47.9337       9.693      0.9693      666   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1764.03    0.00166276       54.0604           1           1      798   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1767.94    0.00140491       55.8681           1           1      930   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     730       1768.17   4.77631e-05       42.7196   2.992e-07       0.001     1007  LS failed, Hessian reset \n",
      "     799        1768.5   7.17704e-05       35.2393      0.5042      0.5042     1094   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1769.24    0.00115671        140.89      0.3846           1     1220   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     965        1770.9   3.11187e-05       55.8631   4.511e-07       0.001     1354  LS failed, Hessian reset \n",
      "     999       1772.03   3.09945e-05       51.2719   9.134e-07       0.001     1445  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1061        1772.5     2.522e-05       44.4801   4.168e-07       0.001     1566  LS failed, Hessian reset \n",
      "    1099       1772.58   4.75858e-05       41.2506           1           1     1617   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1117       1772.59   6.98346e-05       79.2528   1.932e-06       0.001     1674  LS failed, Hessian reset \n",
      "    1160       1772.61   0.000196604       89.0954   3.646e-06       0.001     1761  LS failed, Hessian reset \n",
      "    1190       1772.62   8.89185e-06         31.95   2.369e-07       0.001     1852  LS failed, Hessian reset \n",
      "    1199       1772.62   2.15173e-06       28.5464      0.7429      0.7429     1863   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1243       1772.62   3.80608e-07       27.5717      0.3604           1     1914   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -7.67663\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1680.19     0.0111933       285.252           1           1      125   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1732.57    0.00647803       474.535           1           1      247   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     206        1734.1   3.94861e-05       47.6462   3.679e-07       0.001      290  LS failed, Hessian reset \n",
      "     299       1744.54     0.0267475       182.739           1           1      408   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1750.96     0.0323815       204.658           1           1      531   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1755.66   0.000866777       44.1568           1           1      675   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     530       1757.87   5.47879e-05        82.645   8.123e-07       0.001      754  LS failed, Hessian reset \n",
      "     599       1760.23   0.000965196       102.337      0.2056           1      835   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     680       1763.34   7.04701e-05       98.4285   3.814e-07       0.001      977  LS failed, Hessian reset \n",
      "     699       1763.78   0.000774488       153.515           1           1     1001   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1764.86   0.000221541       98.5293           1           1     1132   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1765.77    0.00133532       102.419           1           1     1250   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     960       1766.82   0.000122737       144.926    2.12e-06       0.001     1393  LS failed, Hessian reset \n",
      "     999       1767.43   0.000244005       37.3168           1           1     1445   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1096       1768.35   4.96117e-05       66.3349   1.585e-06       0.001     1602  LS failed, Hessian reset \n",
      "    1099       1768.35   1.14794e-05       56.4558      0.5502      0.5502     1605   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1768.41   8.30946e-07       29.8629      0.3318           1     1737   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1209       1768.41   1.60187e-07         28.36      0.1358      0.3648     1750   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.50018\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99          1660    0.00755101        398.26           1           1      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1709.15     0.0038426       138.125      0.4732      0.4732      244   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299        1730.9     0.0184216       231.621       0.461       0.461      364   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     301       1730.92   7.04838e-05       65.4504   3.856e-07       0.001      405  LS failed, Hessian reset \n",
      "     375       1737.32   6.06362e-05       63.5988   3.812e-07       0.001      549  LS failed, Hessian reset \n",
      "     399       1738.43    0.00147233       264.137      0.4169      0.4169      579   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     429       1739.53   5.72539e-05       81.9919   7.763e-07       0.001      663  LS failed, Hessian reset \n",
      "     499       1741.58     0.0225264       207.883       0.169           1      746   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     548          1744   0.000273013       54.9306   7.025e-06       0.001      852  LS failed, Hessian reset \n",
      "     599       1744.81   0.000367149       82.9046           1           1      921   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1749.83    0.00275096       216.992      0.8532      0.8532     1044   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1751.12    0.00115079       167.422           1           1     1179   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     883       1751.89   0.000113835       100.605   3.308e-07       0.001     1332  LS failed, Hessian reset \n",
      "     899       1752.17    0.00321058       159.948      0.9181      0.9181     1353   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     952       1752.47    3.1794e-05       50.2161   7.352e-07       0.001     1460  LS failed, Hessian reset \n",
      "     980       1752.53   6.94763e-05       65.5607   2.297e-06       0.001     1532  LS failed, Hessian reset \n",
      "     999       1752.54   1.59634e-05       41.3588           1           1     1563   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1752.92   6.95953e-05       36.5027       1.862      0.5215     1695   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1753.18    0.00173396       54.1977           1           1     1810   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1237       1753.34   2.84932e-05       33.6222   3.563e-07       0.001     1948  LS failed, Hessian reset \n",
      "    1299       1753.49   9.12927e-07       30.6294           1           1     2037   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1345       1753.53   0.000118487       49.2659   3.152e-06       0.001     2135  LS failed, Hessian reset \n",
      "    1399       1753.56    1.1403e-05       24.7366      0.8195      0.8195     2200   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1403       1753.56   5.85591e-06       31.7821   2.314e-07       0.001     2241  LS failed, Hessian reset \n",
      "    1424       1753.56   2.51013e-07       28.8377           1           1     2277   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -7.88911\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1668.69    0.00624054       1093.43       0.065           1      129   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1709.77      0.003002       235.737           1           1      253   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1734.39    0.00965373       580.435           1           1      374   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1746.18    0.00169635       117.157      0.5068     0.05068      499   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     495       1749.23   3.30388e-05       55.9456   6.062e-07       0.001      666  LS failed, Hessian reset \n",
      "     499       1749.32   0.000698062       110.593      0.9611      0.9611      671   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     547       1749.89   8.63615e-05       92.0832   2.792e-06       0.001      771  LS failed, Hessian reset \n",
      "     599       1750.34     0.0655286       509.018           1           1      837   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     655       1751.69   0.000253141       207.117   2.357e-06       0.001      942  LS failed, Hessian reset \n",
      "     699       1752.43   0.000589576       38.8139           1           1      994   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1752.64   4.48899e-06       29.3787           1           1     1128   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     815       1752.64     2.787e-07       32.8258           1           1     1152   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -7.12522\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1665.04     0.0261672       1127.02           1           1      119   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        1715.1     0.0267297       2356.61      0.2209           1      237   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1740.27   0.000505058        39.936       3.087     0.03087      364   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1745.08    0.00875264       69.6243           1           1      503   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     404       1745.17   0.000205968        174.92   3.614e-06       0.001      559  LS failed, Hessian reset \n",
      "     439       1747.84   3.61374e-05       57.1522   4.737e-07       0.001      661  LS failed, Hessian reset \n",
      "     494       1749.38    2.7809e-05       41.5923   4.417e-07       0.001      779  LS failed, Hessian reset \n",
      "     499       1749.46   0.000628518       27.0169           1           1      788   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599        1753.4   0.000496506       74.2484      0.1371      0.4094      922   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1755.79    0.00196179       131.337           1           1     1045   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1758.25   7.01079e-05       37.3204       1.941      0.1941     1189   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     862       1758.39   2.85431e-05       52.7851    8.04e-07       0.001     1322  LS failed, Hessian reset \n",
      "     884       1758.39   5.26954e-06        33.059   1.875e-07       0.001     1388  LS failed, Hessian reset \n",
      "     897       1758.39   1.44725e-07       27.2002           1           1     1409   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.56005\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1681.45    0.00222333       169.638     0.06968           1      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1710.73    0.00148532       69.4745      0.8835      0.8835      254   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1731.33    0.00738642         175.5           1           1      379   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1739.16   0.000565074       38.2067           1           1      504   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     416       1740.52   4.94451e-05       71.8611   6.204e-07       0.001      558  LS failed, Hessian reset \n",
      "     450       1741.82   6.97383e-05       85.6931   1.301e-06       0.001      646  LS failed, Hessian reset \n",
      "     499       1743.47   0.000276883       146.918      0.5117      0.5117      710   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1747.91   0.000412958       45.1566      0.2985           1      840   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     644       1749.41   0.000160593       70.9356   3.306e-07       0.001      940  LS failed, Hessian reset \n",
      "     699       1751.19   0.000606993        146.43           1           1     1007   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     793       1752.21   3.78848e-05       55.1878   9.762e-07       0.001     1160  LS failed, Hessian reset \n",
      "     799       1752.26   0.000276621       53.3779      0.3678      0.9225     1170   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     894       1753.15   0.000131399       40.8385   3.212e-07       0.001     1338  LS failed, Hessian reset \n",
      "     899       1753.23   0.000707096       46.6539           1           1     1344   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1753.74   3.04573e-05       37.8026           1           1     1477   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1753.93    0.00434974       40.7985           1           1     1594   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1754.45   0.000774485       31.9307           1           1     1712   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1256        1754.5   2.50833e-07       31.7876      0.3842           1     1799   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -7.06289\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1676.34     0.0122849       511.412      0.3956      0.3956      141   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1715.26     0.0253874       470.943      0.5919      0.5919      263   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1726.35    0.00234374       100.754      0.2034           1      388   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     385        1729.9   0.000104691       79.9383   3.728e-07       0.001      538  LS failed, Hessian reset \n",
      "     399       1731.56    0.00332408       77.2374      0.9748    0.009748      560   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     485       1734.44    0.00234537       206.185   2.937e-05       0.001      706  LS failed, Hessian reset \n",
      "     499        1735.4    0.00160528       561.654      0.3783      0.3783      723   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     548       1736.02   3.53713e-05       50.5804   6.036e-07       0.001      826  LS failed, Hessian reset \n",
      "     589       1736.27   4.73776e-05       57.2544   4.461e-07       0.001      916  LS failed, Hessian reset \n",
      "     599       1736.41   0.000589798       36.5249      0.3285           1      929   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1739.48    0.00235639       67.7321      0.2348           1     1054   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799        1740.4     0.0140906       262.963           1           1     1183   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1741.01    0.00171092       61.8025           1           1     1314   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     977       1742.33   2.85183e-05       43.1709   6.083e-07       0.001     1456  LS failed, Hessian reset \n",
      "     999       1742.62   0.000449274       50.8239       1.438      0.1438     1490   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099        1742.9   0.000147382        38.759       0.761       0.761     1611   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1179       1742.99   3.03542e-05       47.9026    5.39e-07       0.001     1750  LS failed, Hessian reset \n",
      "    1199       1743.03   0.000704095       32.4636           1           1     1771   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299       1743.05   2.96909e-05       38.7732       3.078      0.3078     1899   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399       1743.35    0.00735091       44.9501           1           1     2014   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1463       1743.52   7.78978e-05       85.6542   2.162e-06       0.001     2137  LS failed, Hessian reset \n",
      "    1499       1743.53    0.00158471       50.1443           1           1     2183   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1599       1743.59    0.00102872        34.976           1           1     2302   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1669       1743.63   3.34455e-05       45.8642   9.145e-07       0.001     2442  LS failed, Hessian reset \n",
      "    1685       1743.64   1.53521e-06        23.983   6.004e-08       0.001     2504  LS failed, Hessian reset \n",
      "    1695       1743.64   2.54283e-07        32.742      0.2738           1     2522   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.81336\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1692.96    0.00803082       206.648      0.0912           1      135   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1731.75    0.00868711       49.8234           1           1      256   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1741.61    0.00219852       114.599           1           1      390   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1746.97      0.055394       544.229       9.942      0.9942      522   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1750.41   0.000174883       41.7617           1           1      649   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599        1751.9    0.00486739       73.0358           1           1      772   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     633       1752.21   3.93337e-05       41.8542   3.638e-07       0.001      855  LS failed, Hessian reset \n",
      "     654       1752.31   7.15195e-05       82.1076   1.879e-06       0.001      929  LS failed, Hessian reset \n",
      "     699       1752.35   0.000173032       99.5591      0.6615      0.6615      991   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1752.77   8.75456e-06       36.1231      0.3059      0.3059     1120   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     819       1752.77   6.82736e-08        35.382      0.0471           1     1153   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.18388\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1683.73    0.00469633       320.037       1.387      0.1387      135   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1726.29    0.00301951       180.904      0.1787      0.9645      256   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1742.47    0.00314453       77.5259           1           1      377   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1745.62    0.00357778       112.007      0.5338      0.5338      507   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     468       1751.22   0.000107328        120.83   1.857e-06       0.001      635  LS failed, Hessian reset \n",
      "     492       1751.86   4.29896e-05       60.9282   4.393e-07       0.001      704  LS failed, Hessian reset \n",
      "     499       1751.95   0.000523881       52.6578      0.1025           1      715   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     510       1752.03   0.000143125       96.4624   3.012e-06       0.001      771  LS failed, Hessian reset \n",
      "     520       1752.06   2.59729e-05       36.0187   4.215e-07       0.001      822  LS failed, Hessian reset \n",
      "     558       1752.71   9.33604e-05       137.941   7.946e-07       0.001      909  LS failed, Hessian reset \n",
      "     599       1753.42    0.00017212       35.7124      0.1578           1      960   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1756.18    0.00139482       170.947      0.7707      0.7707     1076   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     788       1758.48    4.8636e-05       65.9904   1.324e-06       0.001     1238  LS failed, Hessian reset \n",
      "     799       1758.55   0.000510075        39.545      0.9744      0.9744     1256   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1759.02     0.0112157       203.457           1           1     1375   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     923       1759.44   2.66932e-05       43.7139   6.172e-07       0.001     1446  LS failed, Hessian reset \n",
      "     932       1759.58   0.000112509       73.2689   3.673e-06       0.001     1496  LS failed, Hessian reset \n",
      "     999       1759.93   0.000302999       46.7818      0.6408      0.6408     1585   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1760.39   0.000508611       38.1015           1           1     1707   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1101       1760.39   0.000217617       97.6781     3.9e-06       0.001     1740  LS failed, Hessian reset \n",
      "    1140       1760.41    1.2914e-07       30.2755      0.1666           1     1798   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.09298\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1681.86    0.00352926       639.626     0.05114           1      125   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1716.25     0.0114041       649.455           1           1      253   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1728.39   0.000622499       96.0448           1           1      376   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     358       1732.81   4.70437e-05       51.0715   3.919e-07       0.001      501  LS failed, Hessian reset \n",
      "     399       1735.32   0.000518614       64.7527           1           1      553   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1739.14    0.00233787       112.012           1           1      682   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     592       1742.36   5.30964e-05       64.4564   1.504e-06       0.001      834  LS failed, Hessian reset \n",
      "     599       1742.48    0.00140499       48.3998        5.35      0.0535      845   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1744.51    0.00404776       46.5337      0.2558      0.2558      972   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     713       1745.19   0.000117205       156.404   7.643e-07       0.001     1073  LS failed, Hessian reset \n",
      "     766       1746.26    7.8194e-05        37.984   3.378e-07       0.001     1184  LS failed, Hessian reset \n",
      "     799       1746.38    3.1331e-05       31.6259           1           1     1232   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     812       1746.42   2.71264e-05       37.2593   7.032e-07       0.001     1286  LS failed, Hessian reset \n",
      "     853        1746.6   4.49524e-05       56.9947   4.309e-07       0.001     1374  LS failed, Hessian reset \n",
      "     899        1746.8   0.000466143       37.5211     0.07092           1     1432   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     900        1746.8   0.000176211       42.8568   4.696e-06       0.001     1469  LS failed, Hessian reset \n",
      "     999       1747.73   0.000303848       67.8382       1.018      0.1018     1604   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1081       1748.73   8.56367e-05       44.6288   3.393e-07       0.001     1768  LS failed, Hessian reset \n",
      "    1099       1749.33    0.00737312       106.272           1           1     1791   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1138       1749.63   2.83749e-05       40.9245   4.826e-07       0.001     1893  LS failed, Hessian reset \n",
      "    1187        1749.8   4.41614e-05       59.6835   1.129e-06       0.001     2000  LS failed, Hessian reset \n",
      "    1199       1749.81   3.94492e-05       30.7345      0.1968           1     2014   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1243       1749.88    5.0232e-05        64.596   1.318e-06       0.001     2112  LS failed, Hessian reset \n",
      "    1299       1749.95   2.50279e-06       37.2181      0.1476           1     2189   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1307       1749.95   2.58837e-07       25.9032       0.981      0.0981     2199   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.87257\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1669.05     0.0436941       145.092           1           1      119   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        1713.1    0.00835674       124.822           1           1      247   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1726.41    0.00416121       133.537           1           1      375   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     328       1727.59   9.98566e-05       110.852    1.24e-06       0.001      454  LS failed, Hessian reset \n",
      "     399       1728.74   0.000890288       226.899      0.8455      0.8455      547   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     486       1732.04   3.74799e-05       40.0511   4.174e-07       0.001      716  LS failed, Hessian reset \n",
      "     499       1732.11   0.000385915        50.579       1.351      0.2686      734   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     556       1734.36   9.59381e-05       84.1371   3.767e-07       0.001      873  LS failed, Hessian reset \n",
      "     598          1737   0.000104851       102.014   3.962e-07       0.001      969  LS failed, Hessian reset \n",
      "     599          1737   3.77741e-05       91.8163           1           1      970   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     683       1738.24   5.90244e-05       70.6997   1.282e-06       0.001     1115  LS failed, Hessian reset \n",
      "     699        1738.3   8.53738e-05       35.5966     0.08949     0.08949     1137   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     711       1738.35   5.51734e-05       76.1228   9.699e-07       0.001     1197  LS failed, Hessian reset \n",
      "     780       1738.51   3.27896e-05       39.1578   4.287e-07       0.001     1333  LS failed, Hessian reset \n",
      "     799       1738.54   1.03627e-05       39.0652      0.2805           1     1363   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     832       1738.55   6.12421e-05        81.512   1.255e-06       0.001     1442  LS failed, Hessian reset \n",
      "     866       1738.55   1.59518e-07       34.7117      0.1909           1     1489   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.79155\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1681.64    0.00516136       170.016      0.1371     0.01371      128   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1719.73    0.00462731       299.857           1           1      246   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1731.86    0.00181973       198.622       8.236      0.8236      370   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     352       1735.35   7.61463e-05       88.2542   4.472e-07       0.001      478  LS failed, Hessian reset \n",
      "     376       1736.15   8.53207e-05       75.9313   3.956e-07       0.001      541  LS failed, Hessian reset \n",
      "     399       1736.78   0.000392574       51.6597           1           1      575   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1738.19    0.00735883       133.449      0.6721      0.6721      701   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     516       1738.93   4.51678e-05       38.3385   3.749e-07       0.001      768  LS failed, Hessian reset \n",
      "     572        1739.6   6.60239e-05       72.4999   1.348e-06       0.001      880  LS failed, Hessian reset \n",
      "     599       1739.65   3.91405e-05       35.0552           1           1      919   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     646       1740.04    0.00045665       65.2115   4.189e-06       0.001     1018  LS failed, Hessian reset \n",
      "     674       1740.26   0.000185422       116.951   5.218e-06       0.001     1094  LS failed, Hessian reset \n",
      "     699       1740.33   0.000190761       45.2915           1           1     1126   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1740.57    0.00134651       283.865       0.516       0.516     1245   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1742.07   0.000678337       71.7623       1.235      0.2514     1375   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1742.32    0.00108625       54.7341           1           1     1492   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099        1742.4   1.26377e-05       37.8463           1           1     1616   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1742.48    0.00771514       192.996           1           1     1736   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1245       1742.53    4.5247e-05       46.4216   1.175e-06       0.001     1831  LS failed, Hessian reset \n",
      "    1299       1742.56   3.29355e-05       34.8172           1           1     1900   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1330       1742.56   4.09715e-07       33.0612           1           1     1941   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.90581\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1683.19     0.0116504       775.649           1           1      135   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1718.36    0.00732443       134.629           1           1      265   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1730.94    0.00340966       221.922      0.4943      0.4943      400   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399          1737    0.00403588       75.3459           1           1      539   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     491        1738.3   2.08364e-05       34.1491   5.553e-07       0.001      693  LS failed, Hessian reset \n",
      "     499       1738.32   0.000107274       38.2061      0.7415      0.7415      704   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1740.83   3.27779e-05       45.5798   5.278e-07       0.001      877  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     625       1741.28   3.13911e-05       40.3322   4.432e-07       0.001      961  LS failed, Hessian reset \n",
      "     642       1741.58   4.11947e-09       39.0967   4.028e-07           1     1009   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "Initial log joint probability = -4.51768\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1705.41     0.0359901       543.951           1           1      121   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     121       1708.93   0.000148969       120.619   2.748e-06       0.001      186  LS failed, Hessian reset \n",
      "     199       1718.77     0.0290737       328.606       2.281      0.2281      282   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1732.08    0.00394484       119.629           1           1      407   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1734.87    0.00262082       155.147           1           1      533   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499        1738.6    0.00279938       66.5106       0.983       0.983      663   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     550       1741.33   0.000451387       60.8442    1.21e-05       0.001      766  LS failed, Hessian reset \n",
      "     599       1741.63    0.00147495       69.0839          10           1      835   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     683       1743.28   3.72262e-05       50.8112   1.044e-06       0.001      981  LS failed, Hessian reset \n",
      "     699       1743.38    0.00196465       283.108       0.656       0.656     1001   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     750       1743.89   3.37326e-05       46.2489   9.035e-07       0.001     1116  LS failed, Hessian reset \n",
      "     799       1744.03    0.00113984       33.1726           1           1     1184   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     868       1744.73   4.69075e-05       63.6095   5.488e-07       0.001     1328  LS failed, Hessian reset \n",
      "     899       1745.22   0.000483811       30.8639      0.7304      0.7304     1365   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     922       1745.28   2.99544e-05       39.9606   4.687e-07       0.001     1434  LS failed, Hessian reset \n",
      "     962       1745.33   3.32921e-05        50.562    5.66e-07       0.001     1529  LS failed, Hessian reset \n",
      "     999       1745.35   6.10996e-05        35.141           1           1     1579   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1020       1745.39   3.24021e-05       44.0851   5.407e-07       0.001     1645  LS failed, Hessian reset \n",
      "    1099       1745.45   0.000972379       29.5412           1           1     1747   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1116       1745.66   0.000219532       158.301   2.114e-06       0.001     1805  LS failed, Hessian reset \n",
      "    1154       1745.84   2.90372e-05       49.1746   6.294e-07       0.001     1910  LS failed, Hessian reset \n",
      "    1191       1745.87   1.35686e-05       30.9786   5.001e-07       0.001     1997  LS failed, Hessian reset \n",
      "    1199       1745.87    5.9834e-07       25.6751       0.514       0.514     2008   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1210       1745.87   6.71156e-07       35.9265      0.2809           1     2037   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.58048\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1687.06     0.0143622       417.393           1           1      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1722.12    0.00778721       170.181           1           1      244   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1730.44     0.0253261       87.3327           1           1      366   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1744.93    0.00339347       71.3068       2.462      0.2462      500   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     415       1745.55   0.000804034       237.515   2.321e-05       0.001      599  LS failed, Hessian reset \n",
      "     499       1746.86   0.000148258       62.4218      0.3357      0.3357      714   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1748.39     0.0039625        177.92     0.08041      0.9004      843   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     601        1748.4   7.06369e-05       88.5243   4.677e-07       0.001      931  LS failed, Hessian reset \n",
      "     691       1749.63   5.17497e-05       64.6731   1.022e-06       0.001     1084  LS failed, Hessian reset \n",
      "     699       1749.64   6.46028e-05       38.2208      0.9671      0.9671     1093   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     737       1749.67   0.000100934       86.1413   2.596e-06       0.001     1185  LS failed, Hessian reset \n",
      "     764       1749.69   2.06852e-05       32.6248   5.389e-07       0.001     1259  LS failed, Hessian reset \n",
      "     784       1749.69   2.52792e-07       31.3325      0.1951           1     1286   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.32908\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1703.08     0.0267156       696.544           1           1      119   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199          1739     0.0263226       100.703           1           1      245   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1752.14   0.000980442       68.2819           1           1      360   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399          1758    0.00120015        100.56       0.458           1      486   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     438       1758.84   3.57028e-05       39.1162   3.885e-07       0.001      568  LS failed, Hessian reset \n",
      "     499       1760.66    0.00776379       286.846           1           1      651   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     542       1762.69    2.5733e-05        40.199   5.213e-07       0.001      750  LS failed, Hessian reset \n",
      "     590        1763.4   4.25907e-05       54.2563   4.121e-07       0.001      864  LS failed, Hessian reset \n",
      "     599       1763.45   7.41505e-05       44.2019     0.02138           1      881   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     683       1764.03    3.9738e-05       50.4921   3.776e-07       0.001     1049  LS failed, Hessian reset \n",
      "     699       1764.55     0.0012205       54.6916      0.2416           1     1070   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     744       1764.68   6.34665e-05       59.0493   1.905e-06       0.001     1161  LS failed, Hessian reset \n",
      "     799       1764.88   0.000816105       36.6337           1           1     1228   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1765.27    0.00544726       50.7213           1           1     1356   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     961        1765.4   0.000149003         46.72   2.889e-06       0.001     1489  LS failed, Hessian reset \n",
      "     999       1765.64    0.00063653        66.946      0.2611           1     1544   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1027        1765.7   2.22951e-05       35.1964   4.884e-07       0.001     1616  LS failed, Hessian reset \n",
      "    1099       1765.77   1.53827e-06       32.8358      0.3547           1     1713   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1194       1765.81   7.94874e-08       31.7799      0.3362           1     1853   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.74359\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        1699.3     0.0736856       372.155           1           1      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1735.54    0.00286302        740.67      0.4143      0.4143      241   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1764.44    0.00371878       204.988           1           1      367   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1768.95    0.00406845        116.65      0.4076     0.04076      495   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     462       1773.67   5.72355e-05       89.9577   5.996e-07       0.001      615  LS failed, Hessian reset \n",
      "     499       1775.04   0.000461933       224.411      0.3285           1      666   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     530       1775.38   5.44675e-05       82.9444   8.624e-07       0.001      744  LS failed, Hessian reset \n",
      "     543       1775.48   5.17801e-05       66.0098   1.472e-06       0.001      803  LS failed, Hessian reset \n",
      "     580       1776.44   3.41546e-05       43.8635   3.693e-07       0.001      898  LS failed, Hessian reset \n",
      "     599       1776.89    0.00309651       238.766       1.828      0.4217      927   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1778.27   0.000406736       98.6717           1           1     1063   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     713       1778.61   0.000329086       289.189   1.781e-06       0.001     1126  LS failed, Hessian reset \n",
      "     799       1779.09    0.00114829       83.1975           1           1     1239   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1779.47   0.000760399       49.0692           1           1     1367   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1779.78   6.80236e-06       28.5428           1           1     1495   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1779.91    0.00113567       51.4972      0.5694      0.5694     1618   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1151       1779.96   8.19779e-05       28.7861   3.062e-06       0.001     1720  LS failed, Hessian reset \n",
      "    1199       1780.01   9.40028e-05       57.1482      0.7829      0.7829     1774   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299        1780.1   1.91173e-06       30.1236      0.1056      0.1056     1908   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1344       1780.15    2.3102e-07       26.6686   9.249e-09       0.001     2008  LS failed, Hessian reset \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.6506\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1711.17     0.0185083       968.689           1           1      120   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1759.77     0.0115092       216.414      0.4538      0.4538      234   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1774.82    0.00810366       293.417      0.2593           1      352   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        1781.1   0.000888487        175.05      0.1276           1      488   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1785.08    0.00048018       267.113           1           1      618   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1787.43    0.00700505       53.3913      0.5209      0.5209      740   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     601       1787.46   4.94859e-05       71.0019   3.462e-07       0.001      782  LS failed, Hessian reset \n",
      "     699       1789.51    0.00042554       43.6433      0.2125      0.2125      903   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1790.05    0.00730249       53.9542      0.9121      0.9121     1019   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     837       1791.02   0.000290276       38.0425   3.144e-06       0.001     1113  LS failed, Hessian reset \n",
      "     881       1792.91    0.00027652       112.655   3.666e-06       0.001     1220  LS failed, Hessian reset \n",
      "     899       1793.11   0.000411081       58.4541      0.3044           1     1248   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     937       1793.27   2.23826e-05       39.3053   4.215e-07       0.001     1345  LS failed, Hessian reset \n",
      "     966       1793.32   3.39709e-05        55.509   4.926e-07       0.001     1429  LS failed, Hessian reset \n",
      "     978       1793.33   1.09411e-05       33.2744   3.093e-07       0.001     1486  LS failed, Hessian reset \n",
      "     999       1793.33   1.48934e-06       29.7774      0.4958      0.4958     1515   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1013       1793.35   2.29427e-05       41.7717   5.105e-07       0.001     1565  LS failed, Hessian reset \n",
      "    1039       1793.35   8.93274e-08        29.406      0.2966           1     1608   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.99472\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1748.77     0.0272884       332.472           1           1      136   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1788.75    0.00246635       204.754           1           1      250   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1810.33     0.0174034       190.302      0.6962     0.06962      369   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1815.54   0.000243361       55.2642           1           1      510   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     453       1821.43   0.000111924       102.173   2.882e-06       0.001      624  LS failed, Hessian reset \n",
      "     499       1822.99    0.00556053       85.2653      0.2189           1      690   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     541       1824.06   4.16716e-05       74.9367   9.167e-07       0.001      804  LS failed, Hessian reset \n",
      "     567       1824.51   5.72267e-05       75.7712   2.746e-07       0.001      885  LS failed, Hessian reset \n",
      "     599       1824.77   0.000845168       144.927           1           1      924   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699        1825.1   1.77964e-05       26.2367           1           1     1056   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799        1825.3    0.00443828       34.3264      0.4926           1     1183   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1826.07    0.00681434       99.4395           1           1     1304   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     942       1826.59   1.84757e-05       31.7325   2.823e-07       0.001     1410  LS failed, Hessian reset \n",
      "     999       1826.93   0.000248398        33.086      0.6841      0.6841     1489   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1051       1826.98   2.30039e-05       34.4543   8.775e-07       0.001     1601  LS failed, Hessian reset \n",
      "    1099       1827.03   0.000474482       172.081     0.04254      0.6086     1662   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1170       1827.17   0.000392584       72.2944    7.98e-06       0.001     1802  LS failed, Hessian reset \n",
      "    1199        1827.2   9.74458e-05       28.4939      0.3626      0.3626     1839   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1270       1827.23   7.01521e-08       29.7027      0.2786      0.2786     1933   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.6338\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1757.46     0.0940336       1195.91           1           1      116   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199          1812     0.0245488       250.607           1           1      236   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1849.26    0.00960483       1183.84           1           1      362   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     387       1859.69   0.000447945       252.415   7.335e-06       0.001      510  LS failed, Hessian reset \n",
      "     399       1860.19    0.00166009       196.338          10           1      524   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     458       1861.27   4.06033e-05        83.537    7.07e-07       0.001      655  LS failed, Hessian reset \n",
      "     499       1861.76    0.00137812       101.073           1           1      702   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1864.19    0.00319814       123.547           1           1      817   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1870.55    0.00649125       555.068      0.6814      0.6814      953   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     749       1873.44   1.53664e-05       40.6032   2.747e-07       0.001     1082  LS failed, Hessian reset \n",
      "     786       1874.36   6.71217e-05       143.377   9.133e-07       0.001     1166  LS failed, Hessian reset \n",
      "     799       1874.67   0.000448314       54.0841           1           1     1183   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     856       1875.06   4.32223e-05       80.0476   2.072e-07       0.001     1301  LS failed, Hessian reset \n",
      "     899       1875.38    0.00136145       47.5422           1           1     1362   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1877.37    0.00378235        113.28      0.4216      0.4216     1483   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1877.64    0.00576443       314.704           1           1     1602   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1116       1878.23   4.44889e-05        105.27   2.225e-07       0.001     1668  LS failed, Hessian reset \n",
      "    1157       1878.78   9.31451e-05       129.585   2.514e-06       0.001     1763  LS failed, Hessian reset \n",
      "    1199        1878.8   0.000156494       42.7608           1           1     1818   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1235       1878.83   2.83867e-05       72.3238   6.316e-07       0.001     1914  LS failed, Hessian reset \n",
      "    1299       1878.85    0.00045658       41.8177      0.4966      0.4966     2003   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399       1879.25    0.00158839       39.3476           1           1     2130   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1499       1880.29    0.00515942       116.504      0.3465           1     2261   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1500       1880.29   2.34262e-05       46.7379   2.011e-07       0.001     2331  LS failed, Hessian reset \n",
      "    1543       1880.56   0.000104069       56.4755    3.24e-06       0.001     2413  LS failed, Hessian reset \n",
      "    1554       1880.61   1.33323e-05       32.8315   2.253e-07       0.001     2473  LS failed, Hessian reset \n",
      "    1599       1880.67   1.16679e-05       35.1461      0.4987      0.4987     2539   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1691       1880.73   4.32625e-07       28.5565     0.08325           1     2677   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.40469\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1764.25     0.0163004       408.634           1           1      135   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1819.04     0.0128694       259.661           1           1      258   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1856.27     0.0388135       1155.87      0.4533           1      385   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1870.18   0.000668267       232.772      0.2439      0.2439      514   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1884.42     0.0119878       594.857      0.2089           1      641   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     558       1891.21   5.26388e-05       134.625   2.481e-07       0.001      752  LS failed, Hessian reset \n",
      "     599       1894.66    0.00915947       97.0845           1           1      804   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1898.17    0.00138484       60.7564           1           1      928   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1903.86    0.00144165       198.875           1           1     1056   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1906.15   0.000492814       142.246      0.9214      0.9214     1187   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     936       1906.41   3.09732e-05       70.9532   1.044e-06       0.001     1271  LS failed, Hessian reset \n",
      "     999       1906.61   2.77089e-05       39.4698      0.8899      0.8899     1356   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099        1907.5    0.00569966       76.7428           1           1     1477   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1169       1908.34   2.39109e-05       59.0939    2.03e-07       0.001     1617  LS failed, Hessian reset \n",
      "    1199       1908.73   0.000768992       98.2611      0.2202           1     1659   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1270        1908.9   4.40998e-05       90.3652   1.293e-06       0.001     1794  LS failed, Hessian reset \n",
      "    1299       1908.95   0.000673646       69.0576           1           1     1831   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1352       1909.03   2.15232e-05       58.4703   5.972e-07       0.001     1941  LS failed, Hessian reset \n",
      "    1399       1909.09   3.67518e-06       34.8317      0.2201      0.2201     2009   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1499       1909.35    0.00374848        53.432           1           1     2119   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1599       1909.74    0.00280182       99.7308           1           1     2248   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1663       1910.03   2.07518e-05       36.2975   1.725e-07       0.001     2375  LS failed, Hessian reset \n",
      "    1699        1910.1   0.000303067       88.2035      0.3527      0.3527     2420   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1743       1910.17   1.99999e-05       38.8595   1.758e-07       0.001     2530  LS failed, Hessian reset \n",
      "    1790       1910.21    5.8751e-06       30.8097   1.906e-07       0.001     2634  LS failed, Hessian reset \n",
      "    1799       1910.21   2.48108e-05       41.3904           1           1     2647   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1838       1910.23   2.18579e-05       30.3482   1.649e-07       0.001     2749  LS failed, Hessian reset \n",
      "    1899       1910.25   0.000148261       46.9746           1           1     2827   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1905       1910.25   5.06914e-06       31.8841   1.898e-07       0.001     2880  LS failed, Hessian reset \n",
      "    1999       1910.32    0.00121334       98.0557     0.06288      0.7928     3001   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2000       1910.32   1.78514e-05       41.5652   1.821e-07       0.001     3041  LS failed, Hessian reset \n",
      "    2030       1910.36   3.24085e-05       49.7295   1.126e-06       0.001     3116  LS failed, Hessian reset \n",
      "    2099       1910.37   0.000224005       38.8687           1           1     3218   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2158       1910.38    2.1678e-07        27.736      0.2415           1     3297   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.74879\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1830.93     0.0583562        300.25       4.267     0.04267      137   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1871.02     0.0134601       612.124           1           1      255   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1880.08     0.0382894       963.356           1           1      382   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1892.06    0.00731327       378.616           1           1      499   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1896.86     0.0185561       548.822           1           1      629   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     515       1897.86   2.90686e-05       76.9925   4.325e-07       0.001      690  LS failed, Hessian reset \n",
      "     599       1899.06   0.000840203       155.848      0.9253      0.9253      792   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1903.41    0.00510569       104.102           1           1      918   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     737       1904.34   0.000143291       308.379   9.813e-07       0.001     1024  LS failed, Hessian reset \n",
      "     799       1905.18   0.000101106       57.5612      0.2129           1     1105   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     877       1906.03   3.31769e-05       74.1893   6.811e-07       0.001     1272  LS failed, Hessian reset \n",
      "     899       1906.31   2.54019e-05       30.0324   1.766e-07       0.001     1344  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     909       1906.38   1.39692e-05       20.7825   1.807e-07       0.001     1402  LS failed, Hessian reset \n",
      "     941       1906.43   0.000155848       29.9544   5.585e-06       0.001     1489  LS failed, Hessian reset \n",
      "     962       1906.44    1.3016e-05       31.9518   2.515e-07       0.001     1562  LS failed, Hessian reset \n",
      "     999       1906.44   0.000140339       29.1071      0.8958      0.8958     1608   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1097       1906.55   1.97284e-05       54.7979   2.789e-07       0.001     1793  LS failed, Hessian reset \n",
      "    1099       1906.56   0.000101506       41.0818           1           1     1796   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1159        1906.6   8.56793e-06       23.0421   3.015e-07       0.001     1915  LS failed, Hessian reset \n",
      "    1187        1906.6   8.95699e-07       18.1006   4.048e-08       0.001     1995  LS failed, Hessian reset \n",
      "    1188        1906.6    2.8618e-07       13.7452      0.9918      0.9918     1996   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.97127\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1788.24     0.0724107       374.521           1           1      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1850.15     0.0233224       596.116           1           1      245   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1890.04    0.00315257       184.815      0.7211      0.7211      366   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1910.99    0.00785134       251.793      0.3869      0.3869      493   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     419       1914.27    7.2058e-05       200.179   3.739e-07       0.001      559  LS failed, Hessian reset \n",
      "     476       1916.12   1.97417e-05       51.1073   2.399e-07       0.001      680  LS failed, Hessian reset \n",
      "     499       1916.29    0.00479861       36.9486           1           1      706   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     533       1917.19   1.71228e-05       47.8523   3.615e-07       0.001      792  LS failed, Hessian reset \n",
      "     599       1917.63   5.36427e-05       31.6514           1           1      873   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     619       1917.66   1.76732e-05       41.6654   2.194e-07       0.001      932  LS failed, Hessian reset \n",
      "     699       1918.17   0.000109005       72.2888      0.2414      0.6688     1044   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1918.29     0.0003695       35.5602           1           1     1184   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1918.35   0.000545712       100.896      0.9472      0.9472     1316   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1919.13    0.00370687       82.3395      0.1518      0.6149     1443   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1919.46    0.00129059        29.431       2.068      0.5919     1583   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1919.54   3.96314e-06       25.3577    0.008566           1     1717   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1214       1919.54   1.35964e-05       39.2647    2.56e-07       0.001     1782  LS failed, Hessian reset \n",
      "    1231       1919.54   4.99342e-06        33.779   1.832e-07       0.001     1842  LS failed, Hessian reset \n",
      "    1259       1919.54   2.02452e-05       38.1997    6.98e-07       0.001     1917  LS failed, Hessian reset \n",
      "    1299       1919.55   2.76418e-06        31.793           1           1     1978   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1350       1919.56   9.23089e-07       29.6129           1           1     2052   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.86258\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1802.45    0.00461345       301.756           1           1      117   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1868.19     0.0134375       349.814       1.408      0.1408      232   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1892.89    0.00679082       285.519           1           1      346   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1899.62     0.0150622        267.12      0.2855           1      469   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1909.98   0.000582306        356.61      0.2832      0.2832      600   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1914.38   0.000248406       45.8014      0.4693      0.4693      732   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1915.53    0.00218566       267.858      0.1943           1      858   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1917.58    0.00141633       250.081      0.2505           1     1000   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     845       1917.75   2.05858e-05       47.2351   2.033e-07       0.001     1100  LS failed, Hessian reset \n",
      "     872       1917.95   7.77678e-06       21.5476   2.354e-07       0.001     1198  LS failed, Hessian reset \n",
      "     899       1917.99   8.58981e-05       25.5749      0.7501     0.01398     1240   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     900       1917.99   2.90455e-05        34.082   1.136e-06       0.001     1279  LS failed, Hessian reset \n",
      "     999       1919.98     0.0333144       282.841           1           1     1413   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1078       1922.48   5.89267e-05        137.15   6.125e-07       0.001     1593  LS failed, Hessian reset \n",
      "    1099       1922.83    0.00101973       227.544      0.7664      0.7664     1617   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1923.76    0.00332273       69.9863      0.3978           1     1748   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1233        1923.9   1.25055e-05       29.1583   1.831e-07       0.001     1839  LS failed, Hessian reset \n",
      "    1285          1924   0.000232674       183.865   6.755e-06       0.001     1943  LS failed, Hessian reset \n",
      "    1299       1924.03   9.42823e-05       32.9234      0.5201      0.5201     1959   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1317       1924.04   2.57639e-05       63.3335   6.886e-07       0.001     2023  LS failed, Hessian reset \n",
      "    1382       1924.11   1.52878e-05       35.2448   1.823e-07       0.001     2155  LS failed, Hessian reset \n",
      "    1399       1924.14    0.00087572       171.798      0.7561      0.7561     2176   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1428       1924.17   1.39504e-05       37.3744   4.052e-07       0.001     2261  LS failed, Hessian reset \n",
      "    1451       1924.18    3.3557e-05       35.4897    1.16e-06       0.001     2328  LS failed, Hessian reset \n",
      "    1465       1924.18   2.95404e-06       22.7056   1.079e-07       0.001     2380  LS failed, Hessian reset \n",
      "    1470       1924.18   5.84842e-07       21.4163      0.8864      0.8864     2389   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.68773\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1807.87     0.0782544       1259.31           1           1      129   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1867.12      0.024502       206.278      0.5908           1      245   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1890.28    0.00682954       208.512           1           1      371   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399          1900     0.0111476        525.31      0.8088      0.8088      490   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499        1911.9     0.0102146        464.72           1           1      623   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     536       1915.26   4.96005e-05       93.2768   1.853e-07       0.001      734  LS failed, Hessian reset \n",
      "     599       1916.96     0.0121491       218.516           1           1      808   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1921.22    0.00331252       68.2761           1           1      934   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     733       1922.18   2.37408e-05       66.5653    2.31e-07       0.001     1029  LS failed, Hessian reset \n",
      "     799       1923.09   0.000809294       138.444           1           1     1117   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     808       1923.27   3.86453e-05       112.023   2.305e-07       0.001     1167  LS failed, Hessian reset \n",
      "     899       1923.69   0.000277617       86.2745           1           1     1288   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1924.07    0.00523393       85.2381           1           1     1428   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1067       1924.49   4.61953e-05         97.77   1.034e-06       0.001     1555  LS failed, Hessian reset \n",
      "    1099       1924.53   0.000124783       52.8778           1           1     1596   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1925.26     0.0157815        251.31           1           1     1714   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299        1926.7   0.000359248        115.74           1           1     1835   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399       1927.02    0.00152797       31.5935      0.3967           1     1962   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1499       1927.19    0.00160887       77.5419      0.2094           1     2091   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1501        1927.2   1.56438e-05       48.6548     2.5e-07       0.001     2145  LS failed, Hessian reset \n",
      "    1548       1927.26   3.49668e-05       74.9863    9.73e-07       0.001     2243  LS failed, Hessian reset \n",
      "    1599       1927.28    0.00105619       36.4074           1           1     2307   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1665       1927.93   3.57575e-05       72.1037    9.04e-07       0.001     2437  LS failed, Hessian reset \n",
      "    1699       1927.97   0.000624914       86.3304        0.15           1     2481   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1787        1928.1   1.55205e-05       49.5486   2.752e-07       0.001     2646  LS failed, Hessian reset \n",
      "    1799       1928.14   0.000125466       32.6065      0.2561      0.2561     2661   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1863       1928.15   2.34223e-07       31.6145     0.08808           1     2756   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.50969\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1820.66    0.00229915       537.249      0.2604      0.2604      135   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1898.37     0.0106006       254.113       1.288      0.1288      258   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299        1912.2    0.00192194       299.056      0.2322      0.2322      374   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     352       1917.46   7.92484e-05       210.792   1.938e-07       0.001      486  LS failed, Hessian reset \n",
      "     399       1922.09    0.00677534       641.798      0.1077           1      551   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1926.88    0.00623782       370.028     0.06069           1      672   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1931.22    0.00673673       241.883      0.5219      0.5219      806   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1932.56    0.00206675       67.8991      0.4005      0.8569      931   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     750       1933.45   1.10867e-05       36.5888   1.881e-07       0.001     1033  LS failed, Hessian reset \n",
      "     799       1933.69   9.84401e-05       34.7489      0.9558      0.9558     1094   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1934.19    0.00921338        313.86           1           1     1224   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1934.76   0.000347922       35.2687           1           1     1358   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1936.01     0.0120039        289.82      0.4241           1     1484   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1101       1936.05   5.02542e-05       90.8116   1.706e-07       0.001     1527  LS failed, Hessian reset \n",
      "    1136        1936.3   1.14758e-05       29.3786   1.972e-07       0.001     1625  LS failed, Hessian reset \n",
      "    1165       1936.37   0.000122626       234.042   7.723e-07       0.001     1715  LS failed, Hessian reset \n",
      "    1199       1936.41   3.82099e-05       22.5309           1           1     1763   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1203       1936.42   1.41398e-05       37.2466   6.493e-07       0.001     1809  LS failed, Hessian reset \n",
      "    1246       1936.43   1.48717e-05       50.2079   2.943e-07       0.001     1899  LS failed, Hessian reset \n",
      "    1299       1936.43   0.000167003       21.3279      0.3768           1     1967   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399       1936.56   0.000817732       23.4423           1           1     2098   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1494       1936.65   3.02977e-05       81.2118   7.442e-07       0.001     2267  LS failed, Hessian reset \n",
      "    1499       1936.65    5.5064e-06       22.6995      0.4126      0.4126     2273   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1542       1936.66   1.24716e-05       38.6278   2.288e-07       0.001     2373  LS failed, Hessian reset \n",
      "    1568       1936.66   7.31287e-06       23.3954   2.747e-07       0.001     2457  LS failed, Hessian reset \n",
      "    1576       1936.66   6.72801e-07       15.2774     2.3e-08       0.001     2507  LS failed, Hessian reset \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.31693\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1812.68   0.000474157       438.876      0.3137      0.3137      131   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1865.53    0.00315815       620.488           1           1      253   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1915.74    0.00583537       353.852           1           1      376   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1925.45    0.00536723       91.6115           1           1      488   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1931.34   3.17052e-05       70.6763   1.949e-07       0.001      642  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     569       1934.05   2.98236e-05       76.1293   5.631e-07       0.001      778  LS failed, Hessian reset \n",
      "     599        1934.4    0.00071285       103.594           1           1      810   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     610       1934.51   1.21533e-05       34.8218   2.395e-07       0.001      855  LS failed, Hessian reset \n",
      "     671       1935.94   2.90209e-05       78.7154    2.27e-07       0.001      973  LS failed, Hessian reset \n",
      "     697        1936.5   3.04358e-05       62.4674   1.074e-06       0.001     1050  LS failed, Hessian reset \n",
      "     699        1936.5   5.98344e-05       38.4715           1           1     1052   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     740       1936.68   1.35374e-05       39.7944   2.459e-07       0.001     1145  LS failed, Hessian reset \n",
      "     799       1936.96   0.000743821       96.9556           1           1     1217   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     865       1937.17   1.81224e-05       53.6967   2.723e-07       0.001     1335  LS failed, Hessian reset \n",
      "     899       1937.19   0.000199938       36.7752      0.9079      0.9079     1374   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1937.92     0.0105294       230.239           1           1     1504   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1939.72     0.0536175       36.2846           1           1     1630   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1940.17   0.000336845       30.0168      0.4951      0.4951     1776   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1290       1940.34   2.04685e-05         29.61   1.535e-07       0.001     1939  LS failed, Hessian reset \n",
      "    1299       1940.34   1.63915e-05       21.4695      0.1968           1     1951   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1315       1940.39   5.01433e-05       90.2849   9.125e-07       0.001     2007  LS failed, Hessian reset \n",
      "    1399       1940.44   0.000270405       72.8508           1           1     2115   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1484       1940.65   0.000150812       114.926   1.648e-06       0.001     2265  LS failed, Hessian reset \n",
      "    1499       1940.73   0.000113863       73.9318           1           1     2286   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1503       1940.73   1.05865e-05       33.6434   4.223e-07       0.001     2334  LS failed, Hessian reset \n",
      "    1526       1940.74   1.09282e-05       30.3185   1.884e-07       0.001     2415  LS failed, Hessian reset \n",
      "    1556       1940.74   5.59457e-06       21.0591   2.048e-07       0.001     2497  LS failed, Hessian reset \n",
      "    1576       1940.74   1.14587e-07       18.2224      0.1912      0.8134     2534   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.87614\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1809.65     0.0315666       224.447           1           1      130   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        1877.6     0.0163491       184.352           1           1      248   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299        1917.7     0.0205957       1030.14           1           1      386   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1926.89    0.00798832       460.866      0.1499      0.9188      517   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     406       1927.24   2.99431e-05       62.9621   1.849e-07       0.001      565  LS failed, Hessian reset \n",
      "     499       1931.53    0.00269263        58.449           1           1      682   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1934.16    0.00128254       52.2758           1           1      812   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     676        1934.9   0.000742926       84.3323   2.933e-05       0.001      948  LS failed, Hessian reset \n",
      "     699       1934.99   0.000238223       47.8066      0.0852           1      979   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1939.55   0.000829517       66.1943           1           1     1111   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     881       1941.44   9.88429e-06       32.3375    2.24e-07       0.001     1277  LS failed, Hessian reset \n",
      "     899       1941.63   0.000297013       82.7995      0.3642      0.3642     1301   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     929       1941.83   1.12529e-05       38.3616   3.744e-07       0.001     1385  LS failed, Hessian reset \n",
      "     999       1941.99     0.0017225       119.421      0.2232           1     1468   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1048        1942.1   2.45199e-05       65.4099   5.567e-07       0.001     1568  LS failed, Hessian reset \n",
      "    1099       1942.17   0.000219203       23.1968      0.2932           1     1634   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1181       1944.19   3.78822e-05       81.7954   1.551e-07       0.001     1810  LS failed, Hessian reset \n",
      "    1199       1944.73   0.000152999       179.481      0.1565      0.1565     1832   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1215       1944.87   9.79183e-06       29.8916   1.817e-07       0.001     1895  LS failed, Hessian reset \n",
      "    1231       1944.96    2.9485e-05       53.5368   1.081e-06       0.001     1951  LS failed, Hessian reset \n",
      "    1240       1944.99   1.61198e-05       40.7901   1.619e-07       0.001     2007  LS failed, Hessian reset \n",
      "    1299       1945.18   0.000180042       65.7038           1           1     2083   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1365        1945.2    1.4369e-05       18.4489      0.5768      0.5768     2169   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.95852\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1817.89     0.0419363       788.599      0.9254      0.9254      123   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1878.04     0.0472404       1074.49           1           1      248   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     282       1907.17    2.7717e-05       81.2644   3.748e-07       0.001      392  LS failed, Hessian reset \n",
      "     299       1909.21   0.000727685       187.116           1           1      411   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1920.33    0.00106052       94.8004           1           1      537   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1925.51     0.0016373       98.5444     0.09029           1      658   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1929.81   0.000920974       48.8447       1.812     0.03785      792   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1934.51    0.00115392       109.499       3.027      0.3027      921   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     743       1936.13   1.35343e-05       43.1494   2.388e-07       0.001     1014  LS failed, Hessian reset \n",
      "     771       1936.63   1.64653e-05       46.8824   1.916e-07       0.001     1100  LS failed, Hessian reset \n",
      "     799       1936.85   0.000466984       197.213      0.7406     0.07406     1147   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     836        1937.1   2.04117e-05        33.305   1.579e-07       0.001     1235  LS failed, Hessian reset \n",
      "     899       1937.97   0.000231681        35.764           1           1     1306   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     941       1938.72    4.8791e-05       145.012   3.515e-07       0.001     1414  LS failed, Hessian reset \n",
      "     999       1939.05   0.000725053        54.991           1           1     1488   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1005       1939.07   8.53647e-06       29.1468   2.829e-07       0.001     1532  LS failed, Hessian reset \n",
      "    1016       1939.08    1.5093e-05       45.8135    4.79e-07       0.001     1583  LS failed, Hessian reset \n",
      "    1099       1939.26   0.000371022       127.881           1           1     1701   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1143       1940.43   0.000206041       161.077   6.339e-06       0.001     1804  LS failed, Hessian reset \n",
      "    1175       1940.76   6.68573e-06       23.1077   2.631e-07       0.001     1895  LS failed, Hessian reset \n",
      "    1199       1940.84    0.00022719       92.5684      0.7604      0.7604     1923   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1223       1940.89   2.26949e-05       48.7214   1.612e-07       0.001     1995  LS failed, Hessian reset \n",
      "    1249       1940.95    2.9316e-05       68.2571   8.678e-07       0.001     2080  LS failed, Hessian reset \n",
      "    1299       1941.15   0.000572126       70.6386      0.1646           1     2145   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399       1943.36      0.016872       267.804           1           1     2281   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1499       1945.44    0.00504527       360.142           1           1     2415   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1599       1946.03    0.00601659       190.592           1           1     2541   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1695       1946.74   9.95865e-06       34.9009   2.082e-07       0.001     2695  LS failed, Hessian reset \n",
      "    1699       1946.74   6.75484e-05       63.8754           1           1     2699   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1760       1946.93   0.000373314       218.434   1.041e-05       0.001     2856  LS failed, Hessian reset \n",
      "    1799       1947.01   6.83201e-05       27.7281           1           1     2911   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1838       1947.03   4.02588e-05       43.0271   1.256e-06       0.001     3021  LS failed, Hessian reset \n",
      "    1874       1947.06   2.08719e-05       54.5155   7.438e-07       0.001     3100  LS failed, Hessian reset \n",
      "    1899       1947.06   7.74575e-07        23.626      0.1733           1     3135   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1910       1947.06   2.65409e-05        63.053    6.93e-07       0.001     3193  LS failed, Hessian reset \n",
      "    1923       1947.07   4.00238e-06       15.4456    1.86e-07       0.001     3249  LS failed, Hessian reset \n",
      "    1928       1947.07    2.3838e-07       23.6978   1.108e-08       0.001     3303  LS failed, Hessian reset \n",
      "    1929       1947.07   1.05838e-07       15.4221      0.3362           1     3305   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.04649\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        1786.5      0.281331       1972.33           1           1      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1871.92     0.0006722       149.416           1           1      248   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299        1911.6    0.00161822       130.914           1           1      378   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1921.32    0.00280517       185.313           1           1      502   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1927.15    0.00144992       234.805           1           1      616   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     561       1937.89   3.70215e-05       102.921   6.182e-07       0.001      740  LS failed, Hessian reset \n",
      "     599       1939.29   0.000198423       125.418     0.08931      0.3093      789   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1940.07    0.00178003        43.041      0.7193      0.7193      923   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1940.71   0.000404289       107.197      0.6416      0.6416     1060   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1941.02    1.4502e-05       39.2382   1.815e-07       0.001     1244  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     914       1941.05   1.09315e-05       34.5434   4.727e-07       0.001     1298  LS failed, Hessian reset \n",
      "     932       1941.06    1.1378e-05       35.7961   2.017e-07       0.001     1370  LS failed, Hessian reset \n",
      "     999       1941.14   0.000615247       42.1234      0.2462           1     1452   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1012       1941.15   8.75881e-06        31.294   2.313e-07       0.001     1518  LS failed, Hessian reset \n",
      "    1099       1941.19   0.000632651       27.7708           1           1     1631   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1941.34   6.17726e-05       21.8913      0.9466      0.9466     1759   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1205       1941.34   5.65057e-06       25.1058   2.899e-07       0.001     1816  LS failed, Hessian reset \n",
      "    1213       1941.34   1.31779e-06       24.3699   4.785e-08       0.001     1871  LS failed, Hessian reset \n",
      "    1216       1941.34   3.27458e-07       18.5736      0.8344      0.8344     1874   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.0971\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1812.35    0.00482588       170.435           1           1      136   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1870.94       0.12627       1028.17      0.9169      0.9169      265   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1920.15     0.0402771       908.093           1           1      387   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1936.53     0.0105685       98.8878           1           1      510   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1942.89   0.000277997       87.8819           1           1      632   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1948.15    0.00185784       158.019      0.6741      0.6741      754   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1950.03    0.00104352       33.1969       1.836      0.1836      898   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799        1953.1     0.0004488       56.6553      0.1634      0.3855     1035   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1953.42    0.00102744       144.443      0.2843           1     1173   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1954.05    0.00217731       127.812           1           1     1293   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1954.99    0.00385797       112.355           1           1     1434   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1173       1955.43    1.2061e-05       42.8491   2.041e-07       0.001     1580  LS failed, Hessian reset \n",
      "    1199       1955.47   5.60856e-05       36.8082      0.2537           1     1624   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1296       1955.57   7.59789e-06       21.9861   1.603e-07       0.001     1780  LS failed, Hessian reset \n",
      "    1299       1955.57   0.000164893       37.2067           1           1     1784   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1344       1955.59   1.58784e-05       28.8979   7.443e-07       0.001     1910  LS failed, Hessian reset \n",
      "    1399       1955.59   0.000101123       28.8597       3.907      0.3907     1985   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1475       1955.67   1.39833e-05       48.4569   1.764e-07       0.001     2128  LS failed, Hessian reset \n",
      "    1499       1955.68   8.17526e-05         26.35      0.8415      0.8415     2169   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1525       1955.68   1.97979e-06       19.4441   7.379e-08       0.001     2252  LS failed, Hessian reset \n",
      "    1534       1955.68   3.93077e-07       26.4545      0.1979           1     2265   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.44921\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1849.85      0.137654       174.774           1           1      132   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1885.15     0.0317154       190.602           1           1      253   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1936.33    0.00986791       641.781           1           1      367   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1950.94    0.00995705       110.495      0.4898      0.4898      486   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1957.32    0.00252721       240.311           1           1      614   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     543       1963.83   2.88124e-05       74.7947   1.795e-07       0.001      718  LS failed, Hessian reset \n",
      "     571       1966.24   0.000276389        293.57   5.999e-06       0.001      796  LS failed, Hessian reset \n",
      "     599       1966.76    0.00142284       379.147           1           1      830   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1971.37    0.00152374        100.66      0.2509           1      956   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1977.85     0.0130908       535.593           1           1     1075   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1980.13      0.012078       301.438       5.298      0.5298     1196   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     975       1981.88   1.38675e-05       36.7018   1.414e-07       0.001     1335  LS failed, Hessian reset \n",
      "     999       1982.25   0.000906178        127.57      0.3963           1     1373   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1003       1982.26   4.41101e-05        90.559   1.483e-06       0.001     1422  LS failed, Hessian reset \n",
      "    1099       1983.04    0.00017502       83.5377     0.03692           1     1542   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1119       1983.21   5.03005e-05       104.836   8.438e-07       0.001     1604  LS failed, Hessian reset \n",
      "    1140       1983.27   9.22768e-06       38.8868    3.57e-07       0.001     1667  LS failed, Hessian reset \n",
      "    1199        1983.4   0.000311324       59.5197      0.3338     0.03338     1737   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1290       1984.66   4.00346e-05       136.933   4.798e-07       0.001     1937  LS failed, Hessian reset \n",
      "    1299       1984.99    0.00112294       144.818           1           1     1947   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1352       1985.27   1.91969e-05       21.0639   1.236e-07       0.001     2060  LS failed, Hessian reset \n",
      "    1362        1985.3   3.08176e-05        114.99   1.959e-07       0.001     2123  LS failed, Hessian reset \n",
      "    1399       1985.38   2.21329e-05       29.5665      0.1674      0.1674     2168   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1401       1985.38   1.13484e-05       44.3175   2.862e-07       0.001     2208  LS failed, Hessian reset \n",
      "    1419       1985.39   8.05752e-06       25.7211   1.467e-07       0.001     2287  LS failed, Hessian reset \n",
      "    1481       1985.45    6.7827e-06       25.8381   2.935e-07       0.001     2406  LS failed, Hessian reset \n",
      "    1499       1985.45   5.34706e-07       25.6396      0.4454      0.4454     2435   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1560       1985.73   2.82261e-05       101.142   3.371e-07       0.001     2547  LS failed, Hessian reset \n",
      "    1599       1985.91    0.00076409       111.667           1           1     2593   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1645       1985.99   5.05371e-09       44.9429   2.196e-06           1     2680   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "Initial log joint probability = -3.06568\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1842.14     0.0145886       1000.64      0.1969      0.1969      134   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1913.03   0.000962547        418.03      0.4111      0.4111      256   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1937.73   0.000213038       180.259           1           1      386   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        1948.2     0.0398056       753.681           1           1      497   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1955.67     0.0142319       365.899         1.2       0.012      619   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1958.76    0.00329317       173.074       0.364           1      752   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1961.08    0.00584522       161.055           1           1      872   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     728       1962.54   0.000199057       242.917   3.642e-06       0.001      951  LS failed, Hessian reset \n",
      "     799       1965.24   0.000200106       128.466           1           1     1036   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1966.57    0.00354844       71.5076      0.3524           1     1171   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1968.79   0.000822115       287.789      0.1872      0.1872     1297   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1970.02   0.000154966       46.1305      0.4524      0.4524     1418   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1970.84   0.000339067       248.241      0.6806      0.6806     1556   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299       1973.81    0.00121828       103.871           1           1     1673   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1333       1974.07   1.46793e-05       52.8207    2.98e-07       0.001     1756  LS failed, Hessian reset \n",
      "    1377       1974.16   8.20551e-06       22.8185   1.525e-07       0.001     1856  LS failed, Hessian reset \n",
      "    1399       1974.17   0.000399132        34.048           1           1     1884   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1491       1975.11   7.06605e-06       27.2102   2.418e-07       0.001     2062  LS failed, Hessian reset \n",
      "    1499       1975.13   0.000840943       139.827           1           1     2071   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1506       1975.15    1.2037e-05       25.3485   1.399e-07       0.001     2122  LS failed, Hessian reset \n",
      "    1588       1975.33   1.05767e-05       37.1011     4.8e-07       0.001     2277  LS failed, Hessian reset \n",
      "    1599       1975.33    0.00031376       49.3279      0.2578           1     2294   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1699       1975.58    0.00964041        92.916           1           1     2433   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1709       1975.61   1.25707e-05       33.6325   1.502e-07       0.001     2506  LS failed, Hessian reset \n",
      "    1793       1975.91   9.40133e-06       36.3371   2.503e-07       0.001     2674  LS failed, Hessian reset \n",
      "    1799       1975.93   5.69717e-05       73.6555      0.1409      0.5074     2682   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1807       1975.94   9.15321e-05       37.4999   5.857e-06       0.001     2732  LS failed, Hessian reset \n",
      "    1837       1975.95   1.95982e-05       67.2135   3.284e-07       0.001     2813  LS failed, Hessian reset \n",
      "    1886       1975.99   5.20871e-05       104.465   1.606e-06       0.001     2914  LS failed, Hessian reset \n",
      "    1899          1976   3.50857e-05       59.5729      0.3476           1     2930   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1999        1976.1     0.0042959       44.6591           1           1     3061   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2096       1976.68   1.24728e-05       46.6427   3.545e-07       0.001     3237  LS failed, Hessian reset \n",
      "    2099       1976.69    0.00036077       80.1997           1           1     3241   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2108       1976.69   2.31734e-06       21.0884   1.053e-07       0.001     3292  LS failed, Hessian reset \n",
      "    2123       1976.69   6.48903e-06        19.792   1.558e-07       0.001     3350  LS failed, Hessian reset \n",
      "    2173       1976.78   7.89984e-06       30.9997   2.334e-07       0.001     3461  LS failed, Hessian reset \n",
      "    2189        1976.8   1.20489e-05        45.239   2.998e-07       0.001     3527  LS failed, Hessian reset \n",
      "    2199        1976.8   1.11993e-05       16.1423       1.767      0.1767     3539   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2299       1976.83   2.52501e-05       32.6186      0.6943      0.6943     3677   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2399       1976.92   0.000383128       70.1141       0.834       0.834     3815   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2499       1977.35   0.000390593       31.2684      0.8937     0.04882     3950   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2529       1977.41   9.63953e-06       33.7495   1.761e-07       0.001     4047  LS failed, Hessian reset \n",
      "    2568       1977.48   7.94858e-06       30.8046   2.655e-07       0.001     4147  LS failed, Hessian reset \n",
      "    2590        1977.5   7.29071e-05       21.8659   4.239e-06       0.001     4210  LS failed, Hessian reset \n",
      "    2599        1977.5   1.45848e-05       24.2228       2.822      0.2822     4224   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2601        1977.5   5.73998e-06       27.7123    2.45e-07       0.001     4267  LS failed, Hessian reset \n",
      "    2640        1977.5   1.25647e-05       45.6703   4.033e-07       0.001     4369  LS failed, Hessian reset \n",
      "    2699       1977.52   3.14551e-05       29.1813      0.8926      0.8926     4441   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2780       1977.62   5.07886e-06       18.4591   1.736e-07       0.001     4588  LS failed, Hessian reset \n",
      "    2790       1977.62   8.97382e-05       95.7539   3.125e-06       0.001     4641  LS failed, Hessian reset \n",
      "    2799       1977.62   1.09423e-05       20.4477      0.3042           1     4652   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2800       1977.62   4.45823e-06       19.0858    2.18e-07       0.001     4693  LS failed, Hessian reset \n",
      "    2827       1977.62   4.12638e-07       16.0004      0.5475      0.5475     4742   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.68205\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        1840.9      0.011162       1112.65      0.5212      0.5212      140   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        1893.5    0.00168604       84.5682           1           1      267   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1924.75     0.0107242       117.507           1           1      380   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1937.67     0.0234186       179.237           1           1      504   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1946.74    0.00404884       140.099           1           1      621   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599        1951.9    0.00335877        234.66      0.2637      0.2637      741   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     608       1952.29   3.13223e-05       89.4204   1.708e-07       0.001      807  LS failed, Hessian reset \n",
      "     699       1954.98    0.00126804        317.52           1           1      913   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     734       1955.49    9.6114e-06        24.085    1.59e-07       0.001     1014  LS failed, Hessian reset \n",
      "     799        1955.9     0.0170132       223.319      0.3286           1     1101   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     807       1956.09   1.52721e-05       25.0239   1.436e-07       0.001     1159  LS failed, Hessian reset \n",
      "     826       1956.19   1.34542e-05       44.4395   1.983e-07       0.001     1219  LS failed, Hessian reset \n",
      "     899       1956.32   0.000170802       36.5115          10           1     1312   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     904       1956.33   1.72472e-05       50.1521   1.779e-07       0.001     1354  LS failed, Hessian reset \n",
      "     964       1956.42   2.30802e-05        57.899   8.649e-07       0.001     1473  LS failed, Hessian reset \n",
      "     987       1956.43   9.17572e-06       36.4082   4.087e-07       0.001     1547  LS failed, Hessian reset \n",
      "     999       1956.44   0.000297952       127.945           1           1     1564   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1067       1956.57   3.70782e-05       71.7638   1.157e-06       0.001     1712  LS failed, Hessian reset \n",
      "    1094       1956.66   3.10135e-05       61.5302   1.375e-06       0.001     1787  LS failed, Hessian reset \n",
      "    1099       1956.67   5.66413e-05       27.7672           1           1     1793   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1162       1956.76   9.03465e-06       30.1942   4.253e-07       0.001     1934  LS failed, Hessian reset \n",
      "    1178       1956.76   3.16097e-07       18.0073      0.3076      0.3076     1963   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.62343\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1843.56     0.0459359       616.392      0.8426      0.8426      133   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1905.16     0.0379647       761.097      0.8434      0.8434      247   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1932.07      0.187978       345.779           1           1      362   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1939.93      0.001968       60.0252           1           1      495   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1941.62    0.00148154       79.4411      0.2056      0.2056      623   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1943.16    0.00377425       192.282      0.7207      0.7207      752   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     664       1945.78   6.73019e-05       101.404   1.873e-06       0.001      883  LS failed, Hessian reset \n",
      "     699       1946.01    0.00221743       232.305           1           1      922   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1946.39    4.0816e-05        22.198      0.9149      0.9149     1064   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1947.12    0.00162224       46.4145      0.4946           1     1194   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     911       1947.24   8.70061e-06       28.2246   2.362e-07       0.001     1267  LS failed, Hessian reset \n",
      "     926       1947.32   1.20311e-05       33.4688   1.925e-07       0.001     1329  LS failed, Hessian reset \n",
      "     947       1947.36   1.46653e-05       46.3997   2.323e-07       0.001     1400  LS failed, Hessian reset \n",
      "     978        1947.4    2.2019e-05       42.6248    1.65e-07       0.001     1478  LS failed, Hessian reset \n",
      "     999       1947.43   7.66174e-06       27.7951     0.08363           1     1514   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1044       1947.49   1.94827e-05       49.0719   1.852e-07       0.001     1623  LS failed, Hessian reset \n",
      "    1077       1947.54   7.59778e-06       30.5242   2.776e-07       0.001     1706  LS failed, Hessian reset \n",
      "    1087       1947.54    1.4128e-05       38.8517   4.577e-07       0.001     1757  LS failed, Hessian reset \n",
      "    1099       1947.54   1.19559e-06       30.9303        0.49       0.049     1780   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1113       1947.55   3.18109e-05       25.9797   1.401e-06       0.001     1834  LS failed, Hessian reset \n",
      "    1136       1947.55    1.3127e-06       22.1176    5.48e-08       0.001     1907  LS failed, Hessian reset \n",
      "    1145       1947.55   1.26652e-07       27.8768      0.2382      0.5508     1930   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.62179\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1810.49     0.0107272           213           1           1      132   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1842.06     0.0100186       709.453           1           1      248   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1875.62    0.00626573       546.094           1           1      365   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1892.55    0.00909214       110.175      0.6722      0.6722      481   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1896.89     0.0100441       251.579           1           1      608   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1901.54    0.00163774       290.678      0.9393      0.9393      727   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1903.47   0.000628571       230.247      0.6652      0.6652      855   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799        1907.8     0.0168833       371.673       0.128           1      976   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     879       1911.26   7.34905e-05       106.768   2.147e-06       0.001     1132  LS failed, Hessian reset \n",
      "     899       1911.37   0.000270468       231.292      0.5924      0.5924     1156   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     903       1911.38   2.71562e-05       60.0893     8.4e-07       0.001     1198  LS failed, Hessian reset \n",
      "     971       1911.77   2.32767e-05       55.3831   7.135e-07       0.001     1332  LS failed, Hessian reset \n",
      "     999       1911.81   4.29656e-05       67.3872      0.7658      0.7658     1364   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1035       1912.07   3.56274e-05       83.5019   6.009e-07       0.001     1440  LS failed, Hessian reset \n",
      "    1066       1912.45   7.57378e-05       61.3349    3.12e-06       0.001     1523  LS failed, Hessian reset \n",
      "    1099       1912.62   0.000836926       73.5965       4.769      0.4769     1571   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1160       1914.14   0.000265247       622.739   5.045e-07       0.001     1684  LS failed, Hessian reset \n",
      "    1199       1914.96   0.000431935       68.4659       0.624       0.624     1733   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1219       1915.06   1.50128e-05        36.427   2.232e-07       0.001     1805  LS failed, Hessian reset \n",
      "    1250       1915.18   2.86664e-05       56.2785   2.013e-07       0.001     1885  LS failed, Hessian reset \n",
      "    1292       1915.28   1.96583e-05       52.5098   2.612e-07       0.001     1976  LS failed, Hessian reset \n",
      "    1299       1915.29   3.08844e-05        24.686      0.7517      0.7517     1985   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1349       1915.35   1.28987e-05       36.5618   4.039e-07       0.001     2081  LS failed, Hessian reset \n",
      "    1399       1915.37   8.99856e-05       43.0685       2.102      0.2102     2141   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1486       1915.55   2.04258e-05       33.5677   1.875e-07       0.001     2301  LS failed, Hessian reset \n",
      "    1499       1915.55   6.89422e-06       23.0217           1           1     2322   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1505       1915.55   1.56927e-05       42.4326   3.312e-07       0.001     2365  LS failed, Hessian reset \n",
      "    1599       1915.65   0.000715529       37.4011           1           1     2485   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1699       1915.88    0.00116062       45.9463           1           1     2621   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1709       1915.94   1.76707e-05        35.631   1.998e-07       0.001     2681  LS failed, Hessian reset \n",
      "    1799       1916.09    0.00132764       41.9795           1           1     2795   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1894       1916.14   3.30719e-05       32.0744   8.947e-07       0.001     2972  LS failed, Hessian reset \n",
      "    1899       1916.14   5.63912e-06       26.3683      0.4755      0.4755     2977   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1938       1916.15    1.2859e-07       27.4402      0.2654      0.8627     3026   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.6622\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1813.38     0.0153774       438.712           1           1      126   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1852.48    0.00638094       136.487           1           1      238   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299        1866.7   0.000972304       164.785           1           1      366   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     395       1872.44   3.87806e-05       84.8755   4.196e-07       0.001      532  LS failed, Hessian reset \n",
      "     399       1872.48    0.00133665       175.184           1           1      536   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     443       1874.22   1.74054e-05       34.2559   2.929e-07       0.001      629  LS failed, Hessian reset \n",
      "     463       1874.53   3.01123e-05       47.6559   2.482e-07       0.001      694  LS failed, Hessian reset \n",
      "     499          1875    0.00447729       305.285      0.2917      0.2917      740   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1879.14    0.00263349       102.383      0.1359           1      869   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1881.01    0.00200256        107.57           1           1     1000   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     795       1881.94   5.09269e-05        115.28    3.86e-07       0.001     1172  LS failed, Hessian reset \n",
      "     799       1881.97   0.000756847        124.26           1           1     1176   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1882.62    0.00157352        116.38       9.496      0.9496     1306   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1883.25    0.00187247        51.676           1           1     1425   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1054       1883.65   1.70359e-05       41.5462   4.399e-07       0.001     1555  LS failed, Hessian reset \n",
      "    1099       1884.19   0.000989539       78.1737       1.963      0.1963     1613   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1187       1884.55   3.18061e-05       66.1431   6.085e-07       0.001     1762  LS failed, Hessian reset \n",
      "    1199       1884.56   2.98058e-06       31.4711     0.09351     0.09351     1777   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1225       1884.57   6.15931e-05       57.3353   1.671e-06       0.001     1854  LS failed, Hessian reset \n",
      "    1264       1884.59   1.20403e-05       28.5369   3.529e-07       0.001     1954  LS failed, Hessian reset \n",
      "    1289       1884.59   1.11909e-07       34.0581      0.2409      0.7471     1989   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.7552\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1797.81      0.013736       354.986      0.2154           1      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1835.19    0.00818146       209.293           1           1      241   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1848.01      0.003613       308.789      0.5952      0.5952      359   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1854.34   0.000749918       92.0361      0.3444      0.3444      484   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     455       1858.82   2.11659e-05       38.3019   3.065e-07       0.001      615  LS failed, Hessian reset \n",
      "     499        1859.8    0.00326654       90.7267           1           1      669   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     531       1861.46   9.64869e-05        184.95   3.331e-07       0.001      751  LS failed, Hessian reset \n",
      "     599       1864.06   0.000630488       209.737      0.5409           1      839   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     666       1864.86   8.14204e-05       167.067   3.526e-07       0.001      981  LS failed, Hessian reset \n",
      "     699       1866.14   0.000268788       251.688      0.1583      0.5126     1029   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     718       1866.38   2.91304e-05       59.0869   3.167e-07       0.001     1093  LS failed, Hessian reset \n",
      "     745       1866.59   2.59959e-05       53.9435   6.698e-07       0.001     1167  LS failed, Hessian reset \n",
      "     792       1866.79   2.71832e-05       51.6054   3.018e-07       0.001     1268  LS failed, Hessian reset \n",
      "     799       1866.83   0.000120782       57.4305        0.19      0.9475     1277   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     834       1866.86    5.5295e-05       101.452   7.562e-07       0.001     1369  LS failed, Hessian reset \n",
      "     899       1867.17    0.00587156       191.433           1           1     1451   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1868.17   0.000985591       59.6189           1           1     1588   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1015       1868.19   2.12957e-05       47.2386   5.198e-07       0.001     1651  LS failed, Hessian reset \n",
      "    1099       1868.29   1.44865e-05       39.3901     0.02287      0.7269     1764   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1147       1868.31   2.34303e-05        36.399   6.754e-07       0.001     1863  LS failed, Hessian reset \n",
      "    1179       1868.32   2.58065e-07       34.3512           1           1     1909   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.05029\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1792.35    0.00752844       108.804           1           1      118   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1813.19     0.0102567       82.3074           1           1      231   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1828.83     0.0185699       122.939           1           1      351   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     315       1832.39   0.000159078        142.84   2.653e-06       0.001      432  LS failed, Hessian reset \n",
      "     391       1835.91   6.84538e-05       121.628   3.808e-07       0.001      568  LS failed, Hessian reset \n",
      "     399       1836.17    0.00141787       114.352           1           1      576   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     439       1838.52   5.95587e-05       71.5495   2.765e-07       0.001      671  LS failed, Hessian reset \n",
      "     499       1840.02   0.000438492       97.3099      0.8811      0.8811      743   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1844.73     0.0224083       299.612           1           1      869   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1847.12    0.00126347       54.4727           1           1      993   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1847.86    0.00187183       49.0718           1           1     1117   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     805       1847.87   3.11312e-05       63.7121    4.51e-07       0.001     1160  LS failed, Hessian reset \n",
      "     894       1848.07    3.8342e-05       48.6772    2.62e-07       0.001     1316  LS failed, Hessian reset \n",
      "     899       1848.14   0.000654284       63.1346           1           1     1322   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     959       1848.21   3.22316e-05       42.8062   2.636e-07       0.001     1443  LS failed, Hessian reset \n",
      "     998       1848.23   3.09294e-05       25.4011   1.034e-06       0.001     1541  LS failed, Hessian reset \n",
      "     999       1848.23   1.81135e-05       30.5699           1           1     1542   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1848.25   4.46036e-06       28.2669           1           1     1674   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1848.81   0.000777516       68.8908      0.5469      0.5469     1789   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1250       1849.14   3.66379e-05        66.893   3.146e-07       0.001     1906  LS failed, Hessian reset \n",
      "    1299       1849.22   4.36926e-05       41.5428      0.3399      0.3399     1968   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1396        1849.4   3.02332e-05       47.9025   9.677e-07       0.001     2149  LS failed, Hessian reset \n",
      "    1399        1849.4   3.50082e-05       41.0874           1           1     2152   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1465       1849.42   2.66008e-05       57.8593   5.413e-07       0.001     2278  LS failed, Hessian reset \n",
      "    1499       1849.43    2.9993e-05       39.6633      0.6202      0.6202     2324   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1529       1849.43     3.443e-07       26.0399     0.06725           1     2366   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -2.93889\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1765.95    0.00167412       434.707      0.7051      0.7051      123   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1793.64    0.00903531       304.223      0.6942      0.6942      237   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1804.75    0.00170196       144.795      0.2221      0.4446      353   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     329       1806.28   3.70263e-05        69.113   4.172e-07       0.001      431  LS failed, Hessian reset \n",
      "     399       1812.97     0.0102932       190.582           1           1      518   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1815.78   0.000500996        134.73      0.3697      0.3697      645   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     536       1817.01    4.4897e-05       79.0875   3.706e-07       0.001      756  LS failed, Hessian reset \n",
      "     574       1818.48   1.80322e-05       33.3199   4.226e-07       0.001      845  LS failed, Hessian reset \n",
      "     599       1818.59   9.73742e-05       28.3081      0.9685      0.9685      881   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1821.73    0.00171829       175.403           1           1     1009   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     790       1822.35   3.96067e-05       23.5754   2.659e-07       0.001     1171  LS failed, Hessian reset \n",
      "     799       1822.44   0.000862336       52.7479           1           1     1183   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1822.92   0.000557378       50.5733           1           1     1329   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999        1823.2    0.00214001       80.3084           1           1     1467   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1004       1823.22   2.66092e-05       24.7167   2.764e-07       0.001     1518  LS failed, Hessian reset \n",
      "    1083       1823.44   0.000238244       97.7611    6.17e-06       0.001     1667  LS failed, Hessian reset \n",
      "    1099       1823.45    4.7264e-05       23.7709      0.3774           1     1689   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1823.97    0.00130085       151.764           1           1     1826   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1206          1824   2.24908e-05       28.2778   2.922e-07       0.001     1875  LS failed, Hessian reset \n",
      "    1248       1824.07   2.67482e-05       50.5671   4.632e-07       0.001     1973  LS failed, Hessian reset \n",
      "    1282       1824.08   5.30829e-06       26.4081    2.18e-07       0.001     2060  LS failed, Hessian reset \n",
      "    1299       1824.08   4.12941e-05       24.5145      0.3111           1     2085   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1328       1824.08   2.62956e-05         40.86    7.59e-07       0.001     2159  LS failed, Hessian reset \n",
      "    1384       1824.08   9.05434e-07       37.8362      0.1749      0.4247     2232   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.55397\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1762.88    0.00858043        293.93       0.811      0.0811      128   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1785.28    0.00538472       246.722           1           1      259   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     272       1791.25   4.76961e-05       54.9748   3.667e-07       0.001      387  LS failed, Hessian reset \n",
      "     299       1792.27    0.00224334       44.8455      0.2243           1      418   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     301       1792.28   3.61033e-05       55.2955   4.548e-07       0.001      466  LS failed, Hessian reset \n",
      "     399        1795.1    0.00322466       328.581     0.07295           1      577   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     425       1795.53    5.0543e-05        79.099   5.844e-07       0.001      653  LS failed, Hessian reset \n",
      "     499       1796.74    0.00453939       183.928     0.05482           1      747   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1800.28     0.0120179       329.563      0.3616           1      871   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     604       1800.67   6.94633e-05       106.058   3.681e-07       0.001      920  LS failed, Hessian reset \n",
      "     699       1802.89    0.00553207       172.782           1           1     1051   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1803.86    0.00535429       116.314           1           1     1186   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     868       1804.44   0.000211423       76.4395   3.056e-06       0.001     1321  LS failed, Hessian reset \n",
      "     899       1804.47    1.7932e-05       37.0829       0.524       0.524     1369   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     933       1804.67   2.68627e-05       47.1197   6.674e-07       0.001     1462  LS failed, Hessian reset \n",
      "     999       1805.01   9.68963e-05       37.9558       1.014      0.1014     1554   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1805.74    0.00263399       46.2765      0.8489      0.8489     1676   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1126       1805.97   3.43686e-05       60.1122   7.191e-07       0.001     1789  LS failed, Hessian reset \n",
      "    1199       1806.54   9.68593e-05       155.046      0.4298      0.4298     1888   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1243       1806.77   7.94113e-05       83.0589   2.607e-06       0.001     1979  LS failed, Hessian reset \n",
      "    1263       1806.77   1.75572e-05       44.2746    4.96e-07       0.001     2040  LS failed, Hessian reset \n",
      "    1284       1806.77   2.18923e-07       32.8687      0.2512           1     2075   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.40493\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        1743.9     0.0721762       282.827       2.871      0.2871      131   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1776.55    0.00159767       388.664      0.8552      0.8552      255   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1781.56   0.000796932       90.5312      0.5547      0.5547      376   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1789.97    0.00421866        172.63           1           1      502   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1794.94    0.00134072       54.0577      0.2732           1      627   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     564       1795.33   2.62782e-05       43.2757   4.823e-07       0.001      750  LS failed, Hessian reset \n",
      "     599       1795.45   0.000729693       76.3406      0.7548      0.7548      797   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1796.33    0.00155221       87.7355           1           1      921   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1797.33    0.00149667       51.8872           1           1     1047   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     851       1797.39   2.26919e-05       44.1344   3.899e-07       0.001     1157  LS failed, Hessian reset \n",
      "     887        1797.4   2.84144e-07       30.7471           1           1     1201   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.86456\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1710.99     0.0555434       1347.04           1           1      128   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1746.38     0.0123515       687.681           1           1      249   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1762.89    0.00359094        58.203     0.03057      0.8246      387   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1766.83    0.00625442       197.438           1           1      516   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     446       1768.95   0.000196259       259.891   5.146e-07       0.001      610  LS failed, Hessian reset \n",
      "     499       1771.87   0.000489097       80.2548     0.04786      0.6689      672   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     521       1772.28   2.82111e-05       37.2774   4.305e-07       0.001      751  LS failed, Hessian reset \n",
      "     555        1772.7   6.98973e-05       96.1637   4.399e-07       0.001      836  LS failed, Hessian reset \n",
      "     587       1773.19   3.47817e-05       34.8748   3.509e-07       0.001      914  LS failed, Hessian reset \n",
      "     599       1773.31   0.000386693       163.138      0.6762      0.6762      931   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     639       1773.63   9.01885e-05        52.573     3.2e-07       0.001     1020  LS failed, Hessian reset \n",
      "     678        1773.9    6.5962e-05        66.449   2.303e-06       0.001     1105  LS failed, Hessian reset \n",
      "     699       1773.94   0.000396608        94.974           1           1     1129   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1774.16   5.62434e-05       33.8814      0.5959      0.5959     1257   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     818       1774.39   8.71433e-05       104.043   1.539e-06       0.001     1352  LS failed, Hessian reset \n",
      "     891       1774.62   5.77893e-05       44.5427   1.791e-06       0.001     1499  LS failed, Hessian reset \n",
      "     899       1774.62   7.10255e-06       35.1264      0.3411      0.3411     1510   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     976       1774.78   3.56771e-05       56.6064   6.874e-07       0.001     1664  LS failed, Hessian reset \n",
      "     999       1774.87   0.000356386       49.5512      0.1843           1     1700   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1001       1774.87   2.88878e-05       47.3984   5.242e-07       0.001     1743  LS failed, Hessian reset \n",
      "    1036       1774.88   3.11154e-05       32.5852   8.475e-07       0.001     1825  LS failed, Hessian reset \n",
      "    1060       1774.88   2.24303e-07       31.2068      0.6935      0.6935     1855   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.47931\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1707.75    0.00946048       367.372      0.8331      0.8331      135   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1740.09     0.0165313       201.084           1           1      266   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1755.11    0.00576167         74.13           1           1      399   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1757.34   0.000589917       103.635      0.2701           1      518   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     408       1757.42    2.4759e-05       33.8938   4.655e-07       0.001      568  LS failed, Hessian reset \n",
      "     437       1757.74   6.46826e-05       94.1729    5.36e-07       0.001      641  LS failed, Hessian reset \n",
      "     499          1759    0.00146051       135.488      0.5933      0.5933      719   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1762.39     0.0023074       240.831           1           1      848   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     681       1763.36   4.68359e-05       59.7095   1.228e-06       0.001     1030  LS failed, Hessian reset \n",
      "     696       1763.68   3.20338e-05       36.8546   3.899e-07       0.001     1084  LS failed, Hessian reset \n",
      "     699        1763.8    0.00407446       29.5632           1           1     1089   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     726       1764.09    4.1003e-05       30.4457   3.417e-07       0.001     1166  LS failed, Hessian reset \n",
      "     799       1764.36    0.00360192       64.0631           1           1     1264   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     833       1764.54   2.76045e-05       41.6111   7.618e-07       0.001     1346  LS failed, Hessian reset \n",
      "     887       1764.56    7.8731e-08       34.4999      0.4048           1     1430   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -3.91164\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1705.13     0.0033958       271.443           1           1      128   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1741.06     0.0286508       116.468      0.8699     0.08699      251   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1752.37    0.00489951       50.4299           1           1      376   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     343       1755.36   4.42227e-05        36.739   3.669e-07       0.001      470  LS failed, Hessian reset \n",
      "     399       1756.65   3.15845e-05       35.5521           1           1      561   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     418       1756.86   3.47433e-05       48.2067    8.66e-07       0.001      624  LS failed, Hessian reset \n",
      "     499       1758.21    0.00118972       97.7073      0.7835      0.7835      734   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     524       1758.55   4.04629e-05        55.126   1.115e-06       0.001      813  LS failed, Hessian reset \n",
      "     599       1759.31     0.0123155       119.424           1           1      906   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1761.17    0.00164183       266.561     0.03541           1     1030   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     755       1761.67   2.67566e-05       38.8153   4.812e-07       0.001     1147  LS failed, Hessian reset \n",
      "     799       1761.91   0.000300341       120.132      0.4054      0.4054     1208   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     812       1762.06   5.03098e-05       54.4741   3.812e-07       0.001     1263  LS failed, Hessian reset \n",
      "     899        1762.3    0.00165439       42.1793       0.789       0.789     1376   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1765.11    0.00662866       214.772      0.1558      0.3721     1502   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1000       1765.11   7.29886e-05       65.4561   3.398e-07       0.001     1543  LS failed, Hessian reset \n",
      "    1099       1766.19   0.000353054       59.5942     0.02758           1     1670   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1144       1766.51   0.000169404       112.206   3.181e-06       0.001     1764  LS failed, Hessian reset \n",
      "    1169       1766.56   2.69826e-05       41.8538   5.415e-07       0.001     1842  LS failed, Hessian reset \n",
      "    1199       1766.57   9.72214e-05       35.5133           1           1     1886   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1213       1766.58   2.01748e-05       37.3638   5.441e-07       0.001     1950  LS failed, Hessian reset \n",
      "    1231       1766.58    3.6639e-07       23.0282      0.2196      0.6012     1977   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.34871\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1701.19     0.0174578       210.806           1           1      125   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1739.42     0.0125699       220.764           1           1      258   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1752.57     0.0129518       178.711           1           1      377   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1763.53    0.00308849       157.066    0.009214           1      504   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1768.48   0.000394606       75.1423      0.5429      0.5429      635   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1768.97   0.000128083       43.9118           1           1      771   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1770.41   8.34068e-05       30.9264       0.629       0.629      888   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     775       1770.68    0.00010633        99.181   2.274e-06       0.001     1028  LS failed, Hessian reset \n",
      "     799        1770.8    0.00103903       150.148           1           1     1055   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     885       1770.87   4.04837e-07        28.659     0.02598      0.3621     1164   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.17123\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1704.14     0.0138796       476.047           1           1      126   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1733.72    0.00240409       113.892           1           1      246   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1765.53     0.0180596       70.4792           1           1      368   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        1772.9    0.00451454        152.82      0.6239     0.06239      495   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1777.85    0.00247788       41.2864           1           1      611   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     517       1778.05   4.55386e-05       54.7503   3.521e-07       0.001      671  LS failed, Hessian reset \n",
      "     599       1778.95   0.000849355       141.287           1           1      788   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1780.71   0.000556154       97.1239      0.3339      0.3339      908   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1781.76   0.000418514       50.4522           1           1     1047   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     812       1781.79   3.95416e-05       57.4866   1.179e-06       0.001     1096  LS failed, Hessian reset \n",
      "     899       1781.94    0.00014568       35.6169      0.4164      0.7795     1208   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1782.67   0.000582589       129.587      0.4701      0.4701     1329   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1783.57    0.00110126       128.921           1           1     1456   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1122       1783.74   0.000145101       129.782   3.451e-06       0.001     1534  LS failed, Hessian reset \n",
      "    1199       1783.95    0.00289761       51.3312           1           1     1633   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299       1784.03   2.30916e-05        36.569           1           1     1772   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399       1784.04   1.38151e-06       29.0952      0.2758           1     1902   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1407       1784.04   3.21265e-07       36.3696      0.3307           1     1915   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.7487\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1689.16     0.0350344       460.972           1           1      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1728.37     0.0300295       602.695      0.1537           1      249   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1757.01      0.036067       1236.01      0.4318           1      371   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1764.19     0.0128215       167.159           1           1      493   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     401        1764.2    7.9296e-05       90.6376   4.316e-07       0.001      535  LS failed, Hessian reset \n",
      "     499       1768.67     0.0332051       508.041           1           1      668   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1775.46    0.00149262       41.3942           1           1      795   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     663       1776.22   3.57279e-05       34.6525   3.279e-07       0.001      934  LS failed, Hessian reset \n",
      "     699       1776.27   2.69822e-05       34.0797      0.3109           1      991   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     720       1776.33   5.16061e-05        42.968   3.164e-07       0.001     1055  LS failed, Hessian reset \n",
      "     799       1776.45   0.000846545       32.6074           1           1     1154   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1777.48   3.53495e-05       52.4316       0.472       0.472     1276   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     956       1777.79   2.78577e-05       46.8445   8.283e-07       0.001     1380  LS failed, Hessian reset \n",
      "     999       1777.84   0.000115348       39.2402      0.2092           1     1433   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1778.15   0.000214845       56.3602           1           1     1560   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1122       1778.42   0.000117917       139.737   1.728e-06       0.001     1627  LS failed, Hessian reset \n",
      "    1154       1778.93   4.45531e-05       39.5549   3.144e-07       0.001     1704  LS failed, Hessian reset \n",
      "    1199       1779.06    5.2378e-06       25.3702           1           1     1770   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299       1779.26   3.22721e-05       26.7255      0.5579      0.5579     1898   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1315       1779.26   3.75851e-05       38.3568   1.149e-06       0.001     1958  LS failed, Hessian reset \n",
      "    1341       1779.26   2.71302e-07       28.3179      0.2609           1     1997   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.78922\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1711.53     0.0300218       579.657      0.5064           1      134   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1754.12     0.0249916       826.908           1           1      266   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1772.24     0.0121551       559.909           1           1      387   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     328       1774.19   4.16068e-05       41.1547   3.445e-07       0.001      461  LS failed, Hessian reset \n",
      "     399       1777.62   0.000230723       145.748      0.3848      0.3848      560   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     488       1782.17   3.33723e-05       51.0742    3.84e-07       0.001      703  LS failed, Hessian reset \n",
      "     499       1782.89    0.00738084       640.943      0.9801      0.9801      718   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     515       1783.15   4.03908e-05       59.6334   1.088e-06       0.001      773  LS failed, Hessian reset \n",
      "     557       1784.13   0.000416278       154.463   3.017e-06       0.001      868  LS failed, Hessian reset \n",
      "     599       1784.71   0.000318282       202.389      0.9066      0.9066      923   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1786.57     0.0376642       166.626       3.286      0.3286     1042   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     772       1788.88   6.57629e-05       55.9323   2.821e-07       0.001     1166  LS failed, Hessian reset \n",
      "     799       1789.52   0.000400318       36.2852           1           1     1199   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     825       1789.81   3.05517e-05       38.0737   3.108e-07       0.001     1264  LS failed, Hessian reset \n",
      "     899       1790.33   0.000563334       47.4408       6.603      0.6603     1360   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1790.77      0.001206       41.1408      0.3786           1     1486   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1791.38     0.0026239       35.0145           1           1     1625   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1104        1791.4   3.50077e-05       53.9008   9.878e-07       0.001     1688  LS failed, Hessian reset \n",
      "    1151       1791.51   3.94214e-05       45.0599    3.03e-07       0.001     1791  LS failed, Hessian reset \n",
      "    1199       1791.58   1.98094e-05       28.7152           1           1     1851   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1263       1791.65   1.79148e-05       31.3756   3.954e-07       0.001     1991  LS failed, Hessian reset \n",
      "    1299       1791.71   0.000208073        44.431       0.993       0.993     2042   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1353       1791.73   2.03629e-05        43.818   5.308e-07       0.001     2146  LS failed, Hessian reset \n",
      "    1399       1791.74   0.000346361        38.926      0.2913           1     2202   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1428       1791.74   1.31177e-07       28.5022      0.1945      0.1945     2245   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -7.09832\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1704.61     0.0254308       233.467           1           1      129   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1757.69     0.0593711       353.578           1           1      246   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1784.24    0.00121538       120.266      0.3103      0.3103      373   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     383       1795.56   9.86835e-05       107.777   3.073e-07       0.001      515  LS failed, Hessian reset \n",
      "     399       1797.85    0.00103719       110.653           1           1      532   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     425        1798.8   3.87114e-05       54.8301   3.446e-07       0.001      604  LS failed, Hessian reset \n",
      "     447       1799.81   3.61691e-05       67.7203   4.349e-07       0.001      680  LS failed, Hessian reset \n",
      "     499       1800.54    0.00180631       43.1472           1           1      754   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     589       1801.77   6.81502e-05       75.4941   2.592e-06       0.001      910  LS failed, Hessian reset \n",
      "     599       1801.78   0.000144896       47.1813       1.895      0.1895      924   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1802.29    0.00869728       208.071           1           1     1046   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1804.41   0.000768421       81.4864      0.5789           1     1186   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1805.05   0.000934146       67.1302           1           1     1333   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     913       1805.11   3.45985e-05       48.9485   3.083e-07       0.001     1387  LS failed, Hessian reset \n",
      "     999       1805.47    0.00202864       103.648     0.09848           1     1491   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1004       1805.54   0.000110125       130.359    1.83e-06       0.001     1578  LS failed, Hessian reset \n",
      "    1099       1805.83   8.09052e-06       26.8702           1           1     1694   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1176       1805.84    2.0502e-07       33.0389      0.5812           1     1799   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.98066\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1730.11     0.0124988       132.061           1           1      125   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        1771.3    0.00203587       114.592           1           1      248   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1812.37     0.0106125       283.041           1           1      371   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     391       1817.29   0.000197749       114.541   2.925e-06       0.001      553  LS failed, Hessian reset \n",
      "     399       1817.47    0.00607965        570.52           1           1      561   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1820.56     0.0157577        100.72           1           1      689   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1827.67    0.00535826       125.531           1           1      818   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     629       1827.92   2.09819e-05       41.9731   4.612e-07       0.001      899  LS failed, Hessian reset \n",
      "     699       1829.39     0.0300336       130.903      0.8744      0.8744      998   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     735       1831.88   1.66087e-05        35.412   5.832e-07       0.001     1079  LS failed, Hessian reset \n",
      "     799       1832.84   0.000902993       128.252           1           1     1164   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     847       1833.55    0.00030251       104.581   3.249e-06       0.001     1264  LS failed, Hessian reset \n",
      "     883       1833.77   1.91577e-05       34.6997    2.95e-07       0.001     1357  LS failed, Hessian reset \n",
      "     899       1833.83   0.000447652       64.3959      0.7377      0.7377     1381   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     938       1833.98   4.68594e-05       88.5211   3.106e-07       0.001     1475  LS failed, Hessian reset \n",
      "     993        1834.2   5.13425e-05       106.163   5.077e-07       0.001     1592  LS failed, Hessian reset \n",
      "     999       1834.22   7.59316e-05       28.1856       2.766      0.9394     1601   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1076       1834.52   3.48589e-05       64.6807   3.038e-07       0.001     1758  LS failed, Hessian reset \n",
      "    1099       1834.66   9.01205e-05       22.4739           1           1     1791   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1158       1834.71   6.47472e-06       18.9323   2.438e-07       0.001     1915  LS failed, Hessian reset \n",
      "    1165       1834.71   1.76201e-08       24.4301    0.003799           1     1930   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -7.71452\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1759.15     0.0201693       293.459           1           1      131   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1809.22     0.0200059       925.223      0.0929           1      263   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1835.14      0.052994       53.5275           1           1      393   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1846.32     0.0414507       222.401           1           1      519   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     478       1851.82   3.86614e-05       91.4266   6.369e-07       0.001      649  LS failed, Hessian reset \n",
      "     493       1852.56   0.000488551       247.384   1.734e-05       0.001      706  LS failed, Hessian reset \n",
      "     499       1852.79   5.61608e-05       76.3184     0.05087       0.629      713   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     547        1853.7   0.000267136       74.3356   4.134e-06       0.001      824  LS failed, Hessian reset \n",
      "     599       1854.37    0.00201078       32.1846           1           1      905   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     628       1855.49   1.82931e-05       34.1025   2.411e-07       0.001      997  LS failed, Hessian reset \n",
      "     699       1856.39   0.000127299        99.933      0.3189      0.3189     1102   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     743       1856.56   2.14604e-05        55.532   3.758e-07       0.001     1205  LS failed, Hessian reset \n",
      "     799        1856.7   0.000111239       41.5774      0.3937           1     1276   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     835       1856.97   4.87187e-05       57.9487   1.985e-07       0.001     1371  LS failed, Hessian reset \n",
      "     879       1857.58   9.78895e-05       82.2266   3.925e-06       0.001     1466  LS failed, Hessian reset \n",
      "     899       1857.62    0.00370092       220.233           1           1     1489   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     909       1857.66   1.52278e-05       27.1452   2.303e-07       0.001     1544  LS failed, Hessian reset \n",
      "     948       1857.69   1.58433e-05       37.5504   2.597e-07       0.001     1641  LS failed, Hessian reset \n",
      "     999       1857.78   0.000620872       36.9919           1           1     1701   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1078       1858.38   0.000184565       109.297   7.107e-06       0.001     1840  LS failed, Hessian reset \n",
      "    1099       1858.41   0.000394434       62.2369       7.607      0.7607     1867   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1134       1858.46   1.91685e-05       45.7557   4.856e-07       0.001     1958  LS failed, Hessian reset \n",
      "    1145       1858.48   1.60889e-05       34.6941   5.625e-07       0.001     2017  LS failed, Hessian reset \n",
      "    1199        1858.5   6.30896e-05       31.8678           1           1     2087   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1232        1858.5   7.17879e-07        23.111   3.244e-08       0.001     2180  LS failed, Hessian reset \n",
      "    1299       1858.68     0.0106133       109.158           1           1     2261   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1395       1860.42   0.000120918       33.5248   3.685e-06       0.001     2431  LS failed, Hessian reset \n",
      "    1399       1860.44   0.000432689       129.573           1           1     2435   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1460       1860.68   0.000130815        130.39   3.574e-06       0.001     2571  LS failed, Hessian reset \n",
      "    1499       1860.81   0.000189561       18.8618           1           1     2624   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1515       1860.82   1.91996e-05       32.9562   2.277e-07       0.001     2693  LS failed, Hessian reset \n",
      "    1546       1860.82   1.19093e-05       34.1379   4.259e-07       0.001     2775  LS failed, Hessian reset \n",
      "    1557       1860.82   6.40202e-07       21.2654       2.328      0.2328     2793   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -9.29943\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1748.21     0.0152359         965.5      0.2904      0.2904      121   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1836.12     0.0226882       1160.35      0.1773           1      242   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1856.26     0.0332703       356.011           1           1      362   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1875.33     0.0143861       117.844           1           1      486   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     402       1875.36   3.03718e-05       60.3599   2.925e-07       0.001      534  LS failed, Hessian reset \n",
      "     499       1881.12     0.0383171       179.649       3.126      0.3126      652   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1888.28     0.0128288       224.567           1           1      782   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699        1890.8    0.00698497       342.902      0.4325           1      914   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     733       1891.18   4.32103e-05       66.6183   2.178e-07       0.001      999  LS failed, Hessian reset \n",
      "     799       1891.66    0.00125638        88.948           1           1     1087   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1892.09   0.000148523       73.7357           1           1     1205   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1894.19     0.0077369       195.861           1           1     1329   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1060       1895.06   0.000311282       98.4096   6.357e-06       0.001     1439  LS failed, Hessian reset \n",
      "    1099       1895.22   2.94108e-05       36.8355      0.9574      0.9574     1493   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1178       1895.36   1.42513e-05       30.8249   5.869e-07       0.001     1634  LS failed, Hessian reset \n",
      "    1199       1895.37   0.000229201       28.7922           1           1     1661   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1212       1895.37   2.00011e-05       20.8908   7.088e-07       0.001     1720  LS failed, Hessian reset \n",
      "    1299        1895.4   0.000149864       77.3549           1           1     1832   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1332       1895.48   1.83878e-05       48.6007   3.302e-07       0.001     1927  LS failed, Hessian reset \n",
      "    1345        1895.5   1.21393e-05       31.7564   5.032e-07       0.001     1987  LS failed, Hessian reset \n",
      "    1371        1895.5   4.19334e-05       27.1282   1.479e-06       0.001     2060  LS failed, Hessian reset \n",
      "    1399       1895.51   3.35252e-05       29.2853           1           1     2098   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1457       1895.51   4.55735e-07       25.2278           1           1     2182   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -7.88001\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1752.57     0.0138068       481.293           1           1      128   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1861.33    0.00772542       412.049           1           1      252   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1904.72    0.00149595       475.882      0.7119      0.7119      373   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1924.85    0.00113451       387.029      0.5714      0.5714      495   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1929.88    0.00168835       156.063           1           1      628   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     549       1930.63   6.44402e-05       109.968   1.071e-06       0.001      748  LS failed, Hessian reset \n",
      "     599       1931.02    0.00121035       138.636           1           1      808   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     607       1931.04   3.26891e-05       41.9205   1.701e-07       0.001      857  LS failed, Hessian reset \n",
      "     673        1932.8   0.000691618       668.095   4.661e-06       0.001      987  LS failed, Hessian reset \n",
      "     699       1933.73    0.00148545       77.8402           1           1     1016   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     755       1934.59   1.63335e-05       40.2247    7.23e-07       0.001     1139  LS failed, Hessian reset \n",
      "     799       1934.73   0.000961133       27.7192           1           1     1200   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     804       1934.74    1.2595e-05       33.7695   5.575e-07       0.001     1266  LS failed, Hessian reset \n",
      "     844       1934.83   1.03013e-05       34.8811   2.517e-07       0.001     1358  LS failed, Hessian reset \n",
      "     899       1934.93    0.00944092       131.448           1           1     1433   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     961       1936.18   2.47495e-05       54.7005   1.835e-07       0.001     1549  LS failed, Hessian reset \n",
      "     979       1936.29   1.11028e-05       30.6657   2.072e-07       0.001     1621  LS failed, Hessian reset \n",
      "     999       1936.41   0.000227401       34.2265           1           1     1647   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1027       1936.44   1.96666e-05       48.3234   1.922e-07       0.001     1726  LS failed, Hessian reset \n",
      "    1099       1936.74    0.00562495       173.443           1           1     1825   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1147       1936.87   4.02145e-05       102.034   5.015e-07       0.001     1936  LS failed, Hessian reset \n",
      "    1164       1936.92   9.84546e-06       24.3109   1.864e-07       0.001     2001  LS failed, Hessian reset \n",
      "    1199       1936.96   8.07086e-06       24.4574           1           1     2068   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1272       1937.11   8.23658e-05       77.4891   2.175e-06       0.001     2203  LS failed, Hessian reset \n",
      "    1299       1937.17   0.000417208       65.1961           1           1     2237   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1345       1937.25   6.81045e-05       83.5155   3.279e-06       0.001     2337  LS failed, Hessian reset \n",
      "    1399       1937.27   0.000265625       62.2188      0.3576      0.3576     2425   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1408        1937.3   1.39127e-05       30.2842   1.752e-07       0.001     2485  LS failed, Hessian reset \n",
      "    1462       1937.34   6.91953e-07       17.0777   2.696e-08       0.001     2603  LS failed, Hessian reset \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -9.45093\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1753.35    0.00912221       253.406           1           1      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1876.13     0.0210944       733.993       5.288      0.5288      251   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1925.19     0.0544945       354.966           1           1      373   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1939.14    0.00438557       827.168           1           1      495   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1946.25     0.0133682       469.414           1           1      611   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1949.49   0.000358009       53.7238     0.03076           1      735   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1951.47   0.000307238       139.595      0.4078      0.4078      860   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1952.29    0.00113288       273.389      0.2775      0.2775     1002   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     884       1952.88   7.89553e-06       24.6806   2.265e-07       0.001     1143  LS failed, Hessian reset \n",
      "     899       1952.94   0.000193784       43.0409           1           1     1161   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     963       1953.81   2.73968e-05       80.7433   4.543e-07       0.001     1300  LS failed, Hessian reset \n",
      "     999       1954.54    5.1936e-05       49.3079      0.3287      0.3287     1349   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099        1954.8   1.71455e-05        16.647           1           1     1471   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1117       1954.87   1.50763e-05       37.4012   1.746e-07       0.001     1538  LS failed, Hessian reset \n",
      "    1199       1955.07   0.000959756        42.627           1           1     1641   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299       1956.67      0.170828       658.622           1           1     1767   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399       1959.73    0.00159128       123.793      0.8881      0.8881     1885   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1454       1960.26   5.48009e-06       19.4781   2.423e-07       0.001     2003  LS failed, Hessian reset \n",
      "    1482       1960.43   1.46344e-05       27.5732   1.469e-07       0.001     2086  LS failed, Hessian reset \n",
      "    1499       1960.48   0.000454837       86.9082      0.1306           1     2117   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1501       1960.48   1.50736e-05        47.942   1.979e-07       0.001     2164  LS failed, Hessian reset \n",
      "    1520       1960.49   1.13339e-05       34.2953   1.796e-07       0.001     2229  LS failed, Hessian reset \n",
      "    1550       1960.51   3.44665e-05       71.5421   8.705e-07       0.001     2320  LS failed, Hessian reset \n",
      "    1579       1960.53   1.86907e-05       58.5181   5.684e-07       0.001     2392  LS failed, Hessian reset \n",
      "    1587       1960.53   7.94066e-06       21.0696    3.04e-07       0.001     2434  LS failed, Hessian reset \n",
      "    1596       1960.53   5.42202e-08       16.5479     0.04168           1     2455   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -8.04468\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1770.89     0.0154978       171.805           1           1      128   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1900.09    0.00711971       242.072      0.8739      0.8739      245   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1929.91    0.00624984       181.929           1           1      378   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        1941.7     0.0411937       232.531           1           1      492   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1955.34    0.00165008       234.655      0.4267      0.4267      624   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1959.16    0.00176979       121.268           1           1      744   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1960.44    0.00178814       547.478     0.06514           1      865   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     737       1962.21   2.54121e-05       83.2511   2.372e-07       0.001      950  LS failed, Hessian reset \n",
      "     799       1963.07   0.000705611       37.1545     0.03286           1     1036   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     800       1963.08   0.000124215       45.5875   3.343e-06       0.001     1073  LS failed, Hessian reset \n",
      "     899       1966.39     0.0524155       363.428          10           1     1206   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     963       1969.69   9.00805e-05       55.2818   2.217e-06       0.001     1336  LS failed, Hessian reset \n",
      "     995       1970.17   2.44394e-05       72.1123   4.755e-07       0.001     1417  LS failed, Hessian reset \n",
      "     999       1970.18    0.00057563       141.789           1           1     1421   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1970.71    0.00139412       74.3712           1           1     1555   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1972.79     0.0168574       364.233           1           1     1679   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1288       1973.78   2.61102e-05       84.9104    4.68e-07       0.001     1829  LS failed, Hessian reset \n",
      "    1299       1973.87    0.00224049       144.929           1           1     1842   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1308       1973.94   2.29041e-05       67.1317   6.113e-07       0.001     1895  LS failed, Hessian reset \n",
      "    1399       1974.32   4.15293e-05       35.1227      0.6246      0.6246     2006   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1406       1974.35   1.97154e-05       39.8271   1.505e-07       0.001     2058  LS failed, Hessian reset \n",
      "    1499       1974.48   0.000450568       68.3636           1           1     2191   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1599       1975.27    1.5928e-05       85.1363      0.1927      0.1927     2309   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1676       1975.43   2.28401e-05       66.6399   5.794e-07       0.001     2452  LS failed, Hessian reset \n",
      "    1699       1975.45   0.000122133       48.0382           1           1     2480   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1799       1975.84    0.00860511       203.145           1           1     2607   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1811       1975.97   1.98864e-05       70.5972   2.936e-07       0.001     2689  LS failed, Hessian reset \n",
      "    1859       1976.47   9.41435e-06       31.0652   1.886e-07       0.001     2788  LS failed, Hessian reset \n",
      "    1888       1976.51     7.297e-06       23.3107    1.82e-07       0.001     2865  LS failed, Hessian reset \n",
      "    1899       1976.51   8.32639e-06       23.6916      0.2203           1     2881   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1900       1976.51   1.61523e-05       23.4777   6.818e-07       0.001     2921  LS failed, Hessian reset \n",
      "    1999       1976.67   0.000187216       41.2391      0.2531           1     3054   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2020       1976.68   4.52199e-05       70.2443   1.158e-06       0.001     3118  LS failed, Hessian reset \n",
      "    2059       1976.68   1.81405e-06       29.2502   5.197e-08       0.001     3214  LS failed, Hessian reset \n",
      "    2066       1976.68    4.1481e-07        26.371     0.05385           1     3224   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -8.52312\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1804.31    0.00986002        468.73           1           1      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1901.72    0.00985191       533.909       6.259      0.6259      261   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1927.61    0.00625603       146.846           1           1      378   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1944.01    0.00635879       1011.22           1           1      495   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1948.56    0.00177193       70.5518      0.9433      0.9433      617   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1953.59     0.0105058       690.535           1           1      741   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     646       1955.78    2.8487e-05       88.6278   3.812e-07       0.001      852  LS failed, Hessian reset \n",
      "     699       1957.01   0.000467329       304.807      0.4881      0.4881      914   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     761       1958.56   2.58252e-05       81.1294   3.352e-07       0.001     1025  LS failed, Hessian reset \n",
      "     799       1959.52    0.00058095       55.8722      0.2434           1     1077   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     830       1959.97   1.70225e-05       42.8674   1.836e-07       0.001     1160  LS failed, Hessian reset \n",
      "     899       1960.88      0.018133       358.671           1           1     1247   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     909       1961.07   9.11862e-05       68.6098   1.543e-07       0.001     1316  LS failed, Hessian reset \n",
      "     951        1961.6   1.99877e-05       55.7091   1.951e-07       0.001     1417  LS failed, Hessian reset \n",
      "     973       1961.78   5.63511e-05       84.5397   1.429e-06       0.001     1480  LS failed, Hessian reset \n",
      "     999       1961.82     0.0002399       27.8807      0.8638      0.8638     1511   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1062       1962.11   1.31878e-05       40.5455   2.285e-07       0.001     1628  LS failed, Hessian reset \n",
      "    1099       1962.19   0.000932381       87.5573           1           1     1671   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1962.56    0.00546713       46.7762      0.7749      0.7749     1796   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1251        1962.9   2.62619e-05       76.3759   2.132e-07       0.001     1915  LS failed, Hessian reset \n",
      "    1291       1963.15   2.06624e-05       57.4764   6.615e-07       0.001     2022  LS failed, Hessian reset \n",
      "    1299       1963.16   0.000202592       52.2134      0.5125      0.5125     2031   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1346       1963.29   9.65448e-06       27.9133   1.985e-07       0.001     2141  LS failed, Hessian reset \n",
      "    1366        1963.3   1.18066e-05       43.0333   3.884e-07       0.001     2211  LS failed, Hessian reset \n",
      "    1377        1963.3   3.72119e-06       19.2812   1.728e-07       0.001     2261  LS failed, Hessian reset \n",
      "    1399       1963.31   0.000106982       29.1658       3.672      0.3672     2295   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1415       1963.33   1.22534e-05       28.3731   1.701e-07       0.001     2361  LS failed, Hessian reset \n",
      "    1468       1963.35   4.50258e-06       28.9881   2.163e-07       0.001     2482  LS failed, Hessian reset \n",
      "    1475       1963.35   9.30727e-10       18.9785    0.001497           1     2497   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "Initial log joint probability = -7.78701\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1784.68     0.0220151       274.964           1           1      120   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1877.16    0.00445768       169.582           1           1      237   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1926.62    0.00386419       575.612           1           1      359   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1938.06    0.00177123       83.8809           1           1      478   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1942.26    0.00879386       272.568      0.1889           1      600   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     506       1942.64   1.95747e-05       42.2942    1.82e-07       0.001      643  LS failed, Hessian reset \n",
      "     599       1946.17    0.00566815       147.591           1           1      771   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     621       1946.51   1.57132e-05       49.4856   3.846e-07       0.001      843  LS failed, Hessian reset \n",
      "     650        1946.8   5.76148e-05       85.6871   2.305e-06       0.001      928  LS failed, Hessian reset \n",
      "     699       1947.23    0.00685621       118.186           1           1      988   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     795       1949.04   0.000128802       49.1417   1.886e-06       0.001     1180  LS failed, Hessian reset \n",
      "     799       1949.23    0.00546464       67.9504           1           1     1187   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     819       1949.64   4.69898e-05       104.479   7.303e-07       0.001     1257  LS failed, Hessian reset \n",
      "     831       1949.73   1.11603e-05       39.4714   2.688e-07       0.001     1315  LS failed, Hessian reset \n",
      "     899       1949.96   0.000124671       49.8095           1           1     1403   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1950.42    0.00055938       23.0023           1           1     1536   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1020       1950.44   1.54235e-05       38.0211   1.801e-07       0.001     1606  LS failed, Hessian reset \n",
      "    1034       1950.45   2.01247e-08       26.7148    0.003707           1     1632   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative change in objective function was below tolerance\n",
      "Initial log joint probability = -7.41279\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1789.37    0.00333386       360.602      0.4047     0.04047      130   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1842.11       0.16866       1425.92           1           1      245   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1884.23     0.0026513       638.908      0.2582           1      362   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1895.96    0.00223901       394.154      0.1105           1      492   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     453       1899.58   2.35594e-05       60.7254   3.113e-07       0.001      615  LS failed, Hessian reset \n",
      "     499       1901.19    0.00214617       225.034      0.3109           1      668   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1905.37     0.0381751       272.811      0.8985      0.8985      786   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1908.72   0.000243939       32.7056           1           1      918   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     715       1908.75   8.08559e-06       22.2665   3.482e-07       0.001      983  LS failed, Hessian reset \n",
      "     799       1909.88   0.000741417       60.2073           1           1     1092   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1910.55    0.00407127       86.6842       2.321      0.2321     1217   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     902       1910.56   1.50867e-05       39.1003   2.797e-07       0.001     1260  LS failed, Hessian reset \n",
      "     999        1910.8    0.00221863       36.9265           1           1     1382   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1039       1911.16   2.69744e-05        61.467   6.342e-07       0.001     1476  LS failed, Hessian reset \n",
      "    1073       1911.21    6.6535e-06       14.7695   2.225e-07       0.001     1558  LS failed, Hessian reset \n",
      "    1091       1911.22   9.99702e-06       40.2868   3.588e-07       0.001     1627  LS failed, Hessian reset \n",
      "    1099       1911.22    2.0035e-06       20.2977      0.7798      0.7798     1638   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1911.67    0.00187004       51.2239           1           1     1785   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1214       1911.71   2.93223e-05       76.6134   5.567e-07       0.001     1851  LS failed, Hessian reset \n",
      "    1299       1911.82   0.000240531       17.0843      0.9549      0.9549     1958   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399       1911.94    0.00257456       130.077           1           1     2092   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1443       1912.15    3.1654e-05        84.724   4.235e-07       0.001     2203  LS failed, Hessian reset \n",
      "    1489       1912.29   1.40917e-05       21.5478   2.067e-07       0.001     2303  LS failed, Hessian reset \n",
      "    1499        1912.3   8.12525e-05       58.0383      0.8579      0.8579     2313   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1507       1912.31   5.03141e-05       81.9835   1.653e-06       0.001     2365  LS failed, Hessian reset \n",
      "    1573       1912.35   3.52922e-05       79.7172   5.649e-07       0.001     2492  LS failed, Hessian reset \n",
      "    1598       1912.36   7.51193e-06       24.8431   2.317e-07       0.001     2567  LS failed, Hessian reset \n",
      "    1599       1912.36   3.19622e-06       17.0073           1           1     2568   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1609       1912.36   1.01878e-06       27.7973   3.277e-08       0.001     2626  LS failed, Hessian reset \n",
      "    1610       1912.36   3.19778e-07       16.8505      0.9347      0.9347     2627   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -8.3887\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1790.95    0.00494717       401.276     0.02203           1      122   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1834.48      0.172024       763.422           1           1      255   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1852.19    0.00225293        281.35     0.01461           1      375   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1859.96    0.00979965        475.24      0.9164      0.9164      501   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1870.85    0.00287761       46.8729      0.8804      0.8804      628   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     592       1872.62   0.000196192       150.968   5.712e-06       0.001      787  LS failed, Hessian reset \n",
      "     599       1872.71   0.000248936       237.285      0.6325      0.6325      794   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     604       1872.75   1.43164e-05        30.833   2.944e-07       0.001      843  LS failed, Hessian reset \n",
      "     615       1872.79   1.13733e-05       26.6087   3.266e-07       0.001      904  LS failed, Hessian reset \n",
      "     645       1873.07   1.60371e-05       31.5938   3.364e-07       0.001     1006  LS failed, Hessian reset \n",
      "     662       1873.14   4.80397e-05       65.4106    2.18e-06       0.001     1083  LS failed, Hessian reset \n",
      "     685       1873.18   2.64832e-05       35.6131   2.256e-07       0.001     1157  LS failed, Hessian reset \n",
      "     699       1873.19   3.10756e-05       31.3656           1           1     1178   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1875.08     0.0128776       161.286      0.3967      0.3967     1303   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     876       1876.68   3.25601e-05         54.77   2.396e-07       0.001     1456  LS failed, Hessian reset \n",
      "     899       1876.98    0.00786806       179.107           1           1     1487   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     911       1877.05   4.81095e-05        37.429   2.114e-07       0.001     1543  LS failed, Hessian reset \n",
      "     947       1877.29   1.31645e-05       31.2676   6.529e-07       0.001     1633  LS failed, Hessian reset \n",
      "     983       1877.42   3.00652e-05       46.9449   2.329e-07       0.001     1726  LS failed, Hessian reset \n",
      "     999       1877.49   0.000342914       68.2863           1           1     1747   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1025       1877.51   2.25417e-05       31.7777   2.253e-07       0.001     1822  LS failed, Hessian reset \n",
      "    1099        1877.7   0.000894617        32.645       0.706       0.706     1925   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1102        1877.7   3.49275e-05       64.3428   9.192e-07       0.001     1966  LS failed, Hessian reset \n",
      "    1119       1877.71   1.92586e-05       38.8552   5.348e-07       0.001     2029  LS failed, Hessian reset \n",
      "    1191       1877.79    0.00012951       31.7547   3.574e-06       0.001     2163  LS failed, Hessian reset \n",
      "    1199       1877.79   9.40528e-06       29.1651     0.09264           1     2177   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1297       1877.83   1.42645e-05       25.4064   6.059e-07       0.001     2357  LS failed, Hessian reset \n",
      "    1299       1877.83   1.63359e-06       17.1792     0.08229           1     2361   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1313       1877.83   7.65829e-07       23.6678         0.5         0.5     2388   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -9.10057\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1786.15     0.0344424        633.32       4.912      0.4912      123   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1821.33    0.00709153       356.215           1           1      248   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1839.78     0.0383753       335.606      0.3062           1      369   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     362       1853.18    0.00137094       210.415    1.11e-05       0.001      497  LS failed, Hessian reset \n",
      "     399        1857.5     0.0184372       903.928           1           1      536   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     485       1862.86   5.47759e-05       110.664   4.233e-07       0.001      695  LS failed, Hessian reset \n",
      "     499       1863.49   9.95571e-05       84.2864     0.02096      0.9441      713   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     564       1864.72   2.85042e-05       59.0673   3.742e-07       0.001      844  LS failed, Hessian reset \n",
      "     599       1864.87   5.50317e-05       27.1368           1           1      890   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     613       1864.95    4.8109e-05       76.9776   1.173e-06       0.001      978  LS failed, Hessian reset \n",
      "     699       1865.23   0.000342467       57.2373           1           1     1093   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     797       1866.34   7.94864e-05       85.0364   3.138e-06       0.001     1252  LS failed, Hessian reset \n",
      "     799       1866.34   6.61524e-05       41.2697           1           1     1254   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     841       1866.48   2.41701e-05       51.7817   3.461e-07       0.001     1351  LS failed, Hessian reset \n",
      "     899       1866.54   7.53803e-05        34.333      0.2959           1     1424   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1867.85    0.00508005       52.9702      0.7916      0.7916     1543   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1868.39   7.76866e-05       36.7104       1.368      0.1368     1689   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1136       1868.45   0.000120882       33.2597   3.941e-06       0.001     1774  LS failed, Hessian reset \n",
      "    1165       1868.46   5.35852e-08       19.7483      0.1304      0.1304     1812   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -10.195\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99          1809    0.00206771       84.4363           1           1      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1827.98     0.0106595       227.995      0.4515      0.4515      255   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1838.35    0.00208563       121.358           1           1      378   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1848.07    0.00181869       146.684           1           1      507   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1851.47    0.00187855       63.9293      0.3589           1      632   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1854.17    0.00511277       106.704      0.5155           1      754   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     600       1854.18   3.12043e-05       47.5616   2.924e-07       0.001      799  LS failed, Hessian reset \n",
      "     635       1854.58   4.20349e-05       72.9952   8.411e-07       0.001      885  LS failed, Hessian reset \n",
      "     699       1855.05    0.00913068        404.62      0.6782      0.6782      963   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     722       1856.18   0.000154204       149.481   3.223e-06       0.001     1030  LS failed, Hessian reset \n",
      "     799       1857.17   0.000312949       90.6063      0.1772           1     1129   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1857.64     0.0015409       148.276        0.42      0.8565     1267   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     969       1858.55   0.000242414         274.8   1.369e-06       0.001     1400  LS failed, Hessian reset \n",
      "     999       1859.03    0.00031096       70.7002      0.4808      0.4808     1432   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1003       1859.03   1.55994e-05       32.4943   5.251e-07       0.001     1488  LS failed, Hessian reset \n",
      "    1088       1859.24   9.81658e-06       28.0382   6.112e-07       0.001     1667  LS failed, Hessian reset \n",
      "    1099       1859.24   7.11242e-06       21.8574           1           1     1684   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1103       1859.24   7.44072e-06       34.8073   2.891e-07       0.001     1724  LS failed, Hessian reset \n",
      "    1124       1859.24   1.49904e-05       26.7039   6.393e-07       0.001     1782  LS failed, Hessian reset \n",
      "    1196       1859.45   1.80779e-05       37.7055   3.708e-07       0.001     1902  LS failed, Hessian reset \n",
      "    1199       1859.48   0.000777761       76.0339        3.66       0.366     1909   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1291       1859.61   4.74145e-05        86.127   1.286e-06       0.001     2076  LS failed, Hessian reset \n",
      "    1299       1859.62   6.02954e-05       24.5208      0.5839      0.5839     2084   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1324       1859.63   1.50817e-05       30.6683   4.171e-07       0.001     2166  LS failed, Hessian reset \n",
      "    1336       1859.63   4.76029e-08       30.5998    0.009105           1     2188   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -11.6081\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1806.51     0.0483832       1087.06           1           1      126   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1835.55     0.0293128       477.271           1           1      239   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     268       1847.97   6.95519e-05       135.978   6.534e-07       0.001      368  LS failed, Hessian reset \n",
      "     299       1849.83    0.00216555       54.7428      0.3748           1      411   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1853.01      0.012698       91.6522           1           1      539   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     402       1853.04   3.96678e-05       59.9772   3.164e-07       0.001      584  LS failed, Hessian reset \n",
      "     470       1854.38   0.000268844       157.082   2.974e-06       0.001      733  LS failed, Hessian reset \n",
      "     499       1855.01   0.000117654       40.9197      0.2732      0.2732      765   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599          1857     0.0438319        153.81      0.2634           1      895   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     623        1858.3   6.64222e-05       92.0553   2.679e-07       0.001      969  LS failed, Hessian reset \n",
      "     694       1861.53   2.58295e-05       37.8236   2.714e-07       0.001     1114  LS failed, Hessian reset \n",
      "     699       1861.56   0.000539435       35.5274           1           1     1120   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     732       1861.74   4.31581e-05       32.4261   2.425e-07       0.001     1202  LS failed, Hessian reset \n",
      "     745       1861.75   1.21786e-05       17.6222   2.632e-07       0.001     1255  LS failed, Hessian reset \n",
      "     799       1861.96   0.000160695       24.6615      0.1286           1     1325   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     811       1862.01   4.31708e-05       75.1041   1.009e-06       0.001     1392  LS failed, Hessian reset \n",
      "     840       1862.17   4.98175e-05       91.4766    6.92e-07       0.001     1470  LS failed, Hessian reset \n",
      "     899       1862.28    0.00222937       80.9167           1           1     1543   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     907       1862.31   1.58349e-05       32.9114   4.032e-07       0.001     1595  LS failed, Hessian reset \n",
      "     997        1863.2   3.98928e-05       53.0706   2.609e-07       0.001     1760  LS failed, Hessian reset \n",
      "     999       1863.25    0.00124433       85.9861           1           1     1764   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1021       1863.47   9.14416e-05       77.1867   4.168e-06       0.001     1820  LS failed, Hessian reset \n",
      "    1054       1863.58   2.17872e-05       33.5115   2.725e-07       0.001     1901  LS failed, Hessian reset \n",
      "    1099       1863.67   0.000608684       24.5826           1           1     1958   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1864.03   0.000183065       36.6112      0.2441     0.02441     2076   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1235       1864.09   1.39011e-05        37.588   6.433e-07       0.001     2153  LS failed, Hessian reset \n",
      "    1299        1864.2   0.000534291       35.2519      0.3738           1     2245   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1362       1864.55   3.99742e-05       74.3208   3.214e-07       0.001     2374  LS failed, Hessian reset \n",
      "    1399       1864.76   0.000106128       111.132      0.2172           1     2421   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1402       1864.77   6.06305e-05       78.8457   1.516e-06       0.001     2458  LS failed, Hessian reset \n",
      "    1479       1864.96   2.07007e-05       43.2093   3.918e-07       0.001     2586  LS failed, Hessian reset \n",
      "    1499       1864.97   1.04315e-05       29.9934           1           1     2615   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1593       1865.03   0.000149293        33.686   3.659e-06       0.001     2775  LS failed, Hessian reset \n",
      "    1599       1865.03   8.90055e-05       30.0257           1           1     2782   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1630       1865.03   1.47146e-05       25.5852    5.41e-07       0.001     2860  LS failed, Hessian reset \n",
      "    1653       1865.03   4.77161e-08       23.9953      0.2285      0.2285     2895   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -13.9603\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99          1825     0.0200262       431.272      0.4827      0.4827      125   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1859.76    0.00325973       548.538     0.02664           1      248   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1871.31    0.00473902       425.114           1           1      376   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1876.39    0.00765056       67.9855           1           1      505   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     478       1878.26   2.92098e-05       64.4346   3.409e-07       0.001      645  LS failed, Hessian reset \n",
      "     499       1879.02    0.00148995       130.812           1           1      669   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     539       1879.82    5.0047e-05       96.7502   8.266e-07       0.001      771  LS failed, Hessian reset \n",
      "     577       1880.17   6.59737e-05       64.4998   2.299e-06       0.001      855  LS failed, Hessian reset \n",
      "     599       1880.24   0.000181672       47.0086           1           1      879   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1887.78     0.0018061       67.8131           1           1     1025   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1889.74    0.00135058       107.186           1           1     1144   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     871       1890.95   9.69273e-05       153.031   9.626e-07       0.001     1280  LS failed, Hessian reset \n",
      "     899       1891.47    0.00139655       75.4609      0.3525           1     1314   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     942       1891.61    3.4146e-05       67.3035   8.731e-07       0.001     1422  LS failed, Hessian reset \n",
      "     999       1891.66    0.00031406       48.1762           1           1     1496   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1092       1892.07   2.04276e-05       46.4063   4.161e-07       0.001     1670  LS failed, Hessian reset \n",
      "    1099       1892.07   7.64269e-05       36.9161      0.2713           1     1680   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1892.22    0.00146694        79.265      0.6326      0.6326     1797   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1219       1892.23   1.22083e-05        25.812   2.947e-07       0.001     1861  LS failed, Hessian reset \n",
      "    1268       1892.24   3.14133e-05       41.4774   1.098e-06       0.001     1972  LS failed, Hessian reset \n",
      "    1297       1892.25   2.93131e-06       32.2827   1.367e-07       0.001     2059  LS failed, Hessian reset \n",
      "    1299       1892.25   6.80141e-07       17.4546      0.5742      0.5742     2061   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1304       1892.25   2.15807e-07       19.7961      0.4787      0.1224     2071   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -12.9299\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99          1779     0.0211809       1663.28      0.4586       0.987      119   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1847.28    0.00740198       450.359           1           1      245   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1868.15     0.0621628       700.348           1           1      368   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1880.43   0.000240991       43.1764      0.8434     0.02004      491   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1894.22   0.000849588       119.687      0.5496      0.5496      617   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599        1896.4    0.00168472       186.478      0.3432           1      750   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     685       1897.37   2.80297e-05       32.3993   2.228e-07       0.001      919  LS failed, Hessian reset \n",
      "     699       1897.45   0.000247181       28.7202      0.6631      0.6631      936   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     716       1897.49   1.66972e-05        29.569   2.498e-07       0.001     1002  LS failed, Hessian reset \n",
      "     752       1897.57   3.39079e-05       48.1788   2.335e-07       0.001     1082  LS failed, Hessian reset \n",
      "     776       1897.61    1.4317e-05       35.0466    3.44e-07       0.001     1156  LS failed, Hessian reset \n",
      "     799       1897.61   5.70668e-06       29.0103      0.7559      0.7559     1186   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     833       1898.29   6.39937e-05       52.1799   2.156e-07       0.001     1268  LS failed, Hessian reset \n",
      "     899       1898.53   8.53309e-06       29.7055           1           1     1354   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1899.17    0.00108518       108.649           1           1     1478   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099        1899.4   9.50817e-05       40.3633      0.6474      0.6474     1606   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1161       1899.48   2.69435e-05       46.3029    2.41e-07       0.001     1726  LS failed, Hessian reset \n",
      "    1199        1899.5   3.73732e-06       26.1883      0.6061      0.6061     1780   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1227       1899.53   3.60042e-05       84.2947   5.988e-07       0.001     1854  LS failed, Hessian reset \n",
      "    1240       1899.54   1.33813e-05       32.9746   4.882e-07       0.001     1902  LS failed, Hessian reset \n",
      "    1299       1899.55    1.3797e-05       29.7319           1           1     1986   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399       1899.87    0.00239238       137.932           1           1     2094   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1492       1900.28   1.39702e-05       25.5531   2.428e-07       0.001     2269  LS failed, Hessian reset \n",
      "    1499       1900.29   9.71921e-06       24.4673      0.3306           1     2280   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1515       1900.29   5.29849e-06       27.5776   1.365e-07       0.001     2343  LS failed, Hessian reset \n",
      "    1530       1900.29   6.25797e-07       32.2126   2.109e-08       0.001     2405  LS failed, Hessian reset \n",
      "    1531       1900.29   4.10959e-07       22.5199           1           1     2406   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -16.2033\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        1826.8      0.077186       147.695           1           1      129   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1874.51    0.00643738       328.053      0.4319      0.4319      249   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1893.58     0.0158925       434.998           1           1      381   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1899.83   0.000607349       54.3792      0.8486      0.8486      500   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1902.02   0.000205533       110.165      0.2594           1      646   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599        1903.2    0.00133856       242.513      0.3804      0.3804      769   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     630       1904.14   6.51821e-05       98.1647   2.259e-07       0.001      853  LS failed, Hessian reset \n",
      "     699       1905.34   0.000315745       32.7275           1           1      939   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     733       1905.39   2.54888e-05       58.9572   3.095e-07       0.001     1028  LS failed, Hessian reset \n",
      "     799       1905.52   4.44271e-05        28.103           1           1     1121   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1905.78    0.00285516        34.862           1           1     1243   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     965       1905.85   1.81966e-05       45.5537   3.625e-07       0.001     1383  LS failed, Hessian reset \n",
      "     999       1905.85   9.54773e-06       31.8316      0.6547      0.6547     1433   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1906.98   0.000125736       71.8603      0.3637      0.3637     1560   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1120       1907.07   6.26034e-05       65.7417   2.413e-06       0.001     1624  LS failed, Hessian reset \n",
      "    1178       1907.15   0.000172088       137.289   6.721e-06       0.001     1734  LS failed, Hessian reset \n",
      "    1199       1907.17   8.30471e-06       21.1884     0.06725      0.8102     1763   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1239       1907.19   1.38758e-05       33.2345   3.043e-07       0.001     1868  LS failed, Hessian reset \n",
      "    1299       1907.21   5.79948e-06        27.005      0.3425      0.2809     1958   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1328       1907.21   1.07817e-06       22.8705      0.3693           1     1998   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -16.3503\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1810.11       0.03122       681.568           1           1      138   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1885.97      0.108194       482.059           1           1      257   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1899.84    0.00700048       195.167           1           1      381   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1903.04    0.00201577       49.6929       1.003      0.1003      509   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1905.27    0.00507154       58.8998           1           1      640   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     569       1908.67   4.78518e-05       56.8845   2.016e-07       0.001      774  LS failed, Hessian reset \n",
      "     599       1909.52   0.000218142       76.6191           1           1      811   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     696       1910.21   1.99164e-05       44.7015   2.568e-07       0.001      970  LS failed, Hessian reset \n",
      "     699       1910.23   0.000816387       95.5213           1           1      974   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     783       1910.62   1.41094e-05       34.5812   2.843e-07       0.001     1129  LS failed, Hessian reset \n",
      "     799       1910.65   2.89744e-05        42.541      0.1696      0.1696     1152   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899        1911.5     0.0148567       341.066      0.1635           1     1274   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     901       1911.53   5.96738e-05       76.7891   2.085e-07       0.001     1329  LS failed, Hessian reset \n",
      "     999        1912.3   2.55795e-05       47.4206   8.588e-07       0.001     1480  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1016       1912.36   6.31365e-05       83.9816   2.592e-06       0.001     1539  LS failed, Hessian reset \n",
      "    1099       1912.53    0.00037756       31.3341       1.104      0.3177     1654   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1141       1912.62   0.000210571       49.3396   2.436e-06       0.001     1769  LS failed, Hessian reset \n",
      "    1199       1912.67   4.32963e-05       30.2026       3.825      0.8457     1851   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1211       1912.68   8.70664e-06       27.3711   3.142e-07       0.001     1911  LS failed, Hessian reset \n",
      "    1256       1912.69   1.21637e-05       27.9236   6.467e-07       0.001     2011  LS failed, Hessian reset \n",
      "    1285       1912.69   2.63532e-05        60.286   7.762e-07       0.001     2094  LS failed, Hessian reset \n",
      "    1299       1912.69   9.41694e-07       28.4784      0.4795      0.4795     2115   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1306       1912.69   3.67313e-07       21.3471      0.2453           1     2123   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -12.9621\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1797.52     0.0145041       168.574      0.8537      0.8537      131   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1879.71    0.00972012       677.317           1           1      263   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     279       1890.38   2.96629e-05       66.7165   3.311e-07       0.001      391  LS failed, Hessian reset \n",
      "     299       1891.39    0.00173044       105.173      0.3794           1      414   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1900.48     0.0211801       298.415      0.8073      0.8073      532   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1907.12    0.00657965       210.254           1           1      659   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1908.37    0.00119171       75.9838           1           1      790   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     614       1908.68   2.71957e-05       53.5663    2.38e-07       0.001      859  LS failed, Hessian reset \n",
      "     650       1909.29   3.25545e-05       66.0784   2.598e-07       0.001      950  LS failed, Hessian reset \n",
      "     679       1909.58   1.63309e-05        38.128   2.841e-07       0.001     1033  LS failed, Hessian reset \n",
      "     699        1909.7   0.000477919       80.5857      0.8605     0.08605     1059   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     792       1914.97   0.000134563       283.532   8.711e-07       0.001     1212  LS failed, Hessian reset \n",
      "     799       1916.09    0.00648834       331.708      0.5868      0.5868     1220   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     878       1919.36   1.83146e-05       45.2203   2.975e-07       0.001     1369  LS failed, Hessian reset \n",
      "     899       1919.47   3.69071e-06       23.6629           1           1     1406   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     906       1919.49   1.24784e-05       36.4063   3.215e-07       0.001     1457  LS failed, Hessian reset \n",
      "     929       1919.52   1.60948e-05       38.9619   2.655e-07       0.001     1529  LS failed, Hessian reset \n",
      "     963       1919.57   4.53967e-05       86.9394   1.318e-06       0.001     1622  LS failed, Hessian reset \n",
      "     999        1919.6    2.0839e-05       31.0387     0.05823           1     1670   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1054       1919.76   2.99358e-05       64.8938    2.47e-07       0.001     1809  LS failed, Hessian reset \n",
      "    1099       1919.88   2.59477e-05       53.8838           1           1     1871   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1132       1919.91   5.88987e-05       40.0872   1.954e-06       0.001     1958  LS failed, Hessian reset \n",
      "    1158       1919.92   8.22656e-06       19.6004   2.035e-07       0.001     2035  LS failed, Hessian reset \n",
      "    1185       1919.92   2.81129e-07       24.2571       0.817       0.817     2071   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -12.1502\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        1807.6      0.241399       1589.62       2.517     0.02517      130   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1859.07    0.00978587        581.79      0.2592      0.2592      257   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1878.93     0.0131942       146.992           1           1      377   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1893.33     0.0635015       430.239           1           1      494   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1907.08    0.00102765       147.516       0.459       0.459      615   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     532       1908.36   2.54788e-05       46.1541   2.333e-07       0.001      707  LS failed, Hessian reset \n",
      "     553       1908.63   6.22391e-05       44.6269   2.035e-07       0.001      774  LS failed, Hessian reset \n",
      "     599       1909.38    0.00742224       209.808      0.2665           1      846   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1912.34   0.000791156       51.0406       0.482           1      984   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1913.15    0.00248391       100.479      0.5853      0.5853     1117   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     814       1913.26   1.40566e-05       36.3183   3.611e-07       0.001     1184  LS failed, Hessian reset \n",
      "     899       1913.56   9.55798e-06       48.7232    0.004039           1     1302   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     908       1913.57   5.00535e-05       81.3332   1.431e-06       0.001     1348  LS failed, Hessian reset \n",
      "     999       1913.66   7.71709e-05       19.0093      0.7651      0.7651     1475   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1021       1913.68   2.60328e-05       57.3113   7.766e-07       0.001     1539  LS failed, Hessian reset \n",
      "    1099       1913.78   0.000233867       67.5657           1           1     1639   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1913.87   0.000292486       39.3698      0.8496      0.8496     1768   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1204       1913.89   2.86595e-05       38.9886   2.039e-07       0.001     1815  LS failed, Hessian reset \n",
      "    1276       1913.97   3.35843e-05       42.6079   1.136e-06       0.001     1955  LS failed, Hessian reset \n",
      "    1299       1913.97   7.63035e-06       38.9231           1           1     1992   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399       1914.09   0.000551085       66.4059           1           1     2127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1465       1914.68   4.39634e-05       91.4192   2.406e-07       0.001     2260  LS failed, Hessian reset \n",
      "    1499       1914.97   3.87839e-05       24.7317      0.3156      0.6856     2305   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1523       1914.98   2.76288e-05       33.5643   1.153e-06       0.001     2376  LS failed, Hessian reset \n",
      "    1539       1914.98   4.32955e-07       26.1101      0.3417      0.9301     2406   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -11.2469\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1818.46      0.034668       521.947           1           1      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1857.66     0.0761803       732.134           1           1      248   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299        1880.4   0.000531124       59.2807           1           1      367   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1897.05     0.0281691       91.9885       2.584      0.2584      498   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1901.28   0.000590957        56.661      0.3538      0.3538      627   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1902.55   0.000130735       42.4459     0.03677           1      768   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     631       1902.67   1.15601e-05       25.4034   2.677e-07       0.001      861  LS failed, Hessian reset \n",
      "     699       1903.02     0.0010929        31.774           1           1      951   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     752        1903.6   1.20179e-05        26.075   2.588e-07       0.001     1062  LS failed, Hessian reset \n",
      "     773       1903.71    1.7245e-05       39.4499   4.888e-07       0.001     1142  LS failed, Hessian reset \n",
      "     799       1903.74   9.09297e-05         26.07           1           1     1179   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     818       1903.85    1.4894e-05       29.7925    2.51e-07       0.001     1249  LS failed, Hessian reset \n",
      "     899       1904.29    0.00438467       237.733      0.2859           1     1368   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     923       1904.87   5.08593e-05       54.7799   2.069e-07       0.001     1438  LS failed, Hessian reset \n",
      "     955       1905.08   0.000119691       97.5495   2.004e-06       0.001     1516  LS failed, Hessian reset \n",
      "     978        1905.1   3.12145e-05       47.2844   1.134e-06       0.001     1578  LS failed, Hessian reset \n",
      "     999       1905.12     0.0003842       25.7077      0.6299           1     1603   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1001       1905.12   1.76033e-05        37.751   7.492e-07       0.001     1651  LS failed, Hessian reset \n",
      "    1044       1905.19   3.23298e-05       29.6365   2.038e-07       0.001     1746  LS failed, Hessian reset \n",
      "    1056       1905.23   3.19179e-05       33.7976    2.06e-06       0.001     1801  LS failed, Hessian reset \n",
      "    1081       1905.24   4.69062e-05        63.423   1.624e-06       0.001     1872  LS failed, Hessian reset \n",
      "    1099       1905.24    9.2983e-05       29.2563      0.2773           1     1903   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1111       1905.24   4.48444e-06       19.9619   1.754e-07       0.001     1963  LS failed, Hessian reset \n",
      "    1163       1905.29   4.93481e-05       87.7576   2.354e-07       0.001     2068  LS failed, Hessian reset \n",
      "    1189       1905.32   2.20532e-05       39.7557   7.556e-07       0.001     2142  LS failed, Hessian reset \n",
      "    1199       1905.32   1.18333e-06       17.7795           1           1     2160   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1200       1905.32   2.31627e-07       15.9649   1.303e-08       0.001     2201  LS failed, Hessian reset \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -11.6323\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1838.57     0.0482051        830.45           1           1      115   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1884.53    0.00124533       244.777           1           1      238   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1899.29    0.00216314       179.433           1           1      360   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1904.65     0.0232301       751.117      0.3984           1      484   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1911.34    0.00931994       66.7751           1           1      614   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     517       1911.76   4.07583e-05       98.7421   2.913e-07       0.001      682  LS failed, Hessian reset \n",
      "     599       1913.47    0.00156028       40.7351           1           1      785   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     643       1914.32   0.000126463       126.982   2.353e-06       0.001      889  LS failed, Hessian reset \n",
      "     699       1914.99     0.0157841       50.5436           1           1      969   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1915.32     0.0066657       35.8153           1           1     1098   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     894       1917.94   4.25714e-05       64.4205   2.043e-07       0.001     1282  LS failed, Hessian reset \n",
      "     899       1918.06     0.0035969       63.2748           1           1     1288   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     912       1918.61    8.2719e-05       64.6894   2.085e-06       0.001     1350  LS failed, Hessian reset \n",
      "     981       1919.42   2.28115e-05       51.4832   2.326e-07       0.001     1486  LS failed, Hessian reset \n",
      "     999       1919.54    0.00635549       94.8573           1           1     1509   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1074       1919.77   2.12675e-05       51.8633   2.611e-07       0.001     1658  LS failed, Hessian reset \n",
      "    1099        1919.8    1.9493e-05       21.9146      0.7139      0.7139     1691   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1920.12    0.00676156       164.821           1           1     1821   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1230       1920.93   0.000399511       76.6762   1.784e-06       0.001     1901  LS failed, Hessian reset \n",
      "    1267        1921.7   1.93228e-05        39.277   2.161e-07       0.001     2003  LS failed, Hessian reset \n",
      "    1299       1921.77   0.000221521       70.6102      0.7842      0.7842     2051   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399       1921.83   0.000671128       35.7327      0.3852      0.8358     2182   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1421          1922   1.23413e-05       35.7094   2.407e-07       0.001     2255  LS failed, Hessian reset \n",
      "    1460       1922.08   6.33982e-05       43.5951   2.142e-06       0.001     2344  LS failed, Hessian reset \n",
      "    1499       1922.08   4.94601e-05       36.6358      0.9124      0.9124     2392   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1546       1922.15   2.74131e-05       55.2244   6.811e-07       0.001     2516  LS failed, Hessian reset \n",
      "    1599       1922.18   2.95338e-05       21.0733      0.6753      0.6753     2581   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1634       1922.19   2.29437e-07       26.9651      0.3056           1     2635   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -9.92006\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1868.55    0.00841175       183.357           1           1      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1906.62       0.00478       125.072      0.9692      0.9692      247   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1914.51    0.00198972       368.725     0.02006           1      371   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1924.03   0.000582364       568.328      0.8007      0.8007      500   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1933.23    0.00388955       114.593           1           1      622   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     548       1935.34   3.38354e-05       71.9191    6.45e-07       0.001      733  LS failed, Hessian reset \n",
      "     599       1935.79    0.00134196       55.1696           1           1      795   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1937.78     0.0259854       389.894           1           1      916   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     711       1938.19   3.33208e-05       80.3947    7.16e-07       0.001      973  LS failed, Hessian reset \n",
      "     792       1938.85   1.53358e-05       42.4384   4.049e-07       0.001     1126  LS failed, Hessian reset \n",
      "     799       1938.86   0.000297536       29.1085           1           1     1137   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     830       1939.09   0.000217952       293.547   1.875e-06       0.001     1217  LS failed, Hessian reset \n",
      "     899       1939.49   0.000442802       42.3588           1           1     1302   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     911       1939.51   1.34239e-05       30.9165   2.335e-07       0.001     1363  LS failed, Hessian reset \n",
      "     999       1939.88    0.00502135       71.7561           1           1     1478   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1077       1940.02   1.78602e-05       49.3072   4.261e-07       0.001     1606  LS failed, Hessian reset \n",
      "    1099       1940.04    0.00019115       76.5218           1           1     1637   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1137        1940.1   3.14689e-05       63.3466   1.005e-06       0.001     1732  LS failed, Hessian reset \n",
      "    1166       1940.12    1.5406e-05       39.5155    2.45e-07       0.001     1820  LS failed, Hessian reset \n",
      "    1199       1940.12   2.43285e-06       13.6192           1           1     1870   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1205       1940.13   1.79678e-05        38.147   3.125e-07       0.001     1916  LS failed, Hessian reset \n",
      "    1226       1940.13   4.86524e-06       14.1177   1.995e-07       0.001     1986  LS failed, Hessian reset \n",
      "    1232       1940.13   4.87427e-08       21.5153     0.08098      0.2851     1996   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -8.72514\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1859.45      0.076517       2041.73           1           1      126   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1903.12    0.00321252       189.716           1           1      246   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1912.81    0.00506687       613.298      0.0985           1      370   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        1924.7    0.00184859       157.634           1           1      493   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1932.61    0.00654906       165.873           1           1      624   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1934.09   0.000692351       199.258      0.1639      0.8153      747   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     620       1934.28   2.70435e-05       67.0008    5.04e-07       0.001      826  LS failed, Hessian reset \n",
      "     699       1935.41     0.0435021       288.867           1           1      939   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     767       1937.48   0.000596846       111.268   9.529e-06       0.001     1075  LS failed, Hessian reset \n",
      "     799       1937.88     0.0074262       95.8843       5.382           1     1115   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     826       1938.42    3.2198e-05       79.4834   2.626e-07       0.001     1190  LS failed, Hessian reset \n",
      "     898       1938.82   2.36082e-05       33.6379   1.939e-07       0.001     1320  LS failed, Hessian reset \n",
      "     899       1938.82   6.39854e-05       36.9293          10           1     1322   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     944       1938.86   1.68996e-05       44.8902   3.623e-07       0.001     1421  LS failed, Hessian reset \n",
      "     972       1938.87   7.80888e-06       21.0741   2.572e-07       0.001     1496  LS failed, Hessian reset \n",
      "     994       1938.87    2.3402e-07       24.2076      0.2651      0.8359     1525   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -8.22975\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1865.21    0.00373072       192.017           1           1      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1906.52     0.0172659       221.507           1           1      256   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1921.55    0.00591343       120.742      0.1923           1      388   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1927.67   0.000875006       116.345      0.9032      0.9032      512   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1930.14    0.00564797       326.231      0.8458      0.8458      632   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1932.17     0.0108838       174.427      0.2552           1      768   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699        1933.6    0.00112778       24.9407      0.3109           1      897   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     723       1933.71   1.42943e-05       35.5692   2.845e-07       0.001      986  LS failed, Hessian reset \n",
      "     799       1933.99   0.000100763       20.1982      0.2105      0.7262     1082   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     831       1934.06    1.4588e-05       33.9799   2.766e-07       0.001     1179  LS failed, Hessian reset \n",
      "     899       1934.14   0.000359835       24.9388      0.2326           1     1261   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     985       1934.35   0.000186547       44.1515   2.262e-06       0.001     1404  LS failed, Hessian reset \n",
      "     999       1934.38   0.000300916        27.175           1           1     1423   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1031       1934.41   5.06973e-05       85.4712   9.039e-07       0.001     1514  LS failed, Hessian reset \n",
      "    1061       1934.42   3.65754e-05       51.8361   1.295e-06       0.001     1607  LS failed, Hessian reset \n",
      "    1093       1934.42   2.05748e-07        23.243      0.1485      0.4104     1651   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -7.55489\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1846.99    0.00539016       170.597           1           1      123   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        1903.5     0.0261905       392.595           1           1      245   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1918.73    0.00172939       182.773      0.4235      0.4235      375   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1924.25    0.00260452       229.387           1           1      502   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1929.95     0.0376249       437.479           1           1      630   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     523       1930.89   3.88376e-05       78.5174   9.678e-07       0.001      702  LS failed, Hessian reset \n",
      "     599       1931.61   0.000260969        133.96           1           1      807   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1933.28    0.00299838       99.1207           1           1      937   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     709       1933.42   2.80062e-05       55.2419   2.332e-07       0.001      991  LS failed, Hessian reset \n",
      "     722       1933.65   3.32595e-05        70.443   9.126e-07       0.001     1058  LS failed, Hessian reset \n",
      "     776          1934   5.60722e-05       30.7956   1.917e-07       0.001     1172  LS failed, Hessian reset \n",
      "     783       1934.08   7.77467e-05       100.753   1.286e-06       0.001     1218  LS failed, Hessian reset \n",
      "     799       1934.11   0.000205422       89.4307      0.5124      0.5124     1236   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     814       1934.13   3.65349e-05       61.5559   1.388e-06       0.001     1309  LS failed, Hessian reset \n",
      "     879       1936.69    0.00011213       157.299   2.113e-07       0.001     1435  LS failed, Hessian reset \n",
      "     899       1938.08    0.00139304       109.084      0.8248      0.8248     1458   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1938.61   6.25016e-05       48.8413      0.7319      0.7319     1587   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1014       1938.72   0.000310147       105.364   7.598e-06       0.001     1660  LS failed, Hessian reset \n",
      "    1030       1938.79   1.49229e-05       36.0166   4.941e-07       0.001     1731  LS failed, Hessian reset \n",
      "    1099       1938.98    0.00294471       61.5053      0.1552           1     1822   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1939.78   0.000245518       33.8064      0.2034      0.2034     1952   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1233       1939.86   4.16043e-05       85.9558   7.055e-07       0.001     2039  LS failed, Hessian reset \n",
      "    1284       1939.93   6.48486e-05       96.4062   1.194e-06       0.001     2146  LS failed, Hessian reset \n",
      "    1299       1939.96   0.000154577       47.8095      0.3096           1     2165   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1314       1939.97   4.24468e-05       25.0517   1.606e-06       0.001     2215  LS failed, Hessian reset \n",
      "    1396       1940.12   3.88305e-05       41.7977    1.94e-07       0.001     2351  LS failed, Hessian reset \n",
      "    1399       1940.13   0.000347966       67.9362           1           1     2355   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1499        1940.3   0.000560025       41.2471           1           1     2494   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1520       1940.47   0.000135726       214.534   1.834e-06       0.001     2563  LS failed, Hessian reset \n",
      "    1550       1940.76   0.000178438       150.146   4.691e-06       0.001     2639  LS failed, Hessian reset \n",
      "    1563       1940.83   5.17818e-05       89.6619   1.045e-06       0.001     2695  LS failed, Hessian reset \n",
      "    1599       1940.88   0.000657705       28.3509           1           1     2734   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1608        1940.9   2.66907e-05       64.9704   5.924e-07       0.001     2788  LS failed, Hessian reset \n",
      "    1645       1940.93   2.46892e-05       67.8912   8.558e-07       0.001     2872  LS failed, Hessian reset \n",
      "    1699       1940.97    0.00130734        93.915           1           1     2941   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1706       1940.99   2.21124e-05       40.3203   2.074e-07       0.001     2995  LS failed, Hessian reset \n",
      "    1757       1941.03   1.67096e-05       49.9102   3.446e-07       0.001     3113  LS failed, Hessian reset \n",
      "    1791       1941.03   2.28782e-07       29.3585      0.3058           1     3162   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.10637\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1830.18    0.00665804       208.929           1           1      129   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1886.57     0.0127568       206.536           1           1      250   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1902.75     0.0136036       194.008           1           1      370   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     378       1910.64   4.29772e-05       75.3276   2.457e-07       0.001      505  LS failed, Hessian reset \n",
      "     399       1913.37    0.00583268       52.3684           1           1      533   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     484       1916.29   2.16308e-05       51.8104   4.717e-07       0.001      678  LS failed, Hessian reset \n",
      "     499       1917.05    0.00215426       95.5795           1           1      695   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     562       1919.21   0.000128901       93.4949   1.994e-06       0.001      809  LS failed, Hessian reset \n",
      "     578       1919.52   1.74858e-05        42.302   3.579e-07       0.001      879  LS failed, Hessian reset \n",
      "     599       1919.69    0.00312276       160.309      0.4655     0.04655      904   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1922.15     0.0103871       164.351      0.6388      0.6388     1032   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1923.41   0.000380793       60.7949           1           1     1173   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1924.01   6.31078e-05       76.6698       0.604       0.604     1298   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1924.72    0.00290651       92.3923           1           1     1423   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1071       1925.06   2.03837e-05        37.232   2.306e-07       0.001     1556  LS failed, Hessian reset \n",
      "    1099       1925.07   4.37366e-06       16.3758           1           1     1597   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1152       1925.41   0.000168429       164.196   4.263e-06       0.001     1710  LS failed, Hessian reset \n",
      "    1199       1925.63   0.000141135       14.3944      0.3421      0.8859     1771   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299        1925.7   0.000146543       36.8093      0.3039           1     1904   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399       1925.91    0.00170118       157.018           1           1     2025   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1423          1926   3.16648e-05       39.2586   2.059e-07       0.001     2095  LS failed, Hessian reset \n",
      "    1499       1926.11   2.40316e-05       32.9136      0.4329      0.4329     2207   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1565       1926.16   4.49551e-07       17.0069      0.8787      0.8787     2296   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.19057\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1832.01     0.0158107       1286.48           1           1      131   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1873.92     0.0337348       370.819           1           1      259   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1885.91    0.00480767       254.536           1           1      379   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1893.56     0.0105838       131.073       0.631           1      502   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1903.08    0.00235114       386.453           1           1      635   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     578       1905.03   0.000107504       144.049   2.138e-06       0.001      775  LS failed, Hessian reset \n",
      "     599       1905.21   0.000144624       113.944           1           1      804   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1906.79     0.0256115       569.979           1           1      921   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     721       1907.07    2.2696e-05        34.343   2.356e-07       0.001      990  LS failed, Hessian reset \n",
      "     799       1907.57   0.000696709       78.1127      0.1769           1     1094   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     808       1907.64   2.46765e-05       51.3181   2.809e-07       0.001     1148  LS failed, Hessian reset \n",
      "     899       1907.96    0.00276172       47.0734           1           1     1272   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     984       1908.44   2.72697e-05       62.1599   5.969e-07       0.001     1457  LS failed, Hessian reset \n",
      "     999       1908.64    0.00026474       24.3919      0.9993      0.9993     1479   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1007       1908.68   6.91944e-05       94.1924   2.199e-06       0.001     1531  LS failed, Hessian reset \n",
      "    1050       1908.75   1.43321e-05       30.5037   2.828e-07       0.001     1641  LS failed, Hessian reset \n",
      "    1099       1908.78   4.70976e-05       37.3053           1           1     1707   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1109       1908.78   1.93912e-05       49.2472   6.366e-07       0.001     1759  LS failed, Hessian reset \n",
      "    1199       1908.89   1.81229e-05        22.015       1.555      0.4548     1877   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1224        1908.9    2.8419e-05       54.9665   9.242e-07       0.001     1952  LS failed, Hessian reset \n",
      "    1299       1908.92   4.70577e-05       20.2738           1           1     2055   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1312       1908.98   2.00249e-05       25.0847   2.226e-07       0.001     2114  LS failed, Hessian reset \n",
      "    1351       1909.02   5.08419e-05       39.2595   2.063e-06       0.001     2206  LS failed, Hessian reset \n",
      "    1374       1909.03   3.30731e-05        34.604   8.493e-07       0.001     2279  LS failed, Hessian reset \n",
      "    1399       1909.03   1.03856e-05       24.8715           1           1     2315   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1489       1909.05    4.5459e-07       19.0423      0.4716      0.4716     2438   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.16162\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1847.51     0.0164595       914.547           1           1      133   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1886.75     0.0235397       593.892           1           1      257   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1895.54     0.0273166       967.888           1           1      387   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     334        1898.2   1.63032e-05       40.8674   3.168e-07       0.001      472  LS failed, Hessian reset \n",
      "     399       1899.54     0.0122369       92.6528           1           1      556   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1901.49    0.00392141       95.3316           1           1      688   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     582        1903.3    7.6118e-05       159.993   4.511e-07       0.001      828  LS failed, Hessian reset \n",
      "     599        1903.7    0.00340491       241.365           1           1      847   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1904.33    0.00110667       87.9285       4.422      0.4422      973   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     705       1904.37   2.54685e-05       29.8298   2.283e-07       0.001     1026  LS failed, Hessian reset \n",
      "     799       1904.99    0.00199181       279.048           1           1     1148   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     841       1905.79   0.000707626       132.551   2.041e-05       0.001     1242  LS failed, Hessian reset \n",
      "     865       1905.92   1.14676e-05       27.5586    3.86e-07       0.001     1325  LS failed, Hessian reset \n",
      "     899       1906.08   1.51282e-05       33.1469   3.147e-07       0.001     1408  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     913       1906.09    1.0439e-05       24.4962   3.802e-07       0.001     1463  LS failed, Hessian reset \n",
      "     941       1906.14   2.75966e-05       52.2952   2.689e-07       0.001     1545  LS failed, Hessian reset \n",
      "     983       1906.17   1.98511e-05       49.9758   4.786e-07       0.001     1642  LS failed, Hessian reset \n",
      "     999       1906.17   1.88377e-05       20.3476      0.6727      0.6727     1659   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1045        1906.2   2.20139e-05       44.2196   4.147e-07       0.001     1764  LS failed, Hessian reset \n",
      "    1098       1906.25   2.80567e-05       70.0156   6.235e-07       0.001     1880  LS failed, Hessian reset \n",
      "    1099       1906.25   1.00618e-05       44.0505           1           1     1881   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1113       1906.25   3.02082e-06       23.1697   1.582e-07       0.001     1935  LS failed, Hessian reset \n",
      "    1181       1906.34   4.25291e-05       87.7337   5.097e-07       0.001     2073  LS failed, Hessian reset \n",
      "    1199       1906.39   0.000226768       27.7787           1           1     2096   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1266       1906.43   4.26804e-05       54.2363    1.45e-06       0.001     2239  LS failed, Hessian reset \n",
      "    1299       1906.44    7.4119e-06        25.362      0.5288      0.5288     2289   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1371       1906.67   2.66331e-05       62.6523   4.025e-07       0.001     2443  LS failed, Hessian reset \n",
      "    1399       1906.82   0.000604631       107.381      0.8949      0.8949     2479   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1473       1906.87   1.86234e-05       44.1111   5.311e-07       0.001     2626  LS failed, Hessian reset \n",
      "    1499       1906.87   4.24582e-06       29.5332           1           1     2664   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1533        1906.9   2.81398e-05       58.2523   8.518e-07       0.001     2764  LS failed, Hessian reset \n",
      "    1599       1906.93   0.000180078       39.7495           1           1     2846   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1624       1906.93   1.23901e-05       38.1542   3.857e-07       0.001     2917  LS failed, Hessian reset \n",
      "    1652       1906.93   5.59065e-06       21.3385   2.619e-07       0.001     3006  LS failed, Hessian reset \n",
      "    1666       1906.93   6.08519e-08       26.8193      0.1184      0.3815     3037   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.76937\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1868.94     0.0825926       1308.72           1           1      146   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        1902.9     0.0413804        450.78      0.2474           1      265   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1911.27     0.0141028       167.753      0.5193     0.05193      391   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1915.68    0.00227914       62.5191           1           1      517   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1917.98   0.000206824       31.3455           1           1      645   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1919.96   0.000551461       160.145      0.7768      0.7768      773   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1920.82   0.000304366       63.6563      0.2628      0.2628      912   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     745       1921.35   2.36939e-05       49.7057   2.691e-07       0.001     1008  LS failed, Hessian reset \n",
      "     780       1921.59   1.79111e-05        31.799   2.401e-07       0.001     1092  LS failed, Hessian reset \n",
      "     799       1921.63    0.00259057       36.9364           1           1     1120   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1924.87     0.0184661       427.019           1           1     1244   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1926.14   0.000393596       36.3844      0.9364      0.9364     1366   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1011       1926.22   8.25714e-05       172.925   5.572e-07       0.001     1423  LS failed, Hessian reset \n",
      "    1019       1926.26   1.02174e-05       32.4385   4.274e-07       0.001     1471  LS failed, Hessian reset \n",
      "    1037       1926.36    3.4748e-05        60.511   1.319e-06       0.001     1549  LS failed, Hessian reset \n",
      "    1076       1926.42    1.5077e-05       34.0831   2.761e-07       0.001     1634  LS failed, Hessian reset \n",
      "    1099       1926.46    0.00130863       101.397          10           1     1663   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1119       1926.52   1.76156e-05       39.3098   2.646e-07       0.001     1727  LS failed, Hessian reset \n",
      "    1198       1926.69   6.29199e-05       71.5479   2.096e-07       0.001     1881  LS failed, Hessian reset \n",
      "    1199        1926.7   0.000146107       50.2851          10           1     1883   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1258       1926.81   1.55208e-05       25.9977   2.459e-07       0.001     2000  LS failed, Hessian reset \n",
      "    1299       1926.81   2.23037e-06       27.8054       1.936      0.1936     2064   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1356       1926.93   2.06836e-05       47.6239   2.919e-07       0.001     2172  LS failed, Hessian reset \n",
      "    1392          1927   1.07256e-05       25.4976   2.798e-07       0.001     2260  LS failed, Hessian reset \n",
      "    1399          1927   1.71342e-05       30.7938           1           1     2267   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1438       1927.02   8.30419e-05       63.4335    4.09e-06       0.001     2358  LS failed, Hessian reset \n",
      "    1499       1927.03   1.22242e-05       23.3305           1           1     2441   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1504       1927.03   1.00135e-06       14.6022      0.2127      0.7156     2451   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -7.02106\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1878.27     0.0130609       296.133           1           1      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1908.12    0.00431255       445.226      0.2318           1      255   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1916.62   0.000856526       227.827           1           1      390   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1922.93     0.0114272       186.493           1           1      522   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499        1928.1    0.00565532       100.527      0.5202      0.5202      649   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     525       1929.04    2.8237e-05       59.4807     2.7e-07       0.001      715  LS failed, Hessian reset \n",
      "     598       1930.24   3.84656e-05       64.0269   2.362e-07       0.001      845  LS failed, Hessian reset \n",
      "     599       1930.24   0.000140748        35.262          10           1      847   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     651       1930.56   6.65811e-05       146.346   4.884e-07       0.001      981  LS failed, Hessian reset \n",
      "     676       1931.03   3.14774e-05       52.4005   1.153e-06       0.001     1057  LS failed, Hessian reset \n",
      "     699       1931.07   0.000222004       37.6709      0.8739      0.8739     1086   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1931.33   0.000141203       77.1149     0.07129           1     1216   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     828       1932.05   7.21335e-05       150.276   5.646e-07       0.001     1295  LS failed, Hessian reset \n",
      "     852       1932.23   9.17501e-06       23.0026   3.523e-07       0.001     1368  LS failed, Hessian reset \n",
      "     899        1932.5     0.0026067       56.7987      0.2041           1     1429   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     913       1932.55   1.88019e-05        36.927   2.271e-07       0.001     1487  LS failed, Hessian reset \n",
      "     999       1932.68    0.00049095       65.1348           1           1     1608   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1038       1933.05   4.39361e-05       101.459   3.376e-07       0.001     1708  LS failed, Hessian reset \n",
      "    1077       1933.31   1.98454e-05       40.8465   2.635e-07       0.001     1797  LS failed, Hessian reset \n",
      "    1099       1933.34   2.00675e-05       33.6298        0.34       0.034     1828   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1107       1933.35    3.4184e-05       72.1333   6.598e-07       0.001     1877  LS failed, Hessian reset \n",
      "    1139       1933.38   2.49445e-05       33.0634   2.111e-07       0.001     1962  LS failed, Hessian reset \n",
      "    1199       1933.43   0.000297276       49.9737      0.6822           1     2049   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299       1933.64   0.000414066       65.4487           1           1     2171   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1324       1933.66   1.17936e-05       30.7358   2.726e-07       0.001     2257  LS failed, Hessian reset \n",
      "    1339       1933.66   7.27438e-06       28.1031   2.648e-07       0.001     2321  LS failed, Hessian reset \n",
      "    1345       1933.66   1.05779e-06       22.5606    5.08e-08       0.001     2370  LS failed, Hessian reset \n",
      "    1370       1933.66    3.6569e-06       27.2831   1.213e-07       0.001     2441  LS failed, Hessian reset \n",
      "    1381       1933.66     5.322e-07       26.5994      0.2554           1     2456   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -8.17691\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1887.79     0.0169082       2677.28      0.7529      0.7529      121   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        1911.4     0.0473299       757.669      0.5807      0.5807      254   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1915.17   0.000632706       113.474       0.928       0.928      371   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1920.54    0.00557026       160.532      0.7003     0.07003      494   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     436       1922.11   2.94768e-05        67.176   4.088e-07       0.001      574  LS failed, Hessian reset \n",
      "     481        1922.8   5.85733e-05       96.4101   1.013e-06       0.001      689  LS failed, Hessian reset \n",
      "     499       1922.96   0.000384431       140.078      0.4913           1      716   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     523       1923.04   1.77448e-05         31.46   2.464e-07       0.001      789  LS failed, Hessian reset \n",
      "     599        1923.4   0.000230559        41.409       3.666     0.03666      906   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     619       1923.59   3.89864e-05       85.9348   6.304e-07       0.001      974  LS failed, Hessian reset \n",
      "     699       1923.95    0.00167229       90.6643       1.952      0.1952     1075   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     737       1925.33   6.75751e-05       167.092   3.563e-07       0.001     1157  LS failed, Hessian reset \n",
      "     757       1925.89   2.02958e-05       25.0043   2.187e-07       0.001     1227  LS failed, Hessian reset \n",
      "     773          1926   7.78203e-05       64.5514   3.313e-06       0.001     1288  LS failed, Hessian reset \n",
      "     799       1926.04    0.00019127       29.1581           1           1     1320   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1926.21   0.000137028       24.1582           1           1     1480   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     917       1926.28   0.000145115       39.9703   2.728e-06       0.001     1552  LS failed, Hessian reset \n",
      "     999       1926.33   0.000115118       31.0457      0.9663      0.9663     1660   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1926.42     0.0194899        366.41           1           1     1785   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1103       1926.45   0.000106764       132.708   1.487e-06       0.001     1845  LS failed, Hessian reset \n",
      "    1157       1926.54    2.4831e-06       23.6219   1.427e-07       0.001     1952  LS failed, Hessian reset \n",
      "    1163       1926.54   3.21827e-07       26.4086      0.2283           1     1962   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.75978\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1881.36     0.0071933       517.335      0.9457      0.9457      131   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1905.33     0.0152535       291.694      0.7681      0.7681      251   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1914.49    0.00100521       288.966      0.2629           1      370   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1919.19    0.00160208       120.845      0.2954      0.7846      497   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     459       1919.88   6.88712e-05       43.3182   2.084e-07       0.001      615  LS failed, Hessian reset \n",
      "     499       1920.34   0.000510142       310.663      0.1736      0.9078      673   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1922.24   0.000344636       144.463      0.7309      0.7309      813   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     642       1923.05   3.64941e-05       68.8702   1.025e-06       0.001      918  LS failed, Hessian reset \n",
      "     699       1923.39    0.00435543       115.459           1           1      987   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     769       1923.53   1.48541e-05       29.9138   2.547e-07       0.001     1135  LS failed, Hessian reset \n",
      "     799       1923.62   0.000639321       88.0087           1           1     1174   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1924.07   0.000463485       92.0768      0.6874      0.6874     1302   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     906       1924.11   2.91633e-05       57.4166    2.56e-07       0.001     1359  LS failed, Hessian reset \n",
      "     941       1924.18    4.8701e-05       47.0214   1.375e-06       0.001     1448  LS failed, Hessian reset \n",
      "     967       1924.19   4.51862e-05       22.8474   1.588e-06       0.001     1513  LS failed, Hessian reset \n",
      "     999       1924.21   0.000604295       179.998      0.7393      0.7393     1551   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1925.09    0.00848989       121.916      0.3842      0.3842     1684   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1119       1925.38   2.58102e-05       64.2827    4.31e-07       0.001     1783  LS failed, Hessian reset \n",
      "    1160       1925.83   2.93694e-05       22.8702   2.043e-07       0.001     1876  LS failed, Hessian reset \n",
      "    1199       1925.98   0.000897182       46.0692      0.3112      0.3112     1941   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299       1926.29   1.42759e-05       34.0301   3.059e-07       0.001     2119  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1346       1926.43   2.81514e-05       26.4854   2.062e-07       0.001     2218  LS failed, Hessian reset \n",
      "    1399       1926.48   0.000410424        41.767           1           1     2280   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1406       1926.48   1.15237e-05       19.3257   4.705e-07       0.001     2336  LS failed, Hessian reset \n",
      "    1443       1926.51   1.95328e-05       32.0553   8.859e-07       0.001     2422  LS failed, Hessian reset \n",
      "    1482       1926.52   1.57373e-05        36.637   7.343e-07       0.001     2508  LS failed, Hessian reset \n",
      "    1499       1926.53   1.54654e-05       27.0271      0.6822      0.6822     2530   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1554       1926.64   2.59462e-05        49.255    2.43e-07       0.001     2643  LS failed, Hessian reset \n",
      "    1599       1926.72   1.84102e-05       31.6434      0.9293      0.9293     2705   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1699       1926.77   0.000711456       47.6767           1           1     2850   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1733       1927.15   9.86582e-05       138.772    1.21e-06       0.001     2937  LS failed, Hessian reset \n",
      "    1799       1927.36   0.000210834       38.5157      0.3438           1     3014   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1817       1927.36   2.15262e-05       52.7922    5.97e-07       0.001     3084  LS failed, Hessian reset \n",
      "    1852       1927.39   3.20444e-05       69.9253   7.491e-07       0.001     3165  LS failed, Hessian reset \n",
      "    1899       1927.42   3.21924e-06       39.5349      0.5132      0.5132     3232   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1955       1927.52   3.57641e-05       64.2731   1.018e-06       0.001     3352  LS failed, Hessian reset \n",
      "    1983       1927.52   1.88488e-06       18.5355   9.894e-08       0.001     3427  LS failed, Hessian reset \n",
      "    1999       1927.52   1.96864e-06       32.0037      0.4403      0.4403     3447   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2036       1927.53   4.28041e-05       75.6346   1.033e-06       0.001     3555  LS failed, Hessian reset \n",
      "    2099       1927.54   1.05601e-06       26.8218           1           1     3644   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2105       1927.54   1.35496e-06       22.9512    5.27e-08       0.001     3706  LS failed, Hessian reset \n",
      "    2107       1927.54   2.68602e-07       16.6328      0.8672      0.8672     3708   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -7.51021\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1885.22    0.00776972       185.904           1           1      134   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1914.84      0.014786       217.008           1           1      251   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299        1923.4    0.00645782       159.671      0.1815           1      378   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1926.24   0.000764807       262.548       0.239           1      506   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499        1928.6   0.000289512       66.2132      0.5543      0.5543      629   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1935.82     0.0133061       262.331        0.22           1      768   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     601       1935.86   6.17048e-05       152.395   3.313e-07       0.001      862  LS failed, Hessian reset \n",
      "     636       1938.16   6.54169e-05       100.864   1.435e-06       0.001      964  LS failed, Hessian reset \n",
      "     699       1939.32    0.00319991       282.077           1           1     1054   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     711       1939.57   1.61902e-05       22.7274   2.067e-07       0.001     1118  LS failed, Hessian reset \n",
      "     799       1940.18    0.00199345       41.4287           1           1     1241   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     846        1940.7   1.09482e-05       19.5303   2.201e-07       0.001     1356  LS failed, Hessian reset \n",
      "     890       1940.79   1.71969e-05       32.2899   2.223e-07       0.001     1451  LS failed, Hessian reset \n",
      "     899        1940.8   4.55306e-06       32.0962     0.01613        0.06     1467   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     912        1940.8   1.35979e-05       30.2223   4.884e-07       0.001     1526  LS failed, Hessian reset \n",
      "     995       1941.31   2.29505e-05       48.4087   2.388e-07       0.001     1722  LS failed, Hessian reset \n",
      "     999       1941.34    0.00083286       49.5162           1           1     1727   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1033       1941.51   1.99896e-05       35.7291   2.177e-07       0.001     1814  LS failed, Hessian reset \n",
      "    1075       1941.57   1.36888e-05       34.1825   2.716e-07       0.001     1913  LS failed, Hessian reset \n",
      "    1099       1941.58   1.10985e-05       30.6852      0.3032           1     1950   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1130       1941.59   3.16793e-05       68.6384   7.309e-07       0.001     2027  LS failed, Hessian reset \n",
      "    1155        1941.6   8.17488e-07       25.1397   3.043e-08       0.001     2093  LS failed, Hessian reset \n",
      "    1167        1941.6   2.40505e-08        29.651     0.01936     0.07649     2113   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -7.61619\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1901.27     0.0402407       692.591           1           1      136   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1928.09    0.00226931       180.065           1           1      259   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1933.17   0.000928451       118.481      0.6405      0.6405      397   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1937.24      0.056498        224.04           1           1      525   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1943.53      0.003256       161.377           1           1      646   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     594       1945.59    3.4894e-05        65.001   2.224e-07       0.001      815  LS failed, Hessian reset \n",
      "     599       1945.66   0.000920562       66.4549      0.7703      0.7703      821   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1946.45     0.0438991       134.263      0.9051      0.9051      951   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     702       1946.49   1.80788e-05        42.269   2.552e-07       0.001     1003  LS failed, Hessian reset \n",
      "     768       1947.01   2.06253e-05       36.7041   2.134e-07       0.001     1131  LS failed, Hessian reset \n",
      "     799       1947.06   0.000109797       29.2758      0.3916           1     1174   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1947.51    0.00522388       122.898      0.3296           1     1301   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     957       1948.08   1.83881e-05       39.6104   2.313e-07       0.001     1429  LS failed, Hessian reset \n",
      "     999       1948.35    0.00464377       143.202           1           1     1491   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1056       1948.51   2.85661e-05       68.4192   6.813e-07       0.001     1610  LS failed, Hessian reset \n",
      "    1099       1948.53   4.34848e-05        25.778           1           1     1661   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1181       1948.65   6.66661e-06       31.3642    2.46e-07       0.001     1833  LS failed, Hessian reset \n",
      "    1199       1948.65    3.8458e-05        25.307           1           1     1854   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1217       1948.66   1.70768e-05       39.9772   2.523e-07       0.001     1916  LS failed, Hessian reset \n",
      "    1238       1948.66   1.38402e-07       29.6135      0.5173       0.139     1952   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -7.39224\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1904.36     0.0160475       730.555      0.7299     0.07299      136   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1927.49    0.00159554       85.7098           1           1      257   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299        1944.6   0.000998344       108.873      0.6557      0.6557      379   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399          1947   0.000549258       158.164     0.05658           1      509   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1948.84   0.000958861         143.6      0.3267      0.3267      627   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1951.42    0.00856494        338.82           1           1      754   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     640       1952.34   4.62718e-05       77.0301   1.091e-06       0.001      853  LS failed, Hessian reset \n",
      "     686       1952.51   1.49269e-05       41.4808   3.377e-07       0.001      964  LS failed, Hessian reset \n",
      "     696       1952.52   2.46654e-05       43.0856   1.008e-06       0.001     1019  LS failed, Hessian reset \n",
      "     699       1952.52   5.70054e-05       39.7429      0.3538           1     1023   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     766       1952.69   2.02483e-05       51.5468   3.729e-07       0.001     1145  LS failed, Hessian reset \n",
      "     799       1952.76    0.00012806        79.025      0.9066      0.9066     1193   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     835       1952.77   1.54135e-05        30.283   6.159e-07       0.001     1284  LS failed, Hessian reset \n",
      "     869       1952.78    1.1479e-05       30.3946   2.911e-07       0.001     1370  LS failed, Hessian reset \n",
      "     897       1952.78   1.49944e-06       19.3158           1           1     1408   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -7.02748\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1882.73    0.00539624       371.334           1           1      129   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        1927.5     0.0650904       244.717           1           1      259   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1945.94    0.00327848       125.296           1           1      387   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1950.63    0.00600662       724.804      0.4378      0.4378      505   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     428       1951.63    4.4459e-05       124.512   3.908e-07       0.001      584  LS failed, Hessian reset \n",
      "     499       1954.46    0.00270437        118.68      0.4874      0.4874      679   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     573       1955.13   1.44145e-05       34.2931   2.388e-07       0.001      815  LS failed, Hessian reset \n",
      "     599       1955.23   0.000224136       60.0134      0.6311      0.6311      849   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1957.49   0.000193099       47.5197      0.2095           1      987   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     711       1957.56    2.2463e-05       58.6234   3.131e-07       0.001     1055  LS failed, Hessian reset \n",
      "     799       1958.08    0.00286075       264.643           1           1     1172   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1959.52   0.000611388       338.625     0.02899           1     1307   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     923       1959.84   1.44023e-05       37.2439   2.552e-07       0.001     1375  LS failed, Hessian reset \n",
      "     941       1959.94   1.28162e-05       32.7405   5.888e-07       0.001     1444  LS failed, Hessian reset \n",
      "     999       1960.14    0.00438284       47.2647           1           1     1524   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1084       1960.96   9.40533e-05       116.065   1.668e-06       0.001     1681  LS failed, Hessian reset \n",
      "    1099          1961   0.000129202       44.0332           1           1     1702   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1961.32   0.000285812       41.5085      0.7237      0.7237     1849   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1293       1962.08   2.24989e-05       61.9461   2.787e-07       0.001     2032  LS failed, Hessian reset \n",
      "    1299       1962.28    0.00283912       199.782           1           1     2040   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399       1962.57   0.000613495       66.6408           1           1     2171   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1489       1962.84   5.55937e-05       36.9655   2.493e-06       0.001     2325  LS failed, Hessian reset \n",
      "    1499       1962.85   0.000137514       48.6383      0.8563      0.8563     2341   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1518       1962.86   1.25265e-05       29.4089   2.503e-07       0.001     2406  LS failed, Hessian reset \n",
      "    1525       1962.86   2.88307e-05       55.8226    6.63e-07       0.001     2455  LS failed, Hessian reset \n",
      "    1599        1962.9   2.34778e-05       25.6498           1           1     2557   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1601        1962.9   5.70902e-06       22.8226   2.486e-07       0.001     2599  LS failed, Hessian reset \n",
      "    1608        1962.9   4.24607e-07       19.2129      0.8935      0.8935     2608   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.83065\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1904.92     0.0172897        1497.6       1.048      0.1048      130   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1941.75    0.00155437       226.504      0.2443     0.02443      261   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1957.02     0.0126802       367.296      0.7443      0.7443      382   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1966.87    0.00387753       199.039      0.9089      0.9089      519   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1974.22    0.00779129       76.7513       3.857     0.03857      654   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1976.91     0.0025332       201.887      0.9979      0.9979      782   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     674       1979.41   0.000119842       43.4249   2.645e-06       0.001      912  LS failed, Hessian reset \n",
      "     699       1979.72    0.00033733       140.146     0.09646           1      942   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1981.29    0.00178122       180.047           1           1     1078   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     842       1981.99   7.33819e-05       41.6633   3.348e-06       0.001     1169  LS failed, Hessian reset \n",
      "     859       1982.04   5.65865e-05       102.482   1.038e-06       0.001     1232  LS failed, Hessian reset \n",
      "     899       1982.16   0.000417774       51.2958           1           1     1288   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     949       1983.76   1.72936e-05       47.0377   2.036e-07       0.001     1390  LS failed, Hessian reset \n",
      "     999        1985.2     0.0074809       25.5343           1           1     1458   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1009       1985.22   1.61591e-05       47.7629   3.951e-07       0.001     1511  LS failed, Hessian reset \n",
      "    1099       1985.68   0.000496956       99.0351      0.5665      0.5665     1634   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1986.14   0.000143005       137.997      0.6232      0.6232     1765   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1210       1986.18   1.87128e-05        28.031   1.626e-07       0.001     1818  LS failed, Hessian reset \n",
      "    1297       1986.39   3.61221e-05       104.181   3.599e-07       0.001     1997  LS failed, Hessian reset \n",
      "    1299        1986.4   0.000105006       26.2535           1           1     1999   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1352       1986.43   6.16124e-05       83.9115     1.7e-06       0.001     2111  LS failed, Hessian reset \n",
      "    1388       1986.43   9.06549e-06       32.8537   2.774e-07       0.001     2201  LS failed, Hessian reset \n",
      "    1399       1986.43   9.28976e-08       15.0587      0.3519      0.3519     2220   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.36795\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1915.13    0.00629172       646.981      0.9515      0.9515      128   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1958.39      0.080057        715.18       14.01      0.1401      258   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1970.44    0.00405348        280.11      0.5396      0.5396      392   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1977.43    0.00201072         139.5      0.1527           1      528   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1981.39     0.0611586       224.643           1           1      656   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     586       1988.25   1.62748e-05       47.4004   2.225e-07       0.001      810  LS failed, Hessian reset \n",
      "     599       1988.45   0.000674398       313.056      0.2166           1      830   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     641       1988.78   1.05054e-05       32.7084   2.572e-07       0.001      923  LS failed, Hessian reset \n",
      "     699       1990.01     0.0100471       221.898           1           1      995   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     754       1991.75   3.14963e-05        100.64   3.383e-07       0.001     1117  LS failed, Hessian reset \n",
      "     799       1993.23   0.000186728       175.274      0.7581      0.7581     1175   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1993.96   0.000285198       106.093           1           1     1313   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     925       1993.99   0.000184383       178.729   5.525e-06       0.001     1380  LS failed, Hessian reset \n",
      "     963       1994.09   0.000120648       147.801   2.833e-06       0.001     1468  LS failed, Hessian reset \n",
      "     999       1994.19   7.44963e-05       30.9647      0.6219      0.6219     1513   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1994.28    0.00676348       103.621           1           1     1643   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1186       1995.06   8.79732e-06       29.3588   2.411e-07       0.001     1810  LS failed, Hessian reset \n",
      "    1199       1995.13   0.000238203       50.3328       0.771       0.771     1829   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1283       1995.41   2.71222e-05       25.7754   1.482e-07       0.001     1981  LS failed, Hessian reset \n",
      "    1299       1995.43   2.69367e-05       23.2901      0.3851      0.3851     2012   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1303       1995.44   1.08208e-05       28.6506   2.902e-07       0.001     2057  LS failed, Hessian reset \n",
      "    1399       1995.52   0.000456244        87.914       5.058      0.5058     2186   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1408       1995.53   3.30065e-05       81.9216   1.251e-06       0.001     2254  LS failed, Hessian reset \n",
      "    1462       1995.58   9.21101e-06       29.7661   2.138e-07       0.001     2366  LS failed, Hessian reset \n",
      "    1486       1995.58   1.42878e-06       26.8776   5.431e-08       0.001     2438  LS failed, Hessian reset \n",
      "    1491       1995.58   3.29833e-07       27.3856           1           1     2447   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.43065\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        1894.5    0.00452699       420.232           1           1      123   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1954.27    0.00317126        1154.2      0.4856      0.4856      240   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1969.24    0.00499705       463.855           1           1      363   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1978.72    0.00537318       173.527           1           1      491   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     476       1981.01   2.45884e-05       62.4008   2.116e-07       0.001      629  LS failed, Hessian reset \n",
      "     499       1981.42    0.00106222       37.3695           1           1      657   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1983.03    0.00328293       145.096      0.1173      0.7845      791   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1984.06    0.00026272       56.6023           1           1      919   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     745       1984.19   3.28514e-05        29.312   1.599e-07       0.001     1017  LS failed, Hessian reset \n",
      "     751       1984.25   1.07267e-05       28.2677   2.024e-07       0.001     1070  LS failed, Hessian reset \n",
      "     799       1984.36   0.000178314       67.5884       0.859       0.859     1130   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     820       1984.95   5.29895e-05       91.8144   1.635e-07       0.001     1202  LS failed, Hessian reset \n",
      "     869       1985.65   1.54904e-05       31.7295    1.75e-07       0.001     1300  LS failed, Hessian reset \n",
      "     899        1985.7   0.000263247       60.7498           1           1     1342   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     905       1985.72   2.14555e-05        64.146   2.959e-07       0.001     1393  LS failed, Hessian reset \n",
      "     999       1986.13    0.00205005       45.3881           1           1     1514   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1024       1986.42   7.59685e-05       197.094   6.622e-07       0.001     1598  LS failed, Hessian reset \n",
      "    1099       1986.71    0.00337262        33.673           1           1     1691   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1123       1986.76   5.46678e-05       14.2046    2.47e-06       0.001     1777  LS failed, Hessian reset \n",
      "    1154       1986.78   1.36691e-05       41.6872    2.38e-07       0.001     1863  LS failed, Hessian reset \n",
      "    1199       1986.79    9.0135e-06       21.1959           1           1     1926   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1263       1986.83   4.09887e-06       28.5198   2.855e-07       0.001     2045  LS failed, Hessian reset \n",
      "    1282       1986.84   1.39387e-05       45.0141   3.532e-07       0.001     2120  LS failed, Hessian reset \n",
      "    1299       1986.84    2.0792e-05       33.3376           1           1     2141   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399       1986.88   8.07422e-05       37.4528      0.4487           1     2288   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1499       1987.03     0.0018567       114.555           1           1     2416   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1559       1987.22   1.75875e-05        53.125   4.686e-07       0.001     2556  LS failed, Hessian reset \n",
      "    1599       1987.24   1.08627e-05       31.5481      0.4887      0.4887     2603   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1658       1987.25   3.78881e-06       35.1643   1.509e-07       0.001     2719  LS failed, Hessian reset \n",
      "    1680       1987.25    3.4969e-05       26.5121   1.144e-06       0.001     2785  LS failed, Hessian reset \n",
      "    1699       1987.25   3.58074e-06       26.8586      0.3631           1     2816   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1707       1987.25   6.76437e-07       27.0637        0.45           1     2828   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.88674\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1911.24      0.038412        4315.1      0.3456           1      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1946.51    0.00304796        211.23        0.37           1      242   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1965.59    0.00061345       58.1748           1           1      375   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1968.64    0.00699485        51.005           1           1      495   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1974.35      0.004047       127.575           1           1      614   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     590       1975.56   1.45083e-05       42.5747   2.806e-07       0.001      773  LS failed, Hessian reset \n",
      "     599       1975.65   0.000669193       198.983      0.4423      0.4423      784   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     642       1975.88   0.000124875       129.009    4.54e-06       0.001      872  LS failed, Hessian reset \n",
      "     699       1976.27     0.0173554       281.806           1           1      943   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1978.34    0.00171197       91.4215      0.5077           1     1077   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     856       1980.43   5.08063e-05        137.72   3.905e-07       0.001     1194  LS failed, Hessian reset \n",
      "     899       1981.46   0.000606114        59.561       1.034      0.1034     1252   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     934       1981.61    1.3242e-05       41.2161   2.782e-07       0.001     1351  LS failed, Hessian reset \n",
      "     999        1981.9   0.000114107       45.9284      0.2605           1     1440   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099        1982.6   0.000608183       105.072      0.4399      0.4399     1570   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1155       1982.78   1.10427e-05       25.0297    1.87e-07       0.001     1680  LS failed, Hessian reset \n",
      "    1199       1982.82   0.000114145       67.5067      0.4241      0.4241     1738   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299       1984.47    0.00384498       116.369           1           1     1870   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1326       1984.82   1.34746e-05       41.2359    3.86e-07       0.001     1950  LS failed, Hessian reset \n",
      "    1399       1985.09   0.000137772       33.2442      0.2377           1     2053   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1432       1985.14   1.07143e-05       30.7009    2.43e-07       0.001     2149  LS failed, Hessian reset \n",
      "    1499       1985.19   0.000791996       60.4197           1           1     2231   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1503       1985.19   2.77304e-05        53.974   1.038e-06       0.001     2279  LS failed, Hessian reset \n",
      "    1565       1985.22   1.32368e-05       36.0152   2.736e-07       0.001     2393  LS failed, Hessian reset \n",
      "    1599       1985.24    0.00026122       21.4952           1           1     2438   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1699       1985.59    0.00738565       33.0952           1           1     2566   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1733       1985.64   1.10419e-05       31.2423   2.297e-07       0.001     2660  LS failed, Hessian reset \n",
      "    1758       1985.66   1.58167e-05       49.6294   3.987e-07       0.001     2735  LS failed, Hessian reset \n",
      "    1799       1985.68     0.0003488       37.2855           1           1     2792   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1865       1985.95   1.30531e-05       41.6835   2.658e-07       0.001     2912  LS failed, Hessian reset \n",
      "    1899       1986.01   2.79335e-05       37.3253       0.443       0.443     2962   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1965       1986.06   1.25591e-05       25.9469   5.458e-07       0.001     3094  LS failed, Hessian reset \n",
      "    1978       1986.06   3.57731e-08       30.2337    0.007483     0.08409     3119   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.18356\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1898.69    0.00207743       241.341      0.2113      0.2113      134   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        1934.9     0.0217496       1333.82      0.7859      0.7859      254   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1950.32   0.000871637          59.2           1           1      371   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     361       1956.61   2.90331e-05        71.471    2.39e-07       0.001      517  LS failed, Hessian reset \n",
      "     399        1959.1    0.00697986       541.825     0.08707      0.4662      566   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1963.09   0.000368866       101.037     0.02527           1      694   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1965.93    0.00753295       106.502           1           1      817   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1969.39    0.00147494       78.5429      0.9524     0.09524      943   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1972.49    0.00896962       517.765           1           1     1064   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     872       1973.55   6.70235e-05        131.48   9.036e-07       0.001     1206  LS failed, Hessian reset \n",
      "     898       1973.72   9.41687e-06       23.1251   2.166e-07       0.001     1277  LS failed, Hessian reset \n",
      "     899       1973.72   4.42266e-05       18.8301          10           1     1279   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     955       1973.87   1.51008e-05       38.9711   5.841e-07       0.001     1391  LS failed, Hessian reset \n",
      "     999       1973.94   0.000113256       40.2645      0.2347           1     1450   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1974.33   0.000790439       85.7981      0.7176      0.7176     1574   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1195       1974.64   4.86858e-05       76.6324   1.747e-06       0.001     1752  LS failed, Hessian reset \n",
      "    1199       1974.65    5.5094e-05       85.7623      0.9077      0.9077     1756   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1243       1974.77   3.25435e-05       26.4587    1.22e-06       0.001     1861  LS failed, Hessian reset \n",
      "    1266       1974.78   1.39706e-05       37.5721   2.707e-07       0.001     1935  LS failed, Hessian reset \n",
      "    1277       1974.78   2.65279e-06       22.8256   9.382e-08       0.001     1991  LS failed, Hessian reset \n",
      "    1280       1974.78   1.19837e-07       22.3218      0.0332      0.6746     1997   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.31498\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1874.93    0.00459107       143.392           1           1      132   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1914.99    0.00593077        1281.8      0.2099      0.2099      249   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1924.51   0.000621107       63.3906           1           1      382   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1931.67    0.00243835       63.4174      0.2003      0.8043      508   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1936.08    0.00275261       207.539      0.6263      0.2294      635   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     597       1937.67   1.58001e-05        39.932   3.891e-07       0.001      818  LS failed, Hessian reset \n",
      "     599       1937.68    0.00118655       185.053          10           1      822   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     650       1938.01   3.13637e-05       76.8274   3.601e-07       0.001      934  LS failed, Hessian reset \n",
      "     699       1938.27   0.000151328       67.7237           1           1     1004   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     720       1938.52   3.48041e-05       74.8954   8.546e-07       0.001     1074  LS failed, Hessian reset \n",
      "     786        1938.7   1.34244e-05       33.6314   3.026e-07       0.001     1199  LS failed, Hessian reset \n",
      "     795       1938.74   1.21075e-05       28.8978   4.633e-07       0.001     1259  LS failed, Hessian reset \n",
      "     799       1938.75   0.000396313       23.6315      0.1647           1     1264   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1939.49    0.00504766       59.7865           1           1     1394   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     918        1939.9   2.06275e-05       48.7455   2.726e-07       0.001     1467  LS failed, Hessian reset \n",
      "     984       1940.25   1.50398e-05       37.4012   5.506e-07       0.001     1593  LS failed, Hessian reset \n",
      "     999       1940.27   3.41797e-05       48.4526     0.04231           1     1617   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1031       1940.29   2.88091e-05       64.0179   5.791e-07       0.001     1701  LS failed, Hessian reset \n",
      "    1099       1940.34   7.64917e-05       106.012      0.3891      0.3891     1784   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1104       1940.36   0.000153165        49.166   2.579e-06       0.001     1830  LS failed, Hessian reset \n",
      "    1149       1940.38   5.10454e-06       17.9267   1.626e-07       0.001     1926  LS failed, Hessian reset \n",
      "    1163       1940.38   5.21112e-07       25.7998      0.6397      0.6397     1945   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.74755\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99          1882     0.0786977       560.043           1           1      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1914.23     0.0101869       290.652      0.1225           1      251   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1923.49    0.00101583       412.189     0.07978     0.07978      377   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1927.42    0.00565497       239.082      0.4361    0.004361      502   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1929.15   0.000139891       31.1143      0.4066           1      633   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1930.76   0.000590705       181.897      0.5577      0.5577      761   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     638       1931.22   3.58164e-05       59.0474   2.125e-07       0.001      845  LS failed, Hessian reset \n",
      "     679       1931.68   1.00016e-05       26.3893   3.853e-07       0.001      942  LS failed, Hessian reset \n",
      "     699       1931.72    0.00103488       38.2557           1           1      969   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     709       1931.75   2.26114e-05       53.7796    5.31e-07       0.001     1052  LS failed, Hessian reset \n",
      "     765       1931.82   1.34088e-05       33.1933   2.783e-07       0.001     1168  LS failed, Hessian reset \n",
      "     799       1931.84   0.000168653       60.5976     0.07127           1     1220   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     800       1931.84   1.25869e-05       27.9579   2.077e-07       0.001     1260  LS failed, Hessian reset \n",
      "     891       1931.97     1.915e-05       47.6643   3.249e-07       0.001     1453  LS failed, Hessian reset \n",
      "     899       1932.01   0.000556343       29.7505       4.433     0.04433     1467   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     912       1932.04   1.27171e-05       26.5735   2.106e-07       0.001     1520  LS failed, Hessian reset \n",
      "     939       1932.05   1.51624e-05        35.194   7.708e-07       0.001     1608  LS failed, Hessian reset \n",
      "     960       1932.05   9.49549e-06       21.1707   2.725e-07       0.001     1681  LS failed, Hessian reset \n",
      "     975       1932.05   4.81117e-07       20.8938      0.9938      0.9938     1709   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.77031\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1872.84    0.00739486       284.399      0.3444           1      121   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1909.02    0.00372609       136.872           1           1      246   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1913.74     0.0137671       156.886      0.3258           1      362   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1923.14    0.00545149       379.074       0.854       0.854      489   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     490       1925.93   1.30291e-05       31.6396    3.02e-07       0.001      639  LS failed, Hessian reset \n",
      "     499       1926.05     0.0117174       65.8862           1           1      651   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     567       1929.72   0.000176604       385.813   5.374e-07       0.001      778  LS failed, Hessian reset \n",
      "     599       1931.16    0.00109331       71.7417       0.829       0.829      821   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     696       1932.98    1.8624e-05        48.743   3.197e-07       0.001      993  LS failed, Hessian reset \n",
      "     699       1933.01   0.000259325       51.8448      0.6584      0.6584      997   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     750       1933.43   5.78639e-10       124.623   7.672e-08      0.3467     1086   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "Initial log joint probability = -5.75319\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1873.47    0.00253321       210.299      0.2784      0.2784      131   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1902.61     0.0124471       77.7655           1           1      241   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1907.96     0.0197403       263.185           1           1      360   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        1916.5     0.0187964       552.171           1           1      489   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1924.07     0.0051118       200.165           1           1      630   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     542       1925.42   3.10163e-05       72.3817   5.019e-07       0.001      728  LS failed, Hessian reset \n",
      "     599       1925.74    0.00174916       235.818           1           1      806   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     621       1926.28   0.000105752       134.761    2.84e-06       0.001      873  LS failed, Hessian reset \n",
      "     642       1926.81   1.36812e-05       21.4879   2.151e-07       0.001      938  LS failed, Hessian reset \n",
      "     699       1927.08    0.00287845       35.4303           1           1     1008   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     729       1927.74   5.27709e-05       29.3783   1.947e-07       0.001     1090  LS failed, Hessian reset \n",
      "     799       1928.15    0.00577515       255.336        1.72       0.172     1192   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     818       1928.72   5.99823e-05       86.2197   2.089e-07       0.001     1272  LS failed, Hessian reset \n",
      "     865       1929.52   2.28219e-05       54.2514   4.481e-07       0.001     1377  LS failed, Hessian reset \n",
      "     899       1929.65    0.00176346       83.5128           1           1     1419   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     904       1929.67   2.38301e-05       54.0788   7.657e-07       0.001     1471  LS failed, Hessian reset \n",
      "     966       1929.87    6.3934e-05       113.156   9.613e-07       0.001     1588  LS failed, Hessian reset \n",
      "     996       1930.01   2.18244e-05       48.5949   2.419e-07       0.001     1674  LS failed, Hessian reset \n",
      "     999       1930.01   2.91942e-05       19.7554      0.9665      0.9665     1677   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1930.36   0.000304982       29.4097      0.3353           1     1809   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1110       1930.37    1.8922e-05       30.1586   2.073e-07       0.001     1863  LS failed, Hessian reset \n",
      "    1199       1930.46   0.000626442        69.455       3.881      0.3881     1977   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299       1931.88     0.0325033       110.491      0.4474      0.4474     2100   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1315       1932.01   1.63375e-05       42.7448   2.755e-07       0.001     2189  LS failed, Hessian reset \n",
      "    1385       1932.45   0.000703929       181.899   1.731e-05       0.001     2335  LS failed, Hessian reset \n",
      "    1399        1932.5   3.21262e-05       64.1682   9.923e-07       0.001     2397  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1499       1932.61   0.000449058       59.5094      0.8508      0.8508     2532   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1524       1932.62    8.9105e-05       110.165    2.24e-06       0.001     2606  LS failed, Hessian reset \n",
      "    1593       1932.65   4.10439e-05       49.5647   1.364e-06       0.001     2761  LS failed, Hessian reset \n",
      "    1599       1932.65    8.6079e-05       45.0713          10           1     2769   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1616       1932.66   3.01763e-05       48.4757   9.865e-07       0.001     2828  LS failed, Hessian reset \n",
      "    1633       1932.66   7.75182e-06       32.4155   4.597e-07       0.001     2877  LS failed, Hessian reset \n",
      "    1643       1932.66   3.82511e-08       25.7362     0.02393     0.08485     2896   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.7487\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1848.67    0.00452401       87.3189           1           1      131   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1888.96     0.0279847       672.788      0.1882           1      243   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1901.61    0.00312829       330.226           1           1      367   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     309       1902.65   4.70568e-05       100.521    7.77e-07       0.001      427  LS failed, Hessian reset \n",
      "     399       1908.39     0.0407973       479.852           1           1      538   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     430       1909.95   2.74885e-05       63.8916   4.598e-07       0.001      617  LS failed, Hessian reset \n",
      "     457       1910.56   4.86963e-05       111.171   3.547e-07       0.001      691  LS failed, Hessian reset \n",
      "     496       1911.19   2.75007e-05       62.1828    3.21e-07       0.001      773  LS failed, Hessian reset \n",
      "     499       1911.23   0.000330529       49.9468      0.6321      0.6321      777   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     531       1911.41   2.00799e-05       46.1436    4.27e-07       0.001      884  LS failed, Hessian reset \n",
      "     560       1911.75   0.000135315       222.047   9.477e-07       0.001      958  LS failed, Hessian reset \n",
      "     591       1912.48   2.90815e-05       58.5846   2.696e-07       0.001     1039  LS failed, Hessian reset \n",
      "     599       1912.59     0.0029884       64.8298      0.5121           1     1051   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699        1913.9     0.0018576       425.244      0.5855      0.5855     1188   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     777       1914.88   5.25461e-05       51.6248   2.096e-07       0.001     1338  LS failed, Hessian reset \n",
      "     799          1915   8.18433e-05       26.2475       0.804       0.804     1369   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1915.75    0.00194822       33.6002      0.7859      0.7859     1494   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     954        1916.1   6.90571e-05       85.0348   2.234e-06       0.001     1668  LS failed, Hessian reset \n",
      "     999       1916.16   6.38426e-05        60.058      0.8526      0.8526     1722   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1004       1916.17   2.74613e-05       60.3733   6.837e-07       0.001     1769  LS failed, Hessian reset \n",
      "    1099       1916.29   0.000785835        33.892           1           1     1889   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1126       1916.32   1.25168e-05       20.3994   2.279e-07       0.001     1980  LS failed, Hessian reset \n",
      "    1150       1916.33   1.45518e-05       43.7033   4.954e-07       0.001     2053  LS failed, Hessian reset \n",
      "    1199       1916.33   1.97422e-05       42.7374     0.04671           1     2123   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1264       1916.34   2.33742e-07       27.0963      0.4093      0.4093     2217   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.91668\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1853.33    0.00939476       143.399      0.7802      0.7802      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1890.02      0.016568       411.888       1.748      0.1748      249   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299        1908.6     0.0125441       124.568           1           1      368   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     364       1913.48   0.000101769       115.793   1.976e-06       0.001      491  LS failed, Hessian reset \n",
      "     399       1914.06   0.000252166       40.5481           1           1      530   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     400       1914.06   2.52536e-05       57.7211   6.228e-07       0.001      569  LS failed, Hessian reset \n",
      "     430       1914.98   0.000206756       288.266   1.045e-06       0.001      644  LS failed, Hessian reset \n",
      "     499       1915.71    0.00303972       433.733           1           1      730   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     544       1917.19   2.08745e-05       40.6547    2.48e-07       0.001      856  LS failed, Hessian reset \n",
      "     599       1918.21    0.00130974        75.119           1           1      928   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     640       1918.47   4.61389e-05       92.0095   7.589e-07       0.001     1027  LS failed, Hessian reset \n",
      "     699       1918.64   0.000333416       36.6944           1           1     1113   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1919.66    0.00030125       37.3647      0.7694      0.7694     1237   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     827       1919.71   3.16143e-05       65.6746    7.46e-07       0.001     1313  LS failed, Hessian reset \n",
      "     899       1919.77   3.22073e-05       23.1491       0.866       0.866     1406   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     943       1919.91   1.70411e-05       16.1074   2.072e-07       0.001     1506  LS failed, Hessian reset \n",
      "     965       1919.98     2.822e-05       61.4106   6.358e-07       0.001     1573  LS failed, Hessian reset \n",
      "     999       1920.04    0.00046101       40.3221      0.4032      0.4032     1623   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1015       1920.09   1.40048e-05       33.9002   3.405e-07       0.001     1681  LS failed, Hessian reset \n",
      "    1049       1920.11   2.45617e-05       50.7909   8.824e-07       0.001     1779  LS failed, Hessian reset \n",
      "    1099       1920.12   1.11024e-05       22.9374           1           1     1859   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1110       1920.12   9.73468e-05       38.9644   2.956e-06       0.001     1913  LS failed, Hessian reset \n",
      "    1166       1920.13   3.32933e-06       18.4668   1.745e-07       0.001     2022  LS failed, Hessian reset \n",
      "    1199       1920.13   8.20016e-06       18.7057      0.8684      0.8684     2069   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1257       1920.33    0.00027474        159.67   3.425e-06       0.001     2188  LS failed, Hessian reset \n",
      "    1293       1920.54   1.63744e-05       20.6577   2.132e-07       0.001     2271  LS failed, Hessian reset \n",
      "    1299       1920.55   0.000208347       37.2276      0.3045           1     2279   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1339       1920.62   2.67096e-05       56.3322   2.615e-07       0.001     2382  LS failed, Hessian reset \n",
      "    1373       1920.64   1.45412e-05       34.4752   2.876e-07       0.001     2477  LS failed, Hessian reset \n",
      "    1399       1920.65   2.11572e-05       35.3551           1           1     2511   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1406       1920.65   6.13955e-06       19.6444    2.27e-07       0.001     2555  LS failed, Hessian reset \n",
      "    1465       1920.69    0.00015607       96.6357   5.659e-06       0.001     2702  LS failed, Hessian reset \n",
      "    1499       1920.71   5.46305e-06       34.4056       0.799       0.799     2750   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1550       1920.72   9.71422e-08       24.1898     0.07931           1     2823   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.77088\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        1872.7    0.00682541       286.928       0.949       0.949      121   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1909.07     0.0135625       341.217           1           1      244   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     212       1910.71   0.000376662       118.208   5.782e-06       0.001      294  LS failed, Hessian reset \n",
      "     299       1916.34    0.00923393        117.69           1           1      403   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1918.56   0.000790862       115.008     0.05037           1      523   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     467        1921.4   8.67645e-05       206.575   4.149e-07       0.001      644  LS failed, Hessian reset \n",
      "     499       1922.72     0.0143303        491.89           1           1      681   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     512       1923.55   7.98961e-05       82.8096    2.15e-07       0.001      733  LS failed, Hessian reset \n",
      "     599        1925.3    0.00462638       53.4695           1           1      847   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     688       1928.43   1.82202e-05       35.8287   2.338e-07       0.001     1002  LS failed, Hessian reset \n",
      "     699       1928.51   0.000481652       67.8513       0.608       0.608     1015   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     769       1928.84   2.85628e-05        54.965   2.332e-07       0.001     1142  LS failed, Hessian reset \n",
      "     799       1928.95   0.000167822       33.3205      0.3294           1     1179   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     819       1929.03   1.56745e-05       31.7951    2.33e-07       0.001     1244  LS failed, Hessian reset \n",
      "     881       1929.34   4.53555e-05       103.926   2.837e-07       0.001     1367  LS failed, Hessian reset \n",
      "     899       1929.53   0.000344215       103.716           1           1     1388   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     904       1929.57   2.55343e-05       60.4777   6.028e-07       0.001     1435  LS failed, Hessian reset \n",
      "     982       1931.43   3.44114e-05       90.0238   3.365e-07       0.001     1594  LS failed, Hessian reset \n",
      "     999       1932.07   0.000343386       49.9792           1           1     1614   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1018       1932.47   1.42223e-05       34.8939   2.649e-07       0.001     1676  LS failed, Hessian reset \n",
      "    1099       1933.08    0.00170823       75.2023           1           1     1779   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1933.44    0.00130009       32.1516      0.2182           1     1908   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1204       1933.45   1.72882e-05       30.5336   2.091e-07       0.001     1977  LS failed, Hessian reset \n",
      "    1299       1933.71    0.00115453       41.9119           1           1     2116   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1308       1933.73   1.15733e-05       35.3851   2.495e-07       0.001     2176  LS failed, Hessian reset \n",
      "    1399       1933.95    0.00471623        94.207       2.206      0.2206     2296   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1431       1934.65   9.21122e-05       59.1419   1.876e-07       0.001     2393  LS failed, Hessian reset \n",
      "    1498       1935.22   2.43609e-05       60.7425   2.729e-07       0.001     2520  LS failed, Hessian reset \n",
      "    1499       1935.22   0.000137406       44.4378          10           1     2522   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1566       1935.36   4.14681e-05       43.9528    1.92e-07       0.001     2646  LS failed, Hessian reset \n",
      "    1599       1935.38   1.68806e-05       47.7457      0.2662      0.2662     2698   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1678       1935.51    3.2223e-05        86.174   3.361e-07       0.001     2841  LS failed, Hessian reset \n",
      "    1699       1935.54   0.000535685       80.9317           1           1     2867   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1763       1935.58   1.47947e-05       19.9647   6.036e-07       0.001     2989  LS failed, Hessian reset \n",
      "    1799       1935.59   5.18302e-05       37.9423      0.6592      0.6592     3038   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1807       1935.59   5.99061e-06       20.9352   1.733e-07       0.001     3090  LS failed, Hessian reset \n",
      "    1899       1935.69    0.00140266       62.6889           1           1     3210   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1979       1935.76    2.2541e-07       17.9373           1           1     3334   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.11216\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1877.44     0.0316933       288.968           1           1      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1912.53    0.00408279       454.526      0.9055      0.9055      244   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1921.95    0.00798859       207.639           1           1      368   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1929.85     0.0734199       720.634           1           1      482   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1933.28   0.000366669       97.2472           1           1      604   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     530       1934.73   0.000140385       318.302   5.191e-07       0.001      681  LS failed, Hessian reset \n",
      "     545       1935.35   0.000173394       52.8282   3.887e-06       0.001      736  LS failed, Hessian reset \n",
      "     599       1935.77   0.000838296       130.981       1.049      0.1049      801   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     687       1936.49   2.10554e-05       50.9123   2.664e-07       0.001      961  LS failed, Hessian reset \n",
      "     699       1936.54   0.000657557       91.7581           1           1      975   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     721       1936.57   4.49802e-05       75.3535   1.164e-06       0.001     1055  LS failed, Hessian reset \n",
      "     799       1936.71   7.82973e-05       28.5359      0.8279      0.8279     1158   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     850       1937.19   6.45679e-05       97.6225   2.091e-06       0.001     1281  LS failed, Hessian reset \n",
      "     899       1937.56    0.00124794       84.9613      0.0556           1     1346   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     902       1937.57   4.30999e-05       89.3832   6.904e-07       0.001     1388  LS failed, Hessian reset \n",
      "     944       1937.66   0.000340269       49.1203   8.372e-06       0.001     1479  LS failed, Hessian reset \n",
      "     964       1937.66   2.01915e-05       33.9627   8.505e-07       0.001     1549  LS failed, Hessian reset \n",
      "     999       1937.67   2.26462e-05       26.2371           1           1     1596   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1044       1937.84   5.08279e-05       86.5931   1.294e-06       0.001     1692  LS failed, Hessian reset \n",
      "    1099       1937.87   0.000183103       35.4894      0.3115           1     1767   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1100       1937.87   1.99377e-05       47.2859   5.618e-07       0.001     1812  LS failed, Hessian reset \n",
      "    1116       1937.87   2.79862e-08       21.2761     0.01857      0.5082     1846   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.3816\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1869.82     0.0274103       1457.02     0.07393           1      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1911.36     0.0156538        229.48       1.354      0.1354      252   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1922.29    0.00271773       239.557           1           1      379   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     306       1922.63   3.50677e-05       82.8816    3.37e-07       0.001      430  LS failed, Hessian reset \n",
      "     350       1924.83   2.13966e-05       53.0132   2.851e-07       0.001      528  LS failed, Hessian reset \n",
      "     399       1927.51    0.00836002       94.5646           1           1      587   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     464       1932.14   6.37939e-05       105.417   1.688e-06       0.001      712  LS failed, Hessian reset \n",
      "     499       1932.72   0.000578337       43.5673      0.2759           1      760   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     510       1932.74   0.000155903       89.9028   7.578e-06       0.001      813  LS failed, Hessian reset \n",
      "     599       1933.61     0.0104844       141.926           1           1      937   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     629        1934.3   0.000292165       320.184   1.824e-06       0.001     1018  LS failed, Hessian reset \n",
      "     699       1935.09   0.000654698        137.37      0.1372      0.4487     1113   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     721       1935.21   1.09567e-05       28.8526   3.263e-07       0.001     1226  LS failed, Hessian reset \n",
      "     726       1935.22   6.29348e-05       72.9781   3.003e-06       0.001     1271  LS failed, Hessian reset \n",
      "     766       1935.26   2.19376e-05       58.2736   3.993e-07       0.001     1365  LS failed, Hessian reset \n",
      "     799       1935.28   0.000272579       32.3182           1           1     1413   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     802       1935.28   1.71684e-05       38.8117   6.546e-07       0.001     1460  LS failed, Hessian reset \n",
      "     899       1935.39   0.000778149       102.888           1           1     1587   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     982       1935.66   2.52007e-05       42.7456   2.127e-07       0.001     1768  LS failed, Hessian reset \n",
      "     999       1935.72   0.000342464       21.6859           1           1     1793   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1062       1935.81   5.19652e-06       21.9218   1.507e-07       0.001     1917  LS failed, Hessian reset \n",
      "    1079       1935.81   4.25771e-06       28.2884   1.343e-07       0.001     1979  LS failed, Hessian reset \n",
      "    1087       1935.81   5.92727e-08       23.5904      0.1524      0.4245     1997   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.10028\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1878.22     0.0104384       285.448       2.684      0.2684      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1915.92    0.00358288       253.336      0.3917      0.3917      252   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1936.41    0.00166976       64.4823     0.06708           1      383   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     338       1938.13   8.56346e-05       147.368   1.056e-06       0.001      479  LS failed, Hessian reset \n",
      "     399       1939.61    0.00302733       365.295           1           1      555   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     451       1940.72   1.68821e-05       40.2924   2.583e-07       0.001      679  LS failed, Hessian reset \n",
      "     499       1941.08     0.0177668       465.679           1           1      745   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     562       1943.09   1.74145e-05       43.1287   2.597e-07       0.001      876  LS failed, Hessian reset \n",
      "     599       1943.42   0.000771566       30.1701           1           1      924   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     664       1943.91   2.55861e-05       38.8801   1.973e-07       0.001     1038  LS failed, Hessian reset \n",
      "     699       1944.09   0.000407432       49.7857           1           1     1087   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799        1944.3   9.61906e-05       42.2172           1           1     1222   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1945.68   0.000444541       55.9295      0.6467      0.6467     1365   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     960       1945.99   3.65397e-05       74.4917   8.754e-07       0.001     1486  LS failed, Hessian reset \n",
      "     999       1946.05   0.000999114       69.0618           1           1     1540   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1946.22   0.000110672        83.731   3.097e-06       0.001     1706  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1136       1946.26   1.63577e-05       28.1035    7.62e-07       0.001     1793  LS failed, Hessian reset \n",
      "    1149       1946.26   1.38579e-07       19.9409     0.08194     0.08194     1816   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.63864\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1874.81    0.00227746       120.737           1           1      123   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        1916.4    0.00544251        271.84      0.1315       0.281      247   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1923.85    0.00370416        167.96      0.3477      0.3477      367   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1936.64    0.00352034       643.243      0.6264      0.6264      487   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     409       1937.92   4.99601e-05       117.841   2.911e-07       0.001      542  LS failed, Hessian reset \n",
      "     499       1939.92     0.0216723       354.417           1           1      654   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     594       1942.76   6.95929e-05        138.61   2.306e-07       0.001      834  LS failed, Hessian reset \n",
      "     599       1943.13    0.00135395       69.1182           1           1      841   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     638       1944.54    4.5072e-05       98.8643   2.325e-07       0.001      932  LS failed, Hessian reset \n",
      "     699       1945.36   0.000247138       48.0493       1.614      0.1614     1018   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1947.68    0.00655644       387.984      0.4682      0.4682     1153   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1950.04   0.000578783       182.024      0.2955     0.02955     1281   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     952       1950.59   5.02691e-05       77.8409   1.936e-07       0.001     1390  LS failed, Hessian reset \n",
      "     979       1951.02   1.41164e-05       21.6441   1.934e-07       0.001     1468  LS failed, Hessian reset \n",
      "     999       1951.04   3.17037e-05       27.3007           1           1     1493   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1022        1951.1   7.71948e-05       105.536   1.224e-06       0.001     1567  LS failed, Hessian reset \n",
      "    1031       1951.14   2.89182e-05       50.5269   1.319e-06       0.001     1613  LS failed, Hessian reset \n",
      "    1041       1951.15   2.06249e-05       45.5108   7.277e-07       0.001     1664  LS failed, Hessian reset \n",
      "    1099       1951.27    0.00102107       304.628     0.03592           1     1740   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1952.01     0.0145096       115.611      0.5938      0.5938     1878   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1207       1952.15   3.08507e-05       78.9891   6.023e-07       0.001     1935  LS failed, Hessian reset \n",
      "    1299       1952.67   0.000687334       32.7806      0.8168      0.8168     2045   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1369       1952.88    6.5251e-05       110.096   1.042e-06       0.001     2171  LS failed, Hessian reset \n",
      "    1385       1952.92   2.64599e-05       67.1207   2.739e-07       0.001     2225  LS failed, Hessian reset \n",
      "    1398       1952.93   1.51906e-05       41.6679   3.901e-07       0.001     2277  LS failed, Hessian reset \n",
      "    1399       1952.93   0.000117125       33.9104          10           1     2279   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1435       1952.97   0.000173237       98.8088   5.881e-06       0.001     2359  LS failed, Hessian reset \n",
      "    1460       1952.98   2.79416e-05       18.4397   1.094e-06       0.001     2426  LS failed, Hessian reset \n",
      "    1499       1952.99   0.000305667        51.837      0.2577           1     2481   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1500       1952.99   0.000113416       118.286   2.188e-06       0.001     2522  LS failed, Hessian reset \n",
      "    1540          1953   1.53914e-05       42.3436   3.963e-07       0.001     2616  LS failed, Hessian reset \n",
      "    1599       1953.01   0.000141028       42.7574           1           1     2697   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1653       1953.29   1.82146e-05       51.7578   2.819e-07       0.001     2815  LS failed, Hessian reset \n",
      "    1699       1953.52    0.00012756       43.1417      0.8721      0.8721     2869   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1706       1953.54   1.75803e-05       30.1797   1.928e-07       0.001     2926  LS failed, Hessian reset \n",
      "    1799        1953.6   0.000369935       30.4207           1           1     3049   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1899       1953.68   5.11339e-05        36.973      0.9557      0.9557     3170   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1971        1953.7    2.5946e-05       50.4615   9.934e-07       0.001     3320  LS failed, Hessian reset \n",
      "    1999        1953.7   3.91124e-05       26.9003      0.5602      0.5602     3353   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2086       1953.72   1.02966e-05        34.098   2.197e-07       0.001     3519  LS failed, Hessian reset \n",
      "    2099       1953.72   7.02287e-07        25.876       0.209           1     3541   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    2103       1953.72   2.72023e-08       26.4991     0.01658           1     3551   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.29473\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1883.76     0.0771642       390.011           1           1      123   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1903.72    0.00799495        111.03           1           1      251   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1913.27    0.00251225       64.0772           1           1      380   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     341       1915.41   4.91994e-05       111.902   4.859e-07       0.001      478  LS failed, Hessian reset \n",
      "     399       1918.06    0.00116553       188.539      0.5079      0.5079      551   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1922.25    0.00593314       311.942           1           1      691   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599        1923.9    0.00477623       51.6112           1           1      825   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     634       1924.46   2.05684e-05       27.3333   2.215e-07       0.001      917  LS failed, Hessian reset \n",
      "     668       1924.59   2.26431e-05       29.4511   2.208e-07       0.001     1008  LS failed, Hessian reset \n",
      "     699       1924.67    0.00136899       121.388           1           1     1047   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     704       1924.73   5.67933e-05       57.2019   2.122e-07       0.001     1088  LS failed, Hessian reset \n",
      "     756       1924.87   3.84922e-05       75.0122    9.06e-07       0.001     1205  LS failed, Hessian reset \n",
      "     799       1925.07    0.00148759       167.199     0.02564           1     1256   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     825       1925.79   2.28893e-05       54.8727   3.286e-07       0.001     1322  LS failed, Hessian reset \n",
      "     899       1926.23   0.000196073       81.5817      0.4494      0.4494     1418   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     981       1926.47   0.000188124       157.539   6.005e-06       0.001     1566  LS failed, Hessian reset \n",
      "     999       1926.54    0.00026513       103.834           1           1     1588   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1043       1926.68   2.15111e-05       54.6512    5.69e-07       0.001     1682  LS failed, Hessian reset \n",
      "    1099       1926.77   0.000397712       36.2756      0.3503           1     1748   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1132       1926.78   8.22045e-06       21.0902   2.091e-07       0.001     1830  LS failed, Hessian reset \n",
      "    1199       1926.81   3.33783e-05         23.38           1           1     1908   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1284       1926.93   1.82994e-05       32.5742   2.343e-07       0.001     2042  LS failed, Hessian reset \n",
      "    1299       1927.03   5.43836e-05       48.1353      0.2612      0.2612     2060   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399       1927.08   0.000313983       47.6845           1           1     2188   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1407        1927.1   0.000151564       37.7148   3.972e-06       0.001     2237  LS failed, Hessian reset \n",
      "    1415       1927.12   2.12297e-05       48.3283   5.417e-07       0.001     2289  LS failed, Hessian reset \n",
      "    1499       1927.17    8.5582e-05       24.6707           1           1     2402   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1524       1927.19   0.000113144       140.338   2.267e-06       0.001     2514  LS failed, Hessian reset \n",
      "    1554       1927.22    6.9322e-05       81.5661   2.075e-06       0.001     2593  LS failed, Hessian reset \n",
      "    1599       1927.22   6.27149e-06       33.3003      0.5693      0.5693     2662   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1619       1927.22   7.92729e-06       25.0906   2.455e-07       0.001     2729  LS failed, Hessian reset \n",
      "    1624       1927.22   2.96619e-07       17.8943      0.3953           1     2737   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.19661\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1864.68     0.0213964       811.415           1           1      131   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1886.41     0.0108731       324.493           1           1      257   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     298       1895.27   3.16479e-05       69.7758   4.033e-07       0.001      416  LS failed, Hessian reset \n",
      "     299       1895.28   0.000210772       55.2579          10           1      418   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     332       1896.82    4.3625e-05       85.5172   3.442e-07       0.001      493  LS failed, Hessian reset \n",
      "     399       1898.66    0.00527548           445           1           1      578   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1899.84    0.00163624       83.0421       0.162           1      712   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1901.03   0.000537544       43.0576      0.5193           1      842   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1902.48    0.00037324       78.6377           1           1      972   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     713       1902.63   7.72979e-05       82.9924   2.833e-06       0.001     1032  LS failed, Hessian reset \n",
      "     755       1902.85   1.41505e-05       28.8912    3.21e-07       0.001     1119  LS failed, Hessian reset \n",
      "     765       1902.86    3.3568e-05       59.0658   1.039e-06       0.001     1175  LS failed, Hessian reset \n",
      "     799       1902.95    0.00198024       73.2787      0.3968           1     1217   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     859        1903.2   2.23107e-05       50.2299     4.3e-07       0.001     1345  LS failed, Hessian reset \n",
      "     899       1903.49   0.000612623       46.3043      0.6006           1     1396   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     927       1903.52   1.85372e-05       35.8796   3.058e-07       0.001     1480  LS failed, Hessian reset \n",
      "     999       1903.62    0.00387867       37.7459           1           1     1570   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1011       1903.67   2.66072e-05        47.041   2.767e-07       0.001     1661  LS failed, Hessian reset \n",
      "    1051       1903.85    2.6778e-05       38.8733   7.999e-07       0.001     1755  LS failed, Hessian reset \n",
      "    1075       1903.87   0.000227835       123.496   6.296e-06       0.001     1829  LS failed, Hessian reset \n",
      "    1099       1903.89   1.31786e-05       23.7838        2.54       0.254     1865   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1138       1903.93   3.39218e-05       74.2565   4.019e-07       0.001     1963  LS failed, Hessian reset \n",
      "    1172       1903.94   5.15357e-06       27.7696   1.524e-07       0.001     2044  LS failed, Hessian reset \n",
      "    1179       1903.94     3.859e-07       23.5926           1           1     2054   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.14871\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        1840.4    0.00328201       521.221      0.3784      0.3784      125   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1861.35     0.0142159       447.797           1           1      237   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1872.72    0.00434502       369.623           1           1      361   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     330       1874.53   7.25713e-05       41.2372   2.499e-07       0.001      436  LS failed, Hessian reset \n",
      "     362       1875.85   3.99935e-05       69.7516   8.269e-07       0.001      514  LS failed, Hessian reset \n",
      "     399       1876.31    0.00140894       193.213           1           1      562   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     434       1876.76   2.50748e-05       40.5707   3.021e-07       0.001      674  LS failed, Hessian reset \n",
      "     485       1877.53    4.0244e-05       66.5281    1.05e-06       0.001      779  LS failed, Hessian reset \n",
      "     499       1877.56   0.000180747       46.5711           1           1      797   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     570        1878.4   8.73955e-05       164.956   3.915e-07       0.001      922  LS failed, Hessian reset \n",
      "     599       1878.93   5.40115e-05       28.2025      0.4369     0.04369      962   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     606       1878.95   2.76391e-05       51.0276   6.307e-07       0.001     1006  LS failed, Hessian reset \n",
      "     634       1879.02    4.4288e-05       76.8569   7.656e-07       0.001     1091  LS failed, Hessian reset \n",
      "     657       1879.08   2.28871e-05       44.2544   3.732e-07       0.001     1159  LS failed, Hessian reset \n",
      "     679       1879.11   0.000240866        141.33   5.892e-06       0.001     1233  LS failed, Hessian reset \n",
      "     699       1879.12   1.15764e-05       21.6055       2.995      0.2995     1261   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1880.65     0.0075557       24.1177      0.6041      0.6041     1380   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     831       1881.03   4.67859e-05       69.7077   2.828e-07       0.001     1477  LS failed, Hessian reset \n",
      "     899       1881.99   0.000792976        88.854           1           1     1561   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1882.18    0.00393603        63.885       7.033      0.7033     1705   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1002       1882.18   6.34082e-05       80.9608   2.095e-06       0.001     1754  LS failed, Hessian reset \n",
      "    1071       1882.25   4.22142e-05       62.6395       1e-06       0.001     1874  LS failed, Hessian reset \n",
      "    1099       1882.26   9.24938e-05       26.3401           1           1     1907   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1138       1882.26   1.71446e-06       31.5096      0.3595      0.3595     1958   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.08329\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1815.17    0.00669209       320.351           1           1      122   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1844.84     0.0221131       418.566           1           1      246   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299        1849.5   0.000598078       264.384      0.1833      0.1833      379   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1853.85     0.0360665       331.973           1           1      500   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1855.58   0.000622906       33.6246           1           1      625   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     525       1855.88    4.1456e-05       54.3672   3.162e-07       0.001      702  LS failed, Hessian reset \n",
      "     599       1856.37   0.000237786       39.5711           1           1      797   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     661       1857.33   0.000110155       75.7045   2.817e-07       0.001      917  LS failed, Hessian reset \n",
      "     699       1859.12   0.000289087       162.604           1           1      961   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     722        1859.7   2.33145e-05       43.4315   4.814e-07       0.001     1034  LS failed, Hessian reset \n",
      "     799       1859.95   0.000123753       68.6067      0.5223      0.5223     1148   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     849       1861.06   5.99589e-05        96.853   1.052e-06       0.001     1258  LS failed, Hessian reset \n",
      "     899       1861.94   0.000449268       71.0525       0.809       0.809     1328   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     934       1862.22    2.0906e-05       40.4795   5.134e-07       0.001     1416  LS failed, Hessian reset \n",
      "     999        1862.4   5.48712e-05       31.3019      0.2001      0.2001     1509   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1054       1862.81   2.67025e-05       49.9149   4.115e-07       0.001     1630  LS failed, Hessian reset \n",
      "    1099       1863.16   2.02033e-05       49.3208      0.5497      0.5497     1693   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1863.31    0.00219045       54.1239           1           1     1829   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1209       1863.36   0.000187896       177.726   3.724e-06       0.001     1883  LS failed, Hessian reset \n",
      "    1277       1863.46    0.00025331       60.5359   6.255e-06       0.001     2008  LS failed, Hessian reset \n",
      "    1299       1863.47   1.26212e-06       25.1144      0.2515           1     2042   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1331       1863.47   1.90898e-05       29.0352   3.049e-07       0.001     2129  LS failed, Hessian reset \n",
      "    1399       1863.48   2.02311e-05       38.0155           1           1     2211   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1499       1863.81     0.0113625       65.5002           1           1     2352   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1599       1864.76    0.00206559       53.7229           1           1     2478   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1699       1865.22   0.000250585       33.9827      0.3712           1     2602   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1742       1865.32   1.97216e-05       34.1913   3.514e-07       0.001     2695  LS failed, Hessian reset \n",
      "    1799       1865.39   0.000474782        96.067           1           1     2763   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1845       1865.42   9.12707e-05       91.4606   2.534e-06       0.001     2860  LS failed, Hessian reset \n",
      "    1893       1865.43    5.2362e-07       27.7808      0.6798      0.6798     2926   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.08854\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1788.81     0.0141373       1078.13      0.3663           1      134   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1819.34    0.00125284       366.481           1           1      255   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1824.21   0.000639824       78.9415      0.4861      0.4861      383   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1829.04    0.00224447       75.9708      0.4931      0.4931      513   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1833.41    0.00282094        148.17           1           1      640   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     566       1835.51    3.4632e-05       37.7534   3.069e-07       0.001      775  LS failed, Hessian reset \n",
      "     599          1836   0.000541664       112.263           1           1      820   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     688       1836.57   4.32518e-05       43.3682   3.118e-07       0.001     1010  LS failed, Hessian reset \n",
      "     699       1836.72   0.000175428       58.4125           1           1     1027   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     730       1836.89   3.68416e-05       61.2096   5.927e-07       0.001     1111  LS failed, Hessian reset \n",
      "     775       1836.95   3.14189e-05       55.3251    7.82e-07       0.001     1215  LS failed, Hessian reset \n",
      "     799       1836.95   5.58583e-06       34.3981      0.4927      0.4927     1245   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     805       1836.95   1.81416e-05       30.9566   6.224e-07       0.001     1286  LS failed, Hessian reset \n",
      "     829       1836.95   8.48605e-09       32.4226     0.04172     0.04172     1327   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: absolute parameter change was below tolerance\n",
      "Initial log joint probability = -5.09965\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1777.39     0.0790321        1264.5           1           1      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1806.68    0.00468334       182.547           1           1      253   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1813.54   0.000495389        69.221           1           1      382   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1815.67   0.000183142       63.4444     0.04579           1      514   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     408        1815.8   0.000317853       173.617    9.29e-06       0.001      566  LS failed, Hessian reset \n",
      "     467       1816.44   6.29145e-05       85.5319    4.06e-07       0.001      685  LS failed, Hessian reset \n",
      "     499       1816.95   9.03513e-05       32.4192      0.8453      0.8453      733   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1817.48     0.0248485       108.083           1           1      869   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     634       1817.98   0.000169989       106.582   3.132e-06       0.001      948  LS failed, Hessian reset \n",
      "     652       1818.21   0.000238282       119.178   5.362e-06       0.001      999  LS failed, Hessian reset \n",
      "     688       1818.38     0.0010136       243.372   3.844e-05       0.001     1075  LS failed, Hessian reset \n",
      "     699       1818.41   4.70054e-05       71.5909      0.1604      0.1604     1088   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1818.84   0.000353765       112.363      0.9093      0.9093     1223   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1819.46    0.00790468       96.9912           1           1     1352   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999        1819.9   0.000208659       30.9373      0.4331           1     1490   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1820.06   0.000600853       29.8951           1           1     1626   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1106       1820.07   9.12948e-05       95.7844   2.522e-06       0.001     1682  LS failed, Hessian reset \n",
      "    1199       1820.11   0.000283875       54.5298       0.259       0.259     1809   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1278       1820.14   2.02797e-07        32.189      0.2515           1     1911   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.26583\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1764.06    0.00821882       191.851           1           1      131   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1788.87    0.00120062       288.989     0.03778           1      256   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1793.24   0.000965841       116.742      0.5449      0.5449      393   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1797.06    0.00135962       89.4125      0.8567      0.8567      528   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     419       1797.38   5.27906e-05       80.3836   7.919e-07       0.001      603  LS failed, Hessian reset \n",
      "     428        1797.5   3.25309e-05        47.239   9.507e-07       0.001      657  LS failed, Hessian reset \n",
      "     499       1797.72   0.000113598       30.7441      0.2781      0.2781      750   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     549       1797.82   2.90148e-05       41.6508   9.745e-07       0.001      859  LS failed, Hessian reset \n",
      "     599       1797.89   1.45162e-05       34.0469      0.5974      0.5974      922   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     614        1797.9    5.4612e-05       47.5331    1.25e-06       0.001      992  LS failed, Hessian reset \n",
      "     699       1798.62     0.0055398       154.765      0.3229           1     1094   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     722       1799.81   5.80716e-05       86.5539   6.954e-07       0.001     1193  LS failed, Hessian reset \n",
      "     799       1801.32   0.000224956       71.4279      0.6844      0.6844     1288   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     803       1801.34   5.33722e-05       72.0008   9.722e-07       0.001     1333  LS failed, Hessian reset \n",
      "     837       1801.45   0.000106797       110.632   1.527e-06       0.001     1414  LS failed, Hessian reset \n",
      "     899       1801.58    0.00019138        46.637      0.1706           1     1495   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     964       1801.64   2.81334e-05       49.2244   5.832e-07       0.001     1643  LS failed, Hessian reset \n",
      "     980       1801.64   2.73062e-07       27.1393      0.6839      0.6839     1672   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.24688\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        1730.1     0.0133461        156.63           1           1      122   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1758.55    0.00608995       130.295           1           1      248   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1763.67    0.00646414       192.495      0.8721      0.8721      367   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1769.05    0.00708707       116.982           1           1      495   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1773.01   0.000282838       46.2367      0.1524      0.1524      624   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     554        1775.6   0.000134349        64.399    3.47e-07       0.001      746  LS failed, Hessian reset \n",
      "     599       1777.65    0.00259973       35.3309       0.255           1      805   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1778.55   0.000126557       72.0469      0.4277      0.4277      930   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     790        1779.4   3.61211e-05       52.7971   5.556e-07       0.001     1107  LS failed, Hessian reset \n",
      "     799       1779.64   0.000768409       33.4689      0.2065           1     1119   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     876       1779.83   3.70283e-05       54.8515   7.446e-07       0.001     1257  LS failed, Hessian reset \n",
      "     899       1779.85   0.000101668       38.3285           1           1     1286   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     996       1780.51   0.000359653       105.461   8.524e-06       0.001     1442  LS failed, Hessian reset \n",
      "     999       1780.52   0.000663592       46.5431           1           1     1447   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1780.76    0.00254023       42.6644           1           1     1581   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1173       1781.05   0.000127285       117.214   1.783e-06       0.001     1719  LS failed, Hessian reset \n",
      "    1199       1781.14   0.000141056       40.5561      0.4057           1     1750   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299       1781.24   0.000957097       40.4901           1           1     1892   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1342       1781.27   4.54006e-05       28.0039     1.5e-06       0.001     1994  LS failed, Hessian reset \n",
      "    1399       1781.27   3.04811e-06       41.6137      0.6282      0.6282     2076   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1408       1781.28    2.8416e-05       41.0106   7.556e-07       0.001     2131  LS failed, Hessian reset \n",
      "    1426       1781.28   2.59466e-07       21.9488      0.3024           1     2158   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.14822\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1736.17    0.00625552       580.013      0.1058           1      128   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1757.18    0.00302241        115.27           1           1      257   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1765.62     0.0397394       330.194           1           1      390   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1770.05     0.0115879       238.273       0.167           1      515   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     471       1775.06   5.52887e-05       71.3315   4.376e-07       0.001      647  LS failed, Hessian reset \n",
      "     499       1775.73   0.000483226       36.5061       0.226       0.226      678   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     526       1776.91    0.00017054       116.687   3.944e-06       0.001      749  LS failed, Hessian reset \n",
      "     578       1777.57   5.98383e-05       71.1178   1.509e-06       0.001      876  LS failed, Hessian reset \n",
      "     599       1777.94    0.00196936       77.0013      0.4426           1      905   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     617       1778.01   5.09202e-05       35.2413   3.396e-07       0.001      966  LS failed, Hessian reset \n",
      "     699       1778.83    0.00195918       143.692           1           1     1072   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     760       1780.24   0.000340864       166.387    1.15e-05       0.001     1201  LS failed, Hessian reset \n",
      "     799       1780.86    0.00200313       42.3999      0.7196           1     1253   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     800       1780.86   3.05549e-05       47.9099   7.206e-07       0.001     1291  LS failed, Hessian reset \n",
      "     874       1781.06    4.7756e-05       45.8623   1.211e-06       0.001     1425  LS failed, Hessian reset \n",
      "     899       1781.07   2.04559e-05       30.3379      0.2632      0.9205     1456   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     920       1781.11   0.000109261       106.937   2.555e-06       0.001     1519  LS failed, Hessian reset \n",
      "     992       1781.17   3.72228e-05       42.8265     3.7e-07       0.001     1652  LS failed, Hessian reset \n",
      "     999       1781.17   2.86472e-05       33.8194           1           1     1661   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1077       1781.23   7.24543e-05       74.3647   1.977e-06       0.001     1811  LS failed, Hessian reset \n",
      "    1099       1781.27   6.42924e-05       35.8987      0.1935      0.3882     1838   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1156       1781.31   3.26565e-05       52.4774   8.585e-07       0.001     1958  LS failed, Hessian reset \n",
      "    1199       1781.31   7.23439e-06       31.4633        1.71      0.6631     2015   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1234       1781.31   3.08283e-07       28.8511   1.371e-08       0.001     2095  LS failed, Hessian reset \n",
      "    1235       1781.31   1.10982e-07       26.1396      0.3288           1     2097   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.83527\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1738.61     0.0233207       781.882           1           1      117   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1766.03    0.00509757       619.456     0.09355       0.383      238   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1779.43   0.000630577       51.3522       1.132      0.1132      364   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399          1785     0.0050339       238.038      0.4081           1      499   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1788.08    0.00292663       59.3118           1           1      624   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1790.71    0.00165094       100.885           1           1      749   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1794.41     0.0159199       199.712           1           1      868   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     781       1795.92   9.95976e-05       117.012   3.388e-07       0.001     1024  LS failed, Hessian reset \n",
      "     799       1796.21   0.000820681        39.409      0.3263           1     1050   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     812       1796.25   3.22789e-05       36.6812   3.285e-07       0.001     1105  LS failed, Hessian reset \n",
      "     846        1796.3   2.58304e-05       43.6212   4.607e-07       0.001     1191  LS failed, Hessian reset \n",
      "     881       1796.34   2.93908e-05       41.9271   3.708e-07       0.001     1282  LS failed, Hessian reset \n",
      "     899       1796.36   2.68411e-05       30.9649           1           1     1310   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     906       1796.36   9.01064e-05       40.0484   3.952e-06       0.001     1361  LS failed, Hessian reset \n",
      "     999       1797.17     0.0207319       115.565       2.086     0.02086     1470   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1006       1797.58   0.000124942       201.096   5.442e-07       0.001     1515  LS failed, Hessian reset \n",
      "    1096       1798.49   5.25509e-05       83.9428   6.571e-07       0.001     1676  LS failed, Hessian reset \n",
      "    1099        1798.5    0.00014451        50.929           1           1     1679   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       1798.55   2.27066e-05       24.8583           1           1     1810   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1208       1798.55   1.13683e-07        22.451     0.07039           1     1827   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.04302\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1767.07     0.0768749       491.765           1           1      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1799.21    0.00668837       275.028           1           1      243   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1816.54    0.00373668       155.186      0.3395     0.03395      363   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1824.25     0.0199956       347.249           1           1      495   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1829.55   9.07577e-05       64.9334      0.4576      0.4576      639   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1834.05     0.0120686       69.2921      0.7613      0.7613      768   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     640       1837.97   0.000133033       234.502   3.225e-07       0.001      852  LS failed, Hessian reset \n",
      "     680       1840.59   0.000166933        221.76   1.203e-06       0.001      933  LS failed, Hessian reset \n",
      "     699       1841.05    0.00236467       89.5729           1           1      957   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1842.71    0.00052852        117.82      0.9197      0.9197     1085   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1843.39   0.000761117       85.0519      0.9128      0.9128     1224   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1845.96    0.00297981       76.8758      0.3567      0.9311     1350   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1052       1847.18   1.47308e-05       30.6159   3.229e-07       0.001     1461  LS failed, Hessian reset \n",
      "    1099       1847.32   0.000122307       35.2911      0.6607      0.6607     1523   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1138       1847.42   2.62694e-05       46.6348    2.84e-07       0.001     1629  LS failed, Hessian reset \n",
      "    1199       1847.48    9.7447e-05       36.2909           1           1     1701   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299       1848.84    0.00238879       52.3742      0.9454     0.09454     1832   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399       1850.24     0.0230534        99.384           1           1     1953   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1426       1850.77    5.1368e-05       114.643   3.529e-07       0.001     2024  LS failed, Hessian reset \n",
      "    1499       1851.21   1.66613e-05       45.0732       0.299       0.299     2122   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1509       1851.26   2.96399e-05       65.7424   6.027e-07       0.001     2178  LS failed, Hessian reset \n",
      "    1585       1851.47   0.000209862       44.3179   8.201e-06       0.001     2308  LS failed, Hessian reset \n",
      "    1599       1851.49   6.94978e-06       40.4858     0.01055           1     2328   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1699       1851.57   0.000493417       23.5173           1           1     2458   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1731       1851.59   2.54933e-05       25.1693   8.283e-07       0.001     2530  LS failed, Hessian reset \n",
      "    1759        1851.6   1.42896e-05       37.7904   2.984e-07       0.001     2608  LS failed, Hessian reset \n",
      "    1771        1851.6   2.98423e-07       23.3334           1           1     2627   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.06147\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1767.23     0.0763971       2393.45           1           1      131   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        1838.8      0.209117       371.994           1           1      256   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1866.71    0.00117723       351.202      0.3144      0.3144      373   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1876.09   0.000265096        142.87      0.2169      0.2169      503   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1883.86    0.00346447       736.868      0.5238      0.5238      620   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599        1890.1     0.0186604       120.074           1           1      741   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     636        1891.8   4.94072e-05       91.4607   2.182e-07       0.001      829  LS failed, Hessian reset \n",
      "     699       1897.44    0.00209123       58.1368           1           1      907   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     707       1897.62   2.48494e-05       67.0009   3.809e-07       0.001      956  LS failed, Hessian reset \n",
      "     799       1898.86   0.000493186       121.696     0.09434    0.009434     1075   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     876        1901.2   7.70321e-05       120.951     1.7e-06       0.001     1224  LS failed, Hessian reset \n",
      "     890       1901.32   0.000116072       174.342   1.083e-06       0.001     1278  LS failed, Hessian reset \n",
      "     899       1901.36   0.000201752       42.6402           1           1     1288   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1901.74    0.00565391       87.2718           1           1     1412   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1903.17     0.0142198        105.11      0.3664      0.9036     1541   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1147       1903.95   2.35723e-05       66.9962   3.506e-07       0.001     1662  LS failed, Hessian reset \n",
      "    1199       1904.43     0.0003228       75.7292      0.1924      0.1924     1726   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299       1904.87   9.67769e-05       36.1499      0.1462           1     1868   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1360       1904.96   1.60639e-05       43.4789   5.099e-07       0.001     1983  LS failed, Hessian reset \n",
      "    1389       1904.97   6.17935e-07       35.2756      0.3206           1     2032   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.02724\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1821.42     0.0309542       496.558           1           1      128   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1887.46      0.175499       1200.86           1           1      242   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1906.02     0.0248792       845.619           1           1      367   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1917.68    0.00237328       142.542      0.7899      0.7899      486   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     498       1921.75   4.19622e-05       87.8418   1.984e-07       0.001      664  LS failed, Hessian reset \n",
      "     499       1921.77   0.000160918       74.4613          10           1      666   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599          1925     0.0312285       379.524           1           1      790   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       1927.69    0.00184496       40.8058           1           1      911   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799        1930.4   0.000469296       45.5194      0.8772      0.8772     1036   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1931.84    0.00744348        233.72           1           1     1162   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1935.73     0.0314997       962.735     0.07025           1     1284   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1938.68    0.00132103       68.6926      0.8621      0.8621     1403   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1150       1939.11   1.07097e-05       34.5567   2.347e-07       0.001     1527  LS failed, Hessian reset \n",
      "    1182       1939.21   1.04354e-05       31.3962    2.19e-07       0.001     1607  LS failed, Hessian reset \n",
      "    1199       1939.27   0.000105605       72.4818      0.2847       0.392     1631   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1209       1939.28   1.34199e-05       39.8154   2.181e-07       0.001     1690  LS failed, Hessian reset \n",
      "    1299        1939.4   0.000106069       30.5047      0.5016      0.5016     1812   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1370       1939.42   1.54855e-06       19.7889      0.2439           1     1919   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.01094\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1847.52     0.0412368       1202.22       0.255           1      125   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1913.54    0.00289902       797.664      0.2826      0.2826      249   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1962.83     0.0817644       479.294           1           1      364   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       1981.48     0.0112809       932.888           1           1      485   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1989.97   0.000755647        144.26      0.1052           1      612   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1992.15     0.0181531       78.9542      0.3829           1      744   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     636       1993.01   3.44686e-05       116.949   3.185e-07       0.001      843  LS failed, Hessian reset \n",
      "     672        1993.5   1.57954e-05       40.1943   1.475e-07       0.001      932  LS failed, Hessian reset \n",
      "     699       1993.98   9.42368e-06       33.7164   1.883e-07       0.001     1009  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     742       1994.24   1.55764e-05       54.7729   1.883e-07       0.001     1110  LS failed, Hessian reset \n",
      "     799       1994.77    0.00686553        197.03           1           1     1197   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       1996.66   0.000429242       318.329        0.18           1     1328   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1997.69   0.000602351       38.9611           1           1     1451   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1999.39     0.0049326       110.121           1           1     1574   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       2001.49    0.00591388       119.641      0.9046      0.9046     1694   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1263       2002.18   9.41013e-06       33.0135   1.775e-07       0.001     1821  LS failed, Hessian reset \n",
      "    1299       2002.29   3.64229e-05       46.5887           1           1     1868   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399       2002.44   0.000130737       44.3537      0.2503           1     1994   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1423       2002.49   0.000350287       94.3429   6.509e-06       0.001     2069  LS failed, Hessian reset \n",
      "    1499       2002.57   0.000634358       50.6074      0.3437      0.3437     2161   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1557       2002.59   2.92669e-07       25.2623      0.6037      0.6037     2251   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.27198\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        1892.5     0.0252188       1152.92           1           1      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1969.25     0.0575983       168.113           1           1      248   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       2000.46    0.00469922       1345.27      0.1945      0.1945      368   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       2014.34     0.0102563       185.906           1           1      493   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       2021.67     0.0022537        604.64      0.2427      0.2427      617   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     570       2029.99   0.000255878       237.229   2.983e-06       0.001      744  LS failed, Hessian reset \n",
      "     599       2030.74    0.00019439       76.6818      0.7117      0.7117      777   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     684       2032.57   2.70793e-05       51.6819   1.221e-07       0.001      932  LS failed, Hessian reset \n",
      "     699       2032.73   0.000555731        167.44      0.6603     0.06603      949   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       2033.21   0.000470509       138.989           1           1     1075   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       2034.07   0.000701526       77.5176      0.3516           1     1218   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     927       2034.24   0.000466568       283.672   1.425e-05       0.001     1277  LS failed, Hessian reset \n",
      "     999       2034.78   0.000170376       102.251      0.1931      0.1931     1370   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       2035.35   2.66242e-05       36.8876      0.4612      0.4612     1508   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1132       2035.37   1.80839e-05       27.6403   1.174e-07       0.001     1593  LS failed, Hessian reset \n",
      "    1189       2035.77   1.87458e-05       80.8232   2.359e-07       0.001     1749  LS failed, Hessian reset \n",
      "    1199       2035.91   0.000957908       121.774           1           1     1761   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1233       2036.28   2.04835e-05       87.3571   1.925e-07       0.001     1849  LS failed, Hessian reset \n",
      "    1283       2036.64   1.59212e-05        65.928   2.013e-07       0.001     1954  LS failed, Hessian reset \n",
      "    1299       2036.65   2.52055e-05       45.9275           1           1     1975   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399       2036.76   0.000172427       46.5508           1           1     2117   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1499       2037.16    0.00333478       46.1336      0.9817      0.9817     2231   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1561       2037.39   1.83089e-05       67.5159   4.877e-07       0.001     2341  LS failed, Hessian reset \n",
      "    1599       2037.48   0.000153554       61.3576      0.7312      0.7312     2391   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1699       2037.65   4.68827e-05       25.8365           1           1     2520   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1723       2037.66   0.000128487       51.4049   2.833e-06       0.001     2588  LS failed, Hessian reset \n",
      "    1795       2037.67   1.12614e-06       32.6691      0.1535     0.01535     2695   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -6.15743\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1921.54    0.00549922        176.77           1           1      134   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1995.03     0.0154595       246.514           1           1      254   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       2023.38     0.0089521       325.699           1           1      375   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        2034.3     0.0488219       1040.44      0.4146           1      513   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       2040.12    0.00100772       70.3314      0.3458       0.844      634   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       2043.61    0.00207439        97.727       1.618      0.1618      760   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       2045.29    0.00127731       116.788      0.5224      0.5224      884   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     728       2045.44   1.38043e-05       59.2261   2.629e-07       0.001      959  LS failed, Hessian reset \n",
      "     743       2045.61   9.08759e-06       39.6835   2.172e-07       0.001     1031  LS failed, Hessian reset \n",
      "     799       2045.84    0.00232061       24.2456      0.5686           1     1112   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     891       2046.39   2.48528e-05       98.5912   1.837e-07       0.001     1273  LS failed, Hessian reset \n",
      "     899       2046.41   0.000188729       43.1234           1           1     1281   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     983        2047.1   8.30238e-05       177.211   1.221e-07       0.001     1418  LS failed, Hessian reset \n",
      "     999       2047.34    0.00249475       277.181           1           1     1440   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1032       2047.56   3.27857e-05       120.054   3.473e-07       0.001     1529  LS failed, Hessian reset \n",
      "    1073       2047.67   1.72492e-05       61.1089   1.472e-07       0.001     1632  LS failed, Hessian reset \n",
      "    1099        2047.7   8.88067e-05       25.7606      0.9176      0.9176     1665   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1106       2047.71   0.000151491       50.1818    6.37e-06       0.001     1722  LS failed, Hessian reset \n",
      "    1196       2048.07   8.90867e-06       38.4973   2.617e-07       0.001     1882  LS failed, Hessian reset \n",
      "    1199       2048.07   9.06126e-05         28.46           1           1     1886   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1222       2048.08   1.88986e-05       70.4296   3.299e-07       0.001     1965  LS failed, Hessian reset \n",
      "    1231       2048.09   6.08173e-06       36.5782   2.914e-07       0.001     2018  LS failed, Hessian reset \n",
      "    1250       2048.09   7.51102e-06        33.355   2.793e-07       0.001     2090  LS failed, Hessian reset \n",
      "    1285        2048.1   5.92683e-05        103.11   1.364e-06       0.001     2177  LS failed, Hessian reset \n",
      "    1299       2048.11   7.95903e-06       32.9981      0.1938      0.1938     2195   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1352       2048.12   1.47179e-05       31.6086   5.226e-07       0.001     2303  LS failed, Hessian reset \n",
      "    1399       2048.13   7.21518e-06       24.1499           1           1     2367   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1499       2048.14   0.000642361       41.7647           1           1     2510   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1558       2048.21    0.00017944       229.759   4.265e-06       0.001     2631  LS failed, Hessian reset \n",
      "    1589       2048.28   6.53143e-05       58.0062   2.749e-06       0.001     2712  LS failed, Hessian reset \n",
      "    1599       2048.28   2.64639e-05       40.7617     0.03156           1     2727   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1654       2048.31   1.64064e-05       44.6431   1.272e-07       0.001     2850  LS failed, Hessian reset \n",
      "    1680       2048.32   5.19369e-06       25.4689   1.984e-07       0.001     2939  LS failed, Hessian reset \n",
      "    1688       2048.32    1.6851e-07       18.8218   7.603e-09       0.001     2994  LS failed, Hessian reset \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.46937\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99          1945     0.0214468       703.463           1           1      128   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1999.51     0.0111199       273.282           1           1      255   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       2027.17    0.00695613       382.183      0.6207      0.6207      374   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     387       2035.78   4.49401e-05       127.925   8.109e-07       0.001      529  LS failed, Hessian reset \n",
      "     399       2036.25    0.00196627       820.505      0.3984      0.3984      542   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     441       2037.73   2.11749e-05        85.218   2.895e-07       0.001      648  LS failed, Hessian reset \n",
      "     499       2039.25   0.000930126       363.846      0.4344      0.4344      718   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     538       2039.91   1.32549e-05       36.2961   1.358e-07       0.001      805  LS failed, Hessian reset \n",
      "     599        2040.5   0.000806847       139.527           1           1      878   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     673       2041.82   4.56286e-05       137.538   5.114e-07       0.001     1055  LS failed, Hessian reset \n",
      "     699       2042.78    0.00114567       87.8385           1           1     1089   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     733       2043.07   8.53286e-05       92.9222   3.343e-06       0.001     1174  LS failed, Hessian reset \n",
      "     799       2043.36   0.000230065       171.801      0.3454     0.03454     1264   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     851       2043.44   1.52508e-05       23.3324   1.205e-07       0.001     1369  LS failed, Hessian reset \n",
      "     866       2043.44   8.42334e-06       30.3802   1.656e-07       0.001     1433  LS failed, Hessian reset \n",
      "     874       2043.44   6.24383e-07       23.6892   2.863e-08       0.001     1479  LS failed, Hessian reset \n",
      "     876       2043.44   1.64954e-07       21.8844     0.09084           1     1483   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.54476\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1937.37    0.00360917       770.925      0.8961      0.8961      125   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        2001.2     0.0146492       1532.86           1           1      247   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       2025.22     0.0151601       618.846           1           1      364   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       2036.02     0.0042557        362.08           1           1      486   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499        2040.9    0.00460135       117.328      0.9139      0.9139      622   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       2044.97    0.00769931       323.474     0.06277      0.4349      746   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     661       2048.76    2.7767e-05       95.9673    3.79e-07       0.001      872  LS failed, Hessian reset \n",
      "     699       2049.08    0.00108343       361.152           1           1      915   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     705       2049.18   4.75134e-05       91.2425   1.228e-07       0.001      966  LS failed, Hessian reset \n",
      "     799       2050.42   0.000792396       94.2702           1           1     1098   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       2051.12   0.000122342       69.1673      0.5004      0.5004     1229   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       2052.47    0.00490949       170.765           1           1     1350   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1017       2052.93   0.000129784       46.6436   1.458e-06       0.001     1414  LS failed, Hessian reset \n",
      "    1039       2053.15   9.63888e-06       41.0162   3.025e-07       0.001     1486  LS failed, Hessian reset \n",
      "    1097       2053.53   5.45355e-05       39.2995   1.141e-07       0.001     1600  LS failed, Hessian reset \n",
      "    1099       2053.54   0.000114329       36.2387           1           1     1603   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1151       2053.64   8.20079e-06        35.396   2.116e-07       0.001     1712  LS failed, Hessian reset \n",
      "    1189       2053.69   1.38935e-05       49.0517   1.438e-07       0.001     1808  LS failed, Hessian reset \n",
      "    1199       2053.72    0.00023891       21.2746      0.8064      0.8064     1821   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1247       2053.74   1.59205e-05       68.1632   2.395e-07       0.001     1928  LS failed, Hessian reset \n",
      "    1269       2053.74   8.49044e-06       43.3796   2.197e-07       0.001     1996  LS failed, Hessian reset \n",
      "    1280       2053.74   3.13346e-08        26.184     0.04549     0.04549     2011   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.48617\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1938.72     0.0214311       603.075      0.1273           1      126   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1996.16     0.0103095       302.717      0.5174      0.5174      265   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       2024.91    0.00197993       390.745       2.371      0.2371      395   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       2039.38     0.0031286       340.601           1           1      514   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       2044.22    0.00553698       173.187           1           1      639   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       2050.29    0.00116519        177.71           1           1      759   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       2052.13    0.00185768       300.732      0.2762           1      881   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     715       2052.37   2.53918e-05        94.739   1.605e-07       0.001      939  LS failed, Hessian reset \n",
      "     765       2053.59   4.44263e-05       103.784   9.575e-07       0.001     1061  LS failed, Hessian reset \n",
      "     799       2053.72   0.000631398       105.229           1           1     1098   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     889       2055.14   1.87554e-05       75.3331   1.695e-07       0.001     1278  LS failed, Hessian reset \n",
      "     899       2055.65    0.00103677       225.229      0.7588      0.7588     1290   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       2056.98   0.000235958       55.5813           1           1     1425   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       2058.84     0.0134239       390.314           1           1     1550   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199        2060.8   0.000575042       124.273      0.2943           1     1675   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1253          2061   2.81096e-05       79.8046   7.014e-07       0.001     1793  LS failed, Hessian reset \n",
      "    1273       2061.03   1.35657e-05       55.3241   1.662e-07       0.001     1859  LS failed, Hessian reset \n",
      "    1299       2061.05   8.90289e-05       32.7887      0.8291      0.8291     1894   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1399        2061.4    0.00423102       192.052     0.08556      0.9759     2015   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1479       2061.54   1.94624e-05       63.5231   5.265e-07       0.001     2172  LS failed, Hessian reset \n",
      "    1499       2061.55   3.13051e-05       40.8476      0.3023      0.7886     2199   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1599       2061.68    0.00216764        64.684      0.2557      0.7877     2326   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1653       2061.83   0.000369628        70.525   1.263e-05       0.001     2434  LS failed, Hessian reset \n",
      "    1699       2061.89   0.000196848       36.4397           1           1     2497   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1799          2062   2.56185e-05       25.6759           1           1     2626   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1883       2062.05   7.57368e-06       29.9667   1.431e-07       0.001     2762  LS failed, Hessian reset \n",
      "    1899       2062.06   1.23156e-05       46.9228      0.7558      0.7558     2784   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1951       2062.08   1.92136e-05       40.2774   7.223e-07       0.001     2884  LS failed, Hessian reset \n",
      "    1963       2062.08   1.84837e-07       24.7196      0.2574           1     2902   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -5.15685\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1931.66    0.00406529       330.189           1           1      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1992.92    0.00362236       1129.21     0.09341      0.3874      259   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       2013.06     0.0358508       1009.74      0.1961           1      381   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       2025.38    0.00325873       808.574      0.3276      0.3276      504   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       2031.52    0.00644176        90.612           1           1      623   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       2037.48     0.0123772       118.569           1           1      747   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       2043.46    0.00037241       98.7163      0.4029           1      881   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       2044.58   0.000249816       28.1205      0.8194      0.8194     1003   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     808       2044.61    1.9503e-05        65.228   4.834e-07       0.001     1053  LS failed, Hessian reset \n",
      "     867       2045.26   3.64754e-05       87.4683   1.307e-07       0.001     1172  LS failed, Hessian reset \n",
      "     899       2045.41    0.00074886       182.539           1           1     1208   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     932       2045.47   1.59464e-05       53.3167   1.496e-07       0.001     1294  LS failed, Hessian reset \n",
      "     978       2045.56   4.38574e-05       106.801   1.207e-06       0.001     1393  LS failed, Hessian reset \n",
      "     999       2045.63   8.80818e-05       142.276           1           1     1422   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       2046.55     0.0236715       95.2568           1           1     1549   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1113       2046.75   8.54331e-06       34.5594   1.771e-07       0.001     1619  LS failed, Hessian reset \n",
      "    1199       2047.19    0.00053247       39.2603     0.09424      0.6854     1733   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1262       2047.35   2.36078e-05       96.4996   2.448e-07       0.001     1867  LS failed, Hessian reset \n",
      "    1299       2047.45   9.55976e-06       33.6971      0.7113      0.7113     1920   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1344       2047.46   7.34585e-06       30.2235   1.816e-07       0.001     2054  LS failed, Hessian reset \n",
      "    1369       2047.46   1.26505e-06       21.3892      0.3007           1     2092   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.72541\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1953.74     0.0273422       1896.36           1           1      137   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       2004.44     0.0188327       609.462           1           1      264   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       2023.16    0.00652722       453.988           1           1      381   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       2029.48   0.000526389        128.66           1           1      508   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       2038.96    0.00121585        199.84     0.06255           1      627   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       2041.32    0.00703605       194.137           1           1      758   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       2042.92    0.00787748       194.416           1           1      884   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     759       2043.51    1.6942e-05       49.3793    1.38e-07       0.001     1006  LS failed, Hessian reset \n",
      "     799          2044   0.000468587       40.9324           1           1     1062   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     821       2044.12   1.34073e-05       34.2491   1.295e-07       0.001     1124  LS failed, Hessian reset \n",
      "     856       2044.28   2.03571e-05       44.1957   1.252e-07       0.001     1222  LS failed, Hessian reset \n",
      "     899        2044.4   1.30355e-05       27.8613           1           1     1281   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       2044.79    0.00272889       100.969           1           1     1415   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1098       2045.28   4.73605e-05       74.9605   1.469e-06       0.001     1579  LS failed, Hessian reset \n",
      "    1099       2045.28   4.45301e-05       36.5917           1           1     1580   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1131       2045.34   7.08459e-05       32.6029   1.842e-06       0.001     1669  LS failed, Hessian reset \n",
      "    1174       2045.35   1.40579e-05       52.9447   1.568e-07       0.001     1773  LS failed, Hessian reset \n",
      "    1199       2045.36   2.23929e-08       26.7147     0.05814     0.03767     1813   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.80074\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1949.59     0.0203337       1089.91           1           1      125   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1983.18    0.00972078       413.998        0.21           1      256   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       2019.46     0.0015982       453.361           1           1      368   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       2039.83    0.00244458        134.95           1           1      487   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       2046.93     0.0706146       1300.73           1           1      605   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       2050.83     0.0039646       404.768           1           1      728   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     607       2050.93   0.000546594        203.74   1.008e-05       0.001      777  LS failed, Hessian reset \n",
      "     699       2052.34    0.00102873       82.3909           1           1      889   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     752       2053.19   8.32176e-05       155.649    2.32e-06       0.001      984  LS failed, Hessian reset \n",
      "     765       2053.82   1.16886e-05       28.9804   1.258e-07       0.001     1042  LS failed, Hessian reset \n",
      "     799       2054.14   0.000246606       194.746      0.2163      0.8852     1091   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       2054.65   1.89973e-05       57.8313      0.3051    0.003051     1234   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       2055.55    0.00215753       83.3067      0.3481           1     1364   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1079       2056.39   6.70466e-06       32.8138   1.911e-07       0.001     1514  LS failed, Hessian reset \n",
      "    1099        2056.4   7.58895e-05       39.4759           1           1     1538   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       2056.61   1.78018e-05       31.2085      0.4476      0.4476     1681   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1285       2056.72   9.59158e-05       112.376   1.798e-06       0.001     1844  LS failed, Hessian reset \n",
      "    1299       2056.77   0.000405487       29.8153           1           1     1861   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1383       2056.84   8.56115e-06       44.6806   1.754e-07       0.001     2023  LS failed, Hessian reset \n",
      "    1399       2056.84   4.36267e-05       49.4462           1           1     2042   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1491       2056.86    6.0194e-06       38.4627   2.192e-07       0.001     2200  LS failed, Hessian reset \n",
      "    1499       2056.86    3.4861e-06       29.1106      0.7952      0.7952     2209   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1589       2056.87   3.51579e-07       21.9327       1.755      0.1755     2341   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.63558\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1919.16    0.00845292       250.194           1           1      129   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1972.93    0.00203271       270.089           1           1      248   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1995.91     0.0109257       1210.95      0.3779           1      364   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       2029.33      0.429529       1626.04           1           1      479   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       2044.45     0.0176654       746.212       1.345      0.1345      602   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     596       2050.48   3.26452e-05       110.125   1.376e-07       0.001      768  LS failed, Hessian reset \n",
      "     599       2050.49   6.79083e-05       51.4238           1           1      771   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       2052.58   0.000555352        73.963      0.1537           1      898   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     701       2052.58   1.20769e-05       37.3626   1.296e-07       0.001      949  LS failed, Hessian reset \n",
      "     785       2054.74   1.54102e-05       67.0657   2.805e-07       0.001     1110  LS failed, Hessian reset \n",
      "     799       2055.21   0.000357454       287.121      0.3017      0.3017     1128   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       2056.54    0.00102426       57.9937           1           1     1256   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     934       2056.77   1.90536e-05       80.8723    1.92e-07       0.001     1339  LS failed, Hessian reset \n",
      "     983       2057.06   2.65953e-05        108.73   2.992e-07       0.001     1458  LS failed, Hessian reset \n",
      "     999       2057.17   0.000126152          60.3           1           1     1479   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1039       2057.29   1.23408e-05        50.877   1.572e-07       0.001     1591  LS failed, Hessian reset \n",
      "    1099       2057.44   7.86631e-05       35.9246      0.3944           1     1669   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1193       2058.94   2.21624e-05        78.948   5.542e-07       0.001     1824  LS failed, Hessian reset \n",
      "    1199       2058.97   5.99306e-05       48.4011      0.2031           1     1834   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1214       2059.02   1.50743e-05       57.6221   1.418e-07       0.001     1887  LS failed, Hessian reset \n",
      "    1299       2059.88    0.00745865       150.827      0.7075      0.7075     1999   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1316        2060.3   1.67495e-05       57.5908   1.283e-07       0.001     2074  LS failed, Hessian reset \n",
      "    1399       2061.34    0.00027926        56.056      0.5576      0.5576     2180   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1408       2061.36   6.06103e-05       70.6834   1.328e-06       0.001     2235  LS failed, Hessian reset \n",
      "    1499       2061.47   0.000375687       95.1225           1           1     2350   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1599       2061.73    0.00246067       100.959           1           1     2473   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1618       2061.92   3.01342e-05        51.763   1.104e-07       0.001     2553  LS failed, Hessian reset \n",
      "    1699        2062.1   2.01476e-05        54.586      0.6909      0.6909     2654   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1731       2062.11   6.79577e-05       47.9565   1.428e-06       0.001     2735  LS failed, Hessian reset \n",
      "    1753       2062.12   1.60367e-05        30.595   6.398e-07       0.001     2805  LS failed, Hessian reset \n",
      "    1781       2062.12   1.87075e-05       69.8622   3.956e-07       0.001     2889  LS failed, Hessian reset \n",
      "    1799       2062.12    5.2526e-07       31.2195      0.1091           1     2917   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1805       2062.12   1.71558e-07       25.8849      0.2781           1     2929   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.44837\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1907.48     0.0490491       2224.53           1           1      118   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199        1965.7     0.0614262       3353.37           1           1      236   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       2015.92    0.00304286       120.404           1           1      372   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       2027.89   0.000710027       202.634           1           1      493   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       2031.45   0.000530413       122.589           1           1      620   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       2035.91   0.000248044       123.645      0.2804      0.2804      745   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     680       2040.25   0.000195783       499.218    5.66e-07       0.001      894  LS failed, Hessian reset \n",
      "     699       2040.57   0.000955075       199.144           1           1      914   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       2042.99    0.00210333        74.243      0.3276           1     1045   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899        2043.8   1.19888e-05       18.7903   1.132e-07       0.001     1233  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     962       2043.97   8.59069e-06       37.5009   2.466e-07       0.001     1364  LS failed, Hessian reset \n",
      "     999       2044.01   0.000436135       41.8461           1           1     1412   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       2044.42   0.000256592       105.124      0.2228      0.6118     1544   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1191       2045.36   1.03675e-05       35.2655   1.334e-07       0.001     1696  LS failed, Hessian reset \n",
      "    1199       2045.37   2.43726e-05       29.2886      0.3893      0.3893     1707   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299       2045.68   0.000207536       44.0643      0.1874       0.682     1851   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1365       2045.73   1.05204e-05       38.6295   3.552e-07       0.001     1990  LS failed, Hessian reset \n",
      "    1378       2045.73   3.17261e-07       20.5282      0.4457      0.4457     2011   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.57345\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1924.86    0.00882777       246.067           1           1      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1960.77    0.00409088       240.442           1           1      244   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       2021.33      0.020766       621.223           1           1      375   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       2032.87   0.000615185       66.7671           1           1      504   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       2039.38   0.000410084       84.0398      0.6145      0.6145      619   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       2040.61     0.0259645        414.72           1           1      745   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     630       2041.87    1.2567e-05       38.8227   1.304e-07       0.001      830  LS failed, Hessian reset \n",
      "     649       2042.07   2.76239e-05       65.9731    1.41e-06       0.001      892  LS failed, Hessian reset \n",
      "     691       2042.44   1.31386e-05       55.6377   3.072e-07       0.001      991  LS failed, Hessian reset \n",
      "     699       2042.49   0.000542549       85.8392      0.5304      0.5304     1001   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       2043.61   0.000396096       54.4457           1           1     1149   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     817       2043.73   1.56562e-05       41.5726   1.226e-07       0.001     1218  LS failed, Hessian reset \n",
      "     897       2043.94   1.44703e-05       44.7886   1.293e-07       0.001     1369  LS failed, Hessian reset \n",
      "     899       2043.95   0.000282776       69.6924           1           1     1372   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       2044.16   8.07197e-05       24.9511      0.8968      0.8968     1496   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1009       2044.16   7.11987e-06       25.4689   1.405e-07       0.001     1548  LS failed, Hessian reset \n",
      "    1088       2044.39   3.27379e-05       124.783   1.536e-07       0.001     1706  LS failed, Hessian reset \n",
      "    1099       2044.53    0.00144007       77.5376           1           1     1719   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1106       2044.62   1.58337e-05       33.8645   1.173e-07       0.001     1774  LS failed, Hessian reset \n",
      "    1134       2044.72   1.07827e-05       43.7844   1.526e-07       0.001     1862  LS failed, Hessian reset \n",
      "    1147       2044.76     5.425e-06       22.9737    2.49e-07       0.001     1916  LS failed, Hessian reset \n",
      "    1178       2044.77   1.29957e-05       57.8489   1.494e-07       0.001     2004  LS failed, Hessian reset \n",
      "    1199       2044.78   2.84338e-07         21.06      0.1426      0.1426     2042   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1201       2044.78   2.27578e-07        21.018   1.392e-08       0.001     2093  LS failed, Hessian reset \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.71088\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1904.07     0.0119334       465.302           1           1      126   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1998.69    0.00710342       207.728           1           1      246   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       2027.99     0.0147525       793.591           1           1      369   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       2034.78    0.00521896        116.27           1           1      485   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       2038.85    0.00169239       172.126      0.0824      0.9671      605   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       2041.83    0.00141057        108.04      0.4809      0.4809      741   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     644       2045.02   2.88048e-05       121.849   2.748e-07       0.001      852  LS failed, Hessian reset \n",
      "     699        2046.8    0.00651234       92.5782           1           1      928   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     730       2047.58   2.14122e-05       72.2204   6.623e-07       0.001     1004  LS failed, Hessian reset \n",
      "     784       2048.16   2.45981e-05       68.0482   1.239e-07       0.001     1126  LS failed, Hessian reset \n",
      "     799       2048.22   0.000562037       161.832       3.524      0.3524     1147   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     805        2048.3   3.23468e-05       102.281   4.592e-07       0.001     1199  LS failed, Hessian reset \n",
      "     845       2048.46   3.76637e-05       141.723   4.337e-07       0.001     1287  LS failed, Hessian reset \n",
      "     899       2048.75    0.00128681       143.148           1           1     1353   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     906       2048.77   2.10719e-05       79.4598   4.335e-07       0.001     1396  LS failed, Hessian reset \n",
      "     999       2049.21   0.000296949       112.758           1           1     1512   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1068       2049.61   1.28628e-05       55.9306   2.927e-07       0.001     1646  LS failed, Hessian reset \n",
      "    1099       2049.66   0.000216291       46.8033      0.4487           1     1690   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1114       2049.69    1.0893e-05       48.8811   2.675e-07       0.001     1786  LS failed, Hessian reset \n",
      "    1147       2049.76   5.33586e-06       23.9514   1.784e-07       0.001     1876  LS failed, Hessian reset \n",
      "    1199       2049.84   0.000307266       31.4081           1           1     1937   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1222       2050.23   3.85408e-05        174.35   2.486e-07       0.001     2010  LS failed, Hessian reset \n",
      "    1250       2050.58   1.11157e-05       48.1331   1.853e-07       0.001     2081  LS failed, Hessian reset \n",
      "    1299       2050.66   0.000228104       27.5995      0.4117           1     2150   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1362       2050.86   1.66705e-05       68.9605   1.621e-07       0.001     2278  LS failed, Hessian reset \n",
      "    1399       2050.95   0.000419372       35.8689      0.5014      0.5014     2327   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1499       2051.01   0.000662837       58.8019           1           1     2460   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1512       2051.05   1.12885e-05        36.347   1.244e-07       0.001     2515  LS failed, Hessian reset \n",
      "    1534       2051.09   5.78967e-06         24.02   1.483e-07       0.001     2582  LS failed, Hessian reset \n",
      "    1599        2051.1   0.000947601       63.2217           1           1     2677   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1665       2051.16   1.35804e-05       65.4279   2.466e-07       0.001     2804  LS failed, Hessian reset \n",
      "    1699       2051.17   0.000687867       134.868           1           1     2847   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1799       2051.21   0.000329294        30.806           1           1     2976   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1809       2051.22   3.04612e-05       29.0436   1.043e-06       0.001     3028  LS failed, Hessian reset \n",
      "    1899       2051.24   3.32541e-06       27.3425      0.3875           1     3148   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1920       2051.24   4.74055e-06       38.9566   9.795e-08       0.001     3223  LS failed, Hessian reset \n",
      "    1934       2051.24   1.45722e-07       23.2449     0.03791           1     3242   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.67838\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1894.86     0.0123346       261.495           1           1      128   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1984.45    0.00427702       750.287           1           1      258   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       2018.23    0.00809709       994.858           1           1      380   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       2027.12      0.015659       1340.74      0.9202      0.9202      502   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       2037.04   0.000458432       203.981           1           1      619   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       2040.65    0.00037508       63.1011           1           1      741   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       2043.85    0.00166563       192.166           1           1      863   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     756       2045.43   1.03408e-05       42.7476   1.804e-07       0.001      984  LS failed, Hessian reset \n",
      "     799       2045.99    0.00418066       43.2678      0.7555           1     1051   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     899       2048.27     0.0157709       477.222           1           1     1181   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     928       2049.77   8.55813e-05       133.843   2.661e-06       0.001     1264  LS failed, Hessian reset \n",
      "     999       2050.92   0.000198554       160.817     0.03642      0.2841     1368   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1046        2051.1   9.32586e-06        41.437   2.424e-07       0.001     1488  LS failed, Hessian reset \n",
      "    1099       2051.13   0.000239765        24.124           1           1     1554   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       2051.58    0.00211221       86.5351           1           1     1683   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1299       2052.02   0.000520764       58.8903      0.1094      0.1094     1810   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1305       2052.03    8.3425e-05       97.1145   2.039e-06       0.001     1857  LS failed, Hessian reset \n",
      "    1336       2052.08   9.36667e-06       41.8933   2.164e-07       0.001     1936  LS failed, Hessian reset \n",
      "    1399       2052.16    1.2856e-05       36.3383       0.357           1     2026   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1499       2052.38    0.00196638       105.733           1           1     2162   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1569       2052.43   8.63296e-06       38.6523   1.779e-07       0.001     2285  LS failed, Hessian reset \n",
      "    1599       2052.44   0.000301756       61.9335           1           1     2326   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1651       2052.44   9.27156e-07       20.8495      0.3022      0.3022     2391   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -4.67805\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1869.94    0.00952698       378.518      0.9585      0.9585      120   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1949.05    0.00287206       137.301           1           1      238   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1999.49     0.0045057       203.633      0.4752      0.4752      371   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       2006.34    0.00616267       322.637           1           1      498   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       2009.44    0.00419403       177.133      0.9837      0.9837      624   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       2011.38    0.00119184       256.751       0.194           1      767   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     639       2012.93   6.12741e-05       90.0707    1.29e-07       0.001      850  LS failed, Hessian reset \n",
      "     699        2014.9   0.000387876       54.4663       0.301      0.9695      920   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     701        2014.9   9.55109e-06       34.8482    2.06e-07       0.001      965  LS failed, Hessian reset \n",
      "     726       2015.12   1.00494e-05       22.3268   1.396e-07       0.001     1043  LS failed, Hessian reset \n",
      "     799       2015.73    0.00172614       39.7135      0.8613      0.8613     1143   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     833       2016.03   5.73173e-05       125.959   1.396e-07       0.001     1261  LS failed, Hessian reset \n",
      "     899       2016.29    0.00132681       60.5161           1           1     1341   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     918       2016.37   1.54341e-05       44.2682     1.5e-07       0.001     1416  LS failed, Hessian reset \n",
      "     999       2016.43   0.000254492       44.8802           1           1     1535   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1036       2016.46   4.39395e-06       18.8768   1.832e-07       0.001     1628  LS failed, Hessian reset \n",
      "    1048       2016.46   8.52162e-06       26.4545   1.588e-07       0.001     1684  LS failed, Hessian reset \n",
      "    1064       2016.46   5.16079e-07       31.8912           1           1     1705   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -54.0726\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       3622.42      0.178304       1264.95      0.3501     0.03501      137   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       3814.82      0.112077       897.544           1           1      261   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       3835.11      0.013992       204.699       0.709       0.709      386   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       3846.51    0.00939561       584.802           1           1      501   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       3854.45   0.000424815       711.794     0.09592     0.09592      625   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     503       3854.59   3.23789e-05       69.3469   3.367e-07       0.001      672  LS failed, Hessian reset \n",
      "     599       3863.03     0.0173584       211.607           1           1      795   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       3872.26    0.00143327       110.639           1           1      920   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       3874.79    0.00186362       190.918       0.605       0.605     1046   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     806       3874.83   9.82154e-06       19.7251   2.898e-07       0.001     1104  LS failed, Hessian reset \n",
      "     820       3874.98   5.95698e-05       40.8249   2.216e-07       0.001     1177  LS failed, Hessian reset \n",
      "     840       3875.21   9.93424e-06       24.1669   2.768e-07       0.001     1242  LS failed, Hessian reset \n",
      "     852       3875.23   2.66681e-05       31.7907   2.333e-07       0.001     1306  LS failed, Hessian reset \n",
      "     865       3875.25    1.9409e-05       19.2256    2.26e-07       0.001     1368  LS failed, Hessian reset \n",
      "     899       3875.51    0.00173908        80.905           1           1     1412   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     907       3875.57      4.78e-05       34.2725   2.218e-07       0.001     1460  LS failed, Hessian reset \n",
      "     942       3875.74   1.98325e-05       34.0871   8.231e-07       0.001     1546  LS failed, Hessian reset \n",
      "     950       3875.75   1.44547e-05       30.8355   3.223e-07       0.001     1590  LS failed, Hessian reset \n",
      "     985       3876.04   5.46735e-05        38.104   2.215e-07       0.001     1686  LS failed, Hessian reset \n",
      "     999       3876.51   0.000226934       66.8702      0.4431      0.4431     1703   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       3876.95   3.29137e-05       20.4934      0.4596      0.4596     1846   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1199       3877.51   6.09063e-05       126.551   3.401e-07       0.001     2039  LS failed, Hessian reset \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1267       3877.92   2.31213e-05       22.8418   2.291e-07       0.001     2161  LS failed, Hessian reset \n",
      "    1299       3877.96   0.000178136       25.9341      0.3685      0.3685     2203   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1312       3877.99   1.51362e-05       34.2323   3.508e-07       0.001     2254  LS failed, Hessian reset \n",
      "    1399       3878.06   8.96097e-05       36.2564           1           1     2360   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1499       3878.11   0.000295885       27.0738      0.8574      0.8574     2484   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1532       3878.14   1.80355e-05       41.6873   4.106e-07       0.001     2573  LS failed, Hessian reset \n",
      "    1564       3878.15   2.65085e-06       22.4663           1           1     2621   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n"
     ]
    }
   ],
   "source": [
    "## Facebook Prophet model fit\n",
    "print(n_loops)\n",
    "total_forecast = None\n",
    "mses = []\n",
    "max_val = multiplier \n",
    "max_interval=600 ##for fb prophet, the max interval needs to be a smaller number\n",
    "growth = \"linear\" # logistic or linear or flat?  ## linear seems to be more stable\n",
    "\n",
    "for i1 in range(20, n_loops): # 39 for normal period and 59 for all\n",
    "    i = i1 * one_step_len\n",
    "    df_train1, df_val1 = df[0:i+one_step_len].copy(), df[i+one_step_len: i + one_step_len*2].copy().reset_index() # no max interval\n",
    "    lb = 0 if i1 == n_loops-1 else max(0, i + one_step_len - max_interval)\n",
    "    df_train1, df_val1 = df[lb:i+one_step_len].copy(), df[i+one_step_len: i + one_step_len*2].copy().reset_index()\n",
    "    fact_values = list(df_val1['y'].values)\n",
    "    \n",
    "    if growth == \"logistic\":\n",
    "        df_train1['cap'], df_val1['cap'] = max_val, max_val\n",
    "        df_train1['floor'], df_val1['floor'] = 0.0, 0.0\n",
    "    pm = Prophet(growth=growth,\n",
    "    yearly_seasonality=False, \n",
    "    weekly_seasonality=False,\n",
    "    daily_seasonality=False,\n",
    "    changepoint_prior_scale=0.1,\n",
    "    interval_width=(0.997 if confidence_interval_level==3 else 0.95 if confidence_interval_level==2 else 0.99),        \n",
    "    ) # need to add min_seasonality\n",
    "    #pm = pm.add_seasonality(name='half_daily', period=500, fourier_order=10) ## tuneable value: period (unit: day), fourier_order: \n",
    "    #pm = pm.add_seasonality(name='hourly', period=0.1, fourier_order=10)\n",
    "    pm.fit(df_train1)   \n",
    "    future = pm.make_future_dataframe(periods=one_step_len,freq=myfreq,include_history=False,)\n",
    "    future[\"cap\"] = max_val\n",
    "    future[\"floor\"] = 0.0\n",
    "    future_forecast = pm.predict(future)\n",
    "    #future_forecast = future_forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper', 'trend']]\n",
    "        \n",
    "        \n",
    "    future_forecast['fact'] = fact_values\n",
    "    \n",
    "#     mse = sum([(f-p) * (f-p) for f,p in zip(fact_values, predicted_values)]) / len(fact_values)\n",
    "#     mses.append(mse)\n",
    "#     future_forecast['yhat_upper'] = updated_upper_stds\n",
    "#     future_forecast['yhat_lower'] = updated_lower_stds\n",
    "    #future_forecast['y'] = df_val1['y']\n",
    "    #pm.plot(future_forecast)\n",
    "    if total_forecast is None:\n",
    "        total_forecast = future_forecast.copy()\n",
    "    else:\n",
    "        total_forecast = pd.concat([total_forecast,future_forecast.copy()])\n",
    "total_forecast = total_forecast.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "309d4d49-d5c5-4de7-8a39-6fb090f602ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-756de045ceab4c3c8e1b0cfadd840ed1\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-756de045ceab4c3c8e1b0cfadd840ed1\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-756de045ceab4c3c8e1b0cfadd840ed1\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"title\": {\"fontSize\": 20}}, \"layer\": [{\"data\": {\"name\": \"data-18adaed4354651714353335e471d547a\"}, \"mark\": {\"type\": \"area\", \"color\": \"#7FC97F\", \"interpolate\": \"basis\"}, \"encoding\": {\"tooltip\": [{\"type\": \"temporal\", \"field\": \"ds\"}, {\"type\": \"quantitative\", \"field\": \"fact\"}, {\"type\": \"quantitative\", \"field\": \"yhat_lower\"}, {\"type\": \"quantitative\", \"field\": \"yhat_upper\"}], \"x\": {\"type\": \"temporal\", \"axis\": {\"format\": \"%H:%M\"}, \"field\": \"ds\", \"title\": \"date\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"yhat_upper\"}, \"y2\": {\"field\": \"yhat_lower\"}}, \"selection\": {\"selector034\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"title\": \"fbprophet Anomaly Detection\"}, {\"data\": {\"name\": \"data-3d1d5fd7fab8322d7a8e26a3c34eb90b\"}, \"mark\": {\"type\": \"circle\", \"color\": \"Black\", \"opacity\": 0.7, \"size\": 15}, \"encoding\": {\"tooltip\": [{\"type\": \"temporal\", \"field\": \"ds\"}, {\"type\": \"quantitative\", \"field\": \"fact\"}, {\"type\": \"quantitative\", \"field\": \"yhat_lower\"}, {\"type\": \"quantitative\", \"field\": \"yhat_upper\"}], \"x\": {\"type\": \"temporal\", \"field\": \"ds\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"fact\", \"title\": \"CPU Utilization Percentage\"}}, \"selection\": {\"selector035\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}}, {\"data\": {\"name\": \"data-a55b879d3e1aa08d4d2d2e85b669ba70\"}, \"mark\": {\"type\": \"circle\", \"color\": \"Red\", \"size\": 30}, \"encoding\": {\"tooltip\": [{\"type\": \"temporal\", \"field\": \"ds\"}, {\"type\": \"quantitative\", \"field\": \"fact\"}, {\"type\": \"quantitative\", \"field\": \"yhat_lower\"}, {\"type\": \"quantitative\", \"field\": \"yhat_upper\"}], \"x\": {\"type\": \"temporal\", \"field\": \"ds\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"fact\", \"title\": \"CPU Utilization Percentage\"}}, \"selection\": {\"selector036\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}}], \"height\": 450, \"width\": 870, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-18adaed4354651714353335e471d547a\": [{\"ds\": \"2021-08-23T01:45:00\", \"yhat\": 3.331885508895142, \"yhat_lower\": 3.052212024039345, \"yhat_upper\": 3.5965979629294735, \"fact\": 3.1900447587564402, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:46:00\", \"yhat\": 3.378647053694313, \"yhat_lower\": 3.092901295077433, \"yhat_upper\": 3.6860139682300455, \"fact\": 3.124001365720735, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:47:00\", \"yhat\": 3.425408598493483, \"yhat_lower\": 3.132391799776443, \"yhat_upper\": 3.696729556021589, \"fact\": 3.0901049942288012, \"anomaly\": 1}, {\"ds\": \"2021-08-23T01:48:00\", \"yhat\": 3.4721701432926544, \"yhat_lower\": 3.1992621515409265, \"yhat_upper\": 3.7631691372904323, \"fact\": 3.008162397059522, \"anomaly\": 1}, {\"ds\": \"2021-08-23T01:49:00\", \"yhat\": 3.518931688091824, \"yhat_lower\": 3.257116838160305, \"yhat_upper\": 3.7892305689426706, \"fact\": 3.0342427632947664, \"anomaly\": 1}, {\"ds\": \"2021-08-23T01:50:00\", \"yhat\": 3.392093895234215, \"yhat_lower\": 3.086854118405039, \"yhat_upper\": 3.689968213478047, \"fact\": 2.9627319946168917, \"anomaly\": 1}, {\"ds\": \"2021-08-23T01:51:00\", \"yhat\": 3.432548403456777, \"yhat_lower\": 3.0856781311569135, \"yhat_upper\": 3.736018074589602, \"fact\": 2.9569461503037706, \"anomaly\": 1}, {\"ds\": \"2021-08-23T01:52:00\", \"yhat\": 3.4730029116793397, \"yhat_lower\": 3.1371896071706606, \"yhat_upper\": 3.7992035296719537, \"fact\": 3.0267749492582157, \"anomaly\": 1}, {\"ds\": \"2021-08-23T01:53:00\", \"yhat\": 3.513457419901903, \"yhat_lower\": 3.2056552665636904, \"yhat_upper\": 3.8386345203755807, \"fact\": 3.07180359176354, \"anomaly\": 1}, {\"ds\": \"2021-08-23T01:54:00\", \"yhat\": 3.553911928124465, \"yhat_lower\": 3.206579091713092, \"yhat_upper\": 3.8862454627927074, \"fact\": 3.1560782394784286, \"anomaly\": 1}, {\"ds\": \"2021-08-23T01:55:00\", \"yhat\": 3.326726721923654, \"yhat_lower\": 2.995565301308796, \"yhat_upper\": 3.657281466339826, \"fact\": 2.997043850204673, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:56:00\", \"yhat\": 3.354736992523734, \"yhat_lower\": 3.0265083673572555, \"yhat_upper\": 3.719540653273529, \"fact\": 3.009950987266252, \"anomaly\": 1}, {\"ds\": \"2021-08-23T01:57:00\", \"yhat\": 3.3827472631238136, \"yhat_lower\": 3.058755664509204, \"yhat_upper\": 3.6872051162868185, \"fact\": 3.0938716467439757, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:58:00\", \"yhat\": 3.4107575337238933, \"yhat_lower\": 3.0637319147610036, \"yhat_upper\": 3.7283201696064405, \"fact\": 3.0880073603636, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:59:00\", \"yhat\": 3.438767804323972, \"yhat_lower\": 3.078429641452841, \"yhat_upper\": 3.7935710826039153, \"fact\": 3.11206377340535, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:00:00\", \"yhat\": 3.191678276332674, \"yhat_lower\": 2.90873924602488, \"yhat_upper\": 3.4887165686753323, \"fact\": 3.071783339491452, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:01:00\", \"yhat\": 3.203825363957521, \"yhat_lower\": 2.894753294576195, \"yhat_upper\": 3.4772100127441385, \"fact\": 2.9694802366080912, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:02:00\", \"yhat\": 3.2159724515823687, \"yhat_lower\": 2.9543560138209273, \"yhat_upper\": 3.4866514798678487, \"fact\": 3.1296100628743804, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:03:00\", \"yhat\": 3.2281195392072157, \"yhat_lower\": 2.929425281126982, \"yhat_upper\": 3.5010914531979935, \"fact\": 3.002978165799547, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:04:00\", \"yhat\": 3.2402666268320637, \"yhat_lower\": 2.959173140363459, \"yhat_upper\": 3.5318312650272174, \"fact\": 2.961692345489058, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:05:00\", \"yhat\": 3.0687511074339198, \"yhat_lower\": 2.7993831520333705, \"yhat_upper\": 3.348537573601157, \"fact\": 2.988327400999106, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:06:00\", \"yhat\": 3.069390703955379, \"yhat_lower\": 2.8213835386948674, \"yhat_upper\": 3.2966205971181943, \"fact\": 2.817236951076069, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:07:00\", \"yhat\": 3.070030300476838, \"yhat_lower\": 2.8059860155734873, \"yhat_upper\": 3.340368071603505, \"fact\": 2.7591756473744242, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:08:00\", \"yhat\": 3.0706698969982975, \"yhat_lower\": 2.8373395353674185, \"yhat_upper\": 3.337804704812789, \"fact\": 2.7415743889488313, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:09:00\", \"yhat\": 3.0713094935197565, \"yhat_lower\": 2.8243268784133555, \"yhat_upper\": 3.305439324044288, \"fact\": 2.634959930239999, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:10:00\", \"yhat\": 2.8754283495553787, \"yhat_lower\": 2.5892944388269146, \"yhat_upper\": 3.14303831235949, \"fact\": 2.684944460100623, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:11:00\", \"yhat\": 2.865643461512848, \"yhat_lower\": 2.6024860878377454, \"yhat_upper\": 3.133534188535957, \"fact\": 2.7044345238588345, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:12:00\", \"yhat\": 2.8558585734703175, \"yhat_lower\": 2.586316587570893, \"yhat_upper\": 3.1304638533646827, \"fact\": 2.6484580732244156, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:13:00\", \"yhat\": 2.846073685427786, \"yhat_lower\": 2.5438306020587738, \"yhat_upper\": 3.1412337425113144, \"fact\": 2.7494103531133773, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:14:00\", \"yhat\": 2.8362887973852557, \"yhat_lower\": 2.5642041430969544, \"yhat_upper\": 3.0925658394126203, \"fact\": 2.8828342883822207, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:15:00\", \"yhat\": 2.751898472868604, \"yhat_lower\": 2.4648251684986304, \"yhat_upper\": 3.042699369283102, \"fact\": 2.8354131880299063, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:16:00\", \"yhat\": 2.7384511558817954, \"yhat_lower\": 2.4473481719243706, \"yhat_upper\": 3.0080800128307037, \"fact\": 2.8000865445536682, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:17:00\", \"yhat\": 2.7250038388949878, \"yhat_lower\": 2.4801484566000953, \"yhat_upper\": 3.006513229680306, \"fact\": 2.7125150434931227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:18:00\", \"yhat\": 2.7115565219081796, \"yhat_lower\": 2.466158576677688, \"yhat_upper\": 2.9886088181374975, \"fact\": 2.5930717283678337, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:19:00\", \"yhat\": 2.6981092049213715, \"yhat_lower\": 2.4573416126882495, \"yhat_upper\": 2.977712475684677, \"fact\": 2.608611290894402, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:20:00\", \"yhat\": 2.675769377971733, \"yhat_lower\": 2.3919393916069946, \"yhat_upper\": 2.929358639329268, \"fact\": 2.630785813099688, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:21:00\", \"yhat\": 2.6618596704140973, \"yhat_lower\": 2.401973007123614, \"yhat_upper\": 2.9236707878969637, \"fact\": 2.4460733245935717, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:22:00\", \"yhat\": 2.6479499628564613, \"yhat_lower\": 2.3908510643751435, \"yhat_upper\": 2.8943733367636364, \"fact\": 2.3347403540561436, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:23:00\", \"yhat\": 2.634040255298826, \"yhat_lower\": 2.3732339208653763, \"yhat_upper\": 2.9191594455580927, \"fact\": 2.262071173411276, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:24:00\", \"yhat\": 2.62013054774119, \"yhat_lower\": 2.3846283823373704, \"yhat_upper\": 2.870851825527081, \"fact\": 2.298347870588908, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:25:00\", \"yhat\": 2.45887584999456, \"yhat_lower\": 2.152597755344225, \"yhat_upper\": 2.737738033631193, \"fact\": 2.3476057569157662, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:26:00\", \"yhat\": 2.438464810043164, \"yhat_lower\": 2.1284939394704327, \"yhat_upper\": 2.6975692798830377, \"fact\": 2.135029126951106, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:27:00\", \"yhat\": 2.4180537700917673, \"yhat_lower\": 2.1299791146054243, \"yhat_upper\": 2.6991839924807235, \"fact\": 2.1239990673356894, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:28:00\", \"yhat\": 2.397642730140371, \"yhat_lower\": 2.0917444228250126, \"yhat_upper\": 2.6640108617393885, \"fact\": 2.0556779001073835, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:29:00\", \"yhat\": 2.3772316901889745, \"yhat_lower\": 2.069641588236509, \"yhat_upper\": 2.7032519022447916, \"fact\": 2.0694340149175385, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:30:00\", \"yhat\": 2.1821328255433174, \"yhat_lower\": 1.89978167547032, \"yhat_upper\": 2.440896076133988, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:31:00\", \"yhat\": 2.1534767673294706, \"yhat_lower\": 1.8717425813587476, \"yhat_upper\": 2.4207655094559524, \"fact\": 2.162436461794182, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:32:00\", \"yhat\": 2.1248207091156246, \"yhat_lower\": 1.854632784377444, \"yhat_upper\": 2.385485779971609, \"fact\": 2.2670705003332525, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:33:00\", \"yhat\": 2.0961646509017777, \"yhat_lower\": 1.8253636194060385, \"yhat_upper\": 2.379452926767455, \"fact\": 2.29288072551883, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:34:00\", \"yhat\": 2.0675085926879313, \"yhat_lower\": 1.7957534465269196, \"yhat_upper\": 2.3331662725999536, \"fact\": 2.3569619929709806, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:35:00\", \"yhat\": 2.1103111573431925, \"yhat_lower\": 1.8205148031004585, \"yhat_upper\": 2.407173260655713, \"fact\": 2.410609579163354, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:36:00\", \"yhat\": 2.084252366417074, \"yhat_lower\": 1.7911272802312475, \"yhat_upper\": 2.370554350994291, \"fact\": 2.3144117890462743, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:37:00\", \"yhat\": 2.058193575490955, \"yhat_lower\": 1.791193465278028, \"yhat_upper\": 2.355704333464961, \"fact\": 2.4445136543567934, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:38:00\", \"yhat\": 2.0321347845648368, \"yhat_lower\": 1.746145442101424, \"yhat_upper\": 2.324336279336982, \"fact\": 2.465681531052395, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:39:00\", \"yhat\": 2.006075993638717, \"yhat_lower\": 1.7148366914792954, \"yhat_upper\": 2.2834432458968137, \"fact\": 2.534376307983406, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:40:00\", \"yhat\": 2.159879255242714, \"yhat_lower\": 1.8315765354301885, \"yhat_upper\": 2.4873264400546877, \"fact\": 2.6272076036465988, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:41:00\", \"yhat\": 2.139922120467743, \"yhat_lower\": 1.8135199963828947, \"yhat_upper\": 2.475209942999132, \"fact\": 2.5816446195896057, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:42:00\", \"yhat\": 2.1199649856927723, \"yhat_lower\": 1.7829911830155571, \"yhat_upper\": 2.4493357402480678, \"fact\": 2.6662380206684615, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:43:00\", \"yhat\": 2.1000078509178013, \"yhat_lower\": 1.7622906318579834, \"yhat_upper\": 2.4381431559151143, \"fact\": 2.7168521403799497, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:44:00\", \"yhat\": 2.0800507161428303, \"yhat_lower\": 1.745373640411029, \"yhat_upper\": 2.425299067412107, \"fact\": 2.8538032872934025, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:45:00\", \"yhat\": 2.271309143852126, \"yhat_lower\": 1.8578218106621547, \"yhat_upper\": 2.6735358447828137, \"fact\": 2.854838809029115, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:46:00\", \"yhat\": 2.2569091566255888, \"yhat_lower\": 1.8471941923572044, \"yhat_upper\": 2.660966261182707, \"fact\": 2.8618450419844574, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:47:00\", \"yhat\": 2.2425091693990518, \"yhat_lower\": 1.85605622944757, \"yhat_upper\": 2.6431103117132837, \"fact\": 2.9749993982224634, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:48:00\", \"yhat\": 2.228109182172514, \"yhat_lower\": 1.8188301058611593, \"yhat_upper\": 2.656676866320554, \"fact\": 2.9242167077789762, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:49:00\", \"yhat\": 2.2137091949459773, \"yhat_lower\": 1.8138875012736324, \"yhat_upper\": 2.5909245685496614, \"fact\": 3.046298158099033, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:50:00\", \"yhat\": 2.472548443619745, \"yhat_lower\": 1.9998059237293389, \"yhat_upper\": 2.9334898514926038, \"fact\": 3.2619941973050857, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:51:00\", \"yhat\": 2.4663863369459005, \"yhat_lower\": 1.9284025315281805, \"yhat_upper\": 2.9282148048205876, \"fact\": 3.2881410304426844, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:52:00\", \"yhat\": 2.4602242302720563, \"yhat_lower\": 2.0029489955966726, \"yhat_upper\": 2.929972502043231, \"fact\": 3.17823623114512, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:53:00\", \"yhat\": 2.4540621235982116, \"yhat_lower\": 1.9550751693593924, \"yhat_upper\": 2.9231924306192525, \"fact\": 3.2035656084512185, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:54:00\", \"yhat\": 2.447900016924367, \"yhat_lower\": 1.9298852025717417, \"yhat_upper\": 3.0029122158163326, \"fact\": 3.2670646744239535, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:55:00\", \"yhat\": 2.8539862357873136, \"yhat_lower\": 2.371093031362268, \"yhat_upper\": 3.3202421956164145, \"fact\": 3.141727652556658, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:56:00\", \"yhat\": 2.863058869938087, \"yhat_lower\": 2.3585960332233737, \"yhat_upper\": 3.3705802024762685, \"fact\": 2.9955668695370674, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:57:00\", \"yhat\": 2.8721315040888595, \"yhat_lower\": 2.4144895086644897, \"yhat_upper\": 3.3544318403949727, \"fact\": 2.9382006257672204, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:58:00\", \"yhat\": 2.881204138239633, \"yhat_lower\": 2.37602423655889, \"yhat_upper\": 3.330135223189448, \"fact\": 3.1072176080352674, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:59:00\", \"yhat\": 2.8902767723904064, \"yhat_lower\": 2.386799892083761, \"yhat_upper\": 3.3773902442046753, \"fact\": 3.2265123861605005, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:00:00\", \"yhat\": 3.0731283993498164, \"yhat_lower\": 2.6297409996170154, \"yhat_upper\": 3.5091809159479603, \"fact\": 3.193007278757366, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:01:00\", \"yhat\": 3.09050903377686, \"yhat_lower\": 2.7297034476757127, \"yhat_upper\": 3.539122551676097, \"fact\": 2.9939694331844597, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:02:00\", \"yhat\": 3.107889668203902, \"yhat_lower\": 2.6639316579012298, \"yhat_upper\": 3.5543615571136753, \"fact\": 3.0510071595638975, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:03:00\", \"yhat\": 3.1252703026309456, \"yhat_lower\": 2.716274606442533, \"yhat_upper\": 3.549170677722936, \"fact\": 3.0843334587124414, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:04:00\", \"yhat\": 3.1426509370579887, \"yhat_lower\": 2.733824266241215, \"yhat_upper\": 3.57928311645811, \"fact\": 3.017355148653572, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:05:00\", \"yhat\": 3.2594710500629622, \"yhat_lower\": 2.884757929334013, \"yhat_upper\": 3.587575528458071, \"fact\": 3.0840789077005564, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:06:00\", \"yhat\": 3.2832541473452275, \"yhat_lower\": 2.9506868010402325, \"yhat_upper\": 3.6609580543261226, \"fact\": 3.2646089479518845, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:07:00\", \"yhat\": 3.3070372446274923, \"yhat_lower\": 2.9711608237273426, \"yhat_upper\": 3.6585272281279253, \"fact\": 3.165542668097864, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:08:00\", \"yhat\": 3.3308203419097575, \"yhat_lower\": 2.971803786026164, \"yhat_upper\": 3.6840542359951094, \"fact\": 3.0844463441003063, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:09:00\", \"yhat\": 3.354603439192022, \"yhat_lower\": 3.0033022397434697, \"yhat_upper\": 3.693139541392709, \"fact\": 3.1069823468616202, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:10:00\", \"yhat\": 3.350596196741683, \"yhat_lower\": 2.9974563392044704, \"yhat_upper\": 3.7134331220542856, \"fact\": 3.219189334092936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:11:00\", \"yhat\": 3.375097246287968, \"yhat_lower\": 3.033688675978871, \"yhat_upper\": 3.744425221666481, \"fact\": 3.253827606819794, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:12:00\", \"yhat\": 3.3995982958342514, \"yhat_lower\": 3.0488792697674016, \"yhat_upper\": 3.815869074322917, \"fact\": 3.2185308345572, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:13:00\", \"yhat\": 3.4240993453805353, \"yhat_lower\": 3.046780915852456, \"yhat_upper\": 3.77673182621073, \"fact\": 3.155315043321703, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:14:00\", \"yhat\": 3.4486003949268205, \"yhat_lower\": 3.0822149117325925, \"yhat_upper\": 3.8127234460846284, \"fact\": 3.3632975565070162, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:15:00\", \"yhat\": 3.3930949389429435, \"yhat_lower\": 3.043038808558256, \"yhat_upper\": 3.748086374590682, \"fact\": 3.343103013230474, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:16:00\", \"yhat\": 3.4146902698062407, \"yhat_lower\": 3.0331022320982703, \"yhat_upper\": 3.755098494367923, \"fact\": 3.2149037491158556, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:17:00\", \"yhat\": 3.4362856006695375, \"yhat_lower\": 3.078249800221042, \"yhat_upper\": 3.7852700476887904, \"fact\": 3.3955861520011412, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:18:00\", \"yhat\": 3.4578809315328343, \"yhat_lower\": 3.067165697041699, \"yhat_upper\": 3.8230486982481766, \"fact\": 3.198464588834615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:19:00\", \"yhat\": 3.479476262396131, \"yhat_lower\": 3.118249580855553, \"yhat_upper\": 3.821403688158535, \"fact\": 3.1356264595407213, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:20:00\", \"yhat\": 3.4402036910316496, \"yhat_lower\": 3.051713405141024, \"yhat_upper\": 3.8158536035572563, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:21:00\", \"yhat\": 3.4602734072323886, \"yhat_lower\": 3.1044844668891005, \"yhat_upper\": 3.857624082827723, \"fact\": 3.216974287061278, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:22:00\", \"yhat\": 3.480343123433126, \"yhat_lower\": 3.0827460583075372, \"yhat_upper\": 3.857357515744436, \"fact\": 3.265503557337653, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:23:00\", \"yhat\": 3.500412839633863, \"yhat_lower\": 3.142280836715296, \"yhat_upper\": 3.903572793049049, \"fact\": 3.282716546203024, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:24:00\", \"yhat\": 3.5204825558346022, \"yhat_lower\": 3.1146098242706572, \"yhat_upper\": 3.9079354091665617, \"fact\": 3.2557944933176817, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:25:00\", \"yhat\": 3.4748684387920403, \"yhat_lower\": 3.096461219714738, \"yhat_upper\": 3.8804041875781987, \"fact\": 3.253280546730072, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:26:00\", \"yhat\": 3.493317842910911, \"yhat_lower\": 3.0840569992382627, \"yhat_upper\": 3.869141569548407, \"fact\": 3.2468023667661132, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:27:00\", \"yhat\": 3.5117672470297836, \"yhat_lower\": 3.1599305862214937, \"yhat_upper\": 3.8851254670367967, \"fact\": 3.2013389472410476, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:28:00\", \"yhat\": 3.5302166511486543, \"yhat_lower\": 3.184212696535398, \"yhat_upper\": 3.907860432758999, \"fact\": 3.303433319153471, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:29:00\", \"yhat\": 3.5486660552675255, \"yhat_lower\": 3.1603680200145665, \"yhat_upper\": 3.944889306112926, \"fact\": 3.282481127060928, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:30:00\", \"yhat\": 3.4443175936829307, \"yhat_lower\": 3.0472898716224517, \"yhat_upper\": 3.7805501226984193, \"fact\": 3.2652271356713536, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:31:00\", \"yhat\": 3.4586729247013213, \"yhat_lower\": 3.1200737700660284, \"yhat_upper\": 3.841706173675522, \"fact\": 3.1595061912084845, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:32:00\", \"yhat\": 3.4730282557197114, \"yhat_lower\": 3.09185543571929, \"yhat_upper\": 3.8784900676273746, \"fact\": 3.150058882565577, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:33:00\", \"yhat\": 3.487383586738102, \"yhat_lower\": 3.136473143039646, \"yhat_upper\": 3.8741709624248055, \"fact\": 3.2408736119745805, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:34:00\", \"yhat\": 3.5017389177564917, \"yhat_lower\": 3.152537563937251, \"yhat_upper\": 3.9005377015269684, \"fact\": 3.1901242584634275, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:35:00\", \"yhat\": 3.3317556973037057, \"yhat_lower\": 3.0147114113878435, \"yhat_upper\": 3.629974103854075, \"fact\": 3.305247070725088, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:36:00\", \"yhat\": 3.33882027829251, \"yhat_lower\": 3.0103181659509697, \"yhat_upper\": 3.6513017946004687, \"fact\": 3.1486164121920943, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:37:00\", \"yhat\": 3.3458848592813153, \"yhat_lower\": 3.071978307889495, \"yhat_upper\": 3.6548125222579477, \"fact\": 3.3311019146556613, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:38:00\", \"yhat\": 3.3529494402701205, \"yhat_lower\": 3.0411211486709955, \"yhat_upper\": 3.6608008904343827, \"fact\": 3.2369006752018885, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:39:00\", \"yhat\": 3.3600140212589253, \"yhat_lower\": 3.036351000610269, \"yhat_upper\": 3.6396415363798953, \"fact\": 3.4338477225305613, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:40:00\", \"yhat\": 3.3305667200082376, \"yhat_lower\": 2.972583441000639, \"yhat_upper\": 3.6473008423829696, \"fact\": 3.5746933953177287, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:41:00\", \"yhat\": 3.335962368950856, \"yhat_lower\": 3.0231796951262706, \"yhat_upper\": 3.693212949377323, \"fact\": 3.668791853750908, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:42:00\", \"yhat\": 3.3413580178934748, \"yhat_lower\": 3.0354100850539494, \"yhat_upper\": 3.6580814601322684, \"fact\": 3.692430901451204, \"anomaly\": 1}, {\"ds\": \"2021-08-23T03:43:00\", \"yhat\": 3.3467536668360927, \"yhat_lower\": 3.027052838779149, \"yhat_upper\": 3.664374895878244, \"fact\": 3.7236669409703915, \"anomaly\": 1}, {\"ds\": \"2021-08-23T03:44:00\", \"yhat\": 3.352149315778712, \"yhat_lower\": 3.038127110240192, \"yhat_upper\": 3.685501955798585, \"fact\": 3.8603194598248907, \"anomaly\": 1}, {\"ds\": \"2021-08-23T03:45:00\", \"yhat\": 3.4967131273264203, \"yhat_lower\": 3.1443722214477288, \"yhat_upper\": 3.8274754190087275, \"fact\": 3.9691359848159276, \"anomaly\": 1}, {\"ds\": \"2021-08-23T03:46:00\", \"yhat\": 3.5060574480757136, \"yhat_lower\": 3.1286472799275127, \"yhat_upper\": 3.8739242540450163, \"fact\": 3.962226709383252, \"anomaly\": 1}, {\"ds\": \"2021-08-23T03:47:00\", \"yhat\": 3.515401768825006, \"yhat_lower\": 3.1463075349687193, \"yhat_upper\": 3.8834755075052363, \"fact\": 3.9138960369194913, \"anomaly\": 1}, {\"ds\": \"2021-08-23T03:48:00\", \"yhat\": 3.5247460895742986, \"yhat_lower\": 3.1636349754927613, \"yhat_upper\": 3.8623763766636983, \"fact\": 3.866906827861522, \"anomaly\": 1}, {\"ds\": \"2021-08-23T03:49:00\", \"yhat\": 3.5340904103235915, \"yhat_lower\": 3.1860157461206438, \"yhat_upper\": 3.8829982895013972, \"fact\": 3.8996568831849046, \"anomaly\": 1}, {\"ds\": \"2021-08-23T03:50:00\", \"yhat\": 3.682953288569056, \"yhat_lower\": 3.2999901168374177, \"yhat_upper\": 4.058948756011183, \"fact\": 3.931161464982215, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:51:00\", \"yhat\": 3.695889861865221, \"yhat_lower\": 3.324276937703001, \"yhat_upper\": 4.107953566827474, \"fact\": 3.9222762574162413, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:52:00\", \"yhat\": 3.7088264351613853, \"yhat_lower\": 3.323878933575683, \"yhat_upper\": 4.096413232906937, \"fact\": 3.9522308518159854, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:53:00\", \"yhat\": 3.7217630084575504, \"yhat_lower\": 3.2609288513834294, \"yhat_upper\": 4.103492149066312, \"fact\": 3.9672379603949333, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:54:00\", \"yhat\": 3.7346995817537145, \"yhat_lower\": 3.3387695344431827, \"yhat_upper\": 4.182167713109382, \"fact\": 3.949120794105074, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:55:00\", \"yhat\": 3.8278368423083955, \"yhat_lower\": 3.4135659413268202, \"yhat_upper\": 4.310086225865733, \"fact\": 4.011080429852479, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:56:00\", \"yhat\": 3.8428222086916195, \"yhat_lower\": 3.4230974020694482, \"yhat_upper\": 4.247407717601834, \"fact\": 3.9773963745259766, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:57:00\", \"yhat\": 3.8578075750748444, \"yhat_lower\": 3.417422271059165, \"yhat_upper\": 4.303359410707985, \"fact\": 4.063919451853195, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:58:00\", \"yhat\": 3.8727929414580684, \"yhat_lower\": 3.4674205500653184, \"yhat_upper\": 4.3081117630519286, \"fact\": 4.041478475360821, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:59:00\", \"yhat\": 3.8877783078412933, \"yhat_lower\": 3.4657001631106525, \"yhat_upper\": 4.300759511593971, \"fact\": 4.062740372256043, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:00:00\", \"yhat\": 3.9369355379253217, \"yhat_lower\": 3.5260257229007568, \"yhat_upper\": 4.3690912404921365, \"fact\": 4.0505187731741525, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:01:00\", \"yhat\": 3.952330897472099, \"yhat_lower\": 3.547098991988449, \"yhat_upper\": 4.364028511900228, \"fact\": 4.1897089265414085, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:02:00\", \"yhat\": 3.967726257018877, \"yhat_lower\": 3.4756986028251307, \"yhat_upper\": 4.415857724055487, \"fact\": 4.284031357825327, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:03:00\", \"yhat\": 3.9831216165656538, \"yhat_lower\": 3.5951580109052004, \"yhat_upper\": 4.437756084628401, \"fact\": 4.343010092731889, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:04:00\", \"yhat\": 3.9985169761124317, \"yhat_lower\": 3.5754153591075992, \"yhat_upper\": 4.393084661963739, \"fact\": 4.185387068316425, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:05:00\", \"yhat\": 4.121406713469101, \"yhat_lower\": 3.782084289041081, \"yhat_upper\": 4.483752747300702, \"fact\": 4.0414341396536315, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:06:00\", \"yhat\": 4.140145828863057, \"yhat_lower\": 3.800788638920203, \"yhat_upper\": 4.480632962245775, \"fact\": 4.158591747922278, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:07:00\", \"yhat\": 4.158884944257013, \"yhat_lower\": 3.7704153189187277, \"yhat_upper\": 4.540828048399778, \"fact\": 4.11021899046745, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:08:00\", \"yhat\": 4.177624059650968, \"yhat_lower\": 3.8015332688159695, \"yhat_upper\": 4.522260918681324, \"fact\": 4.381527688619375, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:09:00\", \"yhat\": 4.196363175044925, \"yhat_lower\": 3.7928417496936873, \"yhat_upper\": 4.546025502373521, \"fact\": 4.3351854149025995, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:10:00\", \"yhat\": 4.267139416629803, \"yhat_lower\": 3.894884158025459, \"yhat_upper\": 4.621965750074829, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:11:00\", \"yhat\": 4.287957188181897, \"yhat_lower\": 3.9069494807249012, \"yhat_upper\": 4.685556112036446, \"fact\": 4.184798061879761, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:12:00\", \"yhat\": 4.308774959733992, \"yhat_lower\": 3.9553366624582402, \"yhat_upper\": 4.697408014607735, \"fact\": 4.217342874859245, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:13:00\", \"yhat\": 4.329592731286086, \"yhat_lower\": 3.9691465356633517, \"yhat_upper\": 4.69424840449723, \"fact\": 4.134349504828188, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:14:00\", \"yhat\": 4.350410502838183, \"yhat_lower\": 3.988036742774894, \"yhat_upper\": 4.751394097606952, \"fact\": 4.00615462019463, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:15:00\", \"yhat\": 4.350678188649738, \"yhat_lower\": 3.9658539076476482, \"yhat_upper\": 4.70653440052513, \"fact\": 4.174443032790151, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:16:00\", \"yhat\": 4.371610013166427, \"yhat_lower\": 3.9752466334608294, \"yhat_upper\": 4.764753263949242, \"fact\": 4.158682107023693, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:17:00\", \"yhat\": 4.392541837683117, \"yhat_lower\": 4.00392212380167, \"yhat_upper\": 4.781734984373571, \"fact\": 4.039980382510705, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:18:00\", \"yhat\": 4.413473662199807, \"yhat_lower\": 4.071347677849834, \"yhat_upper\": 4.762242553201748, \"fact\": 3.963354168012908, \"anomaly\": 1}, {\"ds\": \"2021-08-23T04:19:00\", \"yhat\": 4.434405486716498, \"yhat_lower\": 4.075565914305938, \"yhat_upper\": 4.771860967664088, \"fact\": 4.013776178380292, \"anomaly\": 1}, {\"ds\": \"2021-08-23T04:20:00\", \"yhat\": 4.352324160272001, \"yhat_lower\": 3.9806755869893253, \"yhat_upper\": 4.752044939988422, \"fact\": 3.8392000488227365, \"anomaly\": 1}, {\"ds\": \"2021-08-23T04:21:00\", \"yhat\": 4.370861752224022, \"yhat_lower\": 4.0119134248847335, \"yhat_upper\": 4.764197085934688, \"fact\": 3.9196928506772672, \"anomaly\": 1}, {\"ds\": \"2021-08-23T04:22:00\", \"yhat\": 4.389399344176042, \"yhat_lower\": 4.026553790725365, \"yhat_upper\": 4.774731578975649, \"fact\": 4.026390515550767, \"anomaly\": 1}, {\"ds\": \"2021-08-23T04:23:00\", \"yhat\": 4.407936936128063, \"yhat_lower\": 4.016864680712609, \"yhat_upper\": 4.786862513251709, \"fact\": 4.1533871249773675, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:24:00\", \"yhat\": 4.4264745280800835, \"yhat_lower\": 4.028795057730811, \"yhat_upper\": 4.817069056221719, \"fact\": 4.189958026263005, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:25:00\", \"yhat\": 4.324706346944173, \"yhat_lower\": 3.9141389554595856, \"yhat_upper\": 4.76053105921618, \"fact\": 4.126055761269775, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:26:00\", \"yhat\": 4.340283831284275, \"yhat_lower\": 3.900655042758893, \"yhat_upper\": 4.793702460253192, \"fact\": 4.19189206344511, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:27:00\", \"yhat\": 4.355861315624375, \"yhat_lower\": 3.9058527675528865, \"yhat_upper\": 4.796062198190156, \"fact\": 4.22553102867423, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:28:00\", \"yhat\": 4.371438799964475, \"yhat_lower\": 3.909108354504185, \"yhat_upper\": 4.801101007713667, \"fact\": 4.210411801001582, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:29:00\", \"yhat\": 4.387016284304576, \"yhat_lower\": 3.9519730626909286, \"yhat_upper\": 4.8263659164128745, \"fact\": 4.182752319021494, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:30:00\", \"yhat\": 4.36873803167162, \"yhat_lower\": 3.961856662856284, \"yhat_upper\": 4.804348022799481, \"fact\": 4.217524711732356, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:31:00\", \"yhat\": 4.383814708384479, \"yhat_lower\": 3.947426896947081, \"yhat_upper\": 4.807654263710892, \"fact\": 4.130474550476257, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:32:00\", \"yhat\": 4.398891385097339, \"yhat_lower\": 3.9294461024781357, \"yhat_upper\": 4.83200782654117, \"fact\": 4.17480129452376, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:33:00\", \"yhat\": 4.4139680618102, \"yhat_lower\": 3.961400667179739, \"yhat_upper\": 4.833325509910874, \"fact\": 4.320493820499588, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:34:00\", \"yhat\": 4.42904473852306, \"yhat_lower\": 3.9761434588503297, \"yhat_upper\": 4.875071105931545, \"fact\": 4.185929353510199, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:35:00\", \"yhat\": 4.405231804730728, \"yhat_lower\": 3.998068735308573, \"yhat_upper\": 4.837060099064569, \"fact\": 4.20876999105369, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:36:00\", \"yhat\": 4.419734565676726, \"yhat_lower\": 3.937790054195686, \"yhat_upper\": 4.8490207220344015, \"fact\": 4.205431875057931, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:37:00\", \"yhat\": 4.434237326622724, \"yhat_lower\": 3.9989210646625177, \"yhat_upper\": 4.875493624066652, \"fact\": 4.267783231196223, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:38:00\", \"yhat\": 4.448740087568721, \"yhat_lower\": 4.046157942544992, \"yhat_upper\": 4.840486192914335, \"fact\": 4.243656661707888, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:39:00\", \"yhat\": 4.46324284851472, \"yhat_lower\": 3.9823033209062597, \"yhat_upper\": 4.922610308865338, \"fact\": 4.277196878166224, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:40:00\", \"yhat\": 4.402026424667826, \"yhat_lower\": 3.951600312074524, \"yhat_upper\": 4.840012922368341, \"fact\": 4.3318998015163706, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:41:00\", \"yhat\": 4.41460053966115, \"yhat_lower\": 4.013682360041837, \"yhat_upper\": 4.880432009153059, \"fact\": 4.363011737742668, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:42:00\", \"yhat\": 4.427174654654473, \"yhat_lower\": 4.062070619211303, \"yhat_upper\": 4.829870184370414, \"fact\": 4.180371396839616, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:43:00\", \"yhat\": 4.439748769647797, \"yhat_lower\": 4.006172028486687, \"yhat_upper\": 4.887570015535892, \"fact\": 4.168647619776069, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:44:00\", \"yhat\": 4.452322884641123, \"yhat_lower\": 4.007979268685739, \"yhat_upper\": 4.8767757626517145, \"fact\": 4.175629966333796, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:45:00\", \"yhat\": 4.390443587125803, \"yhat_lower\": 4.013543075996766, \"yhat_upper\": 4.791741627732467, \"fact\": 4.05020272321786, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:46:00\", \"yhat\": 4.401135489420333, \"yhat_lower\": 3.972563142527717, \"yhat_upper\": 4.810307671969482, \"fact\": 4.1803453970069935, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:47:00\", \"yhat\": 4.411827391714863, \"yhat_lower\": 4.007769952981126, \"yhat_upper\": 4.856197692047582, \"fact\": 4.324238542138023, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:48:00\", \"yhat\": 4.422519294009394, \"yhat_lower\": 4.002933691608877, \"yhat_upper\": 4.8693179948179575, \"fact\": 4.332892480853049, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:49:00\", \"yhat\": 4.433211196303924, \"yhat_lower\": 3.9897562559616953, \"yhat_upper\": 4.865255272005709, \"fact\": 4.291603988308282, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:50:00\", \"yhat\": 4.320787395479911, \"yhat_lower\": 3.9988547409425994, \"yhat_upper\": 4.698991468831791, \"fact\": 4.307690348837449, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:51:00\", \"yhat\": 4.32726902612489, \"yhat_lower\": 4.0068124805697725, \"yhat_upper\": 4.687339520201919, \"fact\": 4.235240633659249, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:52:00\", \"yhat\": 4.333750656769869, \"yhat_lower\": 4.010611216229977, \"yhat_upper\": 4.6605359067388425, \"fact\": 4.317974290661283, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:53:00\", \"yhat\": 4.340232287414848, \"yhat_lower\": 3.9531532822959083, \"yhat_upper\": 4.716629854822278, \"fact\": 4.332980571066018, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:54:00\", \"yhat\": 4.3467139180598275, \"yhat_lower\": 4.008788769292159, \"yhat_upper\": 4.717793740113275, \"fact\": 4.487906802061469, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:55:00\", \"yhat\": 4.340761779348489, \"yhat_lower\": 3.9908864889710913, \"yhat_upper\": 4.716284941305372, \"fact\": 4.685148103114914, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:56:00\", \"yhat\": 4.346688536855592, \"yhat_lower\": 3.9753465843849205, \"yhat_upper\": 4.708330382462337, \"fact\": 4.840059501436562, \"anomaly\": 1}, {\"ds\": \"2021-08-23T04:57:00\", \"yhat\": 4.352615294362694, \"yhat_lower\": 4.019225276112996, \"yhat_upper\": 4.693749246346788, \"fact\": 4.799561104428719, \"anomaly\": 1}, {\"ds\": \"2021-08-23T04:58:00\", \"yhat\": 4.358542051869798, \"yhat_lower\": 3.9992077506329, \"yhat_upper\": 4.718019119859398, \"fact\": 4.795506399361607, \"anomaly\": 1}, {\"ds\": \"2021-08-23T04:59:00\", \"yhat\": 4.364468809376901, \"yhat_lower\": 4.000213006495097, \"yhat_upper\": 4.7454308532092835, \"fact\": 4.742588279703727, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:00:00\", \"yhat\": 4.48726521226872, \"yhat_lower\": 4.0984120281612695, \"yhat_upper\": 4.903438165225154, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:01:00\", \"yhat\": 4.495557786032128, \"yhat_lower\": 4.081106749447407, \"yhat_upper\": 4.943151287767519, \"fact\": 4.798220230319819, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:02:00\", \"yhat\": 4.503850359795537, \"yhat_lower\": 4.11010710740573, \"yhat_upper\": 4.929708025870298, \"fact\": 4.829701886057892, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:03:00\", \"yhat\": 4.512142933558946, \"yhat_lower\": 4.051417983000318, \"yhat_upper\": 4.943949991117344, \"fact\": 4.883016949588336, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:04:00\", \"yhat\": 4.520435507322354, \"yhat_lower\": 4.0859755900703, \"yhat_upper\": 4.931814822681542, \"fact\": 4.8937347142287, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:05:00\", \"yhat\": 4.6056454182459685, \"yhat_lower\": 4.1479624260325885, \"yhat_upper\": 5.010421170866701, \"fact\": 4.938648459724199, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:06:00\", \"yhat\": 4.6154607291222485, \"yhat_lower\": 4.176094460747009, \"yhat_upper\": 5.013705228370765, \"fact\": 5.17809129022616, \"anomaly\": 1}, {\"ds\": \"2021-08-23T05:07:00\", \"yhat\": 4.6252760399985275, \"yhat_lower\": 4.1751966173012685, \"yhat_upper\": 5.083359379189993, \"fact\": 5.2277973565851275, \"anomaly\": 1}, {\"ds\": \"2021-08-23T05:08:00\", \"yhat\": 4.6350913508748075, \"yhat_lower\": 4.209902631751856, \"yhat_upper\": 5.063758264132461, \"fact\": 5.060179684851194, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:09:00\", \"yhat\": 4.644906661751087, \"yhat_lower\": 4.242429175454004, \"yhat_upper\": 5.040101244392638, \"fact\": 5.1297403620303, \"anomaly\": 1}, {\"ds\": \"2021-08-23T05:10:00\", \"yhat\": 4.781576548064278, \"yhat_lower\": 4.30256040326423, \"yhat_upper\": 5.219946408576593, \"fact\": 5.15313317767182, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:11:00\", \"yhat\": 4.7939070203906455, \"yhat_lower\": 4.328847874683812, \"yhat_upper\": 5.273063377018562, \"fact\": 5.300808308865612, \"anomaly\": 1}, {\"ds\": \"2021-08-23T05:12:00\", \"yhat\": 4.806237492717013, \"yhat_lower\": 4.334157400345976, \"yhat_upper\": 5.207763631788368, \"fact\": 5.26705268243037, \"anomaly\": 1}, {\"ds\": \"2021-08-23T05:13:00\", \"yhat\": 4.81856796504338, \"yhat_lower\": 4.36227868265493, \"yhat_upper\": 5.259632221388956, \"fact\": 5.18963904990192, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:14:00\", \"yhat\": 4.830898437369748, \"yhat_lower\": 4.369547825027991, \"yhat_upper\": 5.2785530749591105, \"fact\": 5.127358854626321, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:15:00\", \"yhat\": 4.939881102062191, \"yhat_lower\": 4.445960087674595, \"yhat_upper\": 5.431111745925895, \"fact\": 5.29558515008685, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:16:00\", \"yhat\": 4.953816947396386, \"yhat_lower\": 4.446860734085777, \"yhat_upper\": 5.39545693642832, \"fact\": 5.426325324638567, \"anomaly\": 1}, {\"ds\": \"2021-08-23T05:17:00\", \"yhat\": 4.96775279273058, \"yhat_lower\": 4.442939112747611, \"yhat_upper\": 5.426367036509933, \"fact\": 5.398406115283306, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:18:00\", \"yhat\": 4.981688638064775, \"yhat_lower\": 4.5425424312933895, \"yhat_upper\": 5.469092222492535, \"fact\": 5.538297490098523, \"anomaly\": 1}, {\"ds\": \"2021-08-23T05:19:00\", \"yhat\": 4.99562448339897, \"yhat_lower\": 4.515998184645834, \"yhat_upper\": 5.51513469775087, \"fact\": 5.653105045264966, \"anomaly\": 1}, {\"ds\": \"2021-08-23T05:20:00\", \"yhat\": 5.142240208130522, \"yhat_lower\": 4.657569724547791, \"yhat_upper\": 5.653384006886456, \"fact\": 5.765696569733555, \"anomaly\": 1}, {\"ds\": \"2021-08-23T05:21:00\", \"yhat\": 5.158859561773084, \"yhat_lower\": 4.63950371208939, \"yhat_upper\": 5.689368984269376, \"fact\": 5.666272705776069, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:22:00\", \"yhat\": 5.175478915415646, \"yhat_lower\": 4.674895892768942, \"yhat_upper\": 5.655578602340673, \"fact\": 5.567606762643266, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:23:00\", \"yhat\": 5.192098269058208, \"yhat_lower\": 4.662246743347779, \"yhat_upper\": 5.706109627685462, \"fact\": 5.677067547194454, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:24:00\", \"yhat\": 5.208717622700772, \"yhat_lower\": 4.705550487049551, \"yhat_upper\": 5.708481516431225, \"fact\": 5.952771138793346, \"anomaly\": 1}, {\"ds\": \"2021-08-23T05:25:00\", \"yhat\": 5.427060649294872, \"yhat_lower\": 4.990145979793278, \"yhat_upper\": 5.921424574492328, \"fact\": 5.893822573112458, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:26:00\", \"yhat\": 5.448631395930975, \"yhat_lower\": 4.957343001295265, \"yhat_upper\": 5.95090422881013, \"fact\": 5.956312217973574, \"anomaly\": 1}, {\"ds\": \"2021-08-23T05:27:00\", \"yhat\": 5.470202142567078, \"yhat_lower\": 4.9645266379108115, \"yhat_upper\": 5.938512175720528, \"fact\": 5.867959474518728, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:28:00\", \"yhat\": 5.491772889203179, \"yhat_lower\": 5.016359055265832, \"yhat_upper\": 5.9702596734714355, \"fact\": 5.924113424681968, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:29:00\", \"yhat\": 5.513343635839281, \"yhat_lower\": 5.011066686425204, \"yhat_upper\": 5.968093307316472, \"fact\": 5.755143754694852, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:30:00\", \"yhat\": 5.683629484692805, \"yhat_lower\": 5.213269538172652, \"yhat_upper\": 6.141141496127416, \"fact\": 5.748453921221867, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:31:00\", \"yhat\": 5.708913790956951, \"yhat_lower\": 5.24733473816559, \"yhat_upper\": 6.183522323192187, \"fact\": 5.688476020659092, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:32:00\", \"yhat\": 5.734198097221096, \"yhat_lower\": 5.295285652652635, \"yhat_upper\": 6.222466351632571, \"fact\": 5.746675485986374, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:33:00\", \"yhat\": 5.759482403485242, \"yhat_lower\": 5.277964958644908, \"yhat_upper\": 6.212236629426098, \"fact\": 5.843299988713007, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:34:00\", \"yhat\": 5.784766709749386, \"yhat_lower\": 5.372380317899933, \"yhat_upper\": 6.223611499849249, \"fact\": 5.834770667584292, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:35:00\", \"yhat\": 5.8721079073689495, \"yhat_lower\": 5.47578943944234, \"yhat_upper\": 6.342962079152212, \"fact\": 5.867216105273556, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:36:00\", \"yhat\": 5.899528784054233, \"yhat_lower\": 5.531152693734243, \"yhat_upper\": 6.333014978885417, \"fact\": 5.877789831818705, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:37:00\", \"yhat\": 5.926949660739516, \"yhat_lower\": 5.5187737058512765, \"yhat_upper\": 6.3295353529138465, \"fact\": 5.788247198986482, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:38:00\", \"yhat\": 5.9543705374248, \"yhat_lower\": 5.5566233088107015, \"yhat_upper\": 6.322129941025945, \"fact\": 5.855276906622282, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:39:00\", \"yhat\": 5.9817914141100825, \"yhat_lower\": 5.556292044509903, \"yhat_upper\": 6.390882379467749, \"fact\": 5.952180412895244, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:40:00\", \"yhat\": 6.03639476161728, \"yhat_lower\": 5.643062442260527, \"yhat_upper\": 6.422386040137475, \"fact\": 6.064808083145066, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:41:00\", \"yhat\": 6.065094530632954, \"yhat_lower\": 5.674835616148838, \"yhat_upper\": 6.426340051327196, \"fact\": 6.090622739284995, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:42:00\", \"yhat\": 6.093794299648625, \"yhat_lower\": 5.676528421104906, \"yhat_upper\": 6.522376112631604, \"fact\": 6.088539270842496, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:43:00\", \"yhat\": 6.122494068664298, \"yhat_lower\": 5.695962363184954, \"yhat_upper\": 6.5191202408422155, \"fact\": 6.180880255586056, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:44:00\", \"yhat\": 6.151193837679968, \"yhat_lower\": 5.771526095742024, \"yhat_upper\": 6.56168250050933, \"fact\": 6.0829197927436836, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:45:00\", \"yhat\": 6.219419808092494, \"yhat_lower\": 5.8562137843144475, \"yhat_upper\": 6.554321165534096, \"fact\": 6.153305438466777, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:46:00\", \"yhat\": 6.249591296115454, \"yhat_lower\": 5.900366532302038, \"yhat_upper\": 6.6014704950941425, \"fact\": 6.245424626413475, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:47:00\", \"yhat\": 6.279762784138416, \"yhat_lower\": 5.926250229106527, \"yhat_upper\": 6.614521687629934, \"fact\": 6.270181897393748, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:48:00\", \"yhat\": 6.3099342721613745, \"yhat_lower\": 5.953471673698357, \"yhat_upper\": 6.722347691092832, \"fact\": 6.304686334947228, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:49:00\", \"yhat\": 6.340105760184337, \"yhat_lower\": 5.9992889324767695, \"yhat_upper\": 6.72113653922752, \"fact\": 6.2486697214488025, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:50:00\", \"yhat\": 6.396574857203037, \"yhat_lower\": 6.039406453457198, \"yhat_upper\": 6.727349834071051, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:51:00\", \"yhat\": 6.427910680404775, \"yhat_lower\": 6.093574838195784, \"yhat_upper\": 6.772527356576482, \"fact\": 6.23101000200763, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:52:00\", \"yhat\": 6.459246503606512, \"yhat_lower\": 6.08592773348687, \"yhat_upper\": 6.820807550014637, \"fact\": 6.230694728169978, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:53:00\", \"yhat\": 6.490582326808251, \"yhat_lower\": 6.156357541056963, \"yhat_upper\": 6.859196353818595, \"fact\": 6.157703819607037, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:54:00\", \"yhat\": 6.521918150009987, \"yhat_lower\": 6.1644384560093854, \"yhat_upper\": 6.850983095119982, \"fact\": 6.301928313075152, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:55:00\", \"yhat\": 6.516502529662582, \"yhat_lower\": 6.186863454300034, \"yhat_upper\": 6.860841742258601, \"fact\": 6.4061636350278155, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:56:00\", \"yhat\": 6.547470077360365, \"yhat_lower\": 6.167189324239693, \"yhat_upper\": 6.878192389451836, \"fact\": 6.462931053129455, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:57:00\", \"yhat\": 6.578437625058145, \"yhat_lower\": 6.227508307485042, \"yhat_upper\": 6.904399840641194, \"fact\": 6.586302157616276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:58:00\", \"yhat\": 6.609405172755925, \"yhat_lower\": 6.256027983214348, \"yhat_upper\": 6.980844138307398, \"fact\": 6.590380090978745, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:59:00\", \"yhat\": 6.640372720453705, \"yhat_lower\": 6.2967374210540346, \"yhat_upper\": 7.014497804128805, \"fact\": 6.598384601991288, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:00:00\", \"yhat\": 6.674043352445564, \"yhat_lower\": 6.355186869493529, \"yhat_upper\": 6.989641233028706, \"fact\": 6.6087284233126855, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:01:00\", \"yhat\": 6.705350405005895, \"yhat_lower\": 6.34876180398345, \"yhat_upper\": 7.0758662776736205, \"fact\": 6.519586448521761, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:02:00\", \"yhat\": 6.736657457566226, \"yhat_lower\": 6.369886371960954, \"yhat_upper\": 7.106336032661469, \"fact\": 6.585441774813497, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:03:00\", \"yhat\": 6.767964510126559, \"yhat_lower\": 6.442913276719573, \"yhat_upper\": 7.0909122115441034, \"fact\": 6.612122789230208, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:04:00\", \"yhat\": 6.7992715626868865, \"yhat_lower\": 6.45677780743946, \"yhat_upper\": 7.134820604496832, \"fact\": 6.713398361671289, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:05:00\", \"yhat\": 6.784280172868407, \"yhat_lower\": 6.4501983696013685, \"yhat_upper\": 7.136741142738257, \"fact\": 6.822549277291775, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:06:00\", \"yhat\": 6.814503474738018, \"yhat_lower\": 6.459401516388098, \"yhat_upper\": 7.144084497144881, \"fact\": 6.97551658913424, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:07:00\", \"yhat\": 6.844726776607626, \"yhat_lower\": 6.492392388292761, \"yhat_upper\": 7.194224145069087, \"fact\": 7.0245338623762, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:08:00\", \"yhat\": 6.874950078477234, \"yhat_lower\": 6.547437250155813, \"yhat_upper\": 7.204729206877613, \"fact\": 7.011984857308559, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:09:00\", \"yhat\": 6.905173380346845, \"yhat_lower\": 6.531199219608413, \"yhat_upper\": 7.23877037847123, \"fact\": 6.939497193677334, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:10:00\", \"yhat\": 6.963951189416137, \"yhat_lower\": 6.635157054909899, \"yhat_upper\": 7.31197661156237, \"fact\": 7.010406398571905, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:11:00\", \"yhat\": 6.994694107671588, \"yhat_lower\": 6.653185298017418, \"yhat_upper\": 7.372456740117308, \"fact\": 6.931851888092667, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:12:00\", \"yhat\": 7.025437025927041, \"yhat_lower\": 6.66414986852533, \"yhat_upper\": 7.375778232052259, \"fact\": 6.879178023131081, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:13:00\", \"yhat\": 7.056179944182494, \"yhat_lower\": 6.7315427009496, \"yhat_upper\": 7.363715523174066, \"fact\": 7.109475269891421, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:14:00\", \"yhat\": 7.0869228624379454, \"yhat_lower\": 6.7276769556062055, \"yhat_upper\": 7.461882310559937, \"fact\": 7.284680664017118, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:15:00\", \"yhat\": 7.132803604963924, \"yhat_lower\": 6.777679934951311, \"yhat_upper\": 7.486415313222594, \"fact\": 7.395090828652547, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:16:00\", \"yhat\": 7.163954578279268, \"yhat_lower\": 6.797815439972422, \"yhat_upper\": 7.515588869762357, \"fact\": 7.371434651213532, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:17:00\", \"yhat\": 7.195105551594614, \"yhat_lower\": 6.80884857693186, \"yhat_upper\": 7.551663495943614, \"fact\": 7.245236231448149, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:18:00\", \"yhat\": 7.22625652490996, \"yhat_lower\": 6.907690755965588, \"yhat_upper\": 7.601105003603468, \"fact\": 7.344627723533745, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:19:00\", \"yhat\": 7.257407498225306, \"yhat_lower\": 6.891200905184238, \"yhat_upper\": 7.634392517151121, \"fact\": 7.362549605351548, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:20:00\", \"yhat\": 7.305324093724712, \"yhat_lower\": 6.9664209377928525, \"yhat_upper\": 7.671943550095379, \"fact\": 7.316384307810927, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:21:00\", \"yhat\": 7.336517891165314, \"yhat_lower\": 6.983505562721477, \"yhat_upper\": 7.701798551283889, \"fact\": 7.4436762713471, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:22:00\", \"yhat\": 7.3677116886059135, \"yhat_lower\": 7.040263420372385, \"yhat_upper\": 7.728319276665692, \"fact\": 7.586315011635683, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:23:00\", \"yhat\": 7.398905486046514, \"yhat_lower\": 7.09613847711129, \"yhat_upper\": 7.740928034771321, \"fact\": 7.84596167034078, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:24:00\", \"yhat\": 7.430099283487114, \"yhat_lower\": 7.084513306392738, \"yhat_upper\": 7.779680487167167, \"fact\": 7.810708032610894, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:25:00\", \"yhat\": 7.503068449359887, \"yhat_lower\": 7.132077455430907, \"yhat_upper\": 7.856225987832262, \"fact\": 7.869544211046324, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:26:00\", \"yhat\": 7.534807034687965, \"yhat_lower\": 7.168374430311849, \"yhat_upper\": 7.856528741890803, \"fact\": 7.588004256487661, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:27:00\", \"yhat\": 7.566545620016041, \"yhat_lower\": 7.250451274593332, \"yhat_upper\": 7.9050957578606456, \"fact\": 7.4272223763164, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:28:00\", \"yhat\": 7.598284205344119, \"yhat_lower\": 7.2467733443308155, \"yhat_upper\": 7.969593148464202, \"fact\": 7.22636705323483, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:29:00\", \"yhat\": 7.630022790672195, \"yhat_lower\": 7.301578652824, \"yhat_upper\": 8.000935990240233, \"fact\": 7.215400231065601, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:30:00\", \"yhat\": 7.629562987118985, \"yhat_lower\": 7.261415125287637, \"yhat_upper\": 8.005739476634869, \"fact\": 7.212214491649582, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:31:00\", \"yhat\": 7.6606127849134085, \"yhat_lower\": 7.325233217884781, \"yhat_upper\": 8.02199483178143, \"fact\": 7.351039971128483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:32:00\", \"yhat\": 7.69166258270783, \"yhat_lower\": 7.383849137425606, \"yhat_upper\": 8.046448160176297, \"fact\": 7.376476250774716, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:33:00\", \"yhat\": 7.722712380502252, \"yhat_lower\": 7.398064306637721, \"yhat_upper\": 8.075810251913788, \"fact\": 7.335800040585095, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:34:00\", \"yhat\": 7.753762178296674, \"yhat_lower\": 7.370601210402666, \"yhat_upper\": 8.118735515490394, \"fact\": 7.448679719340017, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:35:00\", \"yhat\": 7.703965165027774, \"yhat_lower\": 7.3425561260639185, \"yhat_upper\": 8.110696515242921, \"fact\": 7.483511703168986, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:36:00\", \"yhat\": 7.73358748695763, \"yhat_lower\": 7.367816620384011, \"yhat_upper\": 8.086606486222534, \"fact\": 7.414570983492366, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:37:00\", \"yhat\": 7.763209808887485, \"yhat_lower\": 7.388728097617574, \"yhat_upper\": 8.118224160394597, \"fact\": 7.334626120276795, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:38:00\", \"yhat\": 7.792832130817345, \"yhat_lower\": 7.417666619837894, \"yhat_upper\": 8.141570574359186, \"fact\": 7.3049778908374945, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:39:00\", \"yhat\": 7.822454452747199, \"yhat_lower\": 7.469484917189898, \"yhat_upper\": 8.205196512252298, \"fact\": 7.278459085454509, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:40:00\", \"yhat\": 7.76402963850616, \"yhat_lower\": 7.318373972793362, \"yhat_upper\": 8.215497651257094, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:41:00\", \"yhat\": 7.792207987581591, \"yhat_lower\": 7.429556916184169, \"yhat_upper\": 8.214119403165839, \"fact\": 7.413871916691975, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:42:00\", \"yhat\": 7.820386336657026, \"yhat_lower\": 7.404719473608865, \"yhat_upper\": 8.242390861519052, \"fact\": 7.306328534468085, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:43:00\", \"yhat\": 7.848564685732459, \"yhat_lower\": 7.420736522635234, \"yhat_upper\": 8.213372212623964, \"fact\": 7.135863705449194, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:44:00\", \"yhat\": 7.876743034807889, \"yhat_lower\": 7.467616511941547, \"yhat_upper\": 8.287214680730298, \"fact\": 7.296605351643508, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:45:00\", \"yhat\": 7.803764444314406, \"yhat_lower\": 7.349750848798029, \"yhat_upper\": 8.23344220243976, \"fact\": 7.432244315830181, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:46:00\", \"yhat\": 7.830306081206389, \"yhat_lower\": 7.39575921250863, \"yhat_upper\": 8.218325706653111, \"fact\": 7.395988175550756, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:47:00\", \"yhat\": 7.856847718098372, \"yhat_lower\": 7.402322121416356, \"yhat_upper\": 8.27653302450488, \"fact\": 7.278183825443562, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:48:00\", \"yhat\": 7.883389354990358, \"yhat_lower\": 7.473397927870447, \"yhat_upper\": 8.300350204809368, \"fact\": 7.250066035906667, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:49:00\", \"yhat\": 7.90993099188234, \"yhat_lower\": 7.484630620408147, \"yhat_upper\": 8.33448537232224, \"fact\": 7.282209302585056, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:50:00\", \"yhat\": 7.820125167986293, \"yhat_lower\": 7.372249090014914, \"yhat_upper\": 8.272038076589293, \"fact\": 7.2156324032840775, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:51:00\", \"yhat\": 7.8447492265443355, \"yhat_lower\": 7.384347518218982, \"yhat_upper\": 8.293036971019557, \"fact\": 7.196476313520412, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:52:00\", \"yhat\": 7.869373285102379, \"yhat_lower\": 7.421341055626196, \"yhat_upper\": 8.34531003396715, \"fact\": 7.113119567118843, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:53:00\", \"yhat\": 7.893997343660421, \"yhat_lower\": 7.425386391532291, \"yhat_upper\": 8.334904538797568, \"fact\": 7.162704804924952, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:54:00\", \"yhat\": 7.918621402218465, \"yhat_lower\": 7.463041169508518, \"yhat_upper\": 8.410168450495187, \"fact\": 7.221109884038875, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:55:00\", \"yhat\": 7.792377703855139, \"yhat_lower\": 7.376037184518288, \"yhat_upper\": 8.270816272926876, \"fact\": 7.28587585791872, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:56:00\", \"yhat\": 7.814536149936089, \"yhat_lower\": 7.349443330119734, \"yhat_upper\": 8.320825439606706, \"fact\": 7.33450767010157, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:57:00\", \"yhat\": 7.836694596017037, \"yhat_lower\": 7.319075852028994, \"yhat_upper\": 8.331981688054398, \"fact\": 7.2076185280683, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:58:00\", \"yhat\": 7.858853042097987, \"yhat_lower\": 7.388710758090654, \"yhat_upper\": 8.352935339122777, \"fact\": 7.200436641971628, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:59:00\", \"yhat\": 7.881011488178935, \"yhat_lower\": 7.42388586300723, \"yhat_upper\": 8.402974127198641, \"fact\": 7.174060851045539, \"anomaly\": 1}, {\"ds\": \"2021-08-23T07:00:00\", \"yhat\": 7.768921803448575, \"yhat_lower\": 7.228078268427448, \"yhat_upper\": 8.271746279305482, \"fact\": 7.262444992057902, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:01:00\", \"yhat\": 7.788860526071928, \"yhat_lower\": 7.302443652049297, \"yhat_upper\": 8.250673073778822, \"fact\": 7.34306802733499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:02:00\", \"yhat\": 7.808799248695281, \"yhat_lower\": 7.273735058368175, \"yhat_upper\": 8.399241130213275, \"fact\": 7.316689086557331, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:03:00\", \"yhat\": 7.828737971318636, \"yhat_lower\": 7.3679379553776725, \"yhat_upper\": 8.330722162466632, \"fact\": 7.435901366061946, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:04:00\", \"yhat\": 7.848676693941987, \"yhat_lower\": 7.319190986418027, \"yhat_upper\": 8.382161063940698, \"fact\": 7.519301570079593, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:05:00\", \"yhat\": 7.758085311418496, \"yhat_lower\": 7.20357480950466, \"yhat_upper\": 8.2546506006219, \"fact\": 7.444483463234448, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:06:00\", \"yhat\": 7.776025148545101, \"yhat_lower\": 7.279117891677981, \"yhat_upper\": 8.24254762106406, \"fact\": 7.558503416641305, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:07:00\", \"yhat\": 7.793964985671706, \"yhat_lower\": 7.287808628193732, \"yhat_upper\": 8.317233386543023, \"fact\": 7.502724062217367, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:08:00\", \"yhat\": 7.811904822798311, \"yhat_lower\": 7.276374310307828, \"yhat_upper\": 8.3141970356347, \"fact\": 7.543900869874692, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:09:00\", \"yhat\": 7.829844659924915, \"yhat_lower\": 7.317508138104455, \"yhat_upper\": 8.36285362231184, \"fact\": 7.61793683008212, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:10:00\", \"yhat\": 7.77670793040921, \"yhat_lower\": 7.178357177076908, \"yhat_upper\": 8.379091503507036, \"fact\": 7.576099179026605, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:11:00\", \"yhat\": 7.793328986429839, \"yhat_lower\": 7.28606952202517, \"yhat_upper\": 8.287795131160424, \"fact\": 7.474889511780991, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:12:00\", \"yhat\": 7.809950042450466, \"yhat_lower\": 7.23332607252514, \"yhat_upper\": 8.398189647521402, \"fact\": 7.493594475005889, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:13:00\", \"yhat\": 7.826571098471094, \"yhat_lower\": 7.261077474874074, \"yhat_upper\": 8.318748020642547, \"fact\": 7.394645478479456, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:14:00\", \"yhat\": 7.843192154491723, \"yhat_lower\": 7.3288137028998035, \"yhat_upper\": 8.40486946213267, \"fact\": 7.358314631980785, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:15:00\", \"yhat\": 7.7649579330171425, \"yhat_lower\": 7.236500680398755, \"yhat_upper\": 8.253340348064114, \"fact\": 7.414394947365127, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:16:00\", \"yhat\": 7.779783068810478, \"yhat_lower\": 7.245332292634532, \"yhat_upper\": 8.346807506037468, \"fact\": 7.362071254261016, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:17:00\", \"yhat\": 7.794608204603816, \"yhat_lower\": 7.3043617719127925, \"yhat_upper\": 8.350017784963253, \"fact\": 7.2610336329398955, \"anomaly\": 1}, {\"ds\": \"2021-08-23T07:18:00\", \"yhat\": 7.809433340397153, \"yhat_lower\": 7.311458714437043, \"yhat_upper\": 8.28435584182724, \"fact\": 7.397969492007248, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:19:00\", \"yhat\": 7.824258476190491, \"yhat_lower\": 7.299785886144246, \"yhat_upper\": 8.313205226122603, \"fact\": 7.175585543122942, \"anomaly\": 1}, {\"ds\": \"2021-08-23T07:20:00\", \"yhat\": 7.705203307174814, \"yhat_lower\": 7.179796205071708, \"yhat_upper\": 8.29508889715433, \"fact\": 7.132322801642127, \"anomaly\": 1}, {\"ds\": \"2021-08-23T07:21:00\", \"yhat\": 7.717498375607754, \"yhat_lower\": 7.1750889003409695, \"yhat_upper\": 8.2189327036714, \"fact\": 7.1510859667762, \"anomaly\": 1}, {\"ds\": \"2021-08-23T07:22:00\", \"yhat\": 7.729793444040696, \"yhat_lower\": 7.259635948786028, \"yhat_upper\": 8.246837631570852, \"fact\": 7.086966133877971, \"anomaly\": 1}, {\"ds\": \"2021-08-23T07:23:00\", \"yhat\": 7.742088512473638, \"yhat_lower\": 7.216099345041247, \"yhat_upper\": 8.242590621402277, \"fact\": 7.091083736255178, \"anomaly\": 1}, {\"ds\": \"2021-08-23T07:24:00\", \"yhat\": 7.754383580906579, \"yhat_lower\": 7.241410745110697, \"yhat_upper\": 8.28917597788792, \"fact\": 7.047475782418074, \"anomaly\": 1}, {\"ds\": \"2021-08-23T07:25:00\", \"yhat\": 7.613096301645659, \"yhat_lower\": 7.083790123017878, \"yhat_upper\": 8.177426160061719, \"fact\": 7.009527254558687, \"anomaly\": 1}, {\"ds\": \"2021-08-23T07:26:00\", \"yhat\": 7.622752980306864, \"yhat_lower\": 7.098981327015275, \"yhat_upper\": 8.107482554545278, \"fact\": 7.115014684339309, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:27:00\", \"yhat\": 7.632409658968071, \"yhat_lower\": 7.122940278464718, \"yhat_upper\": 8.227457484277082, \"fact\": 7.158507807273718, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:28:00\", \"yhat\": 7.642066337629277, \"yhat_lower\": 7.126973459663577, \"yhat_upper\": 8.211914211174266, \"fact\": 7.223216693033921, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:29:00\", \"yhat\": 7.651723016290483, \"yhat_lower\": 7.100907330152589, \"yhat_upper\": 8.24565665893417, \"fact\": 7.414873061673024, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:30:00\", \"yhat\": 7.535254655011061, \"yhat_lower\": 7.0142541373102505, \"yhat_upper\": 8.054237372013203, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:31:00\", \"yhat\": 7.542539678937592, \"yhat_lower\": 6.984912837527626, \"yhat_upper\": 8.08908370369584, \"fact\": 7.2522816003485655, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:32:00\", \"yhat\": 7.5498247028641225, \"yhat_lower\": 7.059994248816074, \"yhat_upper\": 8.071199504626291, \"fact\": 7.362085934503852, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:33:00\", \"yhat\": 7.557109726790653, \"yhat_lower\": 7.072806357220526, \"yhat_upper\": 8.023736493522916, \"fact\": 7.467224271777104, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:34:00\", \"yhat\": 7.564394750717183, \"yhat_lower\": 7.057464878082801, \"yhat_upper\": 8.055004442994232, \"fact\": 7.364294904567715, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:35:00\", \"yhat\": 7.493997409493834, \"yhat_lower\": 7.037597915164162, \"yhat_upper\": 7.995398199412876, \"fact\": 7.459430953032399, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:36:00\", \"yhat\": 7.499497657906483, \"yhat_lower\": 7.022657439047381, \"yhat_upper\": 7.979927053199244, \"fact\": 7.452578150899747, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:37:00\", \"yhat\": 7.504997906319134, \"yhat_lower\": 7.0791810429417525, \"yhat_upper\": 7.971913966514989, \"fact\": 7.5133858350161615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:38:00\", \"yhat\": 7.510498154731784, \"yhat_lower\": 7.042142473339802, \"yhat_upper\": 8.003616260809132, \"fact\": 7.4258638789745675, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:39:00\", \"yhat\": 7.515998403144434, \"yhat_lower\": 7.058877734573187, \"yhat_upper\": 7.996124138991123, \"fact\": 7.3737932149732766, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:40:00\", \"yhat\": 7.45559758057194, \"yhat_lower\": 7.023004407262546, \"yhat_upper\": 7.91917560787243, \"fact\": 7.598358267725344, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:41:00\", \"yhat\": 7.459410846016358, \"yhat_lower\": 6.980790101573487, \"yhat_upper\": 7.88611232025243, \"fact\": 7.492834789309395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:42:00\", \"yhat\": 7.463224111460778, \"yhat_lower\": 7.040175636481596, \"yhat_upper\": 7.927124989402325, \"fact\": 7.522201737971649, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:43:00\", \"yhat\": 7.467037376905196, \"yhat_lower\": 6.988949807648115, \"yhat_upper\": 7.865715488761777, \"fact\": 7.302638063120661, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:44:00\", \"yhat\": 7.470850642349615, \"yhat_lower\": 6.997472687895568, \"yhat_upper\": 7.932681972304574, \"fact\": 7.279557282830666, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:45:00\", \"yhat\": 7.424926666599787, \"yhat_lower\": 6.987245133375629, \"yhat_upper\": 7.830279440818849, \"fact\": 7.363046511604048, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:46:00\", \"yhat\": 7.42741028966257, \"yhat_lower\": 7.030542636204192, \"yhat_upper\": 7.827537440953038, \"fact\": 7.326486104423132, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:47:00\", \"yhat\": 7.429893912725353, \"yhat_lower\": 7.0169327692260355, \"yhat_upper\": 7.823074071372155, \"fact\": 7.246927464543807, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:48:00\", \"yhat\": 7.432377535788135, \"yhat_lower\": 6.977496106127263, \"yhat_upper\": 7.853750148068542, \"fact\": 7.41642187662266, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:49:00\", \"yhat\": 7.434861158850919, \"yhat_lower\": 7.030829814358059, \"yhat_upper\": 7.82454028317958, \"fact\": 7.502878653438836, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:50:00\", \"yhat\": 7.391314970411022, \"yhat_lower\": 7.017393429002645, \"yhat_upper\": 7.773890157102199, \"fact\": 7.651020501300728, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:51:00\", \"yhat\": 7.392670718513772, \"yhat_lower\": 6.98694510956702, \"yhat_upper\": 7.754970839952307, \"fact\": 7.73101396367219, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:52:00\", \"yhat\": 7.39402646661652, \"yhat_lower\": 7.0020937753496675, \"yhat_upper\": 7.744473547051534, \"fact\": 7.7908900897128355, \"anomaly\": 1}, {\"ds\": \"2021-08-23T07:53:00\", \"yhat\": 7.39538221471927, \"yhat_lower\": 6.967731083740013, \"yhat_upper\": 7.754467043135887, \"fact\": 7.721905539978192, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:54:00\", \"yhat\": 7.3967379628220185, \"yhat_lower\": 7.017553787122804, \"yhat_upper\": 7.80583772149309, \"fact\": 7.676797763099813, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:55:00\", \"yhat\": 7.424853504479452, \"yhat_lower\": 6.983314878790855, \"yhat_upper\": 7.89685161543284, \"fact\": 7.49859598323504, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:56:00\", \"yhat\": 7.426171976621599, \"yhat_lower\": 7.045452659829252, \"yhat_upper\": 7.847616106532922, \"fact\": 7.476065058965288, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:57:00\", \"yhat\": 7.427490448763745, \"yhat_lower\": 6.992434500451374, \"yhat_upper\": 7.833253527461147, \"fact\": 7.482103132721876, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:58:00\", \"yhat\": 7.428808920905891, \"yhat_lower\": 7.007277755373034, \"yhat_upper\": 7.840107066578102, \"fact\": 7.533694637573916, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:59:00\", \"yhat\": 7.430127393048037, \"yhat_lower\": 6.965924172913014, \"yhat_upper\": 7.8354935331418485, \"fact\": 7.520250704663931, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:00:00\", \"yhat\": 7.423355470694177, \"yhat_lower\": 6.983531401428217, \"yhat_upper\": 7.829645510016864, \"fact\": 7.430552773592014, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:01:00\", \"yhat\": 7.424123796266829, \"yhat_lower\": 6.955459487662165, \"yhat_upper\": 7.857596936092401, \"fact\": 7.425522429366651, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:02:00\", \"yhat\": 7.424892121839481, \"yhat_lower\": 6.961540280924131, \"yhat_upper\": 7.811657880881046, \"fact\": 7.19210405586305, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:03:00\", \"yhat\": 7.425660447412135, \"yhat_lower\": 6.9890382246651805, \"yhat_upper\": 7.824807689192694, \"fact\": 7.28277232480738, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:04:00\", \"yhat\": 7.426428772984786, \"yhat_lower\": 6.999501323021427, \"yhat_upper\": 7.786759634152286, \"fact\": 7.175360535016683, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:05:00\", \"yhat\": 7.40434478604592, \"yhat_lower\": 6.926032401229468, \"yhat_upper\": 7.825779148577989, \"fact\": 7.262163774530336, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:06:00\", \"yhat\": 7.40475931335718, \"yhat_lower\": 6.945005612466555, \"yhat_upper\": 7.833640551961069, \"fact\": 7.203036103460411, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:07:00\", \"yhat\": 7.405173840668439, \"yhat_lower\": 7.001888180077467, \"yhat_upper\": 7.846190148959344, \"fact\": 7.104577394867066, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:08:00\", \"yhat\": 7.405588367979699, \"yhat_lower\": 6.963643326663981, \"yhat_upper\": 7.858486243880416, \"fact\": 7.146838037080654, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:09:00\", \"yhat\": 7.406002895290959, \"yhat_lower\": 6.949778904964724, \"yhat_upper\": 7.832857658903376, \"fact\": 7.1098713925408195, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:10:00\", \"yhat\": 7.384559231465399, \"yhat_lower\": 6.921582561403233, \"yhat_upper\": 7.835047105970848, \"fact\": 6.964204225280627, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:11:00\", \"yhat\": 7.384969201976114, \"yhat_lower\": 6.887588201034092, \"yhat_upper\": 7.823147099420789, \"fact\": 6.8317439585381985, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:12:00\", \"yhat\": 7.385379172486829, \"yhat_lower\": 6.921078090322933, \"yhat_upper\": 7.868204744816045, \"fact\": 6.846925861641189, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:13:00\", \"yhat\": 7.385789142997543, \"yhat_lower\": 6.976642646636571, \"yhat_upper\": 7.8265610129005365, \"fact\": 6.8792347865250285, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:14:00\", \"yhat\": 7.386199113508257, \"yhat_lower\": 6.930498371046004, \"yhat_upper\": 7.834882004509557, \"fact\": 6.918101973663316, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:15:00\", \"yhat\": 7.31082151255353, \"yhat_lower\": 6.882892035858407, \"yhat_upper\": 7.719327953161628, \"fact\": 6.946297846175937, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:16:00\", \"yhat\": 7.310410960703394, \"yhat_lower\": 6.882823137005205, \"yhat_upper\": 7.760499914033369, \"fact\": 6.91741109605579, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:17:00\", \"yhat\": 7.310000408853259, \"yhat_lower\": 6.853268291454035, \"yhat_upper\": 7.773576676566642, \"fact\": 6.792759709575465, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:18:00\", \"yhat\": 7.309589857003124, \"yhat_lower\": 6.881540187568575, \"yhat_upper\": 7.7658349968381675, \"fact\": 6.781526290147463, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:19:00\", \"yhat\": 7.309179305152988, \"yhat_lower\": 6.864750482532545, \"yhat_upper\": 7.723343422628803, \"fact\": 6.527562112720121, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:20:00\", \"yhat\": 7.209955926600148, \"yhat_lower\": 6.773259942117443, \"yhat_upper\": 7.658228006054622, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:21:00\", \"yhat\": 7.208157059778378, \"yhat_lower\": 6.772249277709288, \"yhat_upper\": 7.6153295236104475, \"fact\": 6.342845929573227, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:22:00\", \"yhat\": 7.206358192956609, \"yhat_lower\": 6.74672273570825, \"yhat_upper\": 7.655409083526367, \"fact\": 6.295282891714099, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:23:00\", \"yhat\": 7.204559326134838, \"yhat_lower\": 6.725149994064496, \"yhat_upper\": 7.636262907008109, \"fact\": 6.416976346172642, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:24:00\", \"yhat\": 7.202760459313068, \"yhat_lower\": 6.767415981346756, \"yhat_upper\": 7.632301619229257, \"fact\": 6.474370432036268, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:25:00\", \"yhat\": 7.0818507632437955, \"yhat_lower\": 6.586969941106555, \"yhat_upper\": 7.539378057565671, \"fact\": 6.601555135123274, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:26:00\", \"yhat\": 7.078438936831481, \"yhat_lower\": 6.602551286692136, \"yhat_upper\": 7.658625911752115, \"fact\": 6.565698424868521, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:27:00\", \"yhat\": 7.075027110419166, \"yhat_lower\": 6.62205831349603, \"yhat_upper\": 7.524160609177972, \"fact\": 6.58040116897878, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:28:00\", \"yhat\": 7.0716152840068505, \"yhat_lower\": 6.610655996486932, \"yhat_upper\": 7.5800510269113985, \"fact\": 6.482049789735297, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:29:00\", \"yhat\": 7.068203457594537, \"yhat_lower\": 6.52604184411481, \"yhat_upper\": 7.542549542272263, \"fact\": 6.390248110625829, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:30:00\", \"yhat\": 6.955693739121696, \"yhat_lower\": 6.464919645821934, \"yhat_upper\": 7.426739375059167, \"fact\": 6.32894900581122, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:31:00\", \"yhat\": 6.95072437919594, \"yhat_lower\": 6.420679816492657, \"yhat_upper\": 7.475264250259787, \"fact\": 6.342132763662364, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:32:00\", \"yhat\": 6.945755019270181, \"yhat_lower\": 6.471973054849666, \"yhat_upper\": 7.481771954926537, \"fact\": 6.431054046458639, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:33:00\", \"yhat\": 6.940785659344423, \"yhat_lower\": 6.413067702863305, \"yhat_upper\": 7.448188573730318, \"fact\": 6.373515189094005, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:34:00\", \"yhat\": 6.935816299418664, \"yhat_lower\": 6.431211144255794, \"yhat_upper\": 7.43040174764512, \"fact\": 6.205522054823765, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:35:00\", \"yhat\": 6.820630427058223, \"yhat_lower\": 6.286918104697763, \"yhat_upper\": 7.304713153738256, \"fact\": 6.316785939738493, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:36:00\", \"yhat\": 6.8141854342975465, \"yhat_lower\": 6.279726076172435, \"yhat_upper\": 7.318938960150304, \"fact\": 6.333618541503614, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:37:00\", \"yhat\": 6.80774044153687, \"yhat_lower\": 6.278525264514712, \"yhat_upper\": 7.33825809898715, \"fact\": 6.445636379481378, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:38:00\", \"yhat\": 6.801295448776192, \"yhat_lower\": 6.246680463877369, \"yhat_upper\": 7.3436417911322085, \"fact\": 6.591432527622528, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:39:00\", \"yhat\": 6.794850456015515, \"yhat_lower\": 6.273431489127351, \"yhat_upper\": 7.329139319034951, \"fact\": 6.518538014853173, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:40:00\", \"yhat\": 6.703321587709314, \"yhat_lower\": 6.198076583978248, \"yhat_upper\": 7.219484924135224, \"fact\": 6.403509692296891, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:41:00\", \"yhat\": 6.695554640064032, \"yhat_lower\": 6.174981554704438, \"yhat_upper\": 7.2216759439524605, \"fact\": 6.514920639375976, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:42:00\", \"yhat\": 6.687787692418748, \"yhat_lower\": 6.164865868870506, \"yhat_upper\": 7.202758952931534, \"fact\": 6.698467040888667, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:43:00\", \"yhat\": 6.680020744773466, \"yhat_lower\": 6.150458044631832, \"yhat_upper\": 7.227004101352552, \"fact\": 6.759388401607078, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:44:00\", \"yhat\": 6.672253797128183, \"yhat_lower\": 6.106606127909563, \"yhat_upper\": 7.197042605748562, \"fact\": 6.716490662775344, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:45:00\", \"yhat\": 6.640656505917789, \"yhat_lower\": 6.125194782531541, \"yhat_upper\": 7.173231099773454, \"fact\": 6.5987942999302085, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:46:00\", \"yhat\": 6.632412254890261, \"yhat_lower\": 6.0898884302810705, \"yhat_upper\": 7.161030572102576, \"fact\": 6.65333830003684, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:47:00\", \"yhat\": 6.624168003862734, \"yhat_lower\": 6.129719830185664, \"yhat_upper\": 7.103622139161152, \"fact\": 6.556226307271936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:48:00\", \"yhat\": 6.615923752835207, \"yhat_lower\": 6.133898518627714, \"yhat_upper\": 7.158915231583242, \"fact\": 6.631915596619567, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:49:00\", \"yhat\": 6.60767950180768, \"yhat_lower\": 6.072018223947385, \"yhat_upper\": 7.184087843942095, \"fact\": 6.7418854984709515, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:50:00\", \"yhat\": 6.575359461758412, \"yhat_lower\": 6.031966694351483, \"yhat_upper\": 7.103778548853814, \"fact\": 6.90468821514332, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:51:00\", \"yhat\": 6.566514584248613, \"yhat_lower\": 6.080139751324108, \"yhat_upper\": 7.112692416571872, \"fact\": 6.92379664141639, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:52:00\", \"yhat\": 6.557669706738816, \"yhat_lower\": 6.000954533528328, \"yhat_upper\": 7.102386177413333, \"fact\": 6.946555214531447, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:53:00\", \"yhat\": 6.5488248292290185, \"yhat_lower\": 6.077439580851295, \"yhat_upper\": 7.06502374383959, \"fact\": 6.930459476706841, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:54:00\", \"yhat\": 6.5399799517192205, \"yhat_lower\": 6.048579881496584, \"yhat_upper\": 7.039604331790496, \"fact\": 7.022422718896414, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:55:00\", \"yhat\": 6.579385160727626, \"yhat_lower\": 6.035702068880664, \"yhat_upper\": 7.084989696239746, \"fact\": 7.053346772430454, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:56:00\", \"yhat\": 6.570941728557626, \"yhat_lower\": 6.011040130865521, \"yhat_upper\": 7.088828858973016, \"fact\": 7.097472113550277, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:57:00\", \"yhat\": 6.562498296387626, \"yhat_lower\": 6.044144440236699, \"yhat_upper\": 7.09848640932999, \"fact\": 7.192623177672057, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:58:00\", \"yhat\": 6.554054864217625, \"yhat_lower\": 6.047161465020219, \"yhat_upper\": 7.051623202555208, \"fact\": 7.258527915260533, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:59:00\", \"yhat\": 6.545611432047625, \"yhat_lower\": 6.053415375738495, \"yhat_upper\": 7.080182792218997, \"fact\": 7.282872270839376, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:00:00\", \"yhat\": 6.6280245410127945, \"yhat_lower\": 6.086884179983976, \"yhat_upper\": 7.249727717067758, \"fact\": 7.242022079132392, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:01:00\", \"yhat\": 6.620519091270794, \"yhat_lower\": 6.114832561470911, \"yhat_upper\": 7.1861612186874, \"fact\": 7.261334072336341, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:02:00\", \"yhat\": 6.613013641528794, \"yhat_lower\": 6.081248803795237, \"yhat_upper\": 7.138236163482431, \"fact\": 7.264136729062933, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:03:00\", \"yhat\": 6.605508191786794, \"yhat_lower\": 5.99314182658148, \"yhat_upper\": 7.135596027109164, \"fact\": 7.286273159581655, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:04:00\", \"yhat\": 6.598002742044794, \"yhat_lower\": 6.03325596921655, \"yhat_upper\": 7.178870889543485, \"fact\": 7.357895750482174, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:05:00\", \"yhat\": 6.693912584577759, \"yhat_lower\": 6.11676796451608, \"yhat_upper\": 7.287618523634463, \"fact\": 7.330285522164443, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:06:00\", \"yhat\": 6.687626546711165, \"yhat_lower\": 6.0932735712789885, \"yhat_upper\": 7.2569077094979235, \"fact\": 7.421393852719808, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:07:00\", \"yhat\": 6.681340508844571, \"yhat_lower\": 6.0700848770731115, \"yhat_upper\": 7.262329427769223, \"fact\": 7.5620596009564744, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:08:00\", \"yhat\": 6.675054470977977, \"yhat_lower\": 6.017319891450547, \"yhat_upper\": 7.264344563435307, \"fact\": 7.565735575531843, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:09:00\", \"yhat\": 6.668768433111383, \"yhat_lower\": 6.126128104185291, \"yhat_upper\": 7.2765566661024, \"fact\": 7.58361194350413, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:10:00\", \"yhat\": 6.790741268136085, \"yhat_lower\": 6.146096950777551, \"yhat_upper\": 7.363155640957044, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:11:00\", \"yhat\": 6.785905612619279, \"yhat_lower\": 6.129696847984307, \"yhat_upper\": 7.39782069029602, \"fact\": 7.610778235091248, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:12:00\", \"yhat\": 6.781069957102472, \"yhat_lower\": 6.13836945520072, \"yhat_upper\": 7.418970421260921, \"fact\": 7.521885308219655, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:13:00\", \"yhat\": 6.776234301585666, \"yhat_lower\": 6.200831660603755, \"yhat_upper\": 7.396832435815853, \"fact\": 7.716909631502675, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:14:00\", \"yhat\": 6.77139864606886, \"yhat_lower\": 6.149146992739965, \"yhat_upper\": 7.449934293993054, \"fact\": 7.747519051979066, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:15:00\", \"yhat\": 6.880367151078534, \"yhat_lower\": 6.254174056573473, \"yhat_upper\": 7.472648092124163, \"fact\": 7.785511706436309, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:16:00\", \"yhat\": 6.876878790714677, \"yhat_lower\": 6.225134253127474, \"yhat_upper\": 7.509176537642664, \"fact\": 7.930365226719392, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:17:00\", \"yhat\": 6.873390430350821, \"yhat_lower\": 6.178417285664864, \"yhat_upper\": 7.557568270149349, \"fact\": 7.967473463214496, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:18:00\", \"yhat\": 6.869902069986965, \"yhat_lower\": 6.217304042785024, \"yhat_upper\": 7.546628875382699, \"fact\": 7.999580916809377, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:19:00\", \"yhat\": 6.866413709623108, \"yhat_lower\": 6.186338830996752, \"yhat_upper\": 7.588657362282398, \"fact\": 7.92745812562292, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:20:00\", \"yhat\": 7.00302652264842, \"yhat_lower\": 6.298998606784435, \"yhat_upper\": 7.661574461783752, \"fact\": 8.055342945626094, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:21:00\", \"yhat\": 7.000874251638397, \"yhat_lower\": 6.264926274018221, \"yhat_upper\": 7.680171650560609, \"fact\": 8.069067375478213, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:22:00\", \"yhat\": 6.998721980628374, \"yhat_lower\": 6.253143768910448, \"yhat_upper\": 7.7085189372527765, \"fact\": 8.155734179368574, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:23:00\", \"yhat\": 6.996569709618351, \"yhat_lower\": 6.330389016301272, \"yhat_upper\": 7.704162497349425, \"fact\": 8.011806921777461, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:24:00\", \"yhat\": 6.994417438608328, \"yhat_lower\": 6.311948624162204, \"yhat_upper\": 7.687352137584781, \"fact\": 8.092111510811511, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:25:00\", \"yhat\": 7.131029050513527, \"yhat_lower\": 6.384100621637634, \"yhat_upper\": 7.894534479397975, \"fact\": 8.220078277501383, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:26:00\", \"yhat\": 7.130278443943234, \"yhat_lower\": 6.378717707515412, \"yhat_upper\": 7.9352598995014025, \"fact\": 8.267900885640357, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:27:00\", \"yhat\": 7.1295278373729385, \"yhat_lower\": 6.326141696513547, \"yhat_upper\": 7.826462236198117, \"fact\": 8.340179387722713, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:28:00\", \"yhat\": 7.128777230802644, \"yhat_lower\": 6.382021536165217, \"yhat_upper\": 7.94305033486737, \"fact\": 8.360308596655782, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:29:00\", \"yhat\": 7.12802662423235, \"yhat_lower\": 6.39378107218271, \"yhat_upper\": 7.814559385200954, \"fact\": 8.356915788188523, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:30:00\", \"yhat\": 7.3035367384566054, \"yhat_lower\": 6.514677633155262, \"yhat_upper\": 8.103345597144344, \"fact\": 8.288188793887379, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:31:00\", \"yhat\": 7.30473289081005, \"yhat_lower\": 6.506649251007318, \"yhat_upper\": 8.089088751985285, \"fact\": 8.371033308450802, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:32:00\", \"yhat\": 7.305929043163493, \"yhat_lower\": 6.504231989126135, \"yhat_upper\": 8.11960879816224, \"fact\": 8.296495018073724, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:33:00\", \"yhat\": 7.307125195516936, \"yhat_lower\": 6.466493859341004, \"yhat_upper\": 8.15868603505896, \"fact\": 8.267777641850003, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:34:00\", \"yhat\": 7.308321347870381, \"yhat_lower\": 6.550370623563716, \"yhat_upper\": 8.130118489074738, \"fact\": 8.144346886350423, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:35:00\", \"yhat\": 7.488526194898056, \"yhat_lower\": 6.595976213857549, \"yhat_upper\": 8.32622328628154, \"fact\": 8.061674389304113, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:36:00\", \"yhat\": 7.491977698020609, \"yhat_lower\": 6.664590105250331, \"yhat_upper\": 8.241681004613039, \"fact\": 8.101904105964518, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:37:00\", \"yhat\": 7.495429201143162, \"yhat_lower\": 6.784759326529417, \"yhat_upper\": 8.30547230060603, \"fact\": 8.049382116624201, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:38:00\", \"yhat\": 7.498880704265716, \"yhat_lower\": 6.738021391673902, \"yhat_upper\": 8.303074710623097, \"fact\": 7.9510567258113305, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:39:00\", \"yhat\": 7.502332207388268, \"yhat_lower\": 6.7111888204192995, \"yhat_upper\": 8.341201162403278, \"fact\": 7.962974507940454, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:40:00\", \"yhat\": 7.606359694173765, \"yhat_lower\": 6.814868476302952, \"yhat_upper\": 8.449338222767048, \"fact\": 7.805239859715092, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:41:00\", \"yhat\": 7.611140302486328, \"yhat_lower\": 6.757599190497899, \"yhat_upper\": 8.377479922025593, \"fact\": 7.663667118812604, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:42:00\", \"yhat\": 7.6159209107988906, \"yhat_lower\": 6.826712891121579, \"yhat_upper\": 8.420709112125982, \"fact\": 7.514024098971325, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:43:00\", \"yhat\": 7.620701519111454, \"yhat_lower\": 6.848367427056519, \"yhat_upper\": 8.404792570703705, \"fact\": 7.471366107835003, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:44:00\", \"yhat\": 7.625482127424015, \"yhat_lower\": 6.769064140191452, \"yhat_upper\": 8.417058933698806, \"fact\": 7.445667100893326, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:45:00\", \"yhat\": 7.642284363266123, \"yhat_lower\": 6.868683141611956, \"yhat_upper\": 8.438119269749595, \"fact\": 7.456711779886499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:46:00\", \"yhat\": 7.647373730394403, \"yhat_lower\": 6.771390280838565, \"yhat_upper\": 8.454693285043472, \"fact\": 7.444329373125276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:47:00\", \"yhat\": 7.652463097522682, \"yhat_lower\": 6.909568455005002, \"yhat_upper\": 8.413257051546784, \"fact\": 7.468336779368962, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:48:00\", \"yhat\": 7.657552464650962, \"yhat_lower\": 6.929030452140603, \"yhat_upper\": 8.467355793125341, \"fact\": 7.585589594686708, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:49:00\", \"yhat\": 7.662641831779242, \"yhat_lower\": 6.805864187224094, \"yhat_upper\": 8.389719278647553, \"fact\": 7.750432747546225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:50:00\", \"yhat\": 7.681503916041949, \"yhat_lower\": 6.9506397818446874, \"yhat_upper\": 8.446770190679901, \"fact\": 7.789461459883152, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:51:00\", \"yhat\": 7.687022775642858, \"yhat_lower\": 6.893396727540202, \"yhat_upper\": 8.520874783737518, \"fact\": 7.849428734659802, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:52:00\", \"yhat\": 7.692541635243767, \"yhat_lower\": 6.928646381838062, \"yhat_upper\": 8.628719618631699, \"fact\": 7.945508717131604, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:53:00\", \"yhat\": 7.698060494844677, \"yhat_lower\": 6.966278463815956, \"yhat_upper\": 8.48535990492036, \"fact\": 7.897018421083583, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:54:00\", \"yhat\": 7.703579354445585, \"yhat_lower\": 6.9451718556508695, \"yhat_upper\": 8.617846772514886, \"fact\": 7.790206365474418, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:55:00\", \"yhat\": 7.770283354662266, \"yhat_lower\": 6.996584707831656, \"yhat_upper\": 8.543778732803709, \"fact\": 7.839967858463782, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:56:00\", \"yhat\": 7.77682615858756, \"yhat_lower\": 7.0297691919599075, \"yhat_upper\": 8.6105727258018, \"fact\": 7.8667860803525524, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:57:00\", \"yhat\": 7.783368962512854, \"yhat_lower\": 7.0390396764288825, \"yhat_upper\": 8.553812305715404, \"fact\": 7.7525973626559095, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:58:00\", \"yhat\": 7.78991176643815, \"yhat_lower\": 6.898524344464084, \"yhat_upper\": 8.533215589972233, \"fact\": 7.70504444156228, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:59:00\", \"yhat\": 7.796454570363444, \"yhat_lower\": 7.012342452403471, \"yhat_upper\": 8.518568535800881, \"fact\": 7.801695429233526, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:00:00\", \"yhat\": 7.849359565045376, \"yhat_lower\": 7.07010191578612, \"yhat_upper\": 8.604125598579063, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:01:00\", \"yhat\": 7.856829665276606, \"yhat_lower\": 7.073616922726095, \"yhat_upper\": 8.559033053916947, \"fact\": 7.652667153528996, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:02:00\", \"yhat\": 7.864299765507836, \"yhat_lower\": 7.131669847153401, \"yhat_upper\": 8.666285596819337, \"fact\": 7.578881723592664, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:03:00\", \"yhat\": 7.871769865739065, \"yhat_lower\": 7.026758222839665, \"yhat_upper\": 8.673018177692262, \"fact\": 7.491151863279462, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:04:00\", \"yhat\": 7.879239965970295, \"yhat_lower\": 7.112497562378592, \"yhat_upper\": 8.610124023442737, \"fact\": 7.503454922925876, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:05:00\", \"yhat\": 7.900253693535451, \"yhat_lower\": 7.153318526096101, \"yhat_upper\": 8.652979577398776, \"fact\": 7.599057949270826, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:06:00\", \"yhat\": 7.908376108245216, \"yhat_lower\": 7.177492928749188, \"yhat_upper\": 8.616224433059848, \"fact\": 7.540289550698573, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:07:00\", \"yhat\": 7.9164985229549805, \"yhat_lower\": 7.229538160382668, \"yhat_upper\": 8.645806353387705, \"fact\": 7.709498641608279, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:08:00\", \"yhat\": 7.924620937664746, \"yhat_lower\": 7.18821339493867, \"yhat_upper\": 8.782594930950756, \"fact\": 7.830648777977522, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:09:00\", \"yhat\": 7.932743352374511, \"yhat_lower\": 7.2192578139760535, \"yhat_upper\": 8.611165798160652, \"fact\": 7.833850854121761, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:10:00\", \"yhat\": 7.974252308201126, \"yhat_lower\": 7.271431325029862, \"yhat_upper\": 8.618371414905324, \"fact\": 7.896527014556835, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:11:00\", \"yhat\": 7.983423489595227, \"yhat_lower\": 7.3289647754090295, \"yhat_upper\": 8.645692612561763, \"fact\": 7.740317372019487, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:12:00\", \"yhat\": 7.992594670989327, \"yhat_lower\": 7.217267599062837, \"yhat_upper\": 8.670639812678035, \"fact\": 7.734078442460585, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:13:00\", \"yhat\": 8.001765852383429, \"yhat_lower\": 7.3300449032257164, \"yhat_upper\": 8.75019578286352, \"fact\": 7.68652453910119, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:14:00\", \"yhat\": 8.010937033777529, \"yhat_lower\": 7.243211581791006, \"yhat_upper\": 8.71053540782704, \"fact\": 7.654062933595664, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:15:00\", \"yhat\": 8.054470219185577, \"yhat_lower\": 7.387673969233567, \"yhat_upper\": 8.749217529597006, \"fact\": 7.7323556114676295, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:16:00\", \"yhat\": 8.064785944793194, \"yhat_lower\": 7.415161049974847, \"yhat_upper\": 8.781149638920043, \"fact\": 7.823575479244249, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:17:00\", \"yhat\": 8.07510167040081, \"yhat_lower\": 7.398285067478444, \"yhat_upper\": 8.736279104589153, \"fact\": 7.961063693882232, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:18:00\", \"yhat\": 8.085417396008427, \"yhat_lower\": 7.409974582816505, \"yhat_upper\": 8.791210627628516, \"fact\": 7.66166136402624, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:19:00\", \"yhat\": 8.095733121616044, \"yhat_lower\": 7.443614120387227, \"yhat_upper\": 8.742545792332646, \"fact\": 7.735994319948233, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:20:00\", \"yhat\": 8.11398443503897, \"yhat_lower\": 7.425939772439533, \"yhat_upper\": 8.771197031945823, \"fact\": 7.8172661459687465, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:21:00\", \"yhat\": 8.124909635186974, \"yhat_lower\": 7.450430195728931, \"yhat_upper\": 8.78114762337998, \"fact\": 7.800477360464126, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:22:00\", \"yhat\": 8.135834835334977, \"yhat_lower\": 7.459728323971178, \"yhat_upper\": 8.729786675569487, \"fact\": 7.726932237108902, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:23:00\", \"yhat\": 8.14676003548298, \"yhat_lower\": 7.536593540891993, \"yhat_upper\": 8.757852265515396, \"fact\": 7.811868370741103, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:24:00\", \"yhat\": 8.157685235630986, \"yhat_lower\": 7.53599988854388, \"yhat_upper\": 8.856816051600555, \"fact\": 7.658004719265347, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:25:00\", \"yhat\": 8.149214486375671, \"yhat_lower\": 7.454540292402565, \"yhat_upper\": 8.851174359132328, \"fact\": 7.670100990217529, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:26:00\", \"yhat\": 8.160389804486723, \"yhat_lower\": 7.5001439930559, \"yhat_upper\": 8.853153152413451, \"fact\": 7.45312553026062, \"anomaly\": 1}, {\"ds\": \"2021-08-23T10:27:00\", \"yhat\": 8.171565122597775, \"yhat_lower\": 7.49148288853724, \"yhat_upper\": 8.788524120142503, \"fact\": 7.57061971942359, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:28:00\", \"yhat\": 8.182740440708827, \"yhat_lower\": 7.531858261588673, \"yhat_upper\": 8.777110543030547, \"fact\": 7.584558764339831, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:29:00\", \"yhat\": 8.193915758819879, \"yhat_lower\": 7.499310148227958, \"yhat_upper\": 8.87403778991883, \"fact\": 7.736367838262079, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:30:00\", \"yhat\": 8.134765242169019, \"yhat_lower\": 7.39549864768621, \"yhat_upper\": 8.905010580648085, \"fact\": 7.883967912330481, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:31:00\", \"yhat\": 8.145315217782915, \"yhat_lower\": 7.49195490476029, \"yhat_upper\": 8.79980643324498, \"fact\": 7.9454144774542215, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:32:00\", \"yhat\": 8.15586519339681, \"yhat_lower\": 7.496856180708227, \"yhat_upper\": 8.84246539508402, \"fact\": 7.9815247789264765, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:33:00\", \"yhat\": 8.166415169010705, \"yhat_lower\": 7.423211678065259, \"yhat_upper\": 8.865181559186478, \"fact\": 7.828608211241088, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:34:00\", \"yhat\": 8.1769651446246, \"yhat_lower\": 7.52495576252046, \"yhat_upper\": 8.846908591083668, \"fact\": 7.8866167493939185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:35:00\", \"yhat\": 8.160356016229104, \"yhat_lower\": 7.536189572107841, \"yhat_upper\": 8.838538931955274, \"fact\": 7.718286285065371, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:36:00\", \"yhat\": 8.170776470086302, \"yhat_lower\": 7.496405256003328, \"yhat_upper\": 8.792362920495105, \"fact\": 7.764341416031271, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:37:00\", \"yhat\": 8.1811969239435, \"yhat_lower\": 7.521649489728066, \"yhat_upper\": 8.826824478597421, \"fact\": 7.840706888425015, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:38:00\", \"yhat\": 8.1916173778007, \"yhat_lower\": 7.525622360130334, \"yhat_upper\": 8.890705157372269, \"fact\": 7.938059917879748, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:39:00\", \"yhat\": 8.202037831657899, \"yhat_lower\": 7.450997859522796, \"yhat_upper\": 8.880230171630274, \"fact\": 7.761060058402809, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:40:00\", \"yhat\": 8.131375673314423, \"yhat_lower\": 7.399658595300479, \"yhat_upper\": 8.711637210118798, \"fact\": 7.6946908748491, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:41:00\", \"yhat\": 8.140630056180584, \"yhat_lower\": 7.430732257069129, \"yhat_upper\": 8.78054463421481, \"fact\": 7.672013085482828, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:42:00\", \"yhat\": 8.149884439046746, \"yhat_lower\": 7.425771286643738, \"yhat_upper\": 8.839172217041485, \"fact\": 7.749640954645437, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:43:00\", \"yhat\": 8.159138821912904, \"yhat_lower\": 7.422552852954745, \"yhat_upper\": 8.874007122819835, \"fact\": 7.74351636626246, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:44:00\", \"yhat\": 8.168393204779067, \"yhat_lower\": 7.483087465184355, \"yhat_upper\": 8.913781171382476, \"fact\": 7.758280802421245, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:45:00\", \"yhat\": 8.132314728122346, \"yhat_lower\": 7.461536187292699, \"yhat_upper\": 8.786858708406028, \"fact\": 7.9905599789244945, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:46:00\", \"yhat\": 8.141169029433875, \"yhat_lower\": 7.4027664394050605, \"yhat_upper\": 8.843755486751986, \"fact\": 7.870475361188625, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:47:00\", \"yhat\": 8.150023330745405, \"yhat_lower\": 7.44998449268539, \"yhat_upper\": 8.863428392250901, \"fact\": 7.972400000133551, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:48:00\", \"yhat\": 8.158877632056937, \"yhat_lower\": 7.480179201071224, \"yhat_upper\": 8.8971869956534, \"fact\": 8.089531300610558, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:49:00\", \"yhat\": 8.167731933368467, \"yhat_lower\": 7.566952391638025, \"yhat_upper\": 8.847792289830496, \"fact\": 8.097777022768552, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:50:00\", \"yhat\": 8.134561550956514, \"yhat_lower\": 7.414495755178077, \"yhat_upper\": 8.826130914300759, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:51:00\", \"yhat\": 8.142736710941994, \"yhat_lower\": 7.497427565586647, \"yhat_upper\": 8.76426323404485, \"fact\": 8.031589183895466, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:52:00\", \"yhat\": 8.150911870927473, \"yhat_lower\": 7.514682655678994, \"yhat_upper\": 8.751494145159274, \"fact\": 8.148437931838542, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:53:00\", \"yhat\": 8.159087030912955, \"yhat_lower\": 7.49617256580275, \"yhat_upper\": 8.800459756472542, \"fact\": 8.221370040659716, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:54:00\", \"yhat\": 8.167262190898434, \"yhat_lower\": 7.542059195600432, \"yhat_upper\": 8.823640894933767, \"fact\": 8.333189126475943, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:55:00\", \"yhat\": 8.097944129947894, \"yhat_lower\": 7.508250323446438, \"yhat_upper\": 8.680823531259493, \"fact\": 8.511437080644786, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:56:00\", \"yhat\": 8.104408018773995, \"yhat_lower\": 7.492006028552958, \"yhat_upper\": 8.690828927112607, \"fact\": 8.530259401373554, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:57:00\", \"yhat\": 8.110871907600096, \"yhat_lower\": 7.595530295736425, \"yhat_upper\": 8.688067618200408, \"fact\": 8.464149676702108, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:58:00\", \"yhat\": 8.117335796426199, \"yhat_lower\": 7.428166836422251, \"yhat_upper\": 8.73918842052874, \"fact\": 8.510761154617697, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:59:00\", \"yhat\": 8.123799685252301, \"yhat_lower\": 7.531075742388231, \"yhat_upper\": 8.720762043971591, \"fact\": 8.588384748465963, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:00:00\", \"yhat\": 8.133585901727772, \"yhat_lower\": 7.563042632696578, \"yhat_upper\": 8.755480744341806, \"fact\": 8.596579830973859, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:01:00\", \"yhat\": 8.139469584225735, \"yhat_lower\": 7.5400538246949855, \"yhat_upper\": 8.677866741218198, \"fact\": 8.665254766764672, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:02:00\", \"yhat\": 8.145353266723694, \"yhat_lower\": 7.55791473444561, \"yhat_upper\": 8.678410340733047, \"fact\": 8.571601855976125, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:03:00\", \"yhat\": 8.151236949221657, \"yhat_lower\": 7.5826200725492425, \"yhat_upper\": 8.747602222601632, \"fact\": 8.483149022444422, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:04:00\", \"yhat\": 8.157120631719618, \"yhat_lower\": 7.599821785863784, \"yhat_upper\": 8.804801363213532, \"fact\": 8.392816789809771, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:05:00\", \"yhat\": 8.160289595193463, \"yhat_lower\": 7.579850467588524, \"yhat_upper\": 8.706212189756224, \"fact\": 8.289463311811762, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:06:00\", \"yhat\": 8.165473828902961, \"yhat_lower\": 7.6351230620991535, \"yhat_upper\": 8.729629541969175, \"fact\": 8.293193709584163, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:07:00\", \"yhat\": 8.170658062612459, \"yhat_lower\": 7.61604478369048, \"yhat_upper\": 8.674720087705657, \"fact\": 8.201046712843748, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:08:00\", \"yhat\": 8.175842296321955, \"yhat_lower\": 7.647150784052874, \"yhat_upper\": 8.7872947342085, \"fact\": 8.074013353443654, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:09:00\", \"yhat\": 8.181026530031453, \"yhat_lower\": 7.602616572897667, \"yhat_upper\": 8.730477285761019, \"fact\": 8.060346196714583, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:10:00\", \"yhat\": 8.14830414661521, \"yhat_lower\": 7.6591924753978615, \"yhat_upper\": 8.687284771123052, \"fact\": 8.129960019946706, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:11:00\", \"yhat\": 8.152631665788636, \"yhat_lower\": 7.638307640481854, \"yhat_upper\": 8.650670119210263, \"fact\": 8.093286965059585, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:12:00\", \"yhat\": 8.15695918496206, \"yhat_lower\": 7.686793752769861, \"yhat_upper\": 8.67247696473879, \"fact\": 8.207114051737939, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:13:00\", \"yhat\": 8.161286704135485, \"yhat_lower\": 7.622131017701486, \"yhat_upper\": 8.69671667121086, \"fact\": 8.174797102772132, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:14:00\", \"yhat\": 8.16561422330891, \"yhat_lower\": 7.660845158328703, \"yhat_upper\": 8.677139933704598, \"fact\": 8.244861920292358, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:15:00\", \"yhat\": 8.12708505924496, \"yhat_lower\": 7.613937239720642, \"yhat_upper\": 8.628528451120031, \"fact\": 8.004603702913197, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:16:00\", \"yhat\": 8.130436335302296, \"yhat_lower\": 7.608373517286534, \"yhat_upper\": 8.647424135090764, \"fact\": 7.962191492988927, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:17:00\", \"yhat\": 8.133787611359628, \"yhat_lower\": 7.624585225359804, \"yhat_upper\": 8.666726738216402, \"fact\": 7.82693977677464, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:18:00\", \"yhat\": 8.137138887416961, \"yhat_lower\": 7.649247932104725, \"yhat_upper\": 8.626817932440037, \"fact\": 7.780715623518733, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:19:00\", \"yhat\": 8.140490163474297, \"yhat_lower\": 7.545942795944195, \"yhat_upper\": 8.700218019689721, \"fact\": 7.602800054795464, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:20:00\", \"yhat\": 8.081775127921114, \"yhat_lower\": 7.5125266424364625, \"yhat_upper\": 8.654067104306245, \"fact\": 7.7126592728826395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:21:00\", \"yhat\": 8.084215322045326, \"yhat_lower\": 7.49706602582348, \"yhat_upper\": 8.686308636863838, \"fact\": 7.7702415551012605, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:22:00\", \"yhat\": 8.086655516169538, \"yhat_lower\": 7.566245452166532, \"yhat_upper\": 8.643439624752194, \"fact\": 7.755515291272416, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:23:00\", \"yhat\": 8.08909571029375, \"yhat_lower\": 7.54844521685709, \"yhat_upper\": 8.667725044084683, \"fact\": 7.893932649872157, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:24:00\", \"yhat\": 8.09153590441796, \"yhat_lower\": 7.560205639028493, \"yhat_upper\": 8.723729203497019, \"fact\": 7.9497835809896715, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:25:00\", \"yhat\": 8.03578987861857, \"yhat_lower\": 7.485484492606574, \"yhat_upper\": 8.603409563321398, \"fact\": 7.8758994800134285, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:26:00\", \"yhat\": 8.037350415545445, \"yhat_lower\": 7.471371615778372, \"yhat_upper\": 8.619023795901118, \"fact\": 7.882184263103129, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:27:00\", \"yhat\": 8.038910952472321, \"yhat_lower\": 7.421093171970151, \"yhat_upper\": 8.630328511084457, \"fact\": 8.064546783500113, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:28:00\", \"yhat\": 8.040471489399197, \"yhat_lower\": 7.4685517242061685, \"yhat_upper\": 8.605886091042317, \"fact\": 8.081645734366429, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:29:00\", \"yhat\": 8.042032026326071, \"yhat_lower\": 7.467101841058164, \"yhat_upper\": 8.55846362032243, \"fact\": 8.172757664947504, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:30:00\", \"yhat\": 8.038915773931583, \"yhat_lower\": 7.5118248841892505, \"yhat_upper\": 8.555224494726092, \"fact\": 8.098672806113793, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:31:00\", \"yhat\": 8.04036816917015, \"yhat_lower\": 7.434550553065895, \"yhat_upper\": 8.627510596932979, \"fact\": 8.151170322208227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:32:00\", \"yhat\": 8.041820564408718, \"yhat_lower\": 7.471590464514436, \"yhat_upper\": 8.544696463169592, \"fact\": 8.26088485879859, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:33:00\", \"yhat\": 8.043272959647284, \"yhat_lower\": 7.517341586623978, \"yhat_upper\": 8.5277277788031, \"fact\": 8.191009434921096, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:34:00\", \"yhat\": 8.04472535488585, \"yhat_lower\": 7.522758681102579, \"yhat_upper\": 8.573005719358097, \"fact\": 8.194555208030412, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:35:00\", \"yhat\": 8.095453638586871, \"yhat_lower\": 7.631393825081887, \"yhat_upper\": 8.595305871835855, \"fact\": 8.360453709951065, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:36:00\", \"yhat\": 8.09779357655895, \"yhat_lower\": 7.603983304542168, \"yhat_upper\": 8.564382048052384, \"fact\": 8.396733578661529, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:37:00\", \"yhat\": 8.100133514531027, \"yhat_lower\": 7.619170608819328, \"yhat_upper\": 8.67269322106737, \"fact\": 8.457129588862593, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:38:00\", \"yhat\": 8.102473452503105, \"yhat_lower\": 7.628250485463379, \"yhat_upper\": 8.624473562212998, \"fact\": 8.320222281734633, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:39:00\", \"yhat\": 8.104813390475183, \"yhat_lower\": 7.5165112522085336, \"yhat_upper\": 8.67191506067973, \"fact\": 8.38706323868159, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:40:00\", \"yhat\": 8.138708984471398, \"yhat_lower\": 7.606683132442012, \"yhat_upper\": 8.668064285666501, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:41:00\", \"yhat\": 8.141313436701905, \"yhat_lower\": 7.554966116050032, \"yhat_upper\": 8.67707169517818, \"fact\": 8.47380305154199, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:42:00\", \"yhat\": 8.143917888932412, \"yhat_lower\": 7.60762958050602, \"yhat_upper\": 8.676701667765503, \"fact\": 8.471000521610067, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:43:00\", \"yhat\": 8.146522341162921, \"yhat_lower\": 7.624157608818841, \"yhat_upper\": 8.696567194225706, \"fact\": 8.583404963654896, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:44:00\", \"yhat\": 8.149126793393428, \"yhat_lower\": 7.612631973154556, \"yhat_upper\": 8.691001936317303, \"fact\": 8.531063469573645, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:45:00\", \"yhat\": 8.232743325271262, \"yhat_lower\": 7.739821245174568, \"yhat_upper\": 8.792403147254076, \"fact\": 8.471403101314356, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:46:00\", \"yhat\": 8.236640808991437, \"yhat_lower\": 7.72991788517532, \"yhat_upper\": 8.742667225710983, \"fact\": 8.409649600014262, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:47:00\", \"yhat\": 8.240538292711616, \"yhat_lower\": 7.713080483982559, \"yhat_upper\": 8.752602618155395, \"fact\": 8.370469524136148, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:48:00\", \"yhat\": 8.244435776431791, \"yhat_lower\": 7.79313940380584, \"yhat_upper\": 8.728645051014057, \"fact\": 8.48614212062726, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:49:00\", \"yhat\": 8.248333260151968, \"yhat_lower\": 7.738543111754841, \"yhat_upper\": 8.76583490404711, \"fact\": 8.64617716198996, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:50:00\", \"yhat\": 8.325987299580527, \"yhat_lower\": 7.850232279078016, \"yhat_upper\": 8.794480308507307, \"fact\": 8.53530065692971, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:51:00\", \"yhat\": 8.331100422276082, \"yhat_lower\": 7.863926927941895, \"yhat_upper\": 8.846568115390337, \"fact\": 8.526391763137674, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:52:00\", \"yhat\": 8.336213544971637, \"yhat_lower\": 7.858476418417006, \"yhat_upper\": 8.805025520863124, \"fact\": 8.4747311830338, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:53:00\", \"yhat\": 8.341326667667193, \"yhat_lower\": 7.866647049587784, \"yhat_upper\": 8.850348039039934, \"fact\": 8.369368219481078, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:54:00\", \"yhat\": 8.34643979036275, \"yhat_lower\": 7.866409510039767, \"yhat_upper\": 8.82999234486166, \"fact\": 8.560972818522371, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:55:00\", \"yhat\": 8.390013232829146, \"yhat_lower\": 7.916923859197314, \"yhat_upper\": 8.890098906955645, \"fact\": 8.506389603340054, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:56:00\", \"yhat\": 8.395739853747692, \"yhat_lower\": 7.908995906802384, \"yhat_upper\": 8.860361435137964, \"fact\": 8.481984739041978, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:57:00\", \"yhat\": 8.401466474666238, \"yhat_lower\": 7.930178817431853, \"yhat_upper\": 8.93123623643845, \"fact\": 8.485287372932227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:58:00\", \"yhat\": 8.407193095584784, \"yhat_lower\": 7.9015294693364035, \"yhat_upper\": 8.935866449173364, \"fact\": 8.509799875799924, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:59:00\", \"yhat\": 8.41291971650333, \"yhat_lower\": 7.924055571535567, \"yhat_upper\": 8.889439053962498, \"fact\": 8.462839177620474, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:00:00\", \"yhat\": 8.445016784635383, \"yhat_lower\": 7.956068182787008, \"yhat_upper\": 8.93887368876057, \"fact\": 8.500847291856171, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:01:00\", \"yhat\": 8.451137463425706, \"yhat_lower\": 7.967581805928251, \"yhat_upper\": 8.953152774529874, \"fact\": 8.407545286261158, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:02:00\", \"yhat\": 8.457258142216029, \"yhat_lower\": 7.939662247779632, \"yhat_upper\": 8.986134129739852, \"fact\": 8.435490902768226, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:03:00\", \"yhat\": 8.463378821006351, \"yhat_lower\": 7.995817429422728, \"yhat_upper\": 8.991600568470659, \"fact\": 8.405689339518776, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:04:00\", \"yhat\": 8.469499499796674, \"yhat_lower\": 7.992539100166318, \"yhat_upper\": 8.966341348511376, \"fact\": 8.404404408484888, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:05:00\", \"yhat\": 8.494821320583469, \"yhat_lower\": 8.035580795622442, \"yhat_upper\": 9.006849954024934, \"fact\": 8.370573940680746, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:06:00\", \"yhat\": 8.501463796857378, \"yhat_lower\": 8.04317730023773, \"yhat_upper\": 8.977219582643004, \"fact\": 8.356621268629302, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:07:00\", \"yhat\": 8.508106273131288, \"yhat_lower\": 8.0312420275935, \"yhat_upper\": 8.977112313134558, \"fact\": 8.273825661013671, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:08:00\", \"yhat\": 8.514748749405197, \"yhat_lower\": 8.023614077177553, \"yhat_upper\": 9.071364820054983, \"fact\": 8.417744225285109, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:09:00\", \"yhat\": 8.521391225679105, \"yhat_lower\": 8.062672751235787, \"yhat_upper\": 8.986128285815628, \"fact\": 8.333018409415137, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:10:00\", \"yhat\": 8.520555621895811, \"yhat_lower\": 8.067368468492937, \"yhat_upper\": 9.032708292194089, \"fact\": 8.395519857078213, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:11:00\", \"yhat\": 8.527294585657279, \"yhat_lower\": 8.042117386645275, \"yhat_upper\": 8.975635465046146, \"fact\": 8.329430969980034, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:12:00\", \"yhat\": 8.534033549418742, \"yhat_lower\": 8.060127894991927, \"yhat_upper\": 9.072814357644225, \"fact\": 8.393907016426743, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:13:00\", \"yhat\": 8.540772513180208, \"yhat_lower\": 8.118531603374121, \"yhat_upper\": 9.037852524831179, \"fact\": 8.505097929522941, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:14:00\", \"yhat\": 8.547511476941674, \"yhat_lower\": 8.055953001863148, \"yhat_upper\": 9.03154802025885, \"fact\": 8.511009348963547, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:15:00\", \"yhat\": 8.535599138765114, \"yhat_lower\": 8.023033130637184, \"yhat_upper\": 8.977949385246353, \"fact\": 8.485964064563397, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:16:00\", \"yhat\": 8.542113613749102, \"yhat_lower\": 7.997853199186469, \"yhat_upper\": 9.070618073663145, \"fact\": 8.532367389569465, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:17:00\", \"yhat\": 8.548628088733087, \"yhat_lower\": 8.071027565393134, \"yhat_upper\": 8.989129283180334, \"fact\": 8.527169421117446, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:18:00\", \"yhat\": 8.555142563717075, \"yhat_lower\": 8.116838851004845, \"yhat_upper\": 9.076563837913369, \"fact\": 8.770144851734896, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:19:00\", \"yhat\": 8.56165703870106, \"yhat_lower\": 8.026465376909691, \"yhat_upper\": 9.067789754553251, \"fact\": 8.941922134099055, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:20:00\", \"yhat\": 8.58611288620078, \"yhat_lower\": 8.01332242773823, \"yhat_upper\": 9.104349912831527, \"fact\": 8.83656128758854, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:21:00\", \"yhat\": 8.592862857465164, \"yhat_lower\": 8.074930330564122, \"yhat_upper\": 9.128910737071537, \"fact\": 8.75134541259338, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:22:00\", \"yhat\": 8.599612828729546, \"yhat_lower\": 8.05977095685166, \"yhat_upper\": 9.09991683223491, \"fact\": 8.663598406050742, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:23:00\", \"yhat\": 8.606362799993931, \"yhat_lower\": 8.063916143866841, \"yhat_upper\": 9.091641999934671, \"fact\": 8.672674873252237, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:24:00\", \"yhat\": 8.613112771258313, \"yhat_lower\": 8.093442741649492, \"yhat_upper\": 9.110980054604656, \"fact\": 8.52103640042284, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:25:00\", \"yhat\": 8.624828435848084, \"yhat_lower\": 8.16159363940454, \"yhat_upper\": 9.085186731780114, \"fact\": 8.52272103376713, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:26:00\", \"yhat\": 8.631530428803002, \"yhat_lower\": 8.129517411989854, \"yhat_upper\": 9.059239616644577, \"fact\": 8.645248319087003, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:27:00\", \"yhat\": 8.638232421757921, \"yhat_lower\": 8.143315790707545, \"yhat_upper\": 9.127914136822437, \"fact\": 8.674972483541307, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:28:00\", \"yhat\": 8.64493441471284, \"yhat_lower\": 8.128000921895246, \"yhat_upper\": 9.120344977118478, \"fact\": 8.76474826986135, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:29:00\", \"yhat\": 8.651636407667759, \"yhat_lower\": 8.224693394306383, \"yhat_upper\": 9.110021746039653, \"fact\": 8.811453323118272, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:30:00\", \"yhat\": 8.669474242659621, \"yhat_lower\": 8.228048470699806, \"yhat_upper\": 9.115936655885195, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:31:00\", \"yhat\": 8.676333258766956, \"yhat_lower\": 8.269813478611125, \"yhat_upper\": 9.17046819559661, \"fact\": 8.485875363354573, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:32:00\", \"yhat\": 8.683192274874292, \"yhat_lower\": 8.214097331832784, \"yhat_upper\": 9.097641809470247, \"fact\": 8.399451833349502, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:33:00\", \"yhat\": 8.690051290981625, \"yhat_lower\": 8.245090291657403, \"yhat_upper\": 9.15728684286937, \"fact\": 8.457620981862641, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:34:00\", \"yhat\": 8.696910307088963, \"yhat_lower\": 8.207119811990882, \"yhat_upper\": 9.12189502436019, \"fact\": 8.612568848026724, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:35:00\", \"yhat\": 8.680293667632633, \"yhat_lower\": 8.189767907151708, \"yhat_upper\": 9.154608159842414, \"fact\": 8.514394842156392, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:36:00\", \"yhat\": 8.686917849022423, \"yhat_lower\": 8.191180540254512, \"yhat_upper\": 9.138291066549998, \"fact\": 8.387880106011288, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:37:00\", \"yhat\": 8.693542030412216, \"yhat_lower\": 8.220767328010469, \"yhat_upper\": 9.177256788945986, \"fact\": 8.223871883913581, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:38:00\", \"yhat\": 8.700166211802006, \"yhat_lower\": 8.225244475155694, \"yhat_upper\": 9.176062005549236, \"fact\": 8.098826371466577, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:39:00\", \"yhat\": 8.706790393191799, \"yhat_lower\": 8.255054506734641, \"yhat_upper\": 9.188267998347873, \"fact\": 8.05572889460056, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:40:00\", \"yhat\": 8.661109523746958, \"yhat_lower\": 8.184440202539015, \"yhat_upper\": 9.148540557976316, \"fact\": 7.956979270891584, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:41:00\", \"yhat\": 8.667286355567727, \"yhat_lower\": 8.164404869596712, \"yhat_upper\": 9.194275264701021, \"fact\": 7.811500666817628, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:42:00\", \"yhat\": 8.673463187388498, \"yhat_lower\": 8.224273460689343, \"yhat_upper\": 9.188713581595733, \"fact\": 7.690415462062634, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:43:00\", \"yhat\": 8.679640019209266, \"yhat_lower\": 8.185427701812879, \"yhat_upper\": 9.22515182459256, \"fact\": 7.717134221024015, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:44:00\", \"yhat\": 8.685816851030035, \"yhat_lower\": 8.235081269625013, \"yhat_upper\": 9.180386245492839, \"fact\": 7.835378833401439, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:45:00\", \"yhat\": 8.550187207709826, \"yhat_lower\": 8.070662275017789, \"yhat_upper\": 9.066935743542079, \"fact\": 7.711894191123989, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:46:00\", \"yhat\": 8.554695449985976, \"yhat_lower\": 8.031305185087305, \"yhat_upper\": 9.062844409884526, \"fact\": 7.7229591895282015, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:47:00\", \"yhat\": 8.559203692262129, \"yhat_lower\": 8.019299291137859, \"yhat_upper\": 9.031548686459688, \"fact\": 7.669836539613878, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:48:00\", \"yhat\": 8.563711934538278, \"yhat_lower\": 8.09644705625358, \"yhat_upper\": 9.098011884893127, \"fact\": 7.717692584250162, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:49:00\", \"yhat\": 8.56822017681443, \"yhat_lower\": 8.02695221382311, \"yhat_upper\": 9.065868239009239, \"fact\": 7.761794676176121, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:50:00\", \"yhat\": 8.434641254257627, \"yhat_lower\": 7.941520340731242, \"yhat_upper\": 8.949197115935734, \"fact\": 7.780476902942309, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:51:00\", \"yhat\": 8.437524250662507, \"yhat_lower\": 7.872875295054652, \"yhat_upper\": 9.008375635903983, \"fact\": 7.977593528807279, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:52:00\", \"yhat\": 8.440407247067387, \"yhat_lower\": 7.935298651467496, \"yhat_upper\": 9.025623520969638, \"fact\": 7.918981702230322, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:53:00\", \"yhat\": 8.443290243472266, \"yhat_lower\": 7.910092859766831, \"yhat_upper\": 8.964656002789654, \"fact\": 8.014169824247498, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:54:00\", \"yhat\": 8.446173239877146, \"yhat_lower\": 7.905867501140967, \"yhat_upper\": 8.994434738508456, \"fact\": 8.002420669187153, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:55:00\", \"yhat\": 8.345446374687723, \"yhat_lower\": 7.803361060039244, \"yhat_upper\": 8.8898510670618, \"fact\": 8.151076376650083, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:56:00\", \"yhat\": 8.346893088725626, \"yhat_lower\": 7.7868708763573435, \"yhat_upper\": 8.877763621936666, \"fact\": 7.979406800773713, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:57:00\", \"yhat\": 8.348339802763528, \"yhat_lower\": 7.751697224434376, \"yhat_upper\": 8.895544754431729, \"fact\": 7.92353421269369, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:58:00\", \"yhat\": 8.349786516801428, \"yhat_lower\": 7.815654872862193, \"yhat_upper\": 8.878487303403098, \"fact\": 8.068779742758723, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:59:00\", \"yhat\": 8.35123323083933, \"yhat_lower\": 7.817491549129765, \"yhat_upper\": 8.829042990625453, \"fact\": 8.078786779675173, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:00:00\", \"yhat\": 8.29067985310056, \"yhat_lower\": 7.705907071935438, \"yhat_upper\": 8.88512128912387, \"fact\": 8.191788462425002, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:01:00\", \"yhat\": 8.291267339342003, \"yhat_lower\": 7.697983613229138, \"yhat_upper\": 8.799054283511861, \"fact\": 8.000415544530842, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:02:00\", \"yhat\": 8.291854825583444, \"yhat_lower\": 7.682388907155187, \"yhat_upper\": 8.864215057854478, \"fact\": 8.071115630032562, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:03:00\", \"yhat\": 8.292442311824887, \"yhat_lower\": 7.794804959087799, \"yhat_upper\": 8.85953054846824, \"fact\": 8.081479750948631, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:04:00\", \"yhat\": 8.293029798066328, \"yhat_lower\": 7.728310944759558, \"yhat_upper\": 8.895065108822825, \"fact\": 8.098170821285184, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:05:00\", \"yhat\": 8.243101944344636, \"yhat_lower\": 7.691924661657023, \"yhat_upper\": 8.797990341403109, \"fact\": 8.267139845953881, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:06:00\", \"yhat\": 8.242885711720225, \"yhat_lower\": 7.7167409625311105, \"yhat_upper\": 8.71614864496976, \"fact\": 8.212596119789714, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:07:00\", \"yhat\": 8.242669479095817, \"yhat_lower\": 7.70301787439335, \"yhat_upper\": 8.778925781227725, \"fact\": 8.230590163089623, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:08:00\", \"yhat\": 8.242453246471406, \"yhat_lower\": 7.694694614843176, \"yhat_upper\": 8.69692712771857, \"fact\": 8.318860440882997, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:09:00\", \"yhat\": 8.242237013846996, \"yhat_lower\": 7.757158292830677, \"yhat_upper\": 8.770291002039562, \"fact\": 8.392351095262217, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:10:00\", \"yhat\": 8.242738501051726, \"yhat_lower\": 7.718938882054202, \"yhat_upper\": 8.749614434693205, \"fact\": 8.398247511408044, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:11:00\", \"yhat\": 8.242447127981558, \"yhat_lower\": 7.68448043823853, \"yhat_upper\": 8.772991490684559, \"fact\": 8.545377931691302, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:12:00\", \"yhat\": 8.24215575491139, \"yhat_lower\": 7.663947188153545, \"yhat_upper\": 8.76810914577026, \"fact\": 8.553662460728718, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:13:00\", \"yhat\": 8.241864381841221, \"yhat_lower\": 7.713610077019909, \"yhat_upper\": 8.758558027956473, \"fact\": 8.539053365383428, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:14:00\", \"yhat\": 8.241573008771052, \"yhat_lower\": 7.69803499591047, \"yhat_upper\": 8.797748389975812, \"fact\": 8.738610081903111, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:15:00\", \"yhat\": 8.286722986533421, \"yhat_lower\": 7.770313487784731, \"yhat_upper\": 8.928294231482933, \"fact\": 8.789728699261456, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:16:00\", \"yhat\": 8.286908882659382, \"yhat_lower\": 7.770699844440091, \"yhat_upper\": 8.86380531534944, \"fact\": 8.672292432735887, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:17:00\", \"yhat\": 8.287094778785342, \"yhat_lower\": 7.679833657085695, \"yhat_upper\": 8.91191390320141, \"fact\": 8.583695199589734, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:18:00\", \"yhat\": 8.287280674911301, \"yhat_lower\": 7.7884770028163555, \"yhat_upper\": 8.79922017952833, \"fact\": 8.545572696616933, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:19:00\", \"yhat\": 8.287466571037262, \"yhat_lower\": 7.703817336948908, \"yhat_upper\": 8.836782770711565, \"fact\": 8.53469919243193, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:20:00\", \"yhat\": 8.332481616197516, \"yhat_lower\": 7.786614256800465, \"yhat_upper\": 8.830225362559847, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:21:00\", \"yhat\": 8.333120174492123, \"yhat_lower\": 7.77978275440406, \"yhat_upper\": 8.898963986442402, \"fact\": 8.619454458907168, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:22:00\", \"yhat\": 8.33375873278673, \"yhat_lower\": 7.822862493083819, \"yhat_upper\": 8.878314581379694, \"fact\": 8.64014873041566, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:23:00\", \"yhat\": 8.334397291081338, \"yhat_lower\": 7.828995642331184, \"yhat_upper\": 8.85679531498394, \"fact\": 8.773110778116337, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:24:00\", \"yhat\": 8.335035849375945, \"yhat_lower\": 7.773977734230417, \"yhat_upper\": 8.887308709043065, \"fact\": 8.842045243191007, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:25:00\", \"yhat\": 8.385781944480973, \"yhat_lower\": 7.891048661064227, \"yhat_upper\": 8.875808659204061, \"fact\": 8.779304562733579, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:26:00\", \"yhat\": 8.387008956691918, \"yhat_lower\": 7.883982507431046, \"yhat_upper\": 8.999719914587137, \"fact\": 8.715667021210756, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:27:00\", \"yhat\": 8.388235968902864, \"yhat_lower\": 7.841676014734966, \"yhat_upper\": 8.943183605970667, \"fact\": 8.95869877998149, \"anomaly\": 1}, {\"ds\": \"2021-08-23T13:28:00\", \"yhat\": 8.389462981113807, \"yhat_lower\": 7.8725745274821035, \"yhat_upper\": 8.918451257476587, \"fact\": 9.131002557332641, \"anomaly\": 1}, {\"ds\": \"2021-08-23T13:29:00\", \"yhat\": 8.390689993324752, \"yhat_lower\": 7.8244051825899215, \"yhat_upper\": 8.893450757688052, \"fact\": 9.110278629189814, \"anomaly\": 1}, {\"ds\": \"2021-08-23T13:30:00\", \"yhat\": 8.449019834839346, \"yhat_lower\": 7.814189095174318, \"yhat_upper\": 9.030376573126935, \"fact\": 9.026194022516984, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:31:00\", \"yhat\": 8.450593617164495, \"yhat_lower\": 7.89674109239741, \"yhat_upper\": 9.039659610504945, \"fact\": 8.996799590069418, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:32:00\", \"yhat\": 8.452167399489642, \"yhat_lower\": 7.9055219393125675, \"yhat_upper\": 9.055296107323132, \"fact\": 8.89038427307193, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:33:00\", \"yhat\": 8.453741181814793, \"yhat_lower\": 7.84026726691657, \"yhat_upper\": 9.054505195583921, \"fact\": 8.845887105325563, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:34:00\", \"yhat\": 8.455314964139943, \"yhat_lower\": 7.893305532347313, \"yhat_upper\": 9.070494895393587, \"fact\": 8.940727418078595, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:35:00\", \"yhat\": 8.525062210586926, \"yhat_lower\": 7.950133467186771, \"yhat_upper\": 9.11051206894914, \"fact\": 8.890937823525107, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:36:00\", \"yhat\": 8.527329508283794, \"yhat_lower\": 7.904165251517417, \"yhat_upper\": 9.151475774821444, \"fact\": 8.689691616597951, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:37:00\", \"yhat\": 8.529596805980662, \"yhat_lower\": 7.905919769826134, \"yhat_upper\": 9.191632812498272, \"fact\": 8.859131071315861, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:38:00\", \"yhat\": 8.53186410367753, \"yhat_lower\": 7.935240840191039, \"yhat_upper\": 9.065360291016463, \"fact\": 8.75225132967224, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:39:00\", \"yhat\": 8.534131401374397, \"yhat_lower\": 7.972974989363307, \"yhat_upper\": 9.16096761603271, \"fact\": 8.745441955414979, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:40:00\", \"yhat\": 8.557515011744819, \"yhat_lower\": 7.9558866737891405, \"yhat_upper\": 9.136097795286533, \"fact\": 8.792889390472723, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:41:00\", \"yhat\": 8.559882186265671, \"yhat_lower\": 7.972715084023855, \"yhat_upper\": 9.158438155332782, \"fact\": 8.787700796349098, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:42:00\", \"yhat\": 8.562249360786526, \"yhat_lower\": 8.030510645715724, \"yhat_upper\": 9.16087627806521, \"fact\": 8.865140236693664, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:43:00\", \"yhat\": 8.564616535307378, \"yhat_lower\": 8.005329396352305, \"yhat_upper\": 9.16527942977412, \"fact\": 8.873378150594053, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:44:00\", \"yhat\": 8.56698370982823, \"yhat_lower\": 7.926100057993873, \"yhat_upper\": 9.193926328991262, \"fact\": 9.0222393846978, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:45:00\", \"yhat\": 8.61082940911773, \"yhat_lower\": 8.027406056537847, \"yhat_upper\": 9.131076585153783, \"fact\": 9.065340509014483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:46:00\", \"yhat\": 8.613618652291747, \"yhat_lower\": 8.085253232502163, \"yhat_upper\": 9.190650594279116, \"fact\": 9.08761005037332, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:47:00\", \"yhat\": 8.616407895465763, \"yhat_lower\": 8.027920896783609, \"yhat_upper\": 9.257082486799034, \"fact\": 9.21261808729404, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:48:00\", \"yhat\": 8.61919713863978, \"yhat_lower\": 8.065608866869098, \"yhat_upper\": 9.168493198482807, \"fact\": 9.171105600168334, \"anomaly\": 1}, {\"ds\": \"2021-08-23T13:49:00\", \"yhat\": 8.621986381813796, \"yhat_lower\": 8.055914921852574, \"yhat_upper\": 9.220226242093116, \"fact\": 9.2291796823891, \"anomaly\": 1}, {\"ds\": \"2021-08-23T13:50:00\", \"yhat\": 8.705436371993072, \"yhat_lower\": 8.096219663679909, \"yhat_upper\": 9.380690824748367, \"fact\": 9.306666947502116, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:51:00\", \"yhat\": 8.709080119988137, \"yhat_lower\": 8.09246788169226, \"yhat_upper\": 9.362363982926475, \"fact\": 9.262624362293195, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:52:00\", \"yhat\": 8.7127238679832, \"yhat_lower\": 8.107628044095778, \"yhat_upper\": 9.329100813757629, \"fact\": 9.242218868074156, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:53:00\", \"yhat\": 8.716367615978266, \"yhat_lower\": 8.107224807940304, \"yhat_upper\": 9.3333155551609, \"fact\": 9.33795232275775, \"anomaly\": 1}, {\"ds\": \"2021-08-23T13:54:00\", \"yhat\": 8.720011363973331, \"yhat_lower\": 8.140335785355026, \"yhat_upper\": 9.431625028416123, \"fact\": 9.323311197520256, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:55:00\", \"yhat\": 8.78855475159562, \"yhat_lower\": 8.204676623164586, \"yhat_upper\": 9.414655558914447, \"fact\": 9.224541361617664, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:56:00\", \"yhat\": 8.792753362551911, \"yhat_lower\": 8.1886260698496, \"yhat_upper\": 9.371425053982046, \"fact\": 9.235951852873002, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:57:00\", \"yhat\": 8.796951973508204, \"yhat_lower\": 8.153898192396808, \"yhat_upper\": 9.428170159802889, \"fact\": 9.183230028411051, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:58:00\", \"yhat\": 8.801150584464494, \"yhat_lower\": 8.14039292663244, \"yhat_upper\": 9.355634646481324, \"fact\": 9.303308572775062, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:59:00\", \"yhat\": 8.805349195420785, \"yhat_lower\": 8.18510708491174, \"yhat_upper\": 9.394330684803636, \"fact\": 9.41516862839868, \"anomaly\": 1}, {\"ds\": \"2021-08-23T14:00:00\", \"yhat\": 8.881193752715498, \"yhat_lower\": 8.270527601659392, \"yhat_upper\": 9.50190500492678, \"fact\": 9.344349304080247, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:01:00\", \"yhat\": 8.886200953153784, \"yhat_lower\": 8.254651501752253, \"yhat_upper\": 9.533824568843496, \"fact\": 9.418666704403686, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:02:00\", \"yhat\": 8.89120815359207, \"yhat_lower\": 8.276011062474012, \"yhat_upper\": 9.491431860754748, \"fact\": 9.318795523294629, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:03:00\", \"yhat\": 8.896215354030355, \"yhat_lower\": 8.229843577532272, \"yhat_upper\": 9.502367386171422, \"fact\": 9.361514185397724, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:04:00\", \"yhat\": 8.90122255446864, \"yhat_lower\": 8.341133149232896, \"yhat_upper\": 9.556967643662002, \"fact\": 9.455447864087226, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:05:00\", \"yhat\": 8.99349529189196, \"yhat_lower\": 8.349813497924895, \"yhat_upper\": 9.581649206866109, \"fact\": 9.401919535507847, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:06:00\", \"yhat\": 8.9995490180599, \"yhat_lower\": 8.376847380216361, \"yhat_upper\": 9.580938985744762, \"fact\": 9.38713489217632, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:07:00\", \"yhat\": 9.005602744227842, \"yhat_lower\": 8.42060608229472, \"yhat_upper\": 9.66864045017753, \"fact\": 9.455945295107508, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:08:00\", \"yhat\": 9.011656470395783, \"yhat_lower\": 8.378709016514144, \"yhat_upper\": 9.62722329787564, \"fact\": 9.609159720517681, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:09:00\", \"yhat\": 9.017710196563723, \"yhat_lower\": 8.368637388978673, \"yhat_upper\": 9.678075442346184, \"fact\": 9.614996053596242, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:10:00\", \"yhat\": 9.110282384292743, \"yhat_lower\": 8.488069130242215, \"yhat_upper\": 9.703375523765528, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:11:00\", \"yhat\": 9.11743999930366, \"yhat_lower\": 8.48125817725393, \"yhat_upper\": 9.719653312534952, \"fact\": 9.556691781795077, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:12:00\", \"yhat\": 9.124597614314576, \"yhat_lower\": 8.572489150717423, \"yhat_upper\": 9.748986138048533, \"fact\": 9.643000959964645, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:13:00\", \"yhat\": 9.131755229325492, \"yhat_lower\": 8.421953739137237, \"yhat_upper\": 9.767320178590891, \"fact\": 9.718788895128835, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:14:00\", \"yhat\": 9.138912844336408, \"yhat_lower\": 8.551224754584851, \"yhat_upper\": 9.727348007761105, \"fact\": 9.638302318559198, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:15:00\", \"yhat\": 9.232172233559378, \"yhat_lower\": 8.62856298588939, \"yhat_upper\": 9.88042149584469, \"fact\": 9.86400121471953, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:16:00\", \"yhat\": 9.240507844078527, \"yhat_lower\": 8.59442080053327, \"yhat_upper\": 9.911798992894873, \"fact\": 9.832149494497711, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:17:00\", \"yhat\": 9.248843454597676, \"yhat_lower\": 8.592343388939527, \"yhat_upper\": 9.858677433410008, \"fact\": 9.8378481484009, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:18:00\", \"yhat\": 9.257179065116825, \"yhat_lower\": 8.625816486831873, \"yhat_upper\": 9.855761373553337, \"fact\": 9.86632383278163, \"anomaly\": 1}, {\"ds\": \"2021-08-23T14:19:00\", \"yhat\": 9.265514675635973, \"yhat_lower\": 8.667285166565609, \"yhat_upper\": 9.928473304179048, \"fact\": 9.892267601353337, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:20:00\", \"yhat\": 9.407000191959385, \"yhat_lower\": 8.765441662814544, \"yhat_upper\": 10.057665020619627, \"fact\": 9.931774604936024, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:21:00\", \"yhat\": 9.41722621832168, \"yhat_lower\": 8.709573779918038, \"yhat_upper\": 9.982405304218409, \"fact\": 9.954188808547201, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:22:00\", \"yhat\": 9.427452244683977, \"yhat_lower\": 8.742680753603636, \"yhat_upper\": 10.05739067796284, \"fact\": 9.817695310369409, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:23:00\", \"yhat\": 9.437678271046273, \"yhat_lower\": 8.795176106888594, \"yhat_upper\": 10.085051631309948, \"fact\": 9.84172254699343, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:24:00\", \"yhat\": 9.44790429740857, \"yhat_lower\": 8.818903303370229, \"yhat_upper\": 10.040696661982423, \"fact\": 9.80607724404463, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:25:00\", \"yhat\": 9.57426852185799, \"yhat_lower\": 8.921554751829612, \"yhat_upper\": 10.178327800839291, \"fact\": 9.634992469023846, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:26:00\", \"yhat\": 9.586283079601872, \"yhat_lower\": 8.859765310657572, \"yhat_upper\": 10.191063993369855, \"fact\": 9.719664071742129, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:27:00\", \"yhat\": 9.598297637345752, \"yhat_lower\": 8.973163002637401, \"yhat_upper\": 10.183294028307412, \"fact\": 9.803939082783222, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:28:00\", \"yhat\": 9.610312195089634, \"yhat_lower\": 8.96580365850592, \"yhat_upper\": 10.282700324776728, \"fact\": 9.800414529471565, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:29:00\", \"yhat\": 9.622326752833514, \"yhat_lower\": 9.071840245683727, \"yhat_upper\": 10.215470896404934, \"fact\": 9.82701899851565, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:30:00\", \"yhat\": 9.7176654746229, \"yhat_lower\": 9.139774652262322, \"yhat_upper\": 10.361790370593859, \"fact\": 9.77933964253321, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:31:00\", \"yhat\": 9.731229279042253, \"yhat_lower\": 9.179897882851835, \"yhat_upper\": 10.323277139941291, \"fact\": 9.756520180732126, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:32:00\", \"yhat\": 9.744793083461605, \"yhat_lower\": 9.135464503294576, \"yhat_upper\": 10.384712452029145, \"fact\": 9.850925560836, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:33:00\", \"yhat\": 9.758356887880959, \"yhat_lower\": 9.168271344928662, \"yhat_upper\": 10.350709600175241, \"fact\": 9.804925591815215, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:34:00\", \"yhat\": 9.771920692300313, \"yhat_lower\": 9.207868567343407, \"yhat_upper\": 10.390684669792295, \"fact\": 9.619049334366524, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:35:00\", \"yhat\": 9.867632481505684, \"yhat_lower\": 9.303409790342073, \"yhat_upper\": 10.377361996676305, \"fact\": 9.600139673643671, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:36:00\", \"yhat\": 9.88297361009737, \"yhat_lower\": 9.31210936211504, \"yhat_upper\": 10.405740779755504, \"fact\": 9.654070612123258, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:37:00\", \"yhat\": 9.898314738689056, \"yhat_lower\": 9.291843387479904, \"yhat_upper\": 10.44653936237984, \"fact\": 9.81409008687884, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:38:00\", \"yhat\": 9.913655867280744, \"yhat_lower\": 9.398799801812617, \"yhat_upper\": 10.446337652158377, \"fact\": 9.86346342581928, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:39:00\", \"yhat\": 9.928996995872428, \"yhat_lower\": 9.408706893305212, \"yhat_upper\": 10.476172779234753, \"fact\": 9.857124185840512, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:40:00\", \"yhat\": 10.001688979928876, \"yhat_lower\": 9.550306202508931, \"yhat_upper\": 10.519555576424631, \"fact\": 9.983032579376141, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:41:00\", \"yhat\": 10.018562359492545, \"yhat_lower\": 9.58549178588031, \"yhat_upper\": 10.529445194842529, \"fact\": 10.037199180536911, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:42:00\", \"yhat\": 10.035435739056215, \"yhat_lower\": 9.552631372318823, \"yhat_upper\": 10.45641825111819, \"fact\": 9.993484385678066, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:43:00\", \"yhat\": 10.052309118619885, \"yhat_lower\": 9.593794285907855, \"yhat_upper\": 10.519020583891301, \"fact\": 10.0400027689603, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:44:00\", \"yhat\": 10.069182498183553, \"yhat_lower\": 9.62339047032551, \"yhat_upper\": 10.554357797476072, \"fact\": 10.034298117029037, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:45:00\", \"yhat\": 10.132556796881342, \"yhat_lower\": 9.62502895524723, \"yhat_upper\": 10.580591128943476, \"fact\": 10.076049094922666, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:46:00\", \"yhat\": 10.150509488731247, \"yhat_lower\": 9.675361917694502, \"yhat_upper\": 10.597490527666022, \"fact\": 10.0988034535548, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:47:00\", \"yhat\": 10.16846218058115, \"yhat_lower\": 9.672667198971007, \"yhat_upper\": 10.612162794856541, \"fact\": 10.03315333035482, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:48:00\", \"yhat\": 10.186414872431056, \"yhat_lower\": 9.744198680201933, \"yhat_upper\": 10.680755737992193, \"fact\": 9.989417587885512, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:49:00\", \"yhat\": 10.20436756428096, \"yhat_lower\": 9.72399835011808, \"yhat_upper\": 10.684451205494337, \"fact\": 10.142657199531792, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:50:00\", \"yhat\": 10.224309740321996, \"yhat_lower\": 9.77862157087947, \"yhat_upper\": 10.697877531487704, \"fact\": 10.255063743963055, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:51:00\", \"yhat\": 10.242505012938048, \"yhat_lower\": 9.769203005058069, \"yhat_upper\": 10.674046446640716, \"fact\": 10.289207345135177, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:52:00\", \"yhat\": 10.260700285554103, \"yhat_lower\": 9.788209002567164, \"yhat_upper\": 10.722389770732043, \"fact\": 10.290051522452643, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:53:00\", \"yhat\": 10.278895558170156, \"yhat_lower\": 9.768119753515483, \"yhat_upper\": 10.74224757407709, \"fact\": 10.208202234151164, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:54:00\", \"yhat\": 10.297090830786209, \"yhat_lower\": 9.856288726176551, \"yhat_upper\": 10.797147068912752, \"fact\": 10.20744863055363, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:55:00\", \"yhat\": 10.32711395890904, \"yhat_lower\": 9.848017852787736, \"yhat_upper\": 10.767709937418932, \"fact\": 10.102381099087888, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:56:00\", \"yhat\": 10.34563524080256, \"yhat_lower\": 9.880786140240026, \"yhat_upper\": 10.841555227787882, \"fact\": 10.187155935748017, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:57:00\", \"yhat\": 10.364156522696081, \"yhat_lower\": 9.906184618185872, \"yhat_upper\": 10.831432452806352, \"fact\": 10.126046394947553, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:58:00\", \"yhat\": 10.382677804589603, \"yhat_lower\": 9.8969856474249, \"yhat_upper\": 10.826194898347019, \"fact\": 10.077830439271654, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:59:00\", \"yhat\": 10.401199086483123, \"yhat_lower\": 9.911250041506838, \"yhat_upper\": 10.881003805716844, \"fact\": 10.112502220252225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:00:00\", \"yhat\": 10.377943356318609, \"yhat_lower\": 9.933290454004004, \"yhat_upper\": 10.828554199466932, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:01:00\", \"yhat\": 10.395957728135327, \"yhat_lower\": 9.874520317880618, \"yhat_upper\": 10.855407206362445, \"fact\": 10.2942943861814, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:02:00\", \"yhat\": 10.413972099952046, \"yhat_lower\": 9.96501589585462, \"yhat_upper\": 10.861202897290626, \"fact\": 10.205446118651967, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:03:00\", \"yhat\": 10.431986471768765, \"yhat_lower\": 9.94617438160715, \"yhat_upper\": 10.90993552139573, \"fact\": 10.271409386655742, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:04:00\", \"yhat\": 10.450000843585489, \"yhat_lower\": 10.007979018111447, \"yhat_upper\": 10.904328741331977, \"fact\": 10.256522349950478, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:05:00\", \"yhat\": 10.428529223526523, \"yhat_lower\": 9.993695954461923, \"yhat_upper\": 10.869102298290752, \"fact\": 10.17902731704118, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:06:00\", \"yhat\": 10.445882604263392, \"yhat_lower\": 9.987505376170304, \"yhat_upper\": 10.847928284785086, \"fact\": 10.223078359670582, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:07:00\", \"yhat\": 10.463235985000262, \"yhat_lower\": 10.007876966324854, \"yhat_upper\": 10.921637754730124, \"fact\": 10.289101894089889, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:08:00\", \"yhat\": 10.48058936573713, \"yhat_lower\": 10.059532447907438, \"yhat_upper\": 10.953042164595862, \"fact\": 10.452816223055665, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:09:00\", \"yhat\": 10.497942746474001, \"yhat_lower\": 10.072072403485501, \"yhat_upper\": 10.959666045691181, \"fact\": 10.530367461184968, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:10:00\", \"yhat\": 10.510072268977254, \"yhat_lower\": 10.083493617757018, \"yhat_upper\": 11.01479187179078, \"fact\": 10.515200566630206, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:11:00\", \"yhat\": 10.527486846728745, \"yhat_lower\": 10.042607018939425, \"yhat_upper\": 10.988842385107398, \"fact\": 10.462488799078955, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:12:00\", \"yhat\": 10.544901424480237, \"yhat_lower\": 10.087678005060598, \"yhat_upper\": 11.025707118901718, \"fact\": 10.536617371571872, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:13:00\", \"yhat\": 10.562316002231729, \"yhat_lower\": 10.12003537563061, \"yhat_upper\": 11.00027719214921, \"fact\": 10.582085913026225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:14:00\", \"yhat\": 10.579730579983218, \"yhat_lower\": 10.10682509245261, \"yhat_upper\": 11.083099783679245, \"fact\": 10.453705254361472, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:15:00\", \"yhat\": 10.570682555673146, \"yhat_lower\": 10.088015285624504, \"yhat_upper\": 10.988730357906137, \"fact\": 10.481826344423022, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:16:00\", \"yhat\": 10.587580957709477, \"yhat_lower\": 10.136320347874035, \"yhat_upper\": 11.05396028106262, \"fact\": 10.353428837573519, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:17:00\", \"yhat\": 10.604479359745811, \"yhat_lower\": 10.145691745519027, \"yhat_upper\": 11.046973614861926, \"fact\": 10.342528897524867, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:18:00\", \"yhat\": 10.621377761782142, \"yhat_lower\": 10.15717729240886, \"yhat_upper\": 11.095357074367888, \"fact\": 10.289505252298003, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:19:00\", \"yhat\": 10.638276163818475, \"yhat_lower\": 10.223221388676569, \"yhat_upper\": 11.07985595963978, \"fact\": 10.233404516009793, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:20:00\", \"yhat\": 10.594443001543334, \"yhat_lower\": 10.181240923270012, \"yhat_upper\": 11.050553459126789, \"fact\": 10.398350843814256, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:21:00\", \"yhat\": 10.610435683854364, \"yhat_lower\": 10.208814982353612, \"yhat_upper\": 11.04845973228696, \"fact\": 10.413367861232464, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:22:00\", \"yhat\": 10.626428366165392, \"yhat_lower\": 10.16390328808611, \"yhat_upper\": 11.039773949960308, \"fact\": 10.465737097515472, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:23:00\", \"yhat\": 10.64242104847642, \"yhat_lower\": 10.209699622617043, \"yhat_upper\": 11.062964924992137, \"fact\": 10.540956107018431, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:24:00\", \"yhat\": 10.65841373078745, \"yhat_lower\": 10.19833495785173, \"yhat_upper\": 11.114855847022596, \"fact\": 10.419642110204657, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:25:00\", \"yhat\": 10.637007022482484, \"yhat_lower\": 10.164302513610142, \"yhat_upper\": 11.054951261696251, \"fact\": 10.38830467957498, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:26:00\", \"yhat\": 10.652487817731192, \"yhat_lower\": 10.194059849280922, \"yhat_upper\": 11.098730923865281, \"fact\": 10.337534746596601, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:27:00\", \"yhat\": 10.667968612979898, \"yhat_lower\": 10.187333712345199, \"yhat_upper\": 11.082997291907654, \"fact\": 10.446651275126646, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:28:00\", \"yhat\": 10.683449408228606, \"yhat_lower\": 10.253330738667334, \"yhat_upper\": 11.163169396742308, \"fact\": 10.514004036753205, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:29:00\", \"yhat\": 10.698930203477314, \"yhat_lower\": 10.235849392851287, \"yhat_upper\": 11.130428142337887, \"fact\": 10.507311180202013, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:30:00\", \"yhat\": 10.671510735494264, \"yhat_lower\": 10.24521830584141, \"yhat_upper\": 11.137399069928593, \"fact\": 10.600130615972407, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:31:00\", \"yhat\": 10.686409637126719, \"yhat_lower\": 10.208060794683833, \"yhat_upper\": 11.170139979971937, \"fact\": 10.608687106522943, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:32:00\", \"yhat\": 10.701308538759173, \"yhat_lower\": 10.243283057188256, \"yhat_upper\": 11.167952707855255, \"fact\": 10.484335112185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:33:00\", \"yhat\": 10.716207440391628, \"yhat_lower\": 10.277441300573575, \"yhat_upper\": 11.153055318161332, \"fact\": 10.621271569245923, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:34:00\", \"yhat\": 10.731106342024082, \"yhat_lower\": 10.249620169702437, \"yhat_upper\": 11.179247207354106, \"fact\": 10.639575926010757, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:35:00\", \"yhat\": 10.711208340951238, \"yhat_lower\": 10.274575296736609, \"yhat_upper\": 11.140670094056363, \"fact\": 10.596954129260547, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:36:00\", \"yhat\": 10.725503541949355, \"yhat_lower\": 10.320537179771513, \"yhat_upper\": 11.20265975386291, \"fact\": 10.62736816641365, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:37:00\", \"yhat\": 10.739798742947473, \"yhat_lower\": 10.262298537741882, \"yhat_upper\": 11.14894309839503, \"fact\": 10.668971329410926, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:38:00\", \"yhat\": 10.754093943945593, \"yhat_lower\": 10.34832224081996, \"yhat_upper\": 11.191705176420301, \"fact\": 10.960130410890418, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:39:00\", \"yhat\": 10.768389144943711, \"yhat_lower\": 10.346882401905082, \"yhat_upper\": 11.230875802374193, \"fact\": 11.0, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:40:00\", \"yhat\": 10.784416166486261, \"yhat_lower\": 10.352175665075363, \"yhat_upper\": 11.188066484588113, \"fact\": 10.944748604963694, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:41:00\", \"yhat\": 10.798680241645886, \"yhat_lower\": 10.373149984287366, \"yhat_upper\": 11.256959534944956, \"fact\": 10.762400197925471, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:42:00\", \"yhat\": 10.81294431680551, \"yhat_lower\": 10.399697129988397, \"yhat_upper\": 11.279332357495898, \"fact\": 10.633397214168852, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:43:00\", \"yhat\": 10.827208391965133, \"yhat_lower\": 10.35817629574591, \"yhat_upper\": 11.274290085413991, \"fact\": 10.508366912453496, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:44:00\", \"yhat\": 10.841472467124758, \"yhat_lower\": 10.396582041637654, \"yhat_upper\": 11.292136292211614, \"fact\": 10.747813043137848, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:45:00\", \"yhat\": 10.83561976979995, \"yhat_lower\": 10.403821985847355, \"yhat_upper\": 11.294733614464985, \"fact\": 10.616517623097478, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:46:00\", \"yhat\": 10.849605721051214, \"yhat_lower\": 10.429172275727177, \"yhat_upper\": 11.264506628451295, \"fact\": 10.519134892650595, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:47:00\", \"yhat\": 10.863591672302478, \"yhat_lower\": 10.42276846185639, \"yhat_upper\": 11.335984130462148, \"fact\": 10.505485347067411, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:48:00\", \"yhat\": 10.87757762355374, \"yhat_lower\": 10.386860375453077, \"yhat_upper\": 11.319055978910544, \"fact\": 10.370020036709334, \"anomaly\": 1}, {\"ds\": \"2021-08-23T15:49:00\", \"yhat\": 10.891563574805005, \"yhat_lower\": 10.441541522797108, \"yhat_upper\": 11.390525171235838, \"fact\": 10.252602215750233, \"anomaly\": 1}, {\"ds\": \"2021-08-23T15:50:00\", \"yhat\": 10.832762856228467, \"yhat_lower\": 10.366899405916355, \"yhat_upper\": 11.3418305461835, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:51:00\", \"yhat\": 10.84580573619485, \"yhat_lower\": 10.357629242364006, \"yhat_upper\": 11.282443929644463, \"fact\": 10.239477262630865, \"anomaly\": 1}, {\"ds\": \"2021-08-23T15:52:00\", \"yhat\": 10.858848616161232, \"yhat_lower\": 10.412728470794644, \"yhat_upper\": 11.310842948076557, \"fact\": 10.27736285358397, \"anomaly\": 1}, {\"ds\": \"2021-08-23T15:53:00\", \"yhat\": 10.871891496127612, \"yhat_lower\": 10.43108236087461, \"yhat_upper\": 11.298774649483146, \"fact\": 10.253281566040584, \"anomaly\": 1}, {\"ds\": \"2021-08-23T15:54:00\", \"yhat\": 10.884934376093993, \"yhat_lower\": 10.366338888958797, \"yhat_upper\": 11.40875173669462, \"fact\": 10.045963893343206, \"anomaly\": 1}, {\"ds\": \"2021-08-23T15:55:00\", \"yhat\": 10.806553488098153, \"yhat_lower\": 10.30471500208687, \"yhat_upper\": 11.26542326028414, \"fact\": 9.974512039077938, \"anomaly\": 1}, {\"ds\": \"2021-08-23T15:56:00\", \"yhat\": 10.81845720321221, \"yhat_lower\": 10.26238890054902, \"yhat_upper\": 11.328021321368503, \"fact\": 10.041043064809825, \"anomaly\": 1}, {\"ds\": \"2021-08-23T15:57:00\", \"yhat\": 10.830360918326265, \"yhat_lower\": 10.297485939599564, \"yhat_upper\": 11.310433023002384, \"fact\": 10.047700947811453, \"anomaly\": 1}, {\"ds\": \"2021-08-23T15:58:00\", \"yhat\": 10.842264633440323, \"yhat_lower\": 10.360976379526239, \"yhat_upper\": 11.322271367268906, \"fact\": 10.004137092919867, \"anomaly\": 1}, {\"ds\": \"2021-08-23T15:59:00\", \"yhat\": 10.854168348554378, \"yhat_lower\": 10.306231350408726, \"yhat_upper\": 11.31308782000769, \"fact\": 9.966989635494258, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:00:00\", \"yhat\": 10.727546407892202, \"yhat_lower\": 10.214686828101975, \"yhat_upper\": 11.19506076647489, \"fact\": 9.988342774645961, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:01:00\", \"yhat\": 10.737780509810392, \"yhat_lower\": 10.206463407758527, \"yhat_upper\": 11.23235214628739, \"fact\": 9.964268279658732, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:02:00\", \"yhat\": 10.748014611728582, \"yhat_lower\": 10.25620180809148, \"yhat_upper\": 11.239398936938837, \"fact\": 9.838689442516403, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:03:00\", \"yhat\": 10.758248713646774, \"yhat_lower\": 10.224051498020215, \"yhat_upper\": 11.269984296872675, \"fact\": 9.773522635065854, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:04:00\", \"yhat\": 10.768482815564964, \"yhat_lower\": 10.238227197592655, \"yhat_upper\": 11.28987423193651, \"fact\": 9.868386927448714, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:05:00\", \"yhat\": 10.639862185313838, \"yhat_lower\": 10.097139975653352, \"yhat_upper\": 11.236741682282082, \"fact\": 9.830469543424808, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:06:00\", \"yhat\": 10.648461523136131, \"yhat_lower\": 10.109029732115753, \"yhat_upper\": 11.24378049469269, \"fact\": 9.788865576129703, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:07:00\", \"yhat\": 10.657060860958426, \"yhat_lower\": 10.130494583258729, \"yhat_upper\": 11.221014292883632, \"fact\": 9.914847367291713, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:08:00\", \"yhat\": 10.665660198780719, \"yhat_lower\": 10.133820352474322, \"yhat_upper\": 11.287525630842095, \"fact\": 9.807562371531388, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:09:00\", \"yhat\": 10.674259536603012, \"yhat_lower\": 10.063949287382982, \"yhat_upper\": 11.26092874033183, \"fact\": 9.670822674017861, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:10:00\", \"yhat\": 10.537486964672853, \"yhat_lower\": 9.93630312059115, \"yhat_upper\": 11.138900105224167, \"fact\": 9.616577898394782, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:11:00\", \"yhat\": 10.544310469116622, \"yhat_lower\": 10.002508331951496, \"yhat_upper\": 11.118286375486054, \"fact\": 9.573703532341133, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:12:00\", \"yhat\": 10.551133973560392, \"yhat_lower\": 9.959203414153173, \"yhat_upper\": 11.12860341023074, \"fact\": 9.467645765284308, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:13:00\", \"yhat\": 10.557957478004163, \"yhat_lower\": 10.002605830508621, \"yhat_upper\": 11.1814231749571, \"fact\": 9.486973369882458, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:14:00\", \"yhat\": 10.564780982447932, \"yhat_lower\": 9.99035998138688, \"yhat_upper\": 11.12949373625888, \"fact\": 9.442311708770832, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:15:00\", \"yhat\": 10.381873533828978, \"yhat_lower\": 9.832408836432972, \"yhat_upper\": 10.994681029707703, \"fact\": 9.395669890818453, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:16:00\", \"yhat\": 10.386235133965277, \"yhat_lower\": 9.7919711607351, \"yhat_upper\": 11.010273627263254, \"fact\": 9.456601403941736, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:17:00\", \"yhat\": 10.390596734101578, \"yhat_lower\": 9.76245087608497, \"yhat_upper\": 10.968684343562138, \"fact\": 9.564992092172044, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:18:00\", \"yhat\": 10.394958334237877, \"yhat_lower\": 9.781721034832145, \"yhat_upper\": 11.000566047808823, \"fact\": 9.63165317584744, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:19:00\", \"yhat\": 10.399319934374176, \"yhat_lower\": 9.787340257811973, \"yhat_upper\": 10.997379436220326, \"fact\": 9.578406412111097, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:20:00\", \"yhat\": 10.245782089410863, \"yhat_lower\": 9.628566648093436, \"yhat_upper\": 10.841340089020287, \"fact\": 9.46403283204649, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:21:00\", \"yhat\": 10.248098500052112, \"yhat_lower\": 9.70907689324114, \"yhat_upper\": 10.902283685592193, \"fact\": 9.216432465535892, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:22:00\", \"yhat\": 10.250414910693364, \"yhat_lower\": 9.64844200586852, \"yhat_upper\": 10.850596066945412, \"fact\": 9.323236419089412, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:23:00\", \"yhat\": 10.252731321334611, \"yhat_lower\": 9.597499157002808, \"yhat_upper\": 10.866292057888014, \"fact\": 9.391465325298743, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:24:00\", \"yhat\": 10.255047731975862, \"yhat_lower\": 9.650310755545087, \"yhat_upper\": 10.869741718803855, \"fact\": 9.50366014614707, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:25:00\", \"yhat\": 10.104342153758534, \"yhat_lower\": 9.469181633384663, \"yhat_upper\": 10.777229435585237, \"fact\": 9.592600239141852, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:26:00\", \"yhat\": 10.104680505809045, \"yhat_lower\": 9.463205552164665, \"yhat_upper\": 10.790731948507142, \"fact\": 9.355788749450348, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:27:00\", \"yhat\": 10.105018857859555, \"yhat_lower\": 9.46327482409483, \"yhat_upper\": 10.787522123843322, \"fact\": 9.222799348520082, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:28:00\", \"yhat\": 10.105357209910066, \"yhat_lower\": 9.505918189792963, \"yhat_upper\": 10.750531654813361, \"fact\": 9.034232188045483, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:29:00\", \"yhat\": 10.105695561960575, \"yhat_lower\": 9.447258469645945, \"yhat_upper\": 10.728404395400494, \"fact\": 8.988900736784247, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:30:00\", \"yhat\": 9.940448152634987, \"yhat_lower\": 9.289028730787864, \"yhat_upper\": 10.611894733933827, \"fact\": 8.940239461563786, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:31:00\", \"yhat\": 9.938594478473371, \"yhat_lower\": 9.295021841128888, \"yhat_upper\": 10.66246311742404, \"fact\": 8.867726672403123, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:32:00\", \"yhat\": 9.936740804311754, \"yhat_lower\": 9.323496387573872, \"yhat_upper\": 10.576237748377562, \"fact\": 8.750332311139447, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:33:00\", \"yhat\": 9.934887130150138, \"yhat_lower\": 9.279748455982551, \"yhat_upper\": 10.575437989714926, \"fact\": 8.749543232452918, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:34:00\", \"yhat\": 9.933033455988522, \"yhat_lower\": 9.311475066583245, \"yhat_upper\": 10.655191447047962, \"fact\": 8.714350103767188, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:35:00\", \"yhat\": 9.72813327825672, \"yhat_lower\": 9.076197171733748, \"yhat_upper\": 10.422744893952851, \"fact\": 8.70989589254306, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:36:00\", \"yhat\": 9.723623371768536, \"yhat_lower\": 9.02977687890321, \"yhat_upper\": 10.420241840364467, \"fact\": 8.93646758528286, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:37:00\", \"yhat\": 9.719113465280351, \"yhat_lower\": 9.073224522769861, \"yhat_upper\": 10.425603568344398, \"fact\": 9.012239346556045, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:38:00\", \"yhat\": 9.714603558792167, \"yhat_lower\": 9.037755968947904, \"yhat_upper\": 10.361439187708715, \"fact\": 9.039800746733981, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:39:00\", \"yhat\": 9.71009365230398, \"yhat_lower\": 9.04311183279496, \"yhat_upper\": 10.35182835350896, \"fact\": 8.977564792960163, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:40:00\", \"yhat\": 9.536296933553931, \"yhat_lower\": 8.866172936745173, \"yhat_upper\": 10.302073891299463, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:41:00\", \"yhat\": 9.529384710848138, \"yhat_lower\": 8.889563591518273, \"yhat_upper\": 10.232246329663601, \"fact\": 8.798698884079773, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:42:00\", \"yhat\": 9.522472488142345, \"yhat_lower\": 8.773727183614735, \"yhat_upper\": 10.275779225205548, \"fact\": 8.757817163308653, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:43:00\", \"yhat\": 9.515560265436552, \"yhat_lower\": 8.787882790813812, \"yhat_upper\": 10.195324300067606, \"fact\": 8.739247557388522, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:44:00\", \"yhat\": 9.508648042730757, \"yhat_lower\": 8.802622162437133, \"yhat_upper\": 10.218601133734975, \"fact\": 8.70356646824997, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:45:00\", \"yhat\": 9.366646199970733, \"yhat_lower\": 8.607558392562751, \"yhat_upper\": 10.075991135262667, \"fact\": 8.782616489057622, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:46:00\", \"yhat\": 9.35777135227005, \"yhat_lower\": 8.630784665740293, \"yhat_upper\": 10.021725706915213, \"fact\": 8.479925780652454, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:47:00\", \"yhat\": 9.348896504569366, \"yhat_lower\": 8.63648585634246, \"yhat_upper\": 9.988462050167813, \"fact\": 8.273358954380925, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:48:00\", \"yhat\": 9.340021656868682, \"yhat_lower\": 8.68433612117799, \"yhat_upper\": 10.01048805969932, \"fact\": 8.447199865827617, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:49:00\", \"yhat\": 9.331146809167997, \"yhat_lower\": 8.650842321599223, \"yhat_upper\": 9.973294395323588, \"fact\": 8.523194953304365, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:50:00\", \"yhat\": 9.124603463423679, \"yhat_lower\": 8.403112257239563, \"yhat_upper\": 9.78784074383796, \"fact\": 8.530052782649555, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:51:00\", \"yhat\": 9.112817148627423, \"yhat_lower\": 8.419242598469587, \"yhat_upper\": 9.74168392244127, \"fact\": 8.396411307804495, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:52:00\", \"yhat\": 9.101030833831171, \"yhat_lower\": 8.414299874094182, \"yhat_upper\": 9.800222189420403, \"fact\": 8.314908428588723, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:53:00\", \"yhat\": 9.089244519034917, \"yhat_lower\": 8.404888553765515, \"yhat_upper\": 9.731667629466008, \"fact\": 8.244009975240218, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:54:00\", \"yhat\": 9.077458204238663, \"yhat_lower\": 8.395928269273515, \"yhat_upper\": 9.793862365249588, \"fact\": 8.180232114481395, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:55:00\", \"yhat\": 8.88302353417909, \"yhat_lower\": 8.166155427767468, \"yhat_upper\": 9.570169156293238, \"fact\": 7.997073407217911, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:56:00\", \"yhat\": 8.868484826394587, \"yhat_lower\": 8.175483192939092, \"yhat_upper\": 9.490141322546995, \"fact\": 7.997788244170042, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:57:00\", \"yhat\": 8.853946118610086, \"yhat_lower\": 8.227635409978951, \"yhat_upper\": 9.538615954489238, \"fact\": 8.027379343471765, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:58:00\", \"yhat\": 8.839407410825583, \"yhat_lower\": 8.174251156048873, \"yhat_upper\": 9.566077427620714, \"fact\": 7.891617442415619, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:59:00\", \"yhat\": 8.824868703041082, \"yhat_lower\": 8.160324288505546, \"yhat_upper\": 9.496412361947021, \"fact\": 7.993391171167953, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:00:00\", \"yhat\": 8.625091614476457, \"yhat_lower\": 7.917109144103121, \"yhat_upper\": 9.289310080602506, \"fact\": 7.839794824705354, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:01:00\", \"yhat\": 8.607909900958305, \"yhat_lower\": 7.946664354672064, \"yhat_upper\": 9.308565286900068, \"fact\": 7.730599469753859, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:02:00\", \"yhat\": 8.590728187440154, \"yhat_lower\": 7.9480933391506285, \"yhat_upper\": 9.34564451458235, \"fact\": 7.6509477022655386, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:03:00\", \"yhat\": 8.573546473922002, \"yhat_lower\": 7.942169187477774, \"yhat_upper\": 9.22918014323943, \"fact\": 7.6005718066277375, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:04:00\", \"yhat\": 8.556364760403852, \"yhat_lower\": 7.918915538433692, \"yhat_upper\": 9.254916859584227, \"fact\": 7.616974853712176, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:05:00\", \"yhat\": 8.316710754578912, \"yhat_lower\": 7.678323994499728, \"yhat_upper\": 8.98409391867112, \"fact\": 7.452726173004684, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:06:00\", \"yhat\": 8.296125971651247, \"yhat_lower\": 7.670714930761088, \"yhat_upper\": 8.86251618108461, \"fact\": 7.4873100141103475, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:07:00\", \"yhat\": 8.275541188723583, \"yhat_lower\": 7.605220251959977, \"yhat_upper\": 8.955113037786706, \"fact\": 7.355716834977905, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:08:00\", \"yhat\": 8.254956405795916, \"yhat_lower\": 7.669508089663922, \"yhat_upper\": 8.91277763297565, \"fact\": 7.304617707670855, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:09:00\", \"yhat\": 8.23437162286825, \"yhat_lower\": 7.655681275786132, \"yhat_upper\": 8.925925378742216, \"fact\": 7.489866921022014, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:10:00\", \"yhat\": 8.016204123329612, \"yhat_lower\": 7.456478489419429, \"yhat_upper\": 8.60484670472872, \"fact\": 7.457128971331552, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:11:00\", \"yhat\": 7.992657209653554, \"yhat_lower\": 7.379445867378461, \"yhat_upper\": 8.613508153444533, \"fact\": 7.49124494359832, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:12:00\", \"yhat\": 7.969110295977499, \"yhat_lower\": 7.33730891826001, \"yhat_upper\": 8.596489937273272, \"fact\": 7.746174323894706, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:13:00\", \"yhat\": 7.945563382301443, \"yhat_lower\": 7.330088458641419, \"yhat_upper\": 8.586817801914153, \"fact\": 7.728164560761447, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:14:00\", \"yhat\": 7.9220164686253876, \"yhat_lower\": 7.2928357440027884, \"yhat_upper\": 8.626722064420779, \"fact\": 7.57497190780261, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:15:00\", \"yhat\": 7.768477303332562, \"yhat_lower\": 7.0872502622613975, \"yhat_upper\": 8.302808572199314, \"fact\": 7.629350721280201, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:16:00\", \"yhat\": 7.742636916015501, \"yhat_lower\": 7.134193529738729, \"yhat_upper\": 8.35663041102185, \"fact\": 7.670839399995044, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:17:00\", \"yhat\": 7.7167965286984375, \"yhat_lower\": 7.144608474912343, \"yhat_upper\": 8.296734537586406, \"fact\": 7.8020911978599985, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:18:00\", \"yhat\": 7.690956141381374, \"yhat_lower\": 7.076764576098388, \"yhat_upper\": 8.272281113431289, \"fact\": 7.688201610108968, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:19:00\", \"yhat\": 7.665115754064313, \"yhat_lower\": 7.059379449033429, \"yhat_upper\": 8.366249565268514, \"fact\": 7.491134163279598, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:20:00\", \"yhat\": 7.563337328501627, \"yhat_lower\": 7.014869632937802, \"yhat_upper\": 8.114978327545412, \"fact\": 7.541546760013012, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:21:00\", \"yhat\": 7.535885558366894, \"yhat_lower\": 6.928962420684344, \"yhat_upper\": 8.084080266357521, \"fact\": 7.322022918010769, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:22:00\", \"yhat\": 7.50843378823216, \"yhat_lower\": 6.985663305723257, \"yhat_upper\": 8.075801261185855, \"fact\": 7.235580785625353, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:23:00\", \"yhat\": 7.480982018097427, \"yhat_lower\": 6.862226225607545, \"yhat_upper\": 8.04879652176825, \"fact\": 7.270589900870376, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:24:00\", \"yhat\": 7.453530247962691, \"yhat_lower\": 6.900055050587304, \"yhat_upper\": 8.078388014673807, \"fact\": 7.166069908720111, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:25:00\", \"yhat\": 7.341017299196498, \"yhat_lower\": 6.816223900665392, \"yhat_upper\": 7.904981147993691, \"fact\": 7.084649033319625, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:26:00\", \"yhat\": 7.311990409361209, \"yhat_lower\": 6.7911221691770685, \"yhat_upper\": 7.862852600624656, \"fact\": 6.953837567532185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:27:00\", \"yhat\": 7.2829635195259215, \"yhat_lower\": 6.759646442385876, \"yhat_upper\": 7.822096523601909, \"fact\": 6.9788882663663205, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:28:00\", \"yhat\": 7.253936629690635, \"yhat_lower\": 6.703778166787607, \"yhat_upper\": 7.809413009811246, \"fact\": 7.166048798085546, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:29:00\", \"yhat\": 7.224909739855346, \"yhat_lower\": 6.696820450825303, \"yhat_upper\": 7.76485200357573, \"fact\": 7.397644550791485, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:30:00\", \"yhat\": 7.111046612206254, \"yhat_lower\": 6.623004646897468, \"yhat_upper\": 7.584998755709978, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:31:00\", \"yhat\": 7.0803946269283555, \"yhat_lower\": 6.608217268391012, \"yhat_upper\": 7.603231168711064, \"fact\": 7.244896929081159, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:32:00\", \"yhat\": 7.04974264165045, \"yhat_lower\": 6.55328865091066, \"yhat_upper\": 7.610602454321058, \"fact\": 7.163683211087717, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:33:00\", \"yhat\": 7.01909065637255, \"yhat_lower\": 6.556612674182462, \"yhat_upper\": 7.523413045373181, \"fact\": 6.997342471102844, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:34:00\", \"yhat\": 6.988438671094648, \"yhat_lower\": 6.4860269502342565, \"yhat_upper\": 7.4734004438777815, \"fact\": 6.910312134996908, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:35:00\", \"yhat\": 6.91761028625125, \"yhat_lower\": 6.44129447581451, \"yhat_upper\": 7.393743527977997, \"fact\": 6.920281767120731, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:36:00\", \"yhat\": 6.886009254251673, \"yhat_lower\": 6.4113484263359855, \"yhat_upper\": 7.332645257306482, \"fact\": 7.005098218639339, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:37:00\", \"yhat\": 6.8544082222520935, \"yhat_lower\": 6.416287371297286, \"yhat_upper\": 7.314359724610084, \"fact\": 7.073528376327899, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:38:00\", \"yhat\": 6.822807190252517, \"yhat_lower\": 6.3631630730874305, \"yhat_upper\": 7.33553022194231, \"fact\": 7.092071643143026, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:39:00\", \"yhat\": 6.791206158252938, \"yhat_lower\": 6.330088550434519, \"yhat_upper\": 7.250938874117, \"fact\": 7.2003894873370955, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:40:00\", \"yhat\": 6.738995543446881, \"yhat_lower\": 6.302904652969011, \"yhat_upper\": 7.232607551516974, \"fact\": 7.29287665449782, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:41:00\", \"yhat\": 6.706531865831485, \"yhat_lower\": 6.232571322392912, \"yhat_upper\": 7.16235934178656, \"fact\": 7.219469085171615, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:42:00\", \"yhat\": 6.674068188216088, \"yhat_lower\": 6.258265270485607, \"yhat_upper\": 7.1376436786627036, \"fact\": 7.191066675166035, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:43:00\", \"yhat\": 6.641604510600692, \"yhat_lower\": 6.189512914777615, \"yhat_upper\": 7.147385244400855, \"fact\": 7.150610552736501, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:44:00\", \"yhat\": 6.609140832985297, \"yhat_lower\": 6.16759671091267, \"yhat_upper\": 7.062710325171424, \"fact\": 7.173786787560158, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:45:00\", \"yhat\": 6.638676242147621, \"yhat_lower\": 6.157991075990711, \"yhat_upper\": 7.148937675582384, \"fact\": 7.165902938765192, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:46:00\", \"yhat\": 6.606655902574046, \"yhat_lower\": 6.139342338515938, \"yhat_upper\": 7.092612801547553, \"fact\": 7.184761105184088, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:47:00\", \"yhat\": 6.574635563000468, \"yhat_lower\": 6.0932996537552935, \"yhat_upper\": 7.070029953775914, \"fact\": 7.095968849846142, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:48:00\", \"yhat\": 6.542615223426893, \"yhat_lower\": 6.051914886313319, \"yhat_upper\": 7.043128567248866, \"fact\": 7.189463215776056, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:49:00\", \"yhat\": 6.510594883853314, \"yhat_lower\": 6.0068489856690945, \"yhat_upper\": 6.998501028353124, \"fact\": 7.2416172252622815, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:50:00\", \"yhat\": 6.573898036193053, \"yhat_lower\": 6.1313262539196725, \"yhat_upper\": 7.04826770319371, \"fact\": 7.289594697210025, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:51:00\", \"yhat\": 6.542963123323405, \"yhat_lower\": 6.074735589755639, \"yhat_upper\": 7.008523156825859, \"fact\": 7.287819788227195, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:52:00\", \"yhat\": 6.512028210453761, \"yhat_lower\": 6.058525557990556, \"yhat_upper\": 6.97148214064932, \"fact\": 7.252759139403707, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:53:00\", \"yhat\": 6.481093297584116, \"yhat_lower\": 6.02541807348493, \"yhat_upper\": 6.948921590429072, \"fact\": 7.312186655332198, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:54:00\", \"yhat\": 6.450158384714471, \"yhat_lower\": 5.943199455998045, \"yhat_upper\": 6.919253662812838, \"fact\": 7.417825510401695, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:55:00\", \"yhat\": 6.561496312373901, \"yhat_lower\": 6.008569105505864, \"yhat_upper\": 7.073155233512346, \"fact\": 7.537862680510393, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:56:00\", \"yhat\": 6.53239269330437, \"yhat_lower\": 5.9955051968543644, \"yhat_upper\": 7.014895833185693, \"fact\": 7.474088346812236, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:57:00\", \"yhat\": 6.5032890742348375, \"yhat_lower\": 5.962721196522892, \"yhat_upper\": 6.993138033518682, \"fact\": 7.353827173698256, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:58:00\", \"yhat\": 6.474185455165305, \"yhat_lower\": 5.901191555263871, \"yhat_upper\": 6.974741020358067, \"fact\": 7.203553863120317, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:59:00\", \"yhat\": 6.445081836095772, \"yhat_lower\": 5.8449466588201355, \"yhat_upper\": 6.976377723172193, \"fact\": 7.1667714268010965, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:00:00\", \"yhat\": 6.518236750732726, \"yhat_lower\": 5.946018147423554, \"yhat_upper\": 7.159878210943049, \"fact\": 7.199926729249083, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:01:00\", \"yhat\": 6.490043370587163, \"yhat_lower\": 5.905858315707741, \"yhat_upper\": 7.086134146046709, \"fact\": 7.017751526939817, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:02:00\", \"yhat\": 6.4618499904416, \"yhat_lower\": 5.90295522931356, \"yhat_upper\": 7.032666072203013, \"fact\": 7.082192901082215, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:03:00\", \"yhat\": 6.433656610296037, \"yhat_lower\": 5.886008213159699, \"yhat_upper\": 6.956656908586401, \"fact\": 7.060415319852113, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:04:00\", \"yhat\": 6.405463230150473, \"yhat_lower\": 5.8407232264352364, \"yhat_upper\": 7.005558343719051, \"fact\": 7.068729453386899, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:05:00\", \"yhat\": 6.488767446775505, \"yhat_lower\": 5.92017434614851, \"yhat_upper\": 7.118918046548412, \"fact\": 7.039528369282021, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:06:00\", \"yhat\": 6.461993219164632, \"yhat_lower\": 5.846629335046613, \"yhat_upper\": 7.100302981966062, \"fact\": 7.033655777722624, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:07:00\", \"yhat\": 6.435218991553755, \"yhat_lower\": 5.87982041828483, \"yhat_upper\": 7.001392359530289, \"fact\": 7.062204617401134, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:08:00\", \"yhat\": 6.4084447639428825, \"yhat_lower\": 5.817132152405417, \"yhat_upper\": 6.904923445587536, \"fact\": 6.993569720043028, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:09:00\", \"yhat\": 6.38167053633201, \"yhat_lower\": 5.856306141038915, \"yhat_upper\": 6.946368251606744, \"fact\": 6.9882948401110525, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:10:00\", \"yhat\": 6.458592220787118, \"yhat_lower\": 5.81141780301464, \"yhat_upper\": 7.052380949993447, \"fact\": 6.8390032876923215, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:11:00\", \"yhat\": 6.433119916054208, \"yhat_lower\": 5.873171970929596, \"yhat_upper\": 7.078012847797866, \"fact\": 6.691998504671839, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:12:00\", \"yhat\": 6.407647611321295, \"yhat_lower\": 5.808308927952229, \"yhat_upper\": 7.006752916985074, \"fact\": 6.752681942577438, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:13:00\", \"yhat\": 6.382175306588385, \"yhat_lower\": 5.800335207614485, \"yhat_upper\": 7.035526860088057, \"fact\": 6.73868451382265, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:14:00\", \"yhat\": 6.356703001855473, \"yhat_lower\": 5.726310096178405, \"yhat_upper\": 6.938533935927566, \"fact\": 6.680331145067498, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:15:00\", \"yhat\": 6.405434880668331, \"yhat_lower\": 5.8344007570339596, \"yhat_upper\": 6.991768148775121, \"fact\": 6.6180921787104054, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:16:00\", \"yhat\": 6.381043952568925, \"yhat_lower\": 5.784482255801548, \"yhat_upper\": 6.974904555497599, \"fact\": 6.6895657202333645, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:17:00\", \"yhat\": 6.356653024469517, \"yhat_lower\": 5.800129791767797, \"yhat_upper\": 6.998323638177441, \"fact\": 6.72316112495938, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:18:00\", \"yhat\": 6.332262096370111, \"yhat_lower\": 5.7940512741871055, \"yhat_upper\": 6.9159632600761185, \"fact\": 6.738952790095521, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:19:00\", \"yhat\": 6.307871168270705, \"yhat_lower\": 5.676210683853358, \"yhat_upper\": 6.927952096018118, \"fact\": 6.664365358351624, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:20:00\", \"yhat\": 6.369075860623301, \"yhat_lower\": 5.837616921141535, \"yhat_upper\": 6.965969747561376, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:21:00\", \"yhat\": 6.346025816376657, \"yhat_lower\": 5.736789886219477, \"yhat_upper\": 6.922504988240872, \"fact\": 6.724600878108458, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:22:00\", \"yhat\": 6.322975772130011, \"yhat_lower\": 5.705574516983221, \"yhat_upper\": 6.85571896469738, \"fact\": 6.580937541938436, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:23:00\", \"yhat\": 6.299925727883366, \"yhat_lower\": 5.723294877977075, \"yhat_upper\": 6.910919505396513, \"fact\": 6.555562177433832, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:24:00\", \"yhat\": 6.27687568363672, \"yhat_lower\": 5.669579212508893, \"yhat_upper\": 6.864048345163709, \"fact\": 6.659379361607502, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:25:00\", \"yhat\": 6.318371726321388, \"yhat_lower\": 5.728181975035238, \"yhat_upper\": 6.802511527723158, \"fact\": 6.375346888821504, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:26:00\", \"yhat\": 6.296312630989526, \"yhat_lower\": 5.684121513190032, \"yhat_upper\": 6.832592786657831, \"fact\": 6.228907112687021, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:27:00\", \"yhat\": 6.2742535356576665, \"yhat_lower\": 5.696057371346161, \"yhat_upper\": 6.826121399118396, \"fact\": 6.35302739173681, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:28:00\", \"yhat\": 6.252194440325807, \"yhat_lower\": 5.743320292590617, \"yhat_upper\": 6.77229644106809, \"fact\": 6.189166144427423, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:29:00\", \"yhat\": 6.230135344993947, \"yhat_lower\": 5.646325783268235, \"yhat_upper\": 6.769193467444064, \"fact\": 6.260671502798964, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:30:00\", \"yhat\": 6.238910271322805, \"yhat_lower\": 5.609144264190328, \"yhat_upper\": 6.824202081087175, \"fact\": 6.171678268702035, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:31:00\", \"yhat\": 6.217504491025063, \"yhat_lower\": 5.735527801656249, \"yhat_upper\": 6.71973847636509, \"fact\": 6.186759614812712, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:32:00\", \"yhat\": 6.19609871072732, \"yhat_lower\": 5.679283267102276, \"yhat_upper\": 6.743496814226547, \"fact\": 6.140920120718393, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:33:00\", \"yhat\": 6.174692930429579, \"yhat_lower\": 5.611414598905765, \"yhat_upper\": 6.76668178715042, \"fact\": 6.2395658921642525, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:34:00\", \"yhat\": 6.153287150131836, \"yhat_lower\": 5.57534324760784, \"yhat_upper\": 6.746112119489736, \"fact\": 6.243797647964152, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:35:00\", \"yhat\": 6.165676598817967, \"yhat_lower\": 5.629421749213169, \"yhat_upper\": 6.6921755677464505, \"fact\": 6.470077371588114, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:36:00\", \"yhat\": 6.144999160830499, \"yhat_lower\": 5.5911187426424265, \"yhat_upper\": 6.689802155251396, \"fact\": 6.60046767084194, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:37:00\", \"yhat\": 6.124321722843027, \"yhat_lower\": 5.593501325260556, \"yhat_upper\": 6.611653096685884, \"fact\": 6.625989069250561, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:38:00\", \"yhat\": 6.103644284855556, \"yhat_lower\": 5.571752724051457, \"yhat_upper\": 6.662085147900715, \"fact\": 6.7475051661190895, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:39:00\", \"yhat\": 6.082966846868085, \"yhat_lower\": 5.547760029753542, \"yhat_upper\": 6.618425401375162, \"fact\": 6.844731750554106, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:40:00\", \"yhat\": 6.1733693815476895, \"yhat_lower\": 5.6002934308763965, \"yhat_upper\": 6.6733064346010575, \"fact\": 6.859763545701101, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:41:00\", \"yhat\": 6.154238700568382, \"yhat_lower\": 5.63127893977024, \"yhat_upper\": 6.661685855453814, \"fact\": 6.807310091228302, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:42:00\", \"yhat\": 6.135108019589075, \"yhat_lower\": 5.63889182750065, \"yhat_upper\": 6.65765303537158, \"fact\": 6.841886616435936, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:43:00\", \"yhat\": 6.115977338609768, \"yhat_lower\": 5.544826813501997, \"yhat_upper\": 6.637442737355108, \"fact\": 6.85893746778489, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:44:00\", \"yhat\": 6.0968466576304605, \"yhat_lower\": 5.52654776213331, \"yhat_upper\": 6.602790816968387, \"fact\": 6.846026479115778, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:45:00\", \"yhat\": 6.230247883402445, \"yhat_lower\": 5.6508875701623635, \"yhat_upper\": 6.75174652515251, \"fact\": 6.883238199122709, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:46:00\", \"yhat\": 6.213308316530373, \"yhat_lower\": 5.712704901759539, \"yhat_upper\": 6.7597952756968365, \"fact\": 6.809841352593101, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:47:00\", \"yhat\": 6.196368749658301, \"yhat_lower\": 5.651747989412673, \"yhat_upper\": 6.697031505584067, \"fact\": 6.751200710300513, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:48:00\", \"yhat\": 6.1794291827862295, \"yhat_lower\": 5.626152121304647, \"yhat_upper\": 6.709355990832785, \"fact\": 6.805567687218024, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:49:00\", \"yhat\": 6.162489615914158, \"yhat_lower\": 5.6587421251591286, \"yhat_upper\": 6.703564951115963, \"fact\": 6.772889900582233, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:50:00\", \"yhat\": 6.277515612553597, \"yhat_lower\": 5.732103303367954, \"yhat_upper\": 6.858839941541504, \"fact\": 6.728335674496716, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:51:00\", \"yhat\": 6.262483184569454, \"yhat_lower\": 5.734030047134737, \"yhat_upper\": 6.7650729210263645, \"fact\": 6.747618665608875, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:52:00\", \"yhat\": 6.247450756585312, \"yhat_lower\": 5.66069432402467, \"yhat_upper\": 6.851727343580302, \"fact\": 6.555395135552946, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:53:00\", \"yhat\": 6.232418328601169, \"yhat_lower\": 5.633396681325324, \"yhat_upper\": 6.829233896388081, \"fact\": 6.593569618569199, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:54:00\", \"yhat\": 6.217385900617026, \"yhat_lower\": 5.706341660942245, \"yhat_upper\": 6.770813359201885, \"fact\": 6.537512510098631, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:55:00\", \"yhat\": 6.310722064778587, \"yhat_lower\": 5.772672417802252, \"yhat_upper\": 6.844727617864523, \"fact\": 6.511672421125268, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:56:00\", \"yhat\": 6.297457920595258, \"yhat_lower\": 5.752831022853284, \"yhat_upper\": 6.880091673668895, \"fact\": 6.631520179746892, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:57:00\", \"yhat\": 6.284193776411929, \"yhat_lower\": 5.761597511900887, \"yhat_upper\": 6.820761719281001, \"fact\": 6.75546745691182, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:58:00\", \"yhat\": 6.2709296322286, \"yhat_lower\": 5.688629265291276, \"yhat_upper\": 6.745107842358461, \"fact\": 6.765024078734705, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:59:00\", \"yhat\": 6.257665488045271, \"yhat_lower\": 5.765545096836638, \"yhat_upper\": 6.810068271720524, \"fact\": 6.798885033129787, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:00:00\", \"yhat\": 6.348616519518929, \"yhat_lower\": 5.79987090427162, \"yhat_upper\": 6.8734345694426535, \"fact\": 6.74534060560366, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:01:00\", \"yhat\": 6.336999064165523, \"yhat_lower\": 5.828868077770514, \"yhat_upper\": 6.886415808437503, \"fact\": 6.872906486758738, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:02:00\", \"yhat\": 6.325381608812116, \"yhat_lower\": 5.7024460169982385, \"yhat_upper\": 6.885183417192731, \"fact\": 6.914632913487516, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:03:00\", \"yhat\": 6.31376415345871, \"yhat_lower\": 5.788463507847222, \"yhat_upper\": 6.835369767135219, \"fact\": 7.086807423198176, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:04:00\", \"yhat\": 6.302146698105304, \"yhat_lower\": 5.7538906954525375, \"yhat_upper\": 6.802332973203898, \"fact\": 7.073886368734035, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:05:00\", \"yhat\": 6.416873727018654, \"yhat_lower\": 5.923104979891344, \"yhat_upper\": 6.955591870086756, \"fact\": 7.020129069863576, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:06:00\", \"yhat\": 6.407063020226271, \"yhat_lower\": 5.883257250171081, \"yhat_upper\": 6.921490386558398, \"fact\": 7.101131503472381, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:07:00\", \"yhat\": 6.3972523134338894, \"yhat_lower\": 5.846559255483309, \"yhat_upper\": 6.8906393025475845, \"fact\": 7.010405102545185, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:08:00\", \"yhat\": 6.387441606641507, \"yhat_lower\": 5.835242424211177, \"yhat_upper\": 6.87582838997653, \"fact\": 6.951266834994014, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:09:00\", \"yhat\": 6.377630899849125, \"yhat_lower\": 5.882141373860259, \"yhat_upper\": 6.936696538775057, \"fact\": 6.963550333967537, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:10:00\", \"yhat\": 6.490125754204046, \"yhat_lower\": 5.935918485726143, \"yhat_upper\": 6.9971637790041274, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:11:00\", \"yhat\": 6.48203341213298, \"yhat_lower\": 5.960900742965638, \"yhat_upper\": 7.012953259005188, \"fact\": 7.031916357257972, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:12:00\", \"yhat\": 6.473941070061912, \"yhat_lower\": 5.913432210088747, \"yhat_upper\": 7.00569434298764, \"fact\": 6.966991581251915, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:13:00\", \"yhat\": 6.4658487279908465, \"yhat_lower\": 5.866597683652364, \"yhat_upper\": 6.960085693185832, \"fact\": 7.1046647071880225, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:14:00\", \"yhat\": 6.457756385919779, \"yhat_lower\": 5.928570163063725, \"yhat_upper\": 7.009419944771202, \"fact\": 7.040671190034965, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:15:00\", \"yhat\": 6.543452948233109, \"yhat_lower\": 6.039523380505979, \"yhat_upper\": 7.0584662086067, \"fact\": 7.190168047613055, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:16:00\", \"yhat\": 6.5366976210245635, \"yhat_lower\": 6.000407971544045, \"yhat_upper\": 7.09380787529094, \"fact\": 7.253047411598573, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:17:00\", \"yhat\": 6.529942293816019, \"yhat_lower\": 5.946472416155883, \"yhat_upper\": 7.033258039563559, \"fact\": 7.2720044758545415, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:18:00\", \"yhat\": 6.523186966607473, \"yhat_lower\": 6.00366379226002, \"yhat_upper\": 7.03291926487234, \"fact\": 7.381451693947673, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:19:00\", \"yhat\": 6.516431639398928, \"yhat_lower\": 5.997121788196181, \"yhat_upper\": 7.0576380250879165, \"fact\": 7.473923616291, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:20:00\", \"yhat\": 6.656732644607852, \"yhat_lower\": 6.168667916750992, \"yhat_upper\": 7.175356140260079, \"fact\": 7.377898618253228, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:21:00\", \"yhat\": 6.651944241402797, \"yhat_lower\": 6.1495591490426715, \"yhat_upper\": 7.187317076729155, \"fact\": 7.4365645152964674, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:22:00\", \"yhat\": 6.647155838197742, \"yhat_lower\": 6.09397924945614, \"yhat_upper\": 7.183046556161606, \"fact\": 7.424375555436707, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:23:00\", \"yhat\": 6.6423674349926864, \"yhat_lower\": 6.067486346188204, \"yhat_upper\": 7.206929779975967, \"fact\": 7.322828741550124, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:24:00\", \"yhat\": 6.637579031787631, \"yhat_lower\": 6.0706270673031035, \"yhat_upper\": 7.1763147068128434, \"fact\": 7.259170692504289, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:25:00\", \"yhat\": 6.771964021445936, \"yhat_lower\": 6.227183986626315, \"yhat_upper\": 7.346424237172875, \"fact\": 7.123867211441125, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:26:00\", \"yhat\": 6.769069000173238, \"yhat_lower\": 6.207747340274179, \"yhat_upper\": 7.317840898375763, \"fact\": 7.120132713051596, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:27:00\", \"yhat\": 6.7661739789005395, \"yhat_lower\": 6.231850746308391, \"yhat_upper\": 7.426089303502437, \"fact\": 7.0565544845028185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:28:00\", \"yhat\": 6.763278957627842, \"yhat_lower\": 6.2336630803870445, \"yhat_upper\": 7.305835866026459, \"fact\": 7.139838404300698, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:29:00\", \"yhat\": 6.760383936355144, \"yhat_lower\": 6.192677748795659, \"yhat_upper\": 7.356576341170348, \"fact\": 7.20277666346131, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:30:00\", \"yhat\": 6.843311540192162, \"yhat_lower\": 6.25539491852788, \"yhat_upper\": 7.423275209755657, \"fact\": 7.040986511007052, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:31:00\", \"yhat\": 6.841746922933681, \"yhat_lower\": 6.2211606999391975, \"yhat_upper\": 7.455683426140256, \"fact\": 7.006594977513499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:32:00\", \"yhat\": 6.840182305675199, \"yhat_lower\": 6.2982971504262055, \"yhat_upper\": 7.3747318365395955, \"fact\": 7.105131073775493, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:33:00\", \"yhat\": 6.8386176884167185, \"yhat_lower\": 6.276437105712251, \"yhat_upper\": 7.407325729320813, \"fact\": 6.966567283612587, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:34:00\", \"yhat\": 6.837053071158237, \"yhat_lower\": 6.2851351183305155, \"yhat_upper\": 7.510323127862269, \"fact\": 7.067989237821224, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:35:00\", \"yhat\": 6.891893326327778, \"yhat_lower\": 6.333709629602724, \"yhat_upper\": 7.448100788342722, \"fact\": 7.134185474168518, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:36:00\", \"yhat\": 6.891278024364434, \"yhat_lower\": 6.38293198996686, \"yhat_upper\": 7.4532464752417775, \"fact\": 7.0416050260755325, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:37:00\", \"yhat\": 6.89066272240109, \"yhat_lower\": 6.336100258777909, \"yhat_upper\": 7.421572943965253, \"fact\": 6.980618485802484, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:38:00\", \"yhat\": 6.890047420437747, \"yhat_lower\": 6.308480766760866, \"yhat_upper\": 7.436368994018163, \"fact\": 7.066809141768836, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:39:00\", \"yhat\": 6.889432118474404, \"yhat_lower\": 6.310245794433997, \"yhat_upper\": 7.405089560731449, \"fact\": 7.191769766968483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:40:00\", \"yhat\": 6.929110964399863, \"yhat_lower\": 6.325198507320823, \"yhat_upper\": 7.4445609949673415, \"fact\": 7.352789477352357, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:41:00\", \"yhat\": 6.929094638349788, \"yhat_lower\": 6.365627395945476, \"yhat_upper\": 7.441855545205153, \"fact\": 7.435857234044891, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:42:00\", \"yhat\": 6.929078312299715, \"yhat_lower\": 6.422412956293233, \"yhat_upper\": 7.49457329106929, \"fact\": 7.224490309562595, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:43:00\", \"yhat\": 6.929061986249641, \"yhat_lower\": 6.4026431846224945, \"yhat_upper\": 7.4922607084509165, \"fact\": 7.123376652717213, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:44:00\", \"yhat\": 6.9290456601995665, \"yhat_lower\": 6.4170870797699155, \"yhat_upper\": 7.432068985070978, \"fact\": 7.0722055728658, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:45:00\", \"yhat\": 6.986662788632522, \"yhat_lower\": 6.420459937798061, \"yhat_upper\": 7.509044235880721, \"fact\": 7.0742890656413255, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:46:00\", \"yhat\": 6.987425907646082, \"yhat_lower\": 6.428609945196617, \"yhat_upper\": 7.6311293480356674, \"fact\": 7.242089094524295, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:47:00\", \"yhat\": 6.988189026659642, \"yhat_lower\": 6.440385539863452, \"yhat_upper\": 7.57105592164751, \"fact\": 7.124376062669945, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:48:00\", \"yhat\": 6.988952145673201, \"yhat_lower\": 6.476225374738309, \"yhat_upper\": 7.617787587612526, \"fact\": 7.211386630870367, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:49:00\", \"yhat\": 6.98971526468676, \"yhat_lower\": 6.402335000229427, \"yhat_upper\": 7.526116211460091, \"fact\": 7.327778305274825, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:50:00\", \"yhat\": 7.040327953538057, \"yhat_lower\": 6.506998340715512, \"yhat_upper\": 7.5570783792342695, \"fact\": 7.114185757892747, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:51:00\", \"yhat\": 7.041848293258926, \"yhat_lower\": 6.522651200979712, \"yhat_upper\": 7.584156508445419, \"fact\": 7.13394669208722, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:52:00\", \"yhat\": 7.043368632979794, \"yhat_lower\": 6.520281718043915, \"yhat_upper\": 7.567573738130294, \"fact\": 6.998725732620053, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:53:00\", \"yhat\": 7.044888972700662, \"yhat_lower\": 6.503225031943927, \"yhat_upper\": 7.5557592260925235, \"fact\": 6.999429650181499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:54:00\", \"yhat\": 7.04640931242153, \"yhat_lower\": 6.533422979261311, \"yhat_upper\": 7.525636865384239, \"fact\": 6.88988017320615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:55:00\", \"yhat\": 7.068151304632034, \"yhat_lower\": 6.51631147742541, \"yhat_upper\": 7.676119168990066, \"fact\": 7.011925284409866, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:56:00\", \"yhat\": 7.070156396900664, \"yhat_lower\": 6.541183311819202, \"yhat_upper\": 7.575843907717882, \"fact\": 7.0993986854425275, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:57:00\", \"yhat\": 7.072161489169293, \"yhat_lower\": 6.552001098871787, \"yhat_upper\": 7.658977665442215, \"fact\": 7.271220399150457, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:58:00\", \"yhat\": 7.074166581437923, \"yhat_lower\": 6.521260453729821, \"yhat_upper\": 7.606775022462101, \"fact\": 7.264494897726525, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:59:00\", \"yhat\": 7.076171673706552, \"yhat_lower\": 6.5223117587183035, \"yhat_upper\": 7.652861637209306, \"fact\": 7.044423132287613, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:00:00\", \"yhat\": 7.11832187312819, \"yhat_lower\": 6.560945404388113, \"yhat_upper\": 7.667708029776471, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:01:00\", \"yhat\": 7.121103111882368, \"yhat_lower\": 6.627582824579409, \"yhat_upper\": 7.651294181959099, \"fact\": 7.021339661711941, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:02:00\", \"yhat\": 7.123884350636546, \"yhat_lower\": 6.603093209251146, \"yhat_upper\": 7.673561173530908, \"fact\": 7.317534903185268, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:03:00\", \"yhat\": 7.126665589390724, \"yhat_lower\": 6.578549159011809, \"yhat_upper\": 7.668073474482719, \"fact\": 7.10716948495657, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:04:00\", \"yhat\": 7.129446828144903, \"yhat_lower\": 6.6214583882986275, \"yhat_upper\": 7.633661783394348, \"fact\": 7.215310153650435, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:05:00\", \"yhat\": 7.161984072179014, \"yhat_lower\": 6.643744756265082, \"yhat_upper\": 7.732835133867433, \"fact\": 7.220570452422764, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:06:00\", \"yhat\": 7.165342312888633, \"yhat_lower\": 6.617096922464014, \"yhat_upper\": 7.711520597336798, \"fact\": 7.103080980776757, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:07:00\", \"yhat\": 7.16870055359825, \"yhat_lower\": 6.658779685546905, \"yhat_upper\": 7.653939423686793, \"fact\": 7.050846940115519, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:08:00\", \"yhat\": 7.172058794307867, \"yhat_lower\": 6.671271698247327, \"yhat_upper\": 7.728816611592979, \"fact\": 6.939961443394882, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:09:00\", \"yhat\": 7.175417035017484, \"yhat_lower\": 6.6000596871554675, \"yhat_upper\": 7.699997246739782, \"fact\": 6.998102784901203, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:10:00\", \"yhat\": 7.194843411667347, \"yhat_lower\": 6.635870126882315, \"yhat_upper\": 7.750177112763163, \"fact\": 7.099749789012837, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:11:00\", \"yhat\": 7.198721064139031, \"yhat_lower\": 6.665701053921604, \"yhat_upper\": 7.724274564194186, \"fact\": 7.235330438059645, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:12:00\", \"yhat\": 7.202598716610716, \"yhat_lower\": 6.628763262107656, \"yhat_upper\": 7.67348399885847, \"fact\": 7.338052774675268, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:13:00\", \"yhat\": 7.2064763690824, \"yhat_lower\": 6.658351663863388, \"yhat_upper\": 7.691735412612723, \"fact\": 7.288772432558911, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:14:00\", \"yhat\": 7.210354021554085, \"yhat_lower\": 6.684425479957183, \"yhat_upper\": 7.7370263307869145, \"fact\": 7.324544402704568, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:15:00\", \"yhat\": 7.266513797055888, \"yhat_lower\": 6.808054784494294, \"yhat_upper\": 7.791733459834732, \"fact\": 7.121821576872811, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:16:00\", \"yhat\": 7.271434291513951, \"yhat_lower\": 6.787498275102295, \"yhat_upper\": 7.76851365004242, \"fact\": 7.287459513397984, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:17:00\", \"yhat\": 7.276354785972014, \"yhat_lower\": 6.784946429418977, \"yhat_upper\": 7.749520693710653, \"fact\": 7.314871558542801, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:18:00\", \"yhat\": 7.281275280430078, \"yhat_lower\": 6.809427622026922, \"yhat_upper\": 7.819224303497808, \"fact\": 7.415176143796352, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:19:00\", \"yhat\": 7.286195774888141, \"yhat_lower\": 6.786815068841011, \"yhat_upper\": 7.736914398193088, \"fact\": 7.516025127146469, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:20:00\", \"yhat\": 7.333154796597951, \"yhat_lower\": 6.8507843210210995, \"yhat_upper\": 7.79052758142366, \"fact\": 7.6050364669125985, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:21:00\", \"yhat\": 7.338913339014317, \"yhat_lower\": 6.810629516662267, \"yhat_upper\": 7.835059042582909, \"fact\": 7.566205083257227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:22:00\", \"yhat\": 7.344671881430684, \"yhat_lower\": 6.893967695611882, \"yhat_upper\": 7.841694676841951, \"fact\": 7.729722886759445, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:23:00\", \"yhat\": 7.350430423847049, \"yhat_lower\": 6.890253041103809, \"yhat_upper\": 7.814418672647727, \"fact\": 7.763741051140791, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:24:00\", \"yhat\": 7.356188966263416, \"yhat_lower\": 6.923221989822984, \"yhat_upper\": 7.933897481516081, \"fact\": 7.791223704044699, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:25:00\", \"yhat\": 7.441600253902873, \"yhat_lower\": 6.9665411529242425, \"yhat_upper\": 7.891014525109182, \"fact\": 8.00363971231057, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:26:00\", \"yhat\": 7.448542524592189, \"yhat_lower\": 6.995449514110212, \"yhat_upper\": 7.9043720433563935, \"fact\": 7.849663097795245, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:27:00\", \"yhat\": 7.455484795281505, \"yhat_lower\": 7.010506158809517, \"yhat_upper\": 7.953224353593796, \"fact\": 7.787666292025311, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:28:00\", \"yhat\": 7.46242706597082, \"yhat_lower\": 6.99736529118707, \"yhat_upper\": 7.972579448923942, \"fact\": 7.948607630624028, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:29:00\", \"yhat\": 7.469369336660136, \"yhat_lower\": 7.001776110878833, \"yhat_upper\": 7.997542605701324, \"fact\": 8.10370677263385, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:30:00\", \"yhat\": 7.562262913334783, \"yhat_lower\": 7.072805103237986, \"yhat_upper\": 8.029561908055324, \"fact\": 7.939931606789101, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:31:00\", \"yhat\": 7.570334466602441, \"yhat_lower\": 7.0604643245640455, \"yhat_upper\": 8.066583165325037, \"fact\": 8.01138413900431, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:32:00\", \"yhat\": 7.5784060198700995, \"yhat_lower\": 7.094935904491729, \"yhat_upper\": 8.121823874316341, \"fact\": 8.024263331132907, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:33:00\", \"yhat\": 7.586477573137756, \"yhat_lower\": 7.103644463503989, \"yhat_upper\": 8.076668168177017, \"fact\": 8.02728778518364, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:34:00\", \"yhat\": 7.594549126405413, \"yhat_lower\": 7.1129191480053136, \"yhat_upper\": 8.070040619099538, \"fact\": 8.145123103951551, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:35:00\", \"yhat\": 7.681658782793313, \"yhat_lower\": 7.213221537798087, \"yhat_upper\": 8.140104839873622, \"fact\": 8.346190638990999, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:36:00\", \"yhat\": 7.690770633510965, \"yhat_lower\": 7.152445207293392, \"yhat_upper\": 8.168362903788191, \"fact\": 8.422543666781964, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:37:00\", \"yhat\": 7.699882484228617, \"yhat_lower\": 7.1587163314658175, \"yhat_upper\": 8.207881911797879, \"fact\": 8.459908928046268, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:38:00\", \"yhat\": 7.70899433494627, \"yhat_lower\": 7.245776368423086, \"yhat_upper\": 8.237724083165327, \"fact\": 8.455258423436057, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:39:00\", \"yhat\": 7.71810618566392, \"yhat_lower\": 7.18985044213105, \"yhat_upper\": 8.162824034215868, \"fact\": 8.556138297516846, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:40:00\", \"yhat\": 7.8358289639358105, \"yhat_lower\": 7.258101196378829, \"yhat_upper\": 8.40555792461566, \"fact\": 8.519475678661328, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:41:00\", \"yhat\": 7.846145961615911, \"yhat_lower\": 7.313907369109539, \"yhat_upper\": 8.394911681679416, \"fact\": 8.41012741828165, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:42:00\", \"yhat\": 7.856462959296011, \"yhat_lower\": 7.326829943773933, \"yhat_upper\": 8.433110603051192, \"fact\": 8.331208792762425, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:43:00\", \"yhat\": 7.866779956976112, \"yhat_lower\": 7.360029895328991, \"yhat_upper\": 8.421081304009354, \"fact\": 8.236846240515225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:44:00\", \"yhat\": 7.877096954656212, \"yhat_lower\": 7.322644605915213, \"yhat_upper\": 8.413904953284623, \"fact\": 8.256041617140585, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:45:00\", \"yhat\": 7.953556208194658, \"yhat_lower\": 7.388421428488658, \"yhat_upper\": 8.472466092037724, \"fact\": 8.380900569385801, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:46:00\", \"yhat\": 7.964524704606791, \"yhat_lower\": 7.408898604299068, \"yhat_upper\": 8.576995979638907, \"fact\": 8.283185908846015, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:47:00\", \"yhat\": 7.975493201018925, \"yhat_lower\": 7.445983157925619, \"yhat_upper\": 8.549521528846652, \"fact\": 8.19681328000246, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:48:00\", \"yhat\": 7.98646169743106, \"yhat_lower\": 7.440099292150773, \"yhat_upper\": 8.491368746532885, \"fact\": 8.268775956135276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:49:00\", \"yhat\": 7.997430193843193, \"yhat_lower\": 7.4485034713293325, \"yhat_upper\": 8.52627345283565, \"fact\": 8.42869425982205, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:50:00\", \"yhat\": 8.055576873600153, \"yhat_lower\": 7.5505931539661555, \"yhat_upper\": 8.559969408768378, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:51:00\", \"yhat\": 8.067092195709584, \"yhat_lower\": 7.5571753845390175, \"yhat_upper\": 8.579337522603865, \"fact\": 8.475701630597108, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:52:00\", \"yhat\": 8.078607517819016, \"yhat_lower\": 7.4503841722878645, \"yhat_upper\": 8.628498314699392, \"fact\": 8.648756666874846, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:53:00\", \"yhat\": 8.090122839928448, \"yhat_lower\": 7.596539291262366, \"yhat_upper\": 8.645970004088397, \"fact\": 8.687765792214106, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:54:00\", \"yhat\": 8.101638162037883, \"yhat_lower\": 7.524931501623367, \"yhat_upper\": 8.610120334279765, \"fact\": 8.748978959879818, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:55:00\", \"yhat\": 8.189069209178475, \"yhat_lower\": 7.680639686972964, \"yhat_upper\": 8.746702477261046, \"fact\": 8.799798123977336, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:56:00\", \"yhat\": 8.201452295030416, \"yhat_lower\": 7.597889355342116, \"yhat_upper\": 8.699039497924014, \"fact\": 8.712653545197707, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:57:00\", \"yhat\": 8.213835380882355, \"yhat_lower\": 7.6700127792320325, \"yhat_upper\": 8.757749984637162, \"fact\": 8.7413195426343, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:58:00\", \"yhat\": 8.226218466734295, \"yhat_lower\": 7.6984281950199325, \"yhat_upper\": 8.788914770537321, \"fact\": 8.735522823807608, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:59:00\", \"yhat\": 8.238601552586234, \"yhat_lower\": 7.681374963463389, \"yhat_upper\": 8.772181495001483, \"fact\": 8.755033678541, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:00:00\", \"yhat\": 8.347086848218272, \"yhat_lower\": 7.822433697027137, \"yhat_upper\": 8.935566691392399, \"fact\": 8.697623905237386, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:01:00\", \"yhat\": 8.360723004335664, \"yhat_lower\": 7.81546474470819, \"yhat_upper\": 8.923337822232378, \"fact\": 8.732542420245244, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:02:00\", \"yhat\": 8.374359160453057, \"yhat_lower\": 7.761425055549967, \"yhat_upper\": 8.939358357284874, \"fact\": 8.667663294380052, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:03:00\", \"yhat\": 8.38799531657045, \"yhat_lower\": 7.840476634961649, \"yhat_upper\": 8.961077435837518, \"fact\": 8.74224875192919, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:04:00\", \"yhat\": 8.401631472687843, \"yhat_lower\": 7.866307438739334, \"yhat_upper\": 8.953026681188705, \"fact\": 8.813368356071924, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:05:00\", \"yhat\": 8.476246389376694, \"yhat_lower\": 7.919578408460325, \"yhat_upper\": 9.035123614072837, \"fact\": 8.763653819520787, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:06:00\", \"yhat\": 8.490660489607272, \"yhat_lower\": 7.998328860389467, \"yhat_upper\": 9.090334186115374, \"fact\": 8.727719225687869, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:07:00\", \"yhat\": 8.50507458983785, \"yhat_lower\": 7.971555621695731, \"yhat_upper\": 9.02267908729101, \"fact\": 8.757287262181396, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:08:00\", \"yhat\": 8.519488690068428, \"yhat_lower\": 7.925185386494896, \"yhat_upper\": 9.078181529164482, \"fact\": 8.58461198633341, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:09:00\", \"yhat\": 8.533902790299006, \"yhat_lower\": 7.935340377290877, \"yhat_upper\": 9.062923964764959, \"fact\": 8.580523889099103, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:10:00\", \"yhat\": 8.583689707525437, \"yhat_lower\": 8.02919913449831, \"yhat_upper\": 9.110786340606383, \"fact\": 8.729985918072733, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:11:00\", \"yhat\": 8.598556114836583, \"yhat_lower\": 8.026714788574232, \"yhat_upper\": 9.12982030992444, \"fact\": 8.715254942693004, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:12:00\", \"yhat\": 8.613422522147728, \"yhat_lower\": 8.013776623050099, \"yhat_upper\": 9.185813078116317, \"fact\": 8.657186335028134, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:13:00\", \"yhat\": 8.62828892945887, \"yhat_lower\": 8.085555598602387, \"yhat_upper\": 9.185941573444074, \"fact\": 8.715123818586068, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:14:00\", \"yhat\": 8.643155336770016, \"yhat_lower\": 8.148965821104174, \"yhat_upper\": 9.21998573411787, \"fact\": 8.803699468934434, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:15:00\", \"yhat\": 8.69210355785946, \"yhat_lower\": 8.086418285202368, \"yhat_upper\": 9.24378058753363, \"fact\": 8.770428664936265, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:16:00\", \"yhat\": 8.707516938617939, \"yhat_lower\": 8.172616397305655, \"yhat_upper\": 9.298639262838387, \"fact\": 8.68461158678178, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:17:00\", \"yhat\": 8.72293031937642, \"yhat_lower\": 8.230705498621617, \"yhat_upper\": 9.257798423531758, \"fact\": 8.571580251558387, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:18:00\", \"yhat\": 8.7383437001349, \"yhat_lower\": 8.160292134499093, \"yhat_upper\": 9.265225984969174, \"fact\": 8.629115838099489, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:19:00\", \"yhat\": 8.75375708089338, \"yhat_lower\": 8.164504998212019, \"yhat_upper\": 9.304374574904452, \"fact\": 8.680104200208032, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:20:00\", \"yhat\": 8.783402526488135, \"yhat_lower\": 8.314866024717917, \"yhat_upper\": 9.292906829209526, \"fact\": 8.720381281982103, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:21:00\", \"yhat\": 8.799230984437786, \"yhat_lower\": 8.23642791635267, \"yhat_upper\": 9.356485036641976, \"fact\": 8.674145386553628, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:22:00\", \"yhat\": 8.815059442387437, \"yhat_lower\": 8.267002675691955, \"yhat_upper\": 9.333661060603411, \"fact\": 8.645195557966613, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:23:00\", \"yhat\": 8.830887900337087, \"yhat_lower\": 8.338459367849916, \"yhat_upper\": 9.403359639499993, \"fact\": 8.542567468006013, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:24:00\", \"yhat\": 8.846716358286738, \"yhat_lower\": 8.286360851500296, \"yhat_upper\": 9.38026192954718, \"fact\": 8.614450952639153, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:25:00\", \"yhat\": 8.859510573246947, \"yhat_lower\": 8.366551199181913, \"yhat_upper\": 9.381115873338366, \"fact\": 8.600759594883009, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:26:00\", \"yhat\": 8.875527796912952, \"yhat_lower\": 8.315183018669083, \"yhat_upper\": 9.424050932401085, \"fact\": 8.344461174673786, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:27:00\", \"yhat\": 8.891545020578958, \"yhat_lower\": 8.399276300708067, \"yhat_upper\": 9.423284548034756, \"fact\": 8.345833211443853, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:28:00\", \"yhat\": 8.907562244244962, \"yhat_lower\": 8.37111057385977, \"yhat_upper\": 9.422307079282845, \"fact\": 8.308939856017505, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:29:00\", \"yhat\": 8.923579467910967, \"yhat_lower\": 8.406767588772396, \"yhat_upper\": 9.458028997612596, \"fact\": 8.288296800857225, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:30:00\", \"yhat\": 8.885104681947984, \"yhat_lower\": 8.348123176265172, \"yhat_upper\": 9.362688586382857, \"fact\": 8.200204061185255, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:31:00\", \"yhat\": 8.90072860141659, \"yhat_lower\": 8.400359446480206, \"yhat_upper\": 9.393457073727841, \"fact\": 8.316763381802183, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:32:00\", \"yhat\": 8.916352520885196, \"yhat_lower\": 8.3387233943113, \"yhat_upper\": 9.411965955598866, \"fact\": 8.213260542060581, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:33:00\", \"yhat\": 8.9319764403538, \"yhat_lower\": 8.417882878004404, \"yhat_upper\": 9.450644102489388, \"fact\": 8.100444362690379, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:34:00\", \"yhat\": 8.947600359822406, \"yhat_lower\": 8.403533839897207, \"yhat_upper\": 9.475451339159823, \"fact\": 8.166018118282045, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:35:00\", \"yhat\": 8.878005283126727, \"yhat_lower\": 8.338655477761147, \"yhat_upper\": 9.424311423748733, \"fact\": 8.133296418077531, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:36:00\", \"yhat\": 8.892899912045017, \"yhat_lower\": 8.35379147741493, \"yhat_upper\": 9.41421195218914, \"fact\": 8.2170409947153, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:37:00\", \"yhat\": 8.907794540963307, \"yhat_lower\": 8.338645755201, \"yhat_upper\": 9.42928583513676, \"fact\": 8.174451684276958, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:38:00\", \"yhat\": 8.922689169881599, \"yhat_lower\": 8.361914069431117, \"yhat_upper\": 9.50017527292884, \"fact\": 8.145406367187972, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:39:00\", \"yhat\": 8.937583798799889, \"yhat_lower\": 8.435212480535018, \"yhat_upper\": 9.547162823159443, \"fact\": 8.179618234404483, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:40:00\", \"yhat\": 8.860186472999196, \"yhat_lower\": 8.246907562511405, \"yhat_upper\": 9.472134153006735, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:41:00\", \"yhat\": 8.874262963560916, \"yhat_lower\": 8.304710365200487, \"yhat_upper\": 9.457509338995377, \"fact\": 8.079524030680783, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:42:00\", \"yhat\": 8.88833945412264, \"yhat_lower\": 8.276024129931786, \"yhat_upper\": 9.488996019324667, \"fact\": 8.044864923024296, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:43:00\", \"yhat\": 8.902415944684362, \"yhat_lower\": 8.300770007141038, \"yhat_upper\": 9.492226774072448, \"fact\": 7.985665500760242, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:44:00\", \"yhat\": 8.916492435246086, \"yhat_lower\": 8.316634529758382, \"yhat_upper\": 9.493249072365597, \"fact\": 8.046488503559157, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:45:00\", \"yhat\": 8.839186488581527, \"yhat_lower\": 8.25825644394283, \"yhat_upper\": 9.426561642130395, \"fact\": 7.987912077062759, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:46:00\", \"yhat\": 8.852372983907157, \"yhat_lower\": 8.21269367250712, \"yhat_upper\": 9.472124622543557, \"fact\": 7.950148874417816, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:47:00\", \"yhat\": 8.86555947923279, \"yhat_lower\": 8.256477336237364, \"yhat_upper\": 9.45711814763116, \"fact\": 8.068015846901767, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:48:00\", \"yhat\": 8.87874597455842, \"yhat_lower\": 8.356274939150252, \"yhat_upper\": 9.510387770749686, \"fact\": 8.09246969731638, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:49:00\", \"yhat\": 8.891932469884049, \"yhat_lower\": 8.321843439790046, \"yhat_upper\": 9.497059844961603, \"fact\": 8.019705123658905, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:50:00\", \"yhat\": 8.776673260843316, \"yhat_lower\": 8.166502305051383, \"yhat_upper\": 9.399452625934941, \"fact\": 8.06028447175568, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:51:00\", \"yhat\": 8.788458559041583, \"yhat_lower\": 8.180986091712086, \"yhat_upper\": 9.505778759518698, \"fact\": 8.006729199085527, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:52:00\", \"yhat\": 8.80024385723985, \"yhat_lower\": 8.157531777717914, \"yhat_upper\": 9.495394850039432, \"fact\": 7.884033492434073, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:53:00\", \"yhat\": 8.812029155438118, \"yhat_lower\": 8.187839805734223, \"yhat_upper\": 9.419939677547662, \"fact\": 8.046823619428089, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:54:00\", \"yhat\": 8.823814453636386, \"yhat_lower\": 8.11727143456582, \"yhat_upper\": 9.512571913086923, \"fact\": 7.942622275786526, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:55:00\", \"yhat\": 8.728328882974537, \"yhat_lower\": 8.09320232026054, \"yhat_upper\": 9.395505684744627, \"fact\": 8.107336569826192, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:56:00\", \"yhat\": 8.739066573487724, \"yhat_lower\": 8.052565010963995, \"yhat_upper\": 9.378879141497357, \"fact\": 8.118646844437311, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:57:00\", \"yhat\": 8.74980426400091, \"yhat_lower\": 8.122368107300325, \"yhat_upper\": 9.374928825709377, \"fact\": 8.101259000219994, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:58:00\", \"yhat\": 8.760541954514096, \"yhat_lower\": 8.135595390144667, \"yhat_upper\": 9.39320621354414, \"fact\": 7.975741033032815, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:59:00\", \"yhat\": 8.771279645027281, \"yhat_lower\": 8.03227140632031, \"yhat_upper\": 9.45857013951157, \"fact\": 7.988226254020678, \"anomaly\": 1}, {\"ds\": \"2021-08-23T22:00:00\", \"yhat\": 8.708070526410403, \"yhat_lower\": 8.050071967430679, \"yhat_upper\": 9.379216506335705, \"fact\": 8.062133599963992, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:01:00\", \"yhat\": 8.718219789655274, \"yhat_lower\": 8.059950588696648, \"yhat_upper\": 9.400786519855092, \"fact\": 8.023293650410814, \"anomaly\": 1}, {\"ds\": \"2021-08-23T22:02:00\", \"yhat\": 8.728369052900145, \"yhat_lower\": 8.091888710068515, \"yhat_upper\": 9.477491463550109, \"fact\": 7.840974331834362, \"anomaly\": 1}, {\"ds\": \"2021-08-23T22:03:00\", \"yhat\": 8.738518316145015, \"yhat_lower\": 8.001409781733233, \"yhat_upper\": 9.430405302138702, \"fact\": 7.651628623492227, \"anomaly\": 1}, {\"ds\": \"2021-08-23T22:04:00\", \"yhat\": 8.748667579389886, \"yhat_lower\": 8.093246486762494, \"yhat_upper\": 9.371177976080025, \"fact\": 7.656945468320031, \"anomaly\": 1}, {\"ds\": \"2021-08-23T22:05:00\", \"yhat\": 8.610851545371188, \"yhat_lower\": 7.9373407858654055, \"yhat_upper\": 9.282000143907794, \"fact\": 7.567227283798734, \"anomaly\": 1}, {\"ds\": \"2021-08-23T22:06:00\", \"yhat\": 8.619308802404564, \"yhat_lower\": 7.898160837067203, \"yhat_upper\": 9.264237086431503, \"fact\": 7.485420053891467, \"anomaly\": 1}, {\"ds\": \"2021-08-23T22:07:00\", \"yhat\": 8.62776605943794, \"yhat_lower\": 7.894938090051737, \"yhat_upper\": 9.338629380811405, \"fact\": 7.453326960684346, \"anomaly\": 1}, {\"ds\": \"2021-08-23T22:08:00\", \"yhat\": 8.636223316471318, \"yhat_lower\": 7.935645579055604, \"yhat_upper\": 9.312749934385678, \"fact\": 7.5675711212537005, \"anomaly\": 1}, {\"ds\": \"2021-08-23T22:09:00\", \"yhat\": 8.644680573504692, \"yhat_lower\": 7.945108519790623, \"yhat_upper\": 9.402990507510104, \"fact\": 7.59136442192483, \"anomaly\": 1}, {\"ds\": \"2021-08-23T22:10:00\", \"yhat\": 8.451056946076758, \"yhat_lower\": 7.802957495479487, \"yhat_upper\": 9.152669595480148, \"fact\": 7.819711007934736, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:11:00\", \"yhat\": 8.456879859701154, \"yhat_lower\": 7.8023485335973914, \"yhat_upper\": 9.123403135505475, \"fact\": 7.983399267364478, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:12:00\", \"yhat\": 8.462702773325551, \"yhat_lower\": 7.758411782037537, \"yhat_upper\": 9.20749246477543, \"fact\": 7.958116508233395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:13:00\", \"yhat\": 8.468525686949949, \"yhat_lower\": 7.697949609905448, \"yhat_upper\": 9.161630421808495, \"fact\": 7.968943931383387, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:14:00\", \"yhat\": 8.474348600574347, \"yhat_lower\": 7.755732733672537, \"yhat_upper\": 9.217059046268856, \"fact\": 8.088943997843543, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:15:00\", \"yhat\": 8.346218764451846, \"yhat_lower\": 7.6629389311597045, \"yhat_upper\": 9.032946257328117, \"fact\": 7.94868555720843, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:16:00\", \"yhat\": 8.349922325992406, \"yhat_lower\": 7.657003986056391, \"yhat_upper\": 8.989569507659512, \"fact\": 8.031676300784632, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:17:00\", \"yhat\": 8.353625887532965, \"yhat_lower\": 7.673277231758184, \"yhat_upper\": 9.025504978803564, \"fact\": 7.919155930994936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:18:00\", \"yhat\": 8.357329449073525, \"yhat_lower\": 7.682900971894503, \"yhat_upper\": 9.027669121943939, \"fact\": 7.860433362299011, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:19:00\", \"yhat\": 8.361033010614085, \"yhat_lower\": 7.637103996323685, \"yhat_upper\": 9.046910707365022, \"fact\": 7.887708781348885, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:20:00\", \"yhat\": 8.2212083108917, \"yhat_lower\": 7.531288840629488, \"yhat_upper\": 8.893349168061839, \"fact\": 7.95518511616727, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:21:00\", \"yhat\": 8.222452007359095, \"yhat_lower\": 7.618183307310904, \"yhat_upper\": 8.929450639316652, \"fact\": 8.031980714285634, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:22:00\", \"yhat\": 8.22369570382649, \"yhat_lower\": 7.515341854333403, \"yhat_upper\": 8.899236598445272, \"fact\": 7.986336725108602, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:23:00\", \"yhat\": 8.224939400293884, \"yhat_lower\": 7.566477834688715, \"yhat_upper\": 8.950762363295482, \"fact\": 7.9750917218656125, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:24:00\", \"yhat\": 8.22618309676128, \"yhat_lower\": 7.611807036245853, \"yhat_upper\": 8.898333220087881, \"fact\": 7.88889753640553, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:25:00\", \"yhat\": 8.06674401078142, \"yhat_lower\": 7.505273505911564, \"yhat_upper\": 8.642747157868035, \"fact\": 7.99517540935556, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:26:00\", \"yhat\": 8.064801754136132, \"yhat_lower\": 7.541849113167768, \"yhat_upper\": 8.658120942732484, \"fact\": 8.048314544065995, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:27:00\", \"yhat\": 8.062859497490845, \"yhat_lower\": 7.519278223778483, \"yhat_upper\": 8.59759282012534, \"fact\": 7.831803761276401, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:28:00\", \"yhat\": 8.060917240845555, \"yhat_lower\": 7.504786832147551, \"yhat_upper\": 8.658515481441151, \"fact\": 7.813286153136449, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:29:00\", \"yhat\": 8.058974984200267, \"yhat_lower\": 7.507540470531026, \"yhat_upper\": 8.593592077867326, \"fact\": 7.800293226728714, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:30:00\", \"yhat\": 7.95282909228629, \"yhat_lower\": 7.437466966680409, \"yhat_upper\": 8.517129780236267, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:31:00\", \"yhat\": 7.948803913440249, \"yhat_lower\": 7.411687000834916, \"yhat_upper\": 8.531342483573125, \"fact\": 7.568500650268759, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:32:00\", \"yhat\": 7.944778734594205, \"yhat_lower\": 7.3882865829195286, \"yhat_upper\": 8.492387282102019, \"fact\": 7.485083521432123, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:33:00\", \"yhat\": 7.940753555748163, \"yhat_lower\": 7.357213410287356, \"yhat_upper\": 8.44402973557609, \"fact\": 7.562902259069609, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:34:00\", \"yhat\": 7.936728376902121, \"yhat_lower\": 7.43736433222985, \"yhat_upper\": 8.500382214941341, \"fact\": 7.774237559343768, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:35:00\", \"yhat\": 7.8267962781462685, \"yhat_lower\": 7.326673649522851, \"yhat_upper\": 8.2911803059356, \"fact\": 7.84399038958902, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:36:00\", \"yhat\": 7.820862060490238, \"yhat_lower\": 7.34987726235113, \"yhat_upper\": 8.34109173664065, \"fact\": 7.703560195883743, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:37:00\", \"yhat\": 7.814927842834207, \"yhat_lower\": 7.372230050175148, \"yhat_upper\": 8.28435696859054, \"fact\": 7.580990260422031, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:38:00\", \"yhat\": 7.808993625178177, \"yhat_lower\": 7.355171184506618, \"yhat_upper\": 8.36248133299969, \"fact\": 7.536262826528088, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:39:00\", \"yhat\": 7.803059407522146, \"yhat_lower\": 7.300984482578756, \"yhat_upper\": 8.260903730558324, \"fact\": 7.479715123694341, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:40:00\", \"yhat\": 7.701991230539838, \"yhat_lower\": 7.252363939852985, \"yhat_upper\": 8.202450017512144, \"fact\": 7.547983789043043, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:41:00\", \"yhat\": 7.6942285216789195, \"yhat_lower\": 7.24434839615693, \"yhat_upper\": 8.150098397332702, \"fact\": 7.661272545133261, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:42:00\", \"yhat\": 7.686465812818, \"yhat_lower\": 7.288793512655571, \"yhat_upper\": 8.104968952336588, \"fact\": 7.799921735142088, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:43:00\", \"yhat\": 7.678703103957082, \"yhat_lower\": 7.252006635094755, \"yhat_upper\": 8.111991420223939, \"fact\": 7.90744271501311, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:44:00\", \"yhat\": 7.670940395096163, \"yhat_lower\": 7.245753074950463, \"yhat_upper\": 8.107392387692645, \"fact\": 7.9914944717499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:45:00\", \"yhat\": 7.641676978088506, \"yhat_lower\": 7.244558977745912, \"yhat_upper\": 8.015796273285913, \"fact\": 8.078038554719182, \"anomaly\": 1}, {\"ds\": \"2021-08-23T22:46:00\", \"yhat\": 7.633260559616948, \"yhat_lower\": 7.2587927813857345, \"yhat_upper\": 8.051367596940684, \"fact\": 7.887233092209016, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:47:00\", \"yhat\": 7.62484414114539, \"yhat_lower\": 7.209991313003486, \"yhat_upper\": 8.028465456164547, \"fact\": 7.727544853299987, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:48:00\", \"yhat\": 7.616427722673833, \"yhat_lower\": 7.176361659692317, \"yhat_upper\": 7.99000187682177, \"fact\": 7.797725220766124, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:49:00\", \"yhat\": 7.608011304202275, \"yhat_lower\": 7.216217073282192, \"yhat_upper\": 8.05152394239227, \"fact\": 7.873085248908442, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:50:00\", \"yhat\": 7.591456337013657, \"yhat_lower\": 7.114469097408339, \"yhat_upper\": 8.001471275570383, \"fact\": 7.980822066822155, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:51:00\", \"yhat\": 7.582412760718312, \"yhat_lower\": 7.157214055146166, \"yhat_upper\": 8.044323650059408, \"fact\": 7.734172080818521, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:52:00\", \"yhat\": 7.573369184422969, \"yhat_lower\": 7.115197184388591, \"yhat_upper\": 8.006468855945513, \"fact\": 7.599489257353818, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:53:00\", \"yhat\": 7.564325608127627, \"yhat_lower\": 7.113589884751439, \"yhat_upper\": 7.976972138010895, \"fact\": 7.722687896015395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:54:00\", \"yhat\": 7.555282031832282, \"yhat_lower\": 7.1414856486976905, \"yhat_upper\": 7.9585657980004845, \"fact\": 7.77275116820956, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:55:00\", \"yhat\": 7.535593920336, \"yhat_lower\": 7.154221071933848, \"yhat_upper\": 7.956234992541242, \"fact\": 7.558314501085786, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:56:00\", \"yhat\": 7.525961449498143, \"yhat_lower\": 7.079805559711838, \"yhat_upper\": 7.943102130779332, \"fact\": 7.60533623053003, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:57:00\", \"yhat\": 7.516328978660286, \"yhat_lower\": 7.102444682049894, \"yhat_upper\": 7.953940868114787, \"fact\": 7.564962022147053, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:58:00\", \"yhat\": 7.506696507822428, \"yhat_lower\": 7.0716965118860555, \"yhat_upper\": 7.913255069402451, \"fact\": 7.507104599166352, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:59:00\", \"yhat\": 7.497064036984572, \"yhat_lower\": 7.073802855095473, \"yhat_upper\": 7.920162246901812, \"fact\": 7.394733417407842, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:00:00\", \"yhat\": 7.483937072065472, \"yhat_lower\": 7.072061714345916, \"yhat_upper\": 7.884284546170553, \"fact\": 7.209009286177776, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:01:00\", \"yhat\": 7.474182830013936, \"yhat_lower\": 7.067385108195935, \"yhat_upper\": 7.910837547967137, \"fact\": 7.296538174554642, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:02:00\", \"yhat\": 7.464428587962398, \"yhat_lower\": 7.000862604578435, \"yhat_upper\": 7.86224007580215, \"fact\": 7.206584493381573, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:03:00\", \"yhat\": 7.4546743459108615, \"yhat_lower\": 7.012624585980753, \"yhat_upper\": 7.852234119082169, \"fact\": 7.160033858921166, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:04:00\", \"yhat\": 7.4449201038593245, \"yhat_lower\": 7.051419290013115, \"yhat_upper\": 7.860952834122202, \"fact\": 7.254636375974447, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:05:00\", \"yhat\": 7.391231460865729, \"yhat_lower\": 7.020166924353547, \"yhat_upper\": 7.837819286091707, \"fact\": 7.383418162205393, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:06:00\", \"yhat\": 7.380875573380851, \"yhat_lower\": 7.001778774335239, \"yhat_upper\": 7.814084841072749, \"fact\": 7.412786701811927, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:07:00\", \"yhat\": 7.370519685895973, \"yhat_lower\": 6.916059235398335, \"yhat_upper\": 7.790380653341992, \"fact\": 7.410993240415173, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:08:00\", \"yhat\": 7.360163798411095, \"yhat_lower\": 6.96652022728731, \"yhat_upper\": 7.763039502695845, \"fact\": 7.311113765840335, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:09:00\", \"yhat\": 7.349807910926216, \"yhat_lower\": 6.9370218357745115, \"yhat_upper\": 7.7935990875890955, \"fact\": 7.3759026127290195, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:10:00\", \"yhat\": 7.347071499499177, \"yhat_lower\": 6.900309763432042, \"yhat_upper\": 7.747896465446665, \"fact\": 7.429606304723798, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:11:00\", \"yhat\": 7.336865755955575, \"yhat_lower\": 6.898205776447531, \"yhat_upper\": 7.764396659896175, \"fact\": 7.49942313491552, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:12:00\", \"yhat\": 7.326660012411971, \"yhat_lower\": 6.9384552617205335, \"yhat_upper\": 7.725758469217823, \"fact\": 7.391456931311621, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:13:00\", \"yhat\": 7.316454268868368, \"yhat_lower\": 6.891663462208613, \"yhat_upper\": 7.770047460499212, \"fact\": 7.285664791754202, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:14:00\", \"yhat\": 7.306248525324766, \"yhat_lower\": 6.889443940017604, \"yhat_upper\": 7.747376387201753, \"fact\": 7.115643401562619, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:15:00\", \"yhat\": 7.3091287747251314, \"yhat_lower\": 6.864151975967688, \"yhat_upper\": 7.6873468840089, \"fact\": 7.054269618633998, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:16:00\", \"yhat\": 7.2991900880711045, \"yhat_lower\": 6.882019585363145, \"yhat_upper\": 7.747241895668053, \"fact\": 7.060118316641897, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:17:00\", \"yhat\": 7.289251401417076, \"yhat_lower\": 6.8365474265570985, \"yhat_upper\": 7.6931759999372495, \"fact\": 7.161535062516319, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:18:00\", \"yhat\": 7.279312714763048, \"yhat_lower\": 6.858044210869725, \"yhat_upper\": 7.710388391747924, \"fact\": 7.255915033132671, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:19:00\", \"yhat\": 7.269374028109019, \"yhat_lower\": 6.860733945145891, \"yhat_upper\": 7.716262970112493, \"fact\": 7.426012747469036, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:20:00\", \"yhat\": 7.233010125456862, \"yhat_lower\": 6.7843276658920315, \"yhat_upper\": 7.662842167854171, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:21:00\", \"yhat\": 7.222666999564133, \"yhat_lower\": 6.843881517410623, \"yhat_upper\": 7.602182724464214, \"fact\": 7.317126681220951, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:22:00\", \"yhat\": 7.2123238736714015, \"yhat_lower\": 6.759578879564706, \"yhat_upper\": 7.584540951052361, \"fact\": 7.437457589321834, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:23:00\", \"yhat\": 7.201980747778673, \"yhat_lower\": 6.815960885173228, \"yhat_upper\": 7.619627954845317, \"fact\": 7.411908464884772, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:24:00\", \"yhat\": 7.191637621885942, \"yhat_lower\": 6.737571611192854, \"yhat_upper\": 7.668319668688082, \"fact\": 7.524143393749286, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:25:00\", \"yhat\": 7.226905370486768, \"yhat_lower\": 6.7966188951487485, \"yhat_upper\": 7.660259241932242, \"fact\": 7.496314903881952, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:26:00\", \"yhat\": 7.217272560126105, \"yhat_lower\": 6.86475897928047, \"yhat_upper\": 7.639595965576988, \"fact\": 7.573752510226136, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:27:00\", \"yhat\": 7.207639749765441, \"yhat_lower\": 6.804391695255277, \"yhat_upper\": 7.570816685637186, \"fact\": 7.541365430808015, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:28:00\", \"yhat\": 7.198006939404778, \"yhat_lower\": 6.761491337163976, \"yhat_upper\": 7.60917976025573, \"fact\": 7.502722693475748, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:29:00\", \"yhat\": 7.188374129044114, \"yhat_lower\": 6.7846916276273745, \"yhat_upper\": 7.556971153943332, \"fact\": 7.432187339829274, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:30:00\", \"yhat\": 7.244370301405081, \"yhat_lower\": 6.843163377518276, \"yhat_upper\": 7.634695847003431, \"fact\": 7.367743829771953, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:31:00\", \"yhat\": 7.235683410762667, \"yhat_lower\": 6.809806419489486, \"yhat_upper\": 7.659242432431903, \"fact\": 7.2855991505679105, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:32:00\", \"yhat\": 7.226996520120252, \"yhat_lower\": 6.815810457299184, \"yhat_upper\": 7.649326676276867, \"fact\": 7.3253574361749, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:33:00\", \"yhat\": 7.218309629477838, \"yhat_lower\": 6.769297658803058, \"yhat_upper\": 7.606213328092621, \"fact\": 7.612270582135634, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:34:00\", \"yhat\": 7.2096227388354235, \"yhat_lower\": 6.792697206917347, \"yhat_upper\": 7.627051162752228, \"fact\": 7.591724855148331, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:35:00\", \"yhat\": 7.256145692995185, \"yhat_lower\": 6.8590239143007015, \"yhat_upper\": 7.6532787258843475, \"fact\": 7.518090746071456, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:36:00\", \"yhat\": 7.248321864417486, \"yhat_lower\": 6.863260804024741, \"yhat_upper\": 7.657863410372234, \"fact\": 7.676593906453708, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:37:00\", \"yhat\": 7.240498035839787, \"yhat_lower\": 6.822547718370596, \"yhat_upper\": 7.654306354036949, \"fact\": 7.676014289757855, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:38:00\", \"yhat\": 7.232674207262087, \"yhat_lower\": 6.813894730427177, \"yhat_upper\": 7.7086557661759825, \"fact\": 7.662263279799936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:39:00\", \"yhat\": 7.224850378684389, \"yhat_lower\": 6.84384456435657, \"yhat_upper\": 7.66346982136988, \"fact\": 7.744231691853355, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:40:00\", \"yhat\": 7.297126456587372, \"yhat_lower\": 6.882776823300513, \"yhat_upper\": 7.681794157424193, \"fact\": 7.535410761101995, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:41:00\", \"yhat\": 7.290382717114853, \"yhat_lower\": 6.9068836818954855, \"yhat_upper\": 7.6794543920360985, \"fact\": 7.555415160113135, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:42:00\", \"yhat\": 7.283638977642333, \"yhat_lower\": 6.860754381580501, \"yhat_upper\": 7.681196021040207, \"fact\": 7.735896999116704, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:43:00\", \"yhat\": 7.276895238169813, \"yhat_lower\": 6.866484131488323, \"yhat_upper\": 7.691354189159965, \"fact\": 7.847623077982126, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:44:00\", \"yhat\": 7.270151498697294, \"yhat_lower\": 6.858233981743198, \"yhat_upper\": 7.649427988636571, \"fact\": 7.7968137342359105, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:45:00\", \"yhat\": 7.3388000929182695, \"yhat_lower\": 6.917029752053279, \"yhat_upper\": 7.78155126909891, \"fact\": 7.784207158858803, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:46:00\", \"yhat\": 7.333048985645888, \"yhat_lower\": 6.880325852959037, \"yhat_upper\": 7.7159287555518175, \"fact\": 7.853358920798734, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:47:00\", \"yhat\": 7.327297878373508, \"yhat_lower\": 6.916551357848126, \"yhat_upper\": 7.74678672945157, \"fact\": 7.9176391649767295, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:48:00\", \"yhat\": 7.321546771101126, \"yhat_lower\": 6.934123143319656, \"yhat_upper\": 7.713855038288237, \"fact\": 7.831808587137508, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:49:00\", \"yhat\": 7.315795663828746, \"yhat_lower\": 6.9120259855767445, \"yhat_upper\": 7.7246261038277595, \"fact\": 7.74727118708158, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:50:00\", \"yhat\": 7.397604169217175, \"yhat_lower\": 6.993884082760659, \"yhat_upper\": 7.841011737592532, \"fact\": 7.749417906852305, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:51:00\", \"yhat\": 7.392990089234428, \"yhat_lower\": 6.937723951366438, \"yhat_upper\": 7.7564989253349905, \"fact\": 7.788491835544637, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:52:00\", \"yhat\": 7.38837600925168, \"yhat_lower\": 6.9380370710094965, \"yhat_upper\": 7.825166932455365, \"fact\": 7.682725698948679, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:53:00\", \"yhat\": 7.383761929268934, \"yhat_lower\": 6.945820820988156, \"yhat_upper\": 7.831267150686056, \"fact\": 7.663473876690589, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:54:00\", \"yhat\": 7.379147849286186, \"yhat_lower\": 6.949794929913077, \"yhat_upper\": 7.817440138669109, \"fact\": 7.650759642073896, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:55:00\", \"yhat\": 8.030384508793544, \"yhat_lower\": 7.149390083150819, \"yhat_upper\": 8.946872954858689, \"fact\": 7.643660841766507, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:56:00\", \"yhat\": 8.032690590934862, \"yhat_lower\": 7.124038535440943, \"yhat_upper\": 8.892773521544104, \"fact\": 7.740792599980338, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:57:00\", \"yhat\": 8.034996673076183, \"yhat_lower\": 7.206697504705297, \"yhat_upper\": 8.924578326179715, \"fact\": 7.729485101072052, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:58:00\", \"yhat\": 8.0373027552175, \"yhat_lower\": 7.161532080680552, \"yhat_upper\": 8.912983354533928, \"fact\": 7.809879193660448, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:59:00\", \"yhat\": 8.039608837358818, \"yhat_lower\": 7.134411735818428, \"yhat_upper\": 8.867921420995563, \"fact\": 7.870193732739887, \"anomaly\": 0}], \"data-3d1d5fd7fab8322d7a8e26a3c34eb90b\": [{\"ds\": \"2021-08-23T01:45:00\", \"yhat\": 3.331885508895142, \"yhat_lower\": 3.052212024039345, \"yhat_upper\": 3.5965979629294735, \"fact\": 3.1900447587564402, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:46:00\", \"yhat\": 3.378647053694313, \"yhat_lower\": 3.092901295077433, \"yhat_upper\": 3.6860139682300455, \"fact\": 3.124001365720735, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:55:00\", \"yhat\": 3.326726721923654, \"yhat_lower\": 2.995565301308796, \"yhat_upper\": 3.657281466339826, \"fact\": 2.997043850204673, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:57:00\", \"yhat\": 3.3827472631238136, \"yhat_lower\": 3.058755664509204, \"yhat_upper\": 3.6872051162868185, \"fact\": 3.0938716467439757, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:58:00\", \"yhat\": 3.4107575337238933, \"yhat_lower\": 3.0637319147610036, \"yhat_upper\": 3.7283201696064405, \"fact\": 3.0880073603636, \"anomaly\": 0}, {\"ds\": \"2021-08-23T01:59:00\", \"yhat\": 3.438767804323972, \"yhat_lower\": 3.078429641452841, \"yhat_upper\": 3.7935710826039153, \"fact\": 3.11206377340535, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:00:00\", \"yhat\": 3.191678276332674, \"yhat_lower\": 2.90873924602488, \"yhat_upper\": 3.4887165686753323, \"fact\": 3.071783339491452, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:01:00\", \"yhat\": 3.203825363957521, \"yhat_lower\": 2.894753294576195, \"yhat_upper\": 3.4772100127441385, \"fact\": 2.9694802366080912, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:02:00\", \"yhat\": 3.2159724515823687, \"yhat_lower\": 2.9543560138209273, \"yhat_upper\": 3.4866514798678487, \"fact\": 3.1296100628743804, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:03:00\", \"yhat\": 3.2281195392072157, \"yhat_lower\": 2.929425281126982, \"yhat_upper\": 3.5010914531979935, \"fact\": 3.002978165799547, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:04:00\", \"yhat\": 3.2402666268320637, \"yhat_lower\": 2.959173140363459, \"yhat_upper\": 3.5318312650272174, \"fact\": 2.961692345489058, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:05:00\", \"yhat\": 3.0687511074339198, \"yhat_lower\": 2.7993831520333705, \"yhat_upper\": 3.348537573601157, \"fact\": 2.988327400999106, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:10:00\", \"yhat\": 2.8754283495553787, \"yhat_lower\": 2.5892944388269146, \"yhat_upper\": 3.14303831235949, \"fact\": 2.684944460100623, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:11:00\", \"yhat\": 2.865643461512848, \"yhat_lower\": 2.6024860878377454, \"yhat_upper\": 3.133534188535957, \"fact\": 2.7044345238588345, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:12:00\", \"yhat\": 2.8558585734703175, \"yhat_lower\": 2.586316587570893, \"yhat_upper\": 3.1304638533646827, \"fact\": 2.6484580732244156, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:13:00\", \"yhat\": 2.846073685427786, \"yhat_lower\": 2.5438306020587738, \"yhat_upper\": 3.1412337425113144, \"fact\": 2.7494103531133773, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:14:00\", \"yhat\": 2.8362887973852557, \"yhat_lower\": 2.5642041430969544, \"yhat_upper\": 3.0925658394126203, \"fact\": 2.8828342883822207, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:15:00\", \"yhat\": 2.751898472868604, \"yhat_lower\": 2.4648251684986304, \"yhat_upper\": 3.042699369283102, \"fact\": 2.8354131880299063, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:16:00\", \"yhat\": 2.7384511558817954, \"yhat_lower\": 2.4473481719243706, \"yhat_upper\": 3.0080800128307037, \"fact\": 2.8000865445536682, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:17:00\", \"yhat\": 2.7250038388949878, \"yhat_lower\": 2.4801484566000953, \"yhat_upper\": 3.006513229680306, \"fact\": 2.7125150434931227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:18:00\", \"yhat\": 2.7115565219081796, \"yhat_lower\": 2.466158576677688, \"yhat_upper\": 2.9886088181374975, \"fact\": 2.5930717283678337, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:19:00\", \"yhat\": 2.6981092049213715, \"yhat_lower\": 2.4573416126882495, \"yhat_upper\": 2.977712475684677, \"fact\": 2.608611290894402, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:20:00\", \"yhat\": 2.675769377971733, \"yhat_lower\": 2.3919393916069946, \"yhat_upper\": 2.929358639329268, \"fact\": 2.630785813099688, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:21:00\", \"yhat\": 2.6618596704140973, \"yhat_lower\": 2.401973007123614, \"yhat_upper\": 2.9236707878969637, \"fact\": 2.4460733245935717, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:25:00\", \"yhat\": 2.45887584999456, \"yhat_lower\": 2.152597755344225, \"yhat_upper\": 2.737738033631193, \"fact\": 2.3476057569157662, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:26:00\", \"yhat\": 2.438464810043164, \"yhat_lower\": 2.1284939394704327, \"yhat_upper\": 2.6975692798830377, \"fact\": 2.135029126951106, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:30:00\", \"yhat\": 2.1821328255433174, \"yhat_lower\": 1.89978167547032, \"yhat_upper\": 2.440896076133988, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:31:00\", \"yhat\": 2.1534767673294706, \"yhat_lower\": 1.8717425813587476, \"yhat_upper\": 2.4207655094559524, \"fact\": 2.162436461794182, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:32:00\", \"yhat\": 2.1248207091156246, \"yhat_lower\": 1.854632784377444, \"yhat_upper\": 2.385485779971609, \"fact\": 2.2670705003332525, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:33:00\", \"yhat\": 2.0961646509017777, \"yhat_lower\": 1.8253636194060385, \"yhat_upper\": 2.379452926767455, \"fact\": 2.29288072551883, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:36:00\", \"yhat\": 2.084252366417074, \"yhat_lower\": 1.7911272802312475, \"yhat_upper\": 2.370554350994291, \"fact\": 2.3144117890462743, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:55:00\", \"yhat\": 2.8539862357873136, \"yhat_lower\": 2.371093031362268, \"yhat_upper\": 3.3202421956164145, \"fact\": 3.141727652556658, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:56:00\", \"yhat\": 2.863058869938087, \"yhat_lower\": 2.3585960332233737, \"yhat_upper\": 3.3705802024762685, \"fact\": 2.9955668695370674, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:57:00\", \"yhat\": 2.8721315040888595, \"yhat_lower\": 2.4144895086644897, \"yhat_upper\": 3.3544318403949727, \"fact\": 2.9382006257672204, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:58:00\", \"yhat\": 2.881204138239633, \"yhat_lower\": 2.37602423655889, \"yhat_upper\": 3.330135223189448, \"fact\": 3.1072176080352674, \"anomaly\": 0}, {\"ds\": \"2021-08-23T02:59:00\", \"yhat\": 2.8902767723904064, \"yhat_lower\": 2.386799892083761, \"yhat_upper\": 3.3773902442046753, \"fact\": 3.2265123861605005, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:00:00\", \"yhat\": 3.0731283993498164, \"yhat_lower\": 2.6297409996170154, \"yhat_upper\": 3.5091809159479603, \"fact\": 3.193007278757366, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:01:00\", \"yhat\": 3.09050903377686, \"yhat_lower\": 2.7297034476757127, \"yhat_upper\": 3.539122551676097, \"fact\": 2.9939694331844597, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:02:00\", \"yhat\": 3.107889668203902, \"yhat_lower\": 2.6639316579012298, \"yhat_upper\": 3.5543615571136753, \"fact\": 3.0510071595638975, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:03:00\", \"yhat\": 3.1252703026309456, \"yhat_lower\": 2.716274606442533, \"yhat_upper\": 3.549170677722936, \"fact\": 3.0843334587124414, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:04:00\", \"yhat\": 3.1426509370579887, \"yhat_lower\": 2.733824266241215, \"yhat_upper\": 3.57928311645811, \"fact\": 3.017355148653572, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:05:00\", \"yhat\": 3.2594710500629622, \"yhat_lower\": 2.884757929334013, \"yhat_upper\": 3.587575528458071, \"fact\": 3.0840789077005564, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:06:00\", \"yhat\": 3.2832541473452275, \"yhat_lower\": 2.9506868010402325, \"yhat_upper\": 3.6609580543261226, \"fact\": 3.2646089479518845, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:07:00\", \"yhat\": 3.3070372446274923, \"yhat_lower\": 2.9711608237273426, \"yhat_upper\": 3.6585272281279253, \"fact\": 3.165542668097864, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:08:00\", \"yhat\": 3.3308203419097575, \"yhat_lower\": 2.971803786026164, \"yhat_upper\": 3.6840542359951094, \"fact\": 3.0844463441003063, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:09:00\", \"yhat\": 3.354603439192022, \"yhat_lower\": 3.0033022397434697, \"yhat_upper\": 3.693139541392709, \"fact\": 3.1069823468616202, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:10:00\", \"yhat\": 3.350596196741683, \"yhat_lower\": 2.9974563392044704, \"yhat_upper\": 3.7134331220542856, \"fact\": 3.219189334092936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:11:00\", \"yhat\": 3.375097246287968, \"yhat_lower\": 3.033688675978871, \"yhat_upper\": 3.744425221666481, \"fact\": 3.253827606819794, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:12:00\", \"yhat\": 3.3995982958342514, \"yhat_lower\": 3.0488792697674016, \"yhat_upper\": 3.815869074322917, \"fact\": 3.2185308345572, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:13:00\", \"yhat\": 3.4240993453805353, \"yhat_lower\": 3.046780915852456, \"yhat_upper\": 3.77673182621073, \"fact\": 3.155315043321703, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:14:00\", \"yhat\": 3.4486003949268205, \"yhat_lower\": 3.0822149117325925, \"yhat_upper\": 3.8127234460846284, \"fact\": 3.3632975565070162, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:15:00\", \"yhat\": 3.3930949389429435, \"yhat_lower\": 3.043038808558256, \"yhat_upper\": 3.748086374590682, \"fact\": 3.343103013230474, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:16:00\", \"yhat\": 3.4146902698062407, \"yhat_lower\": 3.0331022320982703, \"yhat_upper\": 3.755098494367923, \"fact\": 3.2149037491158556, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:17:00\", \"yhat\": 3.4362856006695375, \"yhat_lower\": 3.078249800221042, \"yhat_upper\": 3.7852700476887904, \"fact\": 3.3955861520011412, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:18:00\", \"yhat\": 3.4578809315328343, \"yhat_lower\": 3.067165697041699, \"yhat_upper\": 3.8230486982481766, \"fact\": 3.198464588834615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:19:00\", \"yhat\": 3.479476262396131, \"yhat_lower\": 3.118249580855553, \"yhat_upper\": 3.821403688158535, \"fact\": 3.1356264595407213, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:20:00\", \"yhat\": 3.4402036910316496, \"yhat_lower\": 3.051713405141024, \"yhat_upper\": 3.8158536035572563, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:21:00\", \"yhat\": 3.4602734072323886, \"yhat_lower\": 3.1044844668891005, \"yhat_upper\": 3.857624082827723, \"fact\": 3.216974287061278, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:22:00\", \"yhat\": 3.480343123433126, \"yhat_lower\": 3.0827460583075372, \"yhat_upper\": 3.857357515744436, \"fact\": 3.265503557337653, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:23:00\", \"yhat\": 3.500412839633863, \"yhat_lower\": 3.142280836715296, \"yhat_upper\": 3.903572793049049, \"fact\": 3.282716546203024, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:24:00\", \"yhat\": 3.5204825558346022, \"yhat_lower\": 3.1146098242706572, \"yhat_upper\": 3.9079354091665617, \"fact\": 3.2557944933176817, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:25:00\", \"yhat\": 3.4748684387920403, \"yhat_lower\": 3.096461219714738, \"yhat_upper\": 3.8804041875781987, \"fact\": 3.253280546730072, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:26:00\", \"yhat\": 3.493317842910911, \"yhat_lower\": 3.0840569992382627, \"yhat_upper\": 3.869141569548407, \"fact\": 3.2468023667661132, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:27:00\", \"yhat\": 3.5117672470297836, \"yhat_lower\": 3.1599305862214937, \"yhat_upper\": 3.8851254670367967, \"fact\": 3.2013389472410476, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:28:00\", \"yhat\": 3.5302166511486543, \"yhat_lower\": 3.184212696535398, \"yhat_upper\": 3.907860432758999, \"fact\": 3.303433319153471, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:29:00\", \"yhat\": 3.5486660552675255, \"yhat_lower\": 3.1603680200145665, \"yhat_upper\": 3.944889306112926, \"fact\": 3.282481127060928, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:30:00\", \"yhat\": 3.4443175936829307, \"yhat_lower\": 3.0472898716224517, \"yhat_upper\": 3.7805501226984193, \"fact\": 3.2652271356713536, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:31:00\", \"yhat\": 3.4586729247013213, \"yhat_lower\": 3.1200737700660284, \"yhat_upper\": 3.841706173675522, \"fact\": 3.1595061912084845, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:32:00\", \"yhat\": 3.4730282557197114, \"yhat_lower\": 3.09185543571929, \"yhat_upper\": 3.8784900676273746, \"fact\": 3.150058882565577, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:33:00\", \"yhat\": 3.487383586738102, \"yhat_lower\": 3.136473143039646, \"yhat_upper\": 3.8741709624248055, \"fact\": 3.2408736119745805, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:34:00\", \"yhat\": 3.5017389177564917, \"yhat_lower\": 3.152537563937251, \"yhat_upper\": 3.9005377015269684, \"fact\": 3.1901242584634275, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:35:00\", \"yhat\": 3.3317556973037057, \"yhat_lower\": 3.0147114113878435, \"yhat_upper\": 3.629974103854075, \"fact\": 3.305247070725088, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:36:00\", \"yhat\": 3.33882027829251, \"yhat_lower\": 3.0103181659509697, \"yhat_upper\": 3.6513017946004687, \"fact\": 3.1486164121920943, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:37:00\", \"yhat\": 3.3458848592813153, \"yhat_lower\": 3.071978307889495, \"yhat_upper\": 3.6548125222579477, \"fact\": 3.3311019146556613, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:38:00\", \"yhat\": 3.3529494402701205, \"yhat_lower\": 3.0411211486709955, \"yhat_upper\": 3.6608008904343827, \"fact\": 3.2369006752018885, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:39:00\", \"yhat\": 3.3600140212589253, \"yhat_lower\": 3.036351000610269, \"yhat_upper\": 3.6396415363798953, \"fact\": 3.4338477225305613, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:40:00\", \"yhat\": 3.3305667200082376, \"yhat_lower\": 2.972583441000639, \"yhat_upper\": 3.6473008423829696, \"fact\": 3.5746933953177287, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:41:00\", \"yhat\": 3.335962368950856, \"yhat_lower\": 3.0231796951262706, \"yhat_upper\": 3.693212949377323, \"fact\": 3.668791853750908, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:50:00\", \"yhat\": 3.682953288569056, \"yhat_lower\": 3.2999901168374177, \"yhat_upper\": 4.058948756011183, \"fact\": 3.931161464982215, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:51:00\", \"yhat\": 3.695889861865221, \"yhat_lower\": 3.324276937703001, \"yhat_upper\": 4.107953566827474, \"fact\": 3.9222762574162413, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:52:00\", \"yhat\": 3.7088264351613853, \"yhat_lower\": 3.323878933575683, \"yhat_upper\": 4.096413232906937, \"fact\": 3.9522308518159854, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:53:00\", \"yhat\": 3.7217630084575504, \"yhat_lower\": 3.2609288513834294, \"yhat_upper\": 4.103492149066312, \"fact\": 3.9672379603949333, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:54:00\", \"yhat\": 3.7346995817537145, \"yhat_lower\": 3.3387695344431827, \"yhat_upper\": 4.182167713109382, \"fact\": 3.949120794105074, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:55:00\", \"yhat\": 3.8278368423083955, \"yhat_lower\": 3.4135659413268202, \"yhat_upper\": 4.310086225865733, \"fact\": 4.011080429852479, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:56:00\", \"yhat\": 3.8428222086916195, \"yhat_lower\": 3.4230974020694482, \"yhat_upper\": 4.247407717601834, \"fact\": 3.9773963745259766, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:57:00\", \"yhat\": 3.8578075750748444, \"yhat_lower\": 3.417422271059165, \"yhat_upper\": 4.303359410707985, \"fact\": 4.063919451853195, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:58:00\", \"yhat\": 3.8727929414580684, \"yhat_lower\": 3.4674205500653184, \"yhat_upper\": 4.3081117630519286, \"fact\": 4.041478475360821, \"anomaly\": 0}, {\"ds\": \"2021-08-23T03:59:00\", \"yhat\": 3.8877783078412933, \"yhat_lower\": 3.4657001631106525, \"yhat_upper\": 4.300759511593971, \"fact\": 4.062740372256043, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:00:00\", \"yhat\": 3.9369355379253217, \"yhat_lower\": 3.5260257229007568, \"yhat_upper\": 4.3690912404921365, \"fact\": 4.0505187731741525, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:01:00\", \"yhat\": 3.952330897472099, \"yhat_lower\": 3.547098991988449, \"yhat_upper\": 4.364028511900228, \"fact\": 4.1897089265414085, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:02:00\", \"yhat\": 3.967726257018877, \"yhat_lower\": 3.4756986028251307, \"yhat_upper\": 4.415857724055487, \"fact\": 4.284031357825327, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:03:00\", \"yhat\": 3.9831216165656538, \"yhat_lower\": 3.5951580109052004, \"yhat_upper\": 4.437756084628401, \"fact\": 4.343010092731889, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:04:00\", \"yhat\": 3.9985169761124317, \"yhat_lower\": 3.5754153591075992, \"yhat_upper\": 4.393084661963739, \"fact\": 4.185387068316425, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:05:00\", \"yhat\": 4.121406713469101, \"yhat_lower\": 3.782084289041081, \"yhat_upper\": 4.483752747300702, \"fact\": 4.0414341396536315, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:06:00\", \"yhat\": 4.140145828863057, \"yhat_lower\": 3.800788638920203, \"yhat_upper\": 4.480632962245775, \"fact\": 4.158591747922278, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:07:00\", \"yhat\": 4.158884944257013, \"yhat_lower\": 3.7704153189187277, \"yhat_upper\": 4.540828048399778, \"fact\": 4.11021899046745, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:08:00\", \"yhat\": 4.177624059650968, \"yhat_lower\": 3.8015332688159695, \"yhat_upper\": 4.522260918681324, \"fact\": 4.381527688619375, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:09:00\", \"yhat\": 4.196363175044925, \"yhat_lower\": 3.7928417496936873, \"yhat_upper\": 4.546025502373521, \"fact\": 4.3351854149025995, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:10:00\", \"yhat\": 4.267139416629803, \"yhat_lower\": 3.894884158025459, \"yhat_upper\": 4.621965750074829, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:11:00\", \"yhat\": 4.287957188181897, \"yhat_lower\": 3.9069494807249012, \"yhat_upper\": 4.685556112036446, \"fact\": 4.184798061879761, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:12:00\", \"yhat\": 4.308774959733992, \"yhat_lower\": 3.9553366624582402, \"yhat_upper\": 4.697408014607735, \"fact\": 4.217342874859245, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:13:00\", \"yhat\": 4.329592731286086, \"yhat_lower\": 3.9691465356633517, \"yhat_upper\": 4.69424840449723, \"fact\": 4.134349504828188, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:14:00\", \"yhat\": 4.350410502838183, \"yhat_lower\": 3.988036742774894, \"yhat_upper\": 4.751394097606952, \"fact\": 4.00615462019463, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:15:00\", \"yhat\": 4.350678188649738, \"yhat_lower\": 3.9658539076476482, \"yhat_upper\": 4.70653440052513, \"fact\": 4.174443032790151, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:16:00\", \"yhat\": 4.371610013166427, \"yhat_lower\": 3.9752466334608294, \"yhat_upper\": 4.764753263949242, \"fact\": 4.158682107023693, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:17:00\", \"yhat\": 4.392541837683117, \"yhat_lower\": 4.00392212380167, \"yhat_upper\": 4.781734984373571, \"fact\": 4.039980382510705, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:23:00\", \"yhat\": 4.407936936128063, \"yhat_lower\": 4.016864680712609, \"yhat_upper\": 4.786862513251709, \"fact\": 4.1533871249773675, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:24:00\", \"yhat\": 4.4264745280800835, \"yhat_lower\": 4.028795057730811, \"yhat_upper\": 4.817069056221719, \"fact\": 4.189958026263005, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:25:00\", \"yhat\": 4.324706346944173, \"yhat_lower\": 3.9141389554595856, \"yhat_upper\": 4.76053105921618, \"fact\": 4.126055761269775, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:26:00\", \"yhat\": 4.340283831284275, \"yhat_lower\": 3.900655042758893, \"yhat_upper\": 4.793702460253192, \"fact\": 4.19189206344511, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:27:00\", \"yhat\": 4.355861315624375, \"yhat_lower\": 3.9058527675528865, \"yhat_upper\": 4.796062198190156, \"fact\": 4.22553102867423, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:28:00\", \"yhat\": 4.371438799964475, \"yhat_lower\": 3.909108354504185, \"yhat_upper\": 4.801101007713667, \"fact\": 4.210411801001582, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:29:00\", \"yhat\": 4.387016284304576, \"yhat_lower\": 3.9519730626909286, \"yhat_upper\": 4.8263659164128745, \"fact\": 4.182752319021494, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:30:00\", \"yhat\": 4.36873803167162, \"yhat_lower\": 3.961856662856284, \"yhat_upper\": 4.804348022799481, \"fact\": 4.217524711732356, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:31:00\", \"yhat\": 4.383814708384479, \"yhat_lower\": 3.947426896947081, \"yhat_upper\": 4.807654263710892, \"fact\": 4.130474550476257, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:32:00\", \"yhat\": 4.398891385097339, \"yhat_lower\": 3.9294461024781357, \"yhat_upper\": 4.83200782654117, \"fact\": 4.17480129452376, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:33:00\", \"yhat\": 4.4139680618102, \"yhat_lower\": 3.961400667179739, \"yhat_upper\": 4.833325509910874, \"fact\": 4.320493820499588, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:34:00\", \"yhat\": 4.42904473852306, \"yhat_lower\": 3.9761434588503297, \"yhat_upper\": 4.875071105931545, \"fact\": 4.185929353510199, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:35:00\", \"yhat\": 4.405231804730728, \"yhat_lower\": 3.998068735308573, \"yhat_upper\": 4.837060099064569, \"fact\": 4.20876999105369, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:36:00\", \"yhat\": 4.419734565676726, \"yhat_lower\": 3.937790054195686, \"yhat_upper\": 4.8490207220344015, \"fact\": 4.205431875057931, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:37:00\", \"yhat\": 4.434237326622724, \"yhat_lower\": 3.9989210646625177, \"yhat_upper\": 4.875493624066652, \"fact\": 4.267783231196223, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:38:00\", \"yhat\": 4.448740087568721, \"yhat_lower\": 4.046157942544992, \"yhat_upper\": 4.840486192914335, \"fact\": 4.243656661707888, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:39:00\", \"yhat\": 4.46324284851472, \"yhat_lower\": 3.9823033209062597, \"yhat_upper\": 4.922610308865338, \"fact\": 4.277196878166224, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:40:00\", \"yhat\": 4.402026424667826, \"yhat_lower\": 3.951600312074524, \"yhat_upper\": 4.840012922368341, \"fact\": 4.3318998015163706, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:41:00\", \"yhat\": 4.41460053966115, \"yhat_lower\": 4.013682360041837, \"yhat_upper\": 4.880432009153059, \"fact\": 4.363011737742668, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:42:00\", \"yhat\": 4.427174654654473, \"yhat_lower\": 4.062070619211303, \"yhat_upper\": 4.829870184370414, \"fact\": 4.180371396839616, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:43:00\", \"yhat\": 4.439748769647797, \"yhat_lower\": 4.006172028486687, \"yhat_upper\": 4.887570015535892, \"fact\": 4.168647619776069, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:44:00\", \"yhat\": 4.452322884641123, \"yhat_lower\": 4.007979268685739, \"yhat_upper\": 4.8767757626517145, \"fact\": 4.175629966333796, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:45:00\", \"yhat\": 4.390443587125803, \"yhat_lower\": 4.013543075996766, \"yhat_upper\": 4.791741627732467, \"fact\": 4.05020272321786, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:46:00\", \"yhat\": 4.401135489420333, \"yhat_lower\": 3.972563142527717, \"yhat_upper\": 4.810307671969482, \"fact\": 4.1803453970069935, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:47:00\", \"yhat\": 4.411827391714863, \"yhat_lower\": 4.007769952981126, \"yhat_upper\": 4.856197692047582, \"fact\": 4.324238542138023, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:48:00\", \"yhat\": 4.422519294009394, \"yhat_lower\": 4.002933691608877, \"yhat_upper\": 4.8693179948179575, \"fact\": 4.332892480853049, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:49:00\", \"yhat\": 4.433211196303924, \"yhat_lower\": 3.9897562559616953, \"yhat_upper\": 4.865255272005709, \"fact\": 4.291603988308282, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:50:00\", \"yhat\": 4.320787395479911, \"yhat_lower\": 3.9988547409425994, \"yhat_upper\": 4.698991468831791, \"fact\": 4.307690348837449, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:51:00\", \"yhat\": 4.32726902612489, \"yhat_lower\": 4.0068124805697725, \"yhat_upper\": 4.687339520201919, \"fact\": 4.235240633659249, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:52:00\", \"yhat\": 4.333750656769869, \"yhat_lower\": 4.010611216229977, \"yhat_upper\": 4.6605359067388425, \"fact\": 4.317974290661283, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:53:00\", \"yhat\": 4.340232287414848, \"yhat_lower\": 3.9531532822959083, \"yhat_upper\": 4.716629854822278, \"fact\": 4.332980571066018, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:54:00\", \"yhat\": 4.3467139180598275, \"yhat_lower\": 4.008788769292159, \"yhat_upper\": 4.717793740113275, \"fact\": 4.487906802061469, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:55:00\", \"yhat\": 4.340761779348489, \"yhat_lower\": 3.9908864889710913, \"yhat_upper\": 4.716284941305372, \"fact\": 4.685148103114914, \"anomaly\": 0}, {\"ds\": \"2021-08-23T04:59:00\", \"yhat\": 4.364468809376901, \"yhat_lower\": 4.000213006495097, \"yhat_upper\": 4.7454308532092835, \"fact\": 4.742588279703727, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:00:00\", \"yhat\": 4.48726521226872, \"yhat_lower\": 4.0984120281612695, \"yhat_upper\": 4.903438165225154, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:01:00\", \"yhat\": 4.495557786032128, \"yhat_lower\": 4.081106749447407, \"yhat_upper\": 4.943151287767519, \"fact\": 4.798220230319819, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:02:00\", \"yhat\": 4.503850359795537, \"yhat_lower\": 4.11010710740573, \"yhat_upper\": 4.929708025870298, \"fact\": 4.829701886057892, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:03:00\", \"yhat\": 4.512142933558946, \"yhat_lower\": 4.051417983000318, \"yhat_upper\": 4.943949991117344, \"fact\": 4.883016949588336, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:04:00\", \"yhat\": 4.520435507322354, \"yhat_lower\": 4.0859755900703, \"yhat_upper\": 4.931814822681542, \"fact\": 4.8937347142287, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:05:00\", \"yhat\": 4.6056454182459685, \"yhat_lower\": 4.1479624260325885, \"yhat_upper\": 5.010421170866701, \"fact\": 4.938648459724199, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:08:00\", \"yhat\": 4.6350913508748075, \"yhat_lower\": 4.209902631751856, \"yhat_upper\": 5.063758264132461, \"fact\": 5.060179684851194, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:10:00\", \"yhat\": 4.781576548064278, \"yhat_lower\": 4.30256040326423, \"yhat_upper\": 5.219946408576593, \"fact\": 5.15313317767182, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:13:00\", \"yhat\": 4.81856796504338, \"yhat_lower\": 4.36227868265493, \"yhat_upper\": 5.259632221388956, \"fact\": 5.18963904990192, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:14:00\", \"yhat\": 4.830898437369748, \"yhat_lower\": 4.369547825027991, \"yhat_upper\": 5.2785530749591105, \"fact\": 5.127358854626321, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:15:00\", \"yhat\": 4.939881102062191, \"yhat_lower\": 4.445960087674595, \"yhat_upper\": 5.431111745925895, \"fact\": 5.29558515008685, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:17:00\", \"yhat\": 4.96775279273058, \"yhat_lower\": 4.442939112747611, \"yhat_upper\": 5.426367036509933, \"fact\": 5.398406115283306, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:21:00\", \"yhat\": 5.158859561773084, \"yhat_lower\": 4.63950371208939, \"yhat_upper\": 5.689368984269376, \"fact\": 5.666272705776069, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:22:00\", \"yhat\": 5.175478915415646, \"yhat_lower\": 4.674895892768942, \"yhat_upper\": 5.655578602340673, \"fact\": 5.567606762643266, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:23:00\", \"yhat\": 5.192098269058208, \"yhat_lower\": 4.662246743347779, \"yhat_upper\": 5.706109627685462, \"fact\": 5.677067547194454, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:25:00\", \"yhat\": 5.427060649294872, \"yhat_lower\": 4.990145979793278, \"yhat_upper\": 5.921424574492328, \"fact\": 5.893822573112458, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:27:00\", \"yhat\": 5.470202142567078, \"yhat_lower\": 4.9645266379108115, \"yhat_upper\": 5.938512175720528, \"fact\": 5.867959474518728, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:28:00\", \"yhat\": 5.491772889203179, \"yhat_lower\": 5.016359055265832, \"yhat_upper\": 5.9702596734714355, \"fact\": 5.924113424681968, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:29:00\", \"yhat\": 5.513343635839281, \"yhat_lower\": 5.011066686425204, \"yhat_upper\": 5.968093307316472, \"fact\": 5.755143754694852, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:30:00\", \"yhat\": 5.683629484692805, \"yhat_lower\": 5.213269538172652, \"yhat_upper\": 6.141141496127416, \"fact\": 5.748453921221867, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:31:00\", \"yhat\": 5.708913790956951, \"yhat_lower\": 5.24733473816559, \"yhat_upper\": 6.183522323192187, \"fact\": 5.688476020659092, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:32:00\", \"yhat\": 5.734198097221096, \"yhat_lower\": 5.295285652652635, \"yhat_upper\": 6.222466351632571, \"fact\": 5.746675485986374, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:33:00\", \"yhat\": 5.759482403485242, \"yhat_lower\": 5.277964958644908, \"yhat_upper\": 6.212236629426098, \"fact\": 5.843299988713007, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:34:00\", \"yhat\": 5.784766709749386, \"yhat_lower\": 5.372380317899933, \"yhat_upper\": 6.223611499849249, \"fact\": 5.834770667584292, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:35:00\", \"yhat\": 5.8721079073689495, \"yhat_lower\": 5.47578943944234, \"yhat_upper\": 6.342962079152212, \"fact\": 5.867216105273556, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:36:00\", \"yhat\": 5.899528784054233, \"yhat_lower\": 5.531152693734243, \"yhat_upper\": 6.333014978885417, \"fact\": 5.877789831818705, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:37:00\", \"yhat\": 5.926949660739516, \"yhat_lower\": 5.5187737058512765, \"yhat_upper\": 6.3295353529138465, \"fact\": 5.788247198986482, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:38:00\", \"yhat\": 5.9543705374248, \"yhat_lower\": 5.5566233088107015, \"yhat_upper\": 6.322129941025945, \"fact\": 5.855276906622282, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:39:00\", \"yhat\": 5.9817914141100825, \"yhat_lower\": 5.556292044509903, \"yhat_upper\": 6.390882379467749, \"fact\": 5.952180412895244, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:40:00\", \"yhat\": 6.03639476161728, \"yhat_lower\": 5.643062442260527, \"yhat_upper\": 6.422386040137475, \"fact\": 6.064808083145066, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:41:00\", \"yhat\": 6.065094530632954, \"yhat_lower\": 5.674835616148838, \"yhat_upper\": 6.426340051327196, \"fact\": 6.090622739284995, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:42:00\", \"yhat\": 6.093794299648625, \"yhat_lower\": 5.676528421104906, \"yhat_upper\": 6.522376112631604, \"fact\": 6.088539270842496, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:43:00\", \"yhat\": 6.122494068664298, \"yhat_lower\": 5.695962363184954, \"yhat_upper\": 6.5191202408422155, \"fact\": 6.180880255586056, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:44:00\", \"yhat\": 6.151193837679968, \"yhat_lower\": 5.771526095742024, \"yhat_upper\": 6.56168250050933, \"fact\": 6.0829197927436836, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:45:00\", \"yhat\": 6.219419808092494, \"yhat_lower\": 5.8562137843144475, \"yhat_upper\": 6.554321165534096, \"fact\": 6.153305438466777, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:46:00\", \"yhat\": 6.249591296115454, \"yhat_lower\": 5.900366532302038, \"yhat_upper\": 6.6014704950941425, \"fact\": 6.245424626413475, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:47:00\", \"yhat\": 6.279762784138416, \"yhat_lower\": 5.926250229106527, \"yhat_upper\": 6.614521687629934, \"fact\": 6.270181897393748, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:48:00\", \"yhat\": 6.3099342721613745, \"yhat_lower\": 5.953471673698357, \"yhat_upper\": 6.722347691092832, \"fact\": 6.304686334947228, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:49:00\", \"yhat\": 6.340105760184337, \"yhat_lower\": 5.9992889324767695, \"yhat_upper\": 6.72113653922752, \"fact\": 6.2486697214488025, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:50:00\", \"yhat\": 6.396574857203037, \"yhat_lower\": 6.039406453457198, \"yhat_upper\": 6.727349834071051, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:51:00\", \"yhat\": 6.427910680404775, \"yhat_lower\": 6.093574838195784, \"yhat_upper\": 6.772527356576482, \"fact\": 6.23101000200763, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:52:00\", \"yhat\": 6.459246503606512, \"yhat_lower\": 6.08592773348687, \"yhat_upper\": 6.820807550014637, \"fact\": 6.230694728169978, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:53:00\", \"yhat\": 6.490582326808251, \"yhat_lower\": 6.156357541056963, \"yhat_upper\": 6.859196353818595, \"fact\": 6.157703819607037, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:54:00\", \"yhat\": 6.521918150009987, \"yhat_lower\": 6.1644384560093854, \"yhat_upper\": 6.850983095119982, \"fact\": 6.301928313075152, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:55:00\", \"yhat\": 6.516502529662582, \"yhat_lower\": 6.186863454300034, \"yhat_upper\": 6.860841742258601, \"fact\": 6.4061636350278155, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:56:00\", \"yhat\": 6.547470077360365, \"yhat_lower\": 6.167189324239693, \"yhat_upper\": 6.878192389451836, \"fact\": 6.462931053129455, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:57:00\", \"yhat\": 6.578437625058145, \"yhat_lower\": 6.227508307485042, \"yhat_upper\": 6.904399840641194, \"fact\": 6.586302157616276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:58:00\", \"yhat\": 6.609405172755925, \"yhat_lower\": 6.256027983214348, \"yhat_upper\": 6.980844138307398, \"fact\": 6.590380090978745, \"anomaly\": 0}, {\"ds\": \"2021-08-23T05:59:00\", \"yhat\": 6.640372720453705, \"yhat_lower\": 6.2967374210540346, \"yhat_upper\": 7.014497804128805, \"fact\": 6.598384601991288, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:00:00\", \"yhat\": 6.674043352445564, \"yhat_lower\": 6.355186869493529, \"yhat_upper\": 6.989641233028706, \"fact\": 6.6087284233126855, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:01:00\", \"yhat\": 6.705350405005895, \"yhat_lower\": 6.34876180398345, \"yhat_upper\": 7.0758662776736205, \"fact\": 6.519586448521761, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:02:00\", \"yhat\": 6.736657457566226, \"yhat_lower\": 6.369886371960954, \"yhat_upper\": 7.106336032661469, \"fact\": 6.585441774813497, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:03:00\", \"yhat\": 6.767964510126559, \"yhat_lower\": 6.442913276719573, \"yhat_upper\": 7.0909122115441034, \"fact\": 6.612122789230208, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:04:00\", \"yhat\": 6.7992715626868865, \"yhat_lower\": 6.45677780743946, \"yhat_upper\": 7.134820604496832, \"fact\": 6.713398361671289, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:05:00\", \"yhat\": 6.784280172868407, \"yhat_lower\": 6.4501983696013685, \"yhat_upper\": 7.136741142738257, \"fact\": 6.822549277291775, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:06:00\", \"yhat\": 6.814503474738018, \"yhat_lower\": 6.459401516388098, \"yhat_upper\": 7.144084497144881, \"fact\": 6.97551658913424, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:07:00\", \"yhat\": 6.844726776607626, \"yhat_lower\": 6.492392388292761, \"yhat_upper\": 7.194224145069087, \"fact\": 7.0245338623762, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:08:00\", \"yhat\": 6.874950078477234, \"yhat_lower\": 6.547437250155813, \"yhat_upper\": 7.204729206877613, \"fact\": 7.011984857308559, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:09:00\", \"yhat\": 6.905173380346845, \"yhat_lower\": 6.531199219608413, \"yhat_upper\": 7.23877037847123, \"fact\": 6.939497193677334, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:10:00\", \"yhat\": 6.963951189416137, \"yhat_lower\": 6.635157054909899, \"yhat_upper\": 7.31197661156237, \"fact\": 7.010406398571905, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:11:00\", \"yhat\": 6.994694107671588, \"yhat_lower\": 6.653185298017418, \"yhat_upper\": 7.372456740117308, \"fact\": 6.931851888092667, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:12:00\", \"yhat\": 7.025437025927041, \"yhat_lower\": 6.66414986852533, \"yhat_upper\": 7.375778232052259, \"fact\": 6.879178023131081, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:13:00\", \"yhat\": 7.056179944182494, \"yhat_lower\": 6.7315427009496, \"yhat_upper\": 7.363715523174066, \"fact\": 7.109475269891421, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:14:00\", \"yhat\": 7.0869228624379454, \"yhat_lower\": 6.7276769556062055, \"yhat_upper\": 7.461882310559937, \"fact\": 7.284680664017118, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:15:00\", \"yhat\": 7.132803604963924, \"yhat_lower\": 6.777679934951311, \"yhat_upper\": 7.486415313222594, \"fact\": 7.395090828652547, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:16:00\", \"yhat\": 7.163954578279268, \"yhat_lower\": 6.797815439972422, \"yhat_upper\": 7.515588869762357, \"fact\": 7.371434651213532, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:17:00\", \"yhat\": 7.195105551594614, \"yhat_lower\": 6.80884857693186, \"yhat_upper\": 7.551663495943614, \"fact\": 7.245236231448149, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:18:00\", \"yhat\": 7.22625652490996, \"yhat_lower\": 6.907690755965588, \"yhat_upper\": 7.601105003603468, \"fact\": 7.344627723533745, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:19:00\", \"yhat\": 7.257407498225306, \"yhat_lower\": 6.891200905184238, \"yhat_upper\": 7.634392517151121, \"fact\": 7.362549605351548, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:20:00\", \"yhat\": 7.305324093724712, \"yhat_lower\": 6.9664209377928525, \"yhat_upper\": 7.671943550095379, \"fact\": 7.316384307810927, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:21:00\", \"yhat\": 7.336517891165314, \"yhat_lower\": 6.983505562721477, \"yhat_upper\": 7.701798551283889, \"fact\": 7.4436762713471, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:22:00\", \"yhat\": 7.3677116886059135, \"yhat_lower\": 7.040263420372385, \"yhat_upper\": 7.728319276665692, \"fact\": 7.586315011635683, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:26:00\", \"yhat\": 7.534807034687965, \"yhat_lower\": 7.168374430311849, \"yhat_upper\": 7.856528741890803, \"fact\": 7.588004256487661, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:27:00\", \"yhat\": 7.566545620016041, \"yhat_lower\": 7.250451274593332, \"yhat_upper\": 7.9050957578606456, \"fact\": 7.4272223763164, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:31:00\", \"yhat\": 7.6606127849134085, \"yhat_lower\": 7.325233217884781, \"yhat_upper\": 8.02199483178143, \"fact\": 7.351039971128483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:34:00\", \"yhat\": 7.753762178296674, \"yhat_lower\": 7.370601210402666, \"yhat_upper\": 8.118735515490394, \"fact\": 7.448679719340017, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:35:00\", \"yhat\": 7.703965165027774, \"yhat_lower\": 7.3425561260639185, \"yhat_upper\": 8.110696515242921, \"fact\": 7.483511703168986, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:36:00\", \"yhat\": 7.73358748695763, \"yhat_lower\": 7.367816620384011, \"yhat_upper\": 8.086606486222534, \"fact\": 7.414570983492366, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:40:00\", \"yhat\": 7.76402963850616, \"yhat_lower\": 7.318373972793362, \"yhat_upper\": 8.215497651257094, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:45:00\", \"yhat\": 7.803764444314406, \"yhat_lower\": 7.349750848798029, \"yhat_upper\": 8.23344220243976, \"fact\": 7.432244315830181, \"anomaly\": 0}, {\"ds\": \"2021-08-23T06:46:00\", \"yhat\": 7.830306081206389, \"yhat_lower\": 7.39575921250863, \"yhat_upper\": 8.218325706653111, \"fact\": 7.395988175550756, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:00:00\", \"yhat\": 7.768921803448575, \"yhat_lower\": 7.228078268427448, \"yhat_upper\": 8.271746279305482, \"fact\": 7.262444992057902, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:01:00\", \"yhat\": 7.788860526071928, \"yhat_lower\": 7.302443652049297, \"yhat_upper\": 8.250673073778822, \"fact\": 7.34306802733499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:02:00\", \"yhat\": 7.808799248695281, \"yhat_lower\": 7.273735058368175, \"yhat_upper\": 8.399241130213275, \"fact\": 7.316689086557331, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:03:00\", \"yhat\": 7.828737971318636, \"yhat_lower\": 7.3679379553776725, \"yhat_upper\": 8.330722162466632, \"fact\": 7.435901366061946, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:04:00\", \"yhat\": 7.848676693941987, \"yhat_lower\": 7.319190986418027, \"yhat_upper\": 8.382161063940698, \"fact\": 7.519301570079593, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:05:00\", \"yhat\": 7.758085311418496, \"yhat_lower\": 7.20357480950466, \"yhat_upper\": 8.2546506006219, \"fact\": 7.444483463234448, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:06:00\", \"yhat\": 7.776025148545101, \"yhat_lower\": 7.279117891677981, \"yhat_upper\": 8.24254762106406, \"fact\": 7.558503416641305, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:07:00\", \"yhat\": 7.793964985671706, \"yhat_lower\": 7.287808628193732, \"yhat_upper\": 8.317233386543023, \"fact\": 7.502724062217367, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:08:00\", \"yhat\": 7.811904822798311, \"yhat_lower\": 7.276374310307828, \"yhat_upper\": 8.3141970356347, \"fact\": 7.543900869874692, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:09:00\", \"yhat\": 7.829844659924915, \"yhat_lower\": 7.317508138104455, \"yhat_upper\": 8.36285362231184, \"fact\": 7.61793683008212, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:10:00\", \"yhat\": 7.77670793040921, \"yhat_lower\": 7.178357177076908, \"yhat_upper\": 8.379091503507036, \"fact\": 7.576099179026605, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:11:00\", \"yhat\": 7.793328986429839, \"yhat_lower\": 7.28606952202517, \"yhat_upper\": 8.287795131160424, \"fact\": 7.474889511780991, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:12:00\", \"yhat\": 7.809950042450466, \"yhat_lower\": 7.23332607252514, \"yhat_upper\": 8.398189647521402, \"fact\": 7.493594475005889, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:13:00\", \"yhat\": 7.826571098471094, \"yhat_lower\": 7.261077474874074, \"yhat_upper\": 8.318748020642547, \"fact\": 7.394645478479456, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:14:00\", \"yhat\": 7.843192154491723, \"yhat_lower\": 7.3288137028998035, \"yhat_upper\": 8.40486946213267, \"fact\": 7.358314631980785, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:15:00\", \"yhat\": 7.7649579330171425, \"yhat_lower\": 7.236500680398755, \"yhat_upper\": 8.253340348064114, \"fact\": 7.414394947365127, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:16:00\", \"yhat\": 7.779783068810478, \"yhat_lower\": 7.245332292634532, \"yhat_upper\": 8.346807506037468, \"fact\": 7.362071254261016, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:18:00\", \"yhat\": 7.809433340397153, \"yhat_lower\": 7.311458714437043, \"yhat_upper\": 8.28435584182724, \"fact\": 7.397969492007248, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:26:00\", \"yhat\": 7.622752980306864, \"yhat_lower\": 7.098981327015275, \"yhat_upper\": 8.107482554545278, \"fact\": 7.115014684339309, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:27:00\", \"yhat\": 7.632409658968071, \"yhat_lower\": 7.122940278464718, \"yhat_upper\": 8.227457484277082, \"fact\": 7.158507807273718, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:28:00\", \"yhat\": 7.642066337629277, \"yhat_lower\": 7.126973459663577, \"yhat_upper\": 8.211914211174266, \"fact\": 7.223216693033921, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:29:00\", \"yhat\": 7.651723016290483, \"yhat_lower\": 7.100907330152589, \"yhat_upper\": 8.24565665893417, \"fact\": 7.414873061673024, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:30:00\", \"yhat\": 7.535254655011061, \"yhat_lower\": 7.0142541373102505, \"yhat_upper\": 8.054237372013203, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:31:00\", \"yhat\": 7.542539678937592, \"yhat_lower\": 6.984912837527626, \"yhat_upper\": 8.08908370369584, \"fact\": 7.2522816003485655, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:32:00\", \"yhat\": 7.5498247028641225, \"yhat_lower\": 7.059994248816074, \"yhat_upper\": 8.071199504626291, \"fact\": 7.362085934503852, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:33:00\", \"yhat\": 7.557109726790653, \"yhat_lower\": 7.072806357220526, \"yhat_upper\": 8.023736493522916, \"fact\": 7.467224271777104, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:34:00\", \"yhat\": 7.564394750717183, \"yhat_lower\": 7.057464878082801, \"yhat_upper\": 8.055004442994232, \"fact\": 7.364294904567715, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:35:00\", \"yhat\": 7.493997409493834, \"yhat_lower\": 7.037597915164162, \"yhat_upper\": 7.995398199412876, \"fact\": 7.459430953032399, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:36:00\", \"yhat\": 7.499497657906483, \"yhat_lower\": 7.022657439047381, \"yhat_upper\": 7.979927053199244, \"fact\": 7.452578150899747, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:37:00\", \"yhat\": 7.504997906319134, \"yhat_lower\": 7.0791810429417525, \"yhat_upper\": 7.971913966514989, \"fact\": 7.5133858350161615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:38:00\", \"yhat\": 7.510498154731784, \"yhat_lower\": 7.042142473339802, \"yhat_upper\": 8.003616260809132, \"fact\": 7.4258638789745675, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:39:00\", \"yhat\": 7.515998403144434, \"yhat_lower\": 7.058877734573187, \"yhat_upper\": 7.996124138991123, \"fact\": 7.3737932149732766, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:40:00\", \"yhat\": 7.45559758057194, \"yhat_lower\": 7.023004407262546, \"yhat_upper\": 7.91917560787243, \"fact\": 7.598358267725344, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:41:00\", \"yhat\": 7.459410846016358, \"yhat_lower\": 6.980790101573487, \"yhat_upper\": 7.88611232025243, \"fact\": 7.492834789309395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:42:00\", \"yhat\": 7.463224111460778, \"yhat_lower\": 7.040175636481596, \"yhat_upper\": 7.927124989402325, \"fact\": 7.522201737971649, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:43:00\", \"yhat\": 7.467037376905196, \"yhat_lower\": 6.988949807648115, \"yhat_upper\": 7.865715488761777, \"fact\": 7.302638063120661, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:44:00\", \"yhat\": 7.470850642349615, \"yhat_lower\": 6.997472687895568, \"yhat_upper\": 7.932681972304574, \"fact\": 7.279557282830666, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:45:00\", \"yhat\": 7.424926666599787, \"yhat_lower\": 6.987245133375629, \"yhat_upper\": 7.830279440818849, \"fact\": 7.363046511604048, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:46:00\", \"yhat\": 7.42741028966257, \"yhat_lower\": 7.030542636204192, \"yhat_upper\": 7.827537440953038, \"fact\": 7.326486104423132, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:47:00\", \"yhat\": 7.429893912725353, \"yhat_lower\": 7.0169327692260355, \"yhat_upper\": 7.823074071372155, \"fact\": 7.246927464543807, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:48:00\", \"yhat\": 7.432377535788135, \"yhat_lower\": 6.977496106127263, \"yhat_upper\": 7.853750148068542, \"fact\": 7.41642187662266, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:49:00\", \"yhat\": 7.434861158850919, \"yhat_lower\": 7.030829814358059, \"yhat_upper\": 7.82454028317958, \"fact\": 7.502878653438836, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:50:00\", \"yhat\": 7.391314970411022, \"yhat_lower\": 7.017393429002645, \"yhat_upper\": 7.773890157102199, \"fact\": 7.651020501300728, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:51:00\", \"yhat\": 7.392670718513772, \"yhat_lower\": 6.98694510956702, \"yhat_upper\": 7.754970839952307, \"fact\": 7.73101396367219, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:53:00\", \"yhat\": 7.39538221471927, \"yhat_lower\": 6.967731083740013, \"yhat_upper\": 7.754467043135887, \"fact\": 7.721905539978192, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:54:00\", \"yhat\": 7.3967379628220185, \"yhat_lower\": 7.017553787122804, \"yhat_upper\": 7.80583772149309, \"fact\": 7.676797763099813, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:55:00\", \"yhat\": 7.424853504479452, \"yhat_lower\": 6.983314878790855, \"yhat_upper\": 7.89685161543284, \"fact\": 7.49859598323504, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:56:00\", \"yhat\": 7.426171976621599, \"yhat_lower\": 7.045452659829252, \"yhat_upper\": 7.847616106532922, \"fact\": 7.476065058965288, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:57:00\", \"yhat\": 7.427490448763745, \"yhat_lower\": 6.992434500451374, \"yhat_upper\": 7.833253527461147, \"fact\": 7.482103132721876, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:58:00\", \"yhat\": 7.428808920905891, \"yhat_lower\": 7.007277755373034, \"yhat_upper\": 7.840107066578102, \"fact\": 7.533694637573916, \"anomaly\": 0}, {\"ds\": \"2021-08-23T07:59:00\", \"yhat\": 7.430127393048037, \"yhat_lower\": 6.965924172913014, \"yhat_upper\": 7.8354935331418485, \"fact\": 7.520250704663931, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:00:00\", \"yhat\": 7.423355470694177, \"yhat_lower\": 6.983531401428217, \"yhat_upper\": 7.829645510016864, \"fact\": 7.430552773592014, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:01:00\", \"yhat\": 7.424123796266829, \"yhat_lower\": 6.955459487662165, \"yhat_upper\": 7.857596936092401, \"fact\": 7.425522429366651, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:02:00\", \"yhat\": 7.424892121839481, \"yhat_lower\": 6.961540280924131, \"yhat_upper\": 7.811657880881046, \"fact\": 7.19210405586305, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:03:00\", \"yhat\": 7.425660447412135, \"yhat_lower\": 6.9890382246651805, \"yhat_upper\": 7.824807689192694, \"fact\": 7.28277232480738, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:04:00\", \"yhat\": 7.426428772984786, \"yhat_lower\": 6.999501323021427, \"yhat_upper\": 7.786759634152286, \"fact\": 7.175360535016683, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:05:00\", \"yhat\": 7.40434478604592, \"yhat_lower\": 6.926032401229468, \"yhat_upper\": 7.825779148577989, \"fact\": 7.262163774530336, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:06:00\", \"yhat\": 7.40475931335718, \"yhat_lower\": 6.945005612466555, \"yhat_upper\": 7.833640551961069, \"fact\": 7.203036103460411, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:07:00\", \"yhat\": 7.405173840668439, \"yhat_lower\": 7.001888180077467, \"yhat_upper\": 7.846190148959344, \"fact\": 7.104577394867066, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:08:00\", \"yhat\": 7.405588367979699, \"yhat_lower\": 6.963643326663981, \"yhat_upper\": 7.858486243880416, \"fact\": 7.146838037080654, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:09:00\", \"yhat\": 7.406002895290959, \"yhat_lower\": 6.949778904964724, \"yhat_upper\": 7.832857658903376, \"fact\": 7.1098713925408195, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:10:00\", \"yhat\": 7.384559231465399, \"yhat_lower\": 6.921582561403233, \"yhat_upper\": 7.835047105970848, \"fact\": 6.964204225280627, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:15:00\", \"yhat\": 7.31082151255353, \"yhat_lower\": 6.882892035858407, \"yhat_upper\": 7.719327953161628, \"fact\": 6.946297846175937, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:16:00\", \"yhat\": 7.310410960703394, \"yhat_lower\": 6.882823137005205, \"yhat_upper\": 7.760499914033369, \"fact\": 6.91741109605579, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:20:00\", \"yhat\": 7.209955926600148, \"yhat_lower\": 6.773259942117443, \"yhat_upper\": 7.658228006054622, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:25:00\", \"yhat\": 7.0818507632437955, \"yhat_lower\": 6.586969941106555, \"yhat_upper\": 7.539378057565671, \"fact\": 6.601555135123274, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:35:00\", \"yhat\": 6.820630427058223, \"yhat_lower\": 6.286918104697763, \"yhat_upper\": 7.304713153738256, \"fact\": 6.316785939738493, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:36:00\", \"yhat\": 6.8141854342975465, \"yhat_lower\": 6.279726076172435, \"yhat_upper\": 7.318938960150304, \"fact\": 6.333618541503614, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:37:00\", \"yhat\": 6.80774044153687, \"yhat_lower\": 6.278525264514712, \"yhat_upper\": 7.33825809898715, \"fact\": 6.445636379481378, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:38:00\", \"yhat\": 6.801295448776192, \"yhat_lower\": 6.246680463877369, \"yhat_upper\": 7.3436417911322085, \"fact\": 6.591432527622528, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:39:00\", \"yhat\": 6.794850456015515, \"yhat_lower\": 6.273431489127351, \"yhat_upper\": 7.329139319034951, \"fact\": 6.518538014853173, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:40:00\", \"yhat\": 6.703321587709314, \"yhat_lower\": 6.198076583978248, \"yhat_upper\": 7.219484924135224, \"fact\": 6.403509692296891, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:41:00\", \"yhat\": 6.695554640064032, \"yhat_lower\": 6.174981554704438, \"yhat_upper\": 7.2216759439524605, \"fact\": 6.514920639375976, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:42:00\", \"yhat\": 6.687787692418748, \"yhat_lower\": 6.164865868870506, \"yhat_upper\": 7.202758952931534, \"fact\": 6.698467040888667, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:43:00\", \"yhat\": 6.680020744773466, \"yhat_lower\": 6.150458044631832, \"yhat_upper\": 7.227004101352552, \"fact\": 6.759388401607078, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:44:00\", \"yhat\": 6.672253797128183, \"yhat_lower\": 6.106606127909563, \"yhat_upper\": 7.197042605748562, \"fact\": 6.716490662775344, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:45:00\", \"yhat\": 6.640656505917789, \"yhat_lower\": 6.125194782531541, \"yhat_upper\": 7.173231099773454, \"fact\": 6.5987942999302085, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:46:00\", \"yhat\": 6.632412254890261, \"yhat_lower\": 6.0898884302810705, \"yhat_upper\": 7.161030572102576, \"fact\": 6.65333830003684, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:47:00\", \"yhat\": 6.624168003862734, \"yhat_lower\": 6.129719830185664, \"yhat_upper\": 7.103622139161152, \"fact\": 6.556226307271936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:48:00\", \"yhat\": 6.615923752835207, \"yhat_lower\": 6.133898518627714, \"yhat_upper\": 7.158915231583242, \"fact\": 6.631915596619567, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:49:00\", \"yhat\": 6.60767950180768, \"yhat_lower\": 6.072018223947385, \"yhat_upper\": 7.184087843942095, \"fact\": 6.7418854984709515, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:50:00\", \"yhat\": 6.575359461758412, \"yhat_lower\": 6.031966694351483, \"yhat_upper\": 7.103778548853814, \"fact\": 6.90468821514332, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:51:00\", \"yhat\": 6.566514584248613, \"yhat_lower\": 6.080139751324108, \"yhat_upper\": 7.112692416571872, \"fact\": 6.92379664141639, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:52:00\", \"yhat\": 6.557669706738816, \"yhat_lower\": 6.000954533528328, \"yhat_upper\": 7.102386177413333, \"fact\": 6.946555214531447, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:53:00\", \"yhat\": 6.5488248292290185, \"yhat_lower\": 6.077439580851295, \"yhat_upper\": 7.06502374383959, \"fact\": 6.930459476706841, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:54:00\", \"yhat\": 6.5399799517192205, \"yhat_lower\": 6.048579881496584, \"yhat_upper\": 7.039604331790496, \"fact\": 7.022422718896414, \"anomaly\": 0}, {\"ds\": \"2021-08-23T08:55:00\", \"yhat\": 6.579385160727626, \"yhat_lower\": 6.035702068880664, \"yhat_upper\": 7.084989696239746, \"fact\": 7.053346772430454, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:00:00\", \"yhat\": 6.6280245410127945, \"yhat_lower\": 6.086884179983976, \"yhat_upper\": 7.249727717067758, \"fact\": 7.242022079132392, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:10:00\", \"yhat\": 6.790741268136085, \"yhat_lower\": 6.146096950777551, \"yhat_upper\": 7.363155640957044, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:35:00\", \"yhat\": 7.488526194898056, \"yhat_lower\": 6.595976213857549, \"yhat_upper\": 8.32622328628154, \"fact\": 8.061674389304113, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:36:00\", \"yhat\": 7.491977698020609, \"yhat_lower\": 6.664590105250331, \"yhat_upper\": 8.241681004613039, \"fact\": 8.101904105964518, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:37:00\", \"yhat\": 7.495429201143162, \"yhat_lower\": 6.784759326529417, \"yhat_upper\": 8.30547230060603, \"fact\": 8.049382116624201, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:38:00\", \"yhat\": 7.498880704265716, \"yhat_lower\": 6.738021391673902, \"yhat_upper\": 8.303074710623097, \"fact\": 7.9510567258113305, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:39:00\", \"yhat\": 7.502332207388268, \"yhat_lower\": 6.7111888204192995, \"yhat_upper\": 8.341201162403278, \"fact\": 7.962974507940454, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:40:00\", \"yhat\": 7.606359694173765, \"yhat_lower\": 6.814868476302952, \"yhat_upper\": 8.449338222767048, \"fact\": 7.805239859715092, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:41:00\", \"yhat\": 7.611140302486328, \"yhat_lower\": 6.757599190497899, \"yhat_upper\": 8.377479922025593, \"fact\": 7.663667118812604, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:42:00\", \"yhat\": 7.6159209107988906, \"yhat_lower\": 6.826712891121579, \"yhat_upper\": 8.420709112125982, \"fact\": 7.514024098971325, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:43:00\", \"yhat\": 7.620701519111454, \"yhat_lower\": 6.848367427056519, \"yhat_upper\": 8.404792570703705, \"fact\": 7.471366107835003, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:44:00\", \"yhat\": 7.625482127424015, \"yhat_lower\": 6.769064140191452, \"yhat_upper\": 8.417058933698806, \"fact\": 7.445667100893326, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:45:00\", \"yhat\": 7.642284363266123, \"yhat_lower\": 6.868683141611956, \"yhat_upper\": 8.438119269749595, \"fact\": 7.456711779886499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:46:00\", \"yhat\": 7.647373730394403, \"yhat_lower\": 6.771390280838565, \"yhat_upper\": 8.454693285043472, \"fact\": 7.444329373125276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:47:00\", \"yhat\": 7.652463097522682, \"yhat_lower\": 6.909568455005002, \"yhat_upper\": 8.413257051546784, \"fact\": 7.468336779368962, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:48:00\", \"yhat\": 7.657552464650962, \"yhat_lower\": 6.929030452140603, \"yhat_upper\": 8.467355793125341, \"fact\": 7.585589594686708, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:49:00\", \"yhat\": 7.662641831779242, \"yhat_lower\": 6.805864187224094, \"yhat_upper\": 8.389719278647553, \"fact\": 7.750432747546225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:50:00\", \"yhat\": 7.681503916041949, \"yhat_lower\": 6.9506397818446874, \"yhat_upper\": 8.446770190679901, \"fact\": 7.789461459883152, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:51:00\", \"yhat\": 7.687022775642858, \"yhat_lower\": 6.893396727540202, \"yhat_upper\": 8.520874783737518, \"fact\": 7.849428734659802, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:52:00\", \"yhat\": 7.692541635243767, \"yhat_lower\": 6.928646381838062, \"yhat_upper\": 8.628719618631699, \"fact\": 7.945508717131604, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:53:00\", \"yhat\": 7.698060494844677, \"yhat_lower\": 6.966278463815956, \"yhat_upper\": 8.48535990492036, \"fact\": 7.897018421083583, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:54:00\", \"yhat\": 7.703579354445585, \"yhat_lower\": 6.9451718556508695, \"yhat_upper\": 8.617846772514886, \"fact\": 7.790206365474418, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:55:00\", \"yhat\": 7.770283354662266, \"yhat_lower\": 6.996584707831656, \"yhat_upper\": 8.543778732803709, \"fact\": 7.839967858463782, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:56:00\", \"yhat\": 7.77682615858756, \"yhat_lower\": 7.0297691919599075, \"yhat_upper\": 8.6105727258018, \"fact\": 7.8667860803525524, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:57:00\", \"yhat\": 7.783368962512854, \"yhat_lower\": 7.0390396764288825, \"yhat_upper\": 8.553812305715404, \"fact\": 7.7525973626559095, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:58:00\", \"yhat\": 7.78991176643815, \"yhat_lower\": 6.898524344464084, \"yhat_upper\": 8.533215589972233, \"fact\": 7.70504444156228, \"anomaly\": 0}, {\"ds\": \"2021-08-23T09:59:00\", \"yhat\": 7.796454570363444, \"yhat_lower\": 7.012342452403471, \"yhat_upper\": 8.518568535800881, \"fact\": 7.801695429233526, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:00:00\", \"yhat\": 7.849359565045376, \"yhat_lower\": 7.07010191578612, \"yhat_upper\": 8.604125598579063, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:01:00\", \"yhat\": 7.856829665276606, \"yhat_lower\": 7.073616922726095, \"yhat_upper\": 8.559033053916947, \"fact\": 7.652667153528996, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:02:00\", \"yhat\": 7.864299765507836, \"yhat_lower\": 7.131669847153401, \"yhat_upper\": 8.666285596819337, \"fact\": 7.578881723592664, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:03:00\", \"yhat\": 7.871769865739065, \"yhat_lower\": 7.026758222839665, \"yhat_upper\": 8.673018177692262, \"fact\": 7.491151863279462, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:04:00\", \"yhat\": 7.879239965970295, \"yhat_lower\": 7.112497562378592, \"yhat_upper\": 8.610124023442737, \"fact\": 7.503454922925876, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:05:00\", \"yhat\": 7.900253693535451, \"yhat_lower\": 7.153318526096101, \"yhat_upper\": 8.652979577398776, \"fact\": 7.599057949270826, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:06:00\", \"yhat\": 7.908376108245216, \"yhat_lower\": 7.177492928749188, \"yhat_upper\": 8.616224433059848, \"fact\": 7.540289550698573, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:07:00\", \"yhat\": 7.9164985229549805, \"yhat_lower\": 7.229538160382668, \"yhat_upper\": 8.645806353387705, \"fact\": 7.709498641608279, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:08:00\", \"yhat\": 7.924620937664746, \"yhat_lower\": 7.18821339493867, \"yhat_upper\": 8.782594930950756, \"fact\": 7.830648777977522, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:09:00\", \"yhat\": 7.932743352374511, \"yhat_lower\": 7.2192578139760535, \"yhat_upper\": 8.611165798160652, \"fact\": 7.833850854121761, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:10:00\", \"yhat\": 7.974252308201126, \"yhat_lower\": 7.271431325029862, \"yhat_upper\": 8.618371414905324, \"fact\": 7.896527014556835, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:11:00\", \"yhat\": 7.983423489595227, \"yhat_lower\": 7.3289647754090295, \"yhat_upper\": 8.645692612561763, \"fact\": 7.740317372019487, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:12:00\", \"yhat\": 7.992594670989327, \"yhat_lower\": 7.217267599062837, \"yhat_upper\": 8.670639812678035, \"fact\": 7.734078442460585, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:13:00\", \"yhat\": 8.001765852383429, \"yhat_lower\": 7.3300449032257164, \"yhat_upper\": 8.75019578286352, \"fact\": 7.68652453910119, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:14:00\", \"yhat\": 8.010937033777529, \"yhat_lower\": 7.243211581791006, \"yhat_upper\": 8.71053540782704, \"fact\": 7.654062933595664, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:15:00\", \"yhat\": 8.054470219185577, \"yhat_lower\": 7.387673969233567, \"yhat_upper\": 8.749217529597006, \"fact\": 7.7323556114676295, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:16:00\", \"yhat\": 8.064785944793194, \"yhat_lower\": 7.415161049974847, \"yhat_upper\": 8.781149638920043, \"fact\": 7.823575479244249, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:17:00\", \"yhat\": 8.07510167040081, \"yhat_lower\": 7.398285067478444, \"yhat_upper\": 8.736279104589153, \"fact\": 7.961063693882232, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:18:00\", \"yhat\": 8.085417396008427, \"yhat_lower\": 7.409974582816505, \"yhat_upper\": 8.791210627628516, \"fact\": 7.66166136402624, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:19:00\", \"yhat\": 8.095733121616044, \"yhat_lower\": 7.443614120387227, \"yhat_upper\": 8.742545792332646, \"fact\": 7.735994319948233, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:20:00\", \"yhat\": 8.11398443503897, \"yhat_lower\": 7.425939772439533, \"yhat_upper\": 8.771197031945823, \"fact\": 7.8172661459687465, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:21:00\", \"yhat\": 8.124909635186974, \"yhat_lower\": 7.450430195728931, \"yhat_upper\": 8.78114762337998, \"fact\": 7.800477360464126, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:22:00\", \"yhat\": 8.135834835334977, \"yhat_lower\": 7.459728323971178, \"yhat_upper\": 8.729786675569487, \"fact\": 7.726932237108902, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:23:00\", \"yhat\": 8.14676003548298, \"yhat_lower\": 7.536593540891993, \"yhat_upper\": 8.757852265515396, \"fact\": 7.811868370741103, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:24:00\", \"yhat\": 8.157685235630986, \"yhat_lower\": 7.53599988854388, \"yhat_upper\": 8.856816051600555, \"fact\": 7.658004719265347, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:25:00\", \"yhat\": 8.149214486375671, \"yhat_lower\": 7.454540292402565, \"yhat_upper\": 8.851174359132328, \"fact\": 7.670100990217529, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:27:00\", \"yhat\": 8.171565122597775, \"yhat_lower\": 7.49148288853724, \"yhat_upper\": 8.788524120142503, \"fact\": 7.57061971942359, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:28:00\", \"yhat\": 8.182740440708827, \"yhat_lower\": 7.531858261588673, \"yhat_upper\": 8.777110543030547, \"fact\": 7.584558764339831, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:29:00\", \"yhat\": 8.193915758819879, \"yhat_lower\": 7.499310148227958, \"yhat_upper\": 8.87403778991883, \"fact\": 7.736367838262079, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:30:00\", \"yhat\": 8.134765242169019, \"yhat_lower\": 7.39549864768621, \"yhat_upper\": 8.905010580648085, \"fact\": 7.883967912330481, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:31:00\", \"yhat\": 8.145315217782915, \"yhat_lower\": 7.49195490476029, \"yhat_upper\": 8.79980643324498, \"fact\": 7.9454144774542215, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:32:00\", \"yhat\": 8.15586519339681, \"yhat_lower\": 7.496856180708227, \"yhat_upper\": 8.84246539508402, \"fact\": 7.9815247789264765, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:33:00\", \"yhat\": 8.166415169010705, \"yhat_lower\": 7.423211678065259, \"yhat_upper\": 8.865181559186478, \"fact\": 7.828608211241088, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:34:00\", \"yhat\": 8.1769651446246, \"yhat_lower\": 7.52495576252046, \"yhat_upper\": 8.846908591083668, \"fact\": 7.8866167493939185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:35:00\", \"yhat\": 8.160356016229104, \"yhat_lower\": 7.536189572107841, \"yhat_upper\": 8.838538931955274, \"fact\": 7.718286285065371, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:36:00\", \"yhat\": 8.170776470086302, \"yhat_lower\": 7.496405256003328, \"yhat_upper\": 8.792362920495105, \"fact\": 7.764341416031271, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:37:00\", \"yhat\": 8.1811969239435, \"yhat_lower\": 7.521649489728066, \"yhat_upper\": 8.826824478597421, \"fact\": 7.840706888425015, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:38:00\", \"yhat\": 8.1916173778007, \"yhat_lower\": 7.525622360130334, \"yhat_upper\": 8.890705157372269, \"fact\": 7.938059917879748, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:39:00\", \"yhat\": 8.202037831657899, \"yhat_lower\": 7.450997859522796, \"yhat_upper\": 8.880230171630274, \"fact\": 7.761060058402809, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:40:00\", \"yhat\": 8.131375673314423, \"yhat_lower\": 7.399658595300479, \"yhat_upper\": 8.711637210118798, \"fact\": 7.6946908748491, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:41:00\", \"yhat\": 8.140630056180584, \"yhat_lower\": 7.430732257069129, \"yhat_upper\": 8.78054463421481, \"fact\": 7.672013085482828, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:42:00\", \"yhat\": 8.149884439046746, \"yhat_lower\": 7.425771286643738, \"yhat_upper\": 8.839172217041485, \"fact\": 7.749640954645437, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:43:00\", \"yhat\": 8.159138821912904, \"yhat_lower\": 7.422552852954745, \"yhat_upper\": 8.874007122819835, \"fact\": 7.74351636626246, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:44:00\", \"yhat\": 8.168393204779067, \"yhat_lower\": 7.483087465184355, \"yhat_upper\": 8.913781171382476, \"fact\": 7.758280802421245, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:45:00\", \"yhat\": 8.132314728122346, \"yhat_lower\": 7.461536187292699, \"yhat_upper\": 8.786858708406028, \"fact\": 7.9905599789244945, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:46:00\", \"yhat\": 8.141169029433875, \"yhat_lower\": 7.4027664394050605, \"yhat_upper\": 8.843755486751986, \"fact\": 7.870475361188625, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:47:00\", \"yhat\": 8.150023330745405, \"yhat_lower\": 7.44998449268539, \"yhat_upper\": 8.863428392250901, \"fact\": 7.972400000133551, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:48:00\", \"yhat\": 8.158877632056937, \"yhat_lower\": 7.480179201071224, \"yhat_upper\": 8.8971869956534, \"fact\": 8.089531300610558, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:49:00\", \"yhat\": 8.167731933368467, \"yhat_lower\": 7.566952391638025, \"yhat_upper\": 8.847792289830496, \"fact\": 8.097777022768552, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:50:00\", \"yhat\": 8.134561550956514, \"yhat_lower\": 7.414495755178077, \"yhat_upper\": 8.826130914300759, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:51:00\", \"yhat\": 8.142736710941994, \"yhat_lower\": 7.497427565586647, \"yhat_upper\": 8.76426323404485, \"fact\": 8.031589183895466, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:52:00\", \"yhat\": 8.150911870927473, \"yhat_lower\": 7.514682655678994, \"yhat_upper\": 8.751494145159274, \"fact\": 8.148437931838542, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:53:00\", \"yhat\": 8.159087030912955, \"yhat_lower\": 7.49617256580275, \"yhat_upper\": 8.800459756472542, \"fact\": 8.221370040659716, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:54:00\", \"yhat\": 8.167262190898434, \"yhat_lower\": 7.542059195600432, \"yhat_upper\": 8.823640894933767, \"fact\": 8.333189126475943, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:55:00\", \"yhat\": 8.097944129947894, \"yhat_lower\": 7.508250323446438, \"yhat_upper\": 8.680823531259493, \"fact\": 8.511437080644786, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:56:00\", \"yhat\": 8.104408018773995, \"yhat_lower\": 7.492006028552958, \"yhat_upper\": 8.690828927112607, \"fact\": 8.530259401373554, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:57:00\", \"yhat\": 8.110871907600096, \"yhat_lower\": 7.595530295736425, \"yhat_upper\": 8.688067618200408, \"fact\": 8.464149676702108, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:58:00\", \"yhat\": 8.117335796426199, \"yhat_lower\": 7.428166836422251, \"yhat_upper\": 8.73918842052874, \"fact\": 8.510761154617697, \"anomaly\": 0}, {\"ds\": \"2021-08-23T10:59:00\", \"yhat\": 8.123799685252301, \"yhat_lower\": 7.531075742388231, \"yhat_upper\": 8.720762043971591, \"fact\": 8.588384748465963, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:00:00\", \"yhat\": 8.133585901727772, \"yhat_lower\": 7.563042632696578, \"yhat_upper\": 8.755480744341806, \"fact\": 8.596579830973859, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:01:00\", \"yhat\": 8.139469584225735, \"yhat_lower\": 7.5400538246949855, \"yhat_upper\": 8.677866741218198, \"fact\": 8.665254766764672, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:02:00\", \"yhat\": 8.145353266723694, \"yhat_lower\": 7.55791473444561, \"yhat_upper\": 8.678410340733047, \"fact\": 8.571601855976125, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:03:00\", \"yhat\": 8.151236949221657, \"yhat_lower\": 7.5826200725492425, \"yhat_upper\": 8.747602222601632, \"fact\": 8.483149022444422, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:04:00\", \"yhat\": 8.157120631719618, \"yhat_lower\": 7.599821785863784, \"yhat_upper\": 8.804801363213532, \"fact\": 8.392816789809771, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:05:00\", \"yhat\": 8.160289595193463, \"yhat_lower\": 7.579850467588524, \"yhat_upper\": 8.706212189756224, \"fact\": 8.289463311811762, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:06:00\", \"yhat\": 8.165473828902961, \"yhat_lower\": 7.6351230620991535, \"yhat_upper\": 8.729629541969175, \"fact\": 8.293193709584163, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:07:00\", \"yhat\": 8.170658062612459, \"yhat_lower\": 7.61604478369048, \"yhat_upper\": 8.674720087705657, \"fact\": 8.201046712843748, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:08:00\", \"yhat\": 8.175842296321955, \"yhat_lower\": 7.647150784052874, \"yhat_upper\": 8.7872947342085, \"fact\": 8.074013353443654, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:09:00\", \"yhat\": 8.181026530031453, \"yhat_lower\": 7.602616572897667, \"yhat_upper\": 8.730477285761019, \"fact\": 8.060346196714583, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:10:00\", \"yhat\": 8.14830414661521, \"yhat_lower\": 7.6591924753978615, \"yhat_upper\": 8.687284771123052, \"fact\": 8.129960019946706, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:11:00\", \"yhat\": 8.152631665788636, \"yhat_lower\": 7.638307640481854, \"yhat_upper\": 8.650670119210263, \"fact\": 8.093286965059585, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:12:00\", \"yhat\": 8.15695918496206, \"yhat_lower\": 7.686793752769861, \"yhat_upper\": 8.67247696473879, \"fact\": 8.207114051737939, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:13:00\", \"yhat\": 8.161286704135485, \"yhat_lower\": 7.622131017701486, \"yhat_upper\": 8.69671667121086, \"fact\": 8.174797102772132, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:14:00\", \"yhat\": 8.16561422330891, \"yhat_lower\": 7.660845158328703, \"yhat_upper\": 8.677139933704598, \"fact\": 8.244861920292358, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:15:00\", \"yhat\": 8.12708505924496, \"yhat_lower\": 7.613937239720642, \"yhat_upper\": 8.628528451120031, \"fact\": 8.004603702913197, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:16:00\", \"yhat\": 8.130436335302296, \"yhat_lower\": 7.608373517286534, \"yhat_upper\": 8.647424135090764, \"fact\": 7.962191492988927, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:17:00\", \"yhat\": 8.133787611359628, \"yhat_lower\": 7.624585225359804, \"yhat_upper\": 8.666726738216402, \"fact\": 7.82693977677464, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:18:00\", \"yhat\": 8.137138887416961, \"yhat_lower\": 7.649247932104725, \"yhat_upper\": 8.626817932440037, \"fact\": 7.780715623518733, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:19:00\", \"yhat\": 8.140490163474297, \"yhat_lower\": 7.545942795944195, \"yhat_upper\": 8.700218019689721, \"fact\": 7.602800054795464, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:20:00\", \"yhat\": 8.081775127921114, \"yhat_lower\": 7.5125266424364625, \"yhat_upper\": 8.654067104306245, \"fact\": 7.7126592728826395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:21:00\", \"yhat\": 8.084215322045326, \"yhat_lower\": 7.49706602582348, \"yhat_upper\": 8.686308636863838, \"fact\": 7.7702415551012605, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:22:00\", \"yhat\": 8.086655516169538, \"yhat_lower\": 7.566245452166532, \"yhat_upper\": 8.643439624752194, \"fact\": 7.755515291272416, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:23:00\", \"yhat\": 8.08909571029375, \"yhat_lower\": 7.54844521685709, \"yhat_upper\": 8.667725044084683, \"fact\": 7.893932649872157, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:24:00\", \"yhat\": 8.09153590441796, \"yhat_lower\": 7.560205639028493, \"yhat_upper\": 8.723729203497019, \"fact\": 7.9497835809896715, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:25:00\", \"yhat\": 8.03578987861857, \"yhat_lower\": 7.485484492606574, \"yhat_upper\": 8.603409563321398, \"fact\": 7.8758994800134285, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:26:00\", \"yhat\": 8.037350415545445, \"yhat_lower\": 7.471371615778372, \"yhat_upper\": 8.619023795901118, \"fact\": 7.882184263103129, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:27:00\", \"yhat\": 8.038910952472321, \"yhat_lower\": 7.421093171970151, \"yhat_upper\": 8.630328511084457, \"fact\": 8.064546783500113, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:28:00\", \"yhat\": 8.040471489399197, \"yhat_lower\": 7.4685517242061685, \"yhat_upper\": 8.605886091042317, \"fact\": 8.081645734366429, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:29:00\", \"yhat\": 8.042032026326071, \"yhat_lower\": 7.467101841058164, \"yhat_upper\": 8.55846362032243, \"fact\": 8.172757664947504, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:30:00\", \"yhat\": 8.038915773931583, \"yhat_lower\": 7.5118248841892505, \"yhat_upper\": 8.555224494726092, \"fact\": 8.098672806113793, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:31:00\", \"yhat\": 8.04036816917015, \"yhat_lower\": 7.434550553065895, \"yhat_upper\": 8.627510596932979, \"fact\": 8.151170322208227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:32:00\", \"yhat\": 8.041820564408718, \"yhat_lower\": 7.471590464514436, \"yhat_upper\": 8.544696463169592, \"fact\": 8.26088485879859, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:33:00\", \"yhat\": 8.043272959647284, \"yhat_lower\": 7.517341586623978, \"yhat_upper\": 8.5277277788031, \"fact\": 8.191009434921096, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:34:00\", \"yhat\": 8.04472535488585, \"yhat_lower\": 7.522758681102579, \"yhat_upper\": 8.573005719358097, \"fact\": 8.194555208030412, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:35:00\", \"yhat\": 8.095453638586871, \"yhat_lower\": 7.631393825081887, \"yhat_upper\": 8.595305871835855, \"fact\": 8.360453709951065, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:36:00\", \"yhat\": 8.09779357655895, \"yhat_lower\": 7.603983304542168, \"yhat_upper\": 8.564382048052384, \"fact\": 8.396733578661529, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:37:00\", \"yhat\": 8.100133514531027, \"yhat_lower\": 7.619170608819328, \"yhat_upper\": 8.67269322106737, \"fact\": 8.457129588862593, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:38:00\", \"yhat\": 8.102473452503105, \"yhat_lower\": 7.628250485463379, \"yhat_upper\": 8.624473562212998, \"fact\": 8.320222281734633, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:39:00\", \"yhat\": 8.104813390475183, \"yhat_lower\": 7.5165112522085336, \"yhat_upper\": 8.67191506067973, \"fact\": 8.38706323868159, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:40:00\", \"yhat\": 8.138708984471398, \"yhat_lower\": 7.606683132442012, \"yhat_upper\": 8.668064285666501, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:41:00\", \"yhat\": 8.141313436701905, \"yhat_lower\": 7.554966116050032, \"yhat_upper\": 8.67707169517818, \"fact\": 8.47380305154199, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:42:00\", \"yhat\": 8.143917888932412, \"yhat_lower\": 7.60762958050602, \"yhat_upper\": 8.676701667765503, \"fact\": 8.471000521610067, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:43:00\", \"yhat\": 8.146522341162921, \"yhat_lower\": 7.624157608818841, \"yhat_upper\": 8.696567194225706, \"fact\": 8.583404963654896, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:44:00\", \"yhat\": 8.149126793393428, \"yhat_lower\": 7.612631973154556, \"yhat_upper\": 8.691001936317303, \"fact\": 8.531063469573645, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:45:00\", \"yhat\": 8.232743325271262, \"yhat_lower\": 7.739821245174568, \"yhat_upper\": 8.792403147254076, \"fact\": 8.471403101314356, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:46:00\", \"yhat\": 8.236640808991437, \"yhat_lower\": 7.72991788517532, \"yhat_upper\": 8.742667225710983, \"fact\": 8.409649600014262, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:47:00\", \"yhat\": 8.240538292711616, \"yhat_lower\": 7.713080483982559, \"yhat_upper\": 8.752602618155395, \"fact\": 8.370469524136148, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:48:00\", \"yhat\": 8.244435776431791, \"yhat_lower\": 7.79313940380584, \"yhat_upper\": 8.728645051014057, \"fact\": 8.48614212062726, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:49:00\", \"yhat\": 8.248333260151968, \"yhat_lower\": 7.738543111754841, \"yhat_upper\": 8.76583490404711, \"fact\": 8.64617716198996, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:50:00\", \"yhat\": 8.325987299580527, \"yhat_lower\": 7.850232279078016, \"yhat_upper\": 8.794480308507307, \"fact\": 8.53530065692971, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:51:00\", \"yhat\": 8.331100422276082, \"yhat_lower\": 7.863926927941895, \"yhat_upper\": 8.846568115390337, \"fact\": 8.526391763137674, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:52:00\", \"yhat\": 8.336213544971637, \"yhat_lower\": 7.858476418417006, \"yhat_upper\": 8.805025520863124, \"fact\": 8.4747311830338, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:53:00\", \"yhat\": 8.341326667667193, \"yhat_lower\": 7.866647049587784, \"yhat_upper\": 8.850348039039934, \"fact\": 8.369368219481078, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:54:00\", \"yhat\": 8.34643979036275, \"yhat_lower\": 7.866409510039767, \"yhat_upper\": 8.82999234486166, \"fact\": 8.560972818522371, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:55:00\", \"yhat\": 8.390013232829146, \"yhat_lower\": 7.916923859197314, \"yhat_upper\": 8.890098906955645, \"fact\": 8.506389603340054, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:56:00\", \"yhat\": 8.395739853747692, \"yhat_lower\": 7.908995906802384, \"yhat_upper\": 8.860361435137964, \"fact\": 8.481984739041978, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:57:00\", \"yhat\": 8.401466474666238, \"yhat_lower\": 7.930178817431853, \"yhat_upper\": 8.93123623643845, \"fact\": 8.485287372932227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:58:00\", \"yhat\": 8.407193095584784, \"yhat_lower\": 7.9015294693364035, \"yhat_upper\": 8.935866449173364, \"fact\": 8.509799875799924, \"anomaly\": 0}, {\"ds\": \"2021-08-23T11:59:00\", \"yhat\": 8.41291971650333, \"yhat_lower\": 7.924055571535567, \"yhat_upper\": 8.889439053962498, \"fact\": 8.462839177620474, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:00:00\", \"yhat\": 8.445016784635383, \"yhat_lower\": 7.956068182787008, \"yhat_upper\": 8.93887368876057, \"fact\": 8.500847291856171, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:01:00\", \"yhat\": 8.451137463425706, \"yhat_lower\": 7.967581805928251, \"yhat_upper\": 8.953152774529874, \"fact\": 8.407545286261158, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:02:00\", \"yhat\": 8.457258142216029, \"yhat_lower\": 7.939662247779632, \"yhat_upper\": 8.986134129739852, \"fact\": 8.435490902768226, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:03:00\", \"yhat\": 8.463378821006351, \"yhat_lower\": 7.995817429422728, \"yhat_upper\": 8.991600568470659, \"fact\": 8.405689339518776, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:04:00\", \"yhat\": 8.469499499796674, \"yhat_lower\": 7.992539100166318, \"yhat_upper\": 8.966341348511376, \"fact\": 8.404404408484888, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:05:00\", \"yhat\": 8.494821320583469, \"yhat_lower\": 8.035580795622442, \"yhat_upper\": 9.006849954024934, \"fact\": 8.370573940680746, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:06:00\", \"yhat\": 8.501463796857378, \"yhat_lower\": 8.04317730023773, \"yhat_upper\": 8.977219582643004, \"fact\": 8.356621268629302, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:07:00\", \"yhat\": 8.508106273131288, \"yhat_lower\": 8.0312420275935, \"yhat_upper\": 8.977112313134558, \"fact\": 8.273825661013671, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:08:00\", \"yhat\": 8.514748749405197, \"yhat_lower\": 8.023614077177553, \"yhat_upper\": 9.071364820054983, \"fact\": 8.417744225285109, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:09:00\", \"yhat\": 8.521391225679105, \"yhat_lower\": 8.062672751235787, \"yhat_upper\": 8.986128285815628, \"fact\": 8.333018409415137, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:10:00\", \"yhat\": 8.520555621895811, \"yhat_lower\": 8.067368468492937, \"yhat_upper\": 9.032708292194089, \"fact\": 8.395519857078213, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:11:00\", \"yhat\": 8.527294585657279, \"yhat_lower\": 8.042117386645275, \"yhat_upper\": 8.975635465046146, \"fact\": 8.329430969980034, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:12:00\", \"yhat\": 8.534033549418742, \"yhat_lower\": 8.060127894991927, \"yhat_upper\": 9.072814357644225, \"fact\": 8.393907016426743, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:13:00\", \"yhat\": 8.540772513180208, \"yhat_lower\": 8.118531603374121, \"yhat_upper\": 9.037852524831179, \"fact\": 8.505097929522941, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:14:00\", \"yhat\": 8.547511476941674, \"yhat_lower\": 8.055953001863148, \"yhat_upper\": 9.03154802025885, \"fact\": 8.511009348963547, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:15:00\", \"yhat\": 8.535599138765114, \"yhat_lower\": 8.023033130637184, \"yhat_upper\": 8.977949385246353, \"fact\": 8.485964064563397, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:16:00\", \"yhat\": 8.542113613749102, \"yhat_lower\": 7.997853199186469, \"yhat_upper\": 9.070618073663145, \"fact\": 8.532367389569465, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:17:00\", \"yhat\": 8.548628088733087, \"yhat_lower\": 8.071027565393134, \"yhat_upper\": 8.989129283180334, \"fact\": 8.527169421117446, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:18:00\", \"yhat\": 8.555142563717075, \"yhat_lower\": 8.116838851004845, \"yhat_upper\": 9.076563837913369, \"fact\": 8.770144851734896, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:19:00\", \"yhat\": 8.56165703870106, \"yhat_lower\": 8.026465376909691, \"yhat_upper\": 9.067789754553251, \"fact\": 8.941922134099055, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:20:00\", \"yhat\": 8.58611288620078, \"yhat_lower\": 8.01332242773823, \"yhat_upper\": 9.104349912831527, \"fact\": 8.83656128758854, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:21:00\", \"yhat\": 8.592862857465164, \"yhat_lower\": 8.074930330564122, \"yhat_upper\": 9.128910737071537, \"fact\": 8.75134541259338, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:22:00\", \"yhat\": 8.599612828729546, \"yhat_lower\": 8.05977095685166, \"yhat_upper\": 9.09991683223491, \"fact\": 8.663598406050742, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:23:00\", \"yhat\": 8.606362799993931, \"yhat_lower\": 8.063916143866841, \"yhat_upper\": 9.091641999934671, \"fact\": 8.672674873252237, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:24:00\", \"yhat\": 8.613112771258313, \"yhat_lower\": 8.093442741649492, \"yhat_upper\": 9.110980054604656, \"fact\": 8.52103640042284, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:25:00\", \"yhat\": 8.624828435848084, \"yhat_lower\": 8.16159363940454, \"yhat_upper\": 9.085186731780114, \"fact\": 8.52272103376713, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:26:00\", \"yhat\": 8.631530428803002, \"yhat_lower\": 8.129517411989854, \"yhat_upper\": 9.059239616644577, \"fact\": 8.645248319087003, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:27:00\", \"yhat\": 8.638232421757921, \"yhat_lower\": 8.143315790707545, \"yhat_upper\": 9.127914136822437, \"fact\": 8.674972483541307, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:28:00\", \"yhat\": 8.64493441471284, \"yhat_lower\": 8.128000921895246, \"yhat_upper\": 9.120344977118478, \"fact\": 8.76474826986135, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:29:00\", \"yhat\": 8.651636407667759, \"yhat_lower\": 8.224693394306383, \"yhat_upper\": 9.110021746039653, \"fact\": 8.811453323118272, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:30:00\", \"yhat\": 8.669474242659621, \"yhat_lower\": 8.228048470699806, \"yhat_upper\": 9.115936655885195, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:31:00\", \"yhat\": 8.676333258766956, \"yhat_lower\": 8.269813478611125, \"yhat_upper\": 9.17046819559661, \"fact\": 8.485875363354573, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:32:00\", \"yhat\": 8.683192274874292, \"yhat_lower\": 8.214097331832784, \"yhat_upper\": 9.097641809470247, \"fact\": 8.399451833349502, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:33:00\", \"yhat\": 8.690051290981625, \"yhat_lower\": 8.245090291657403, \"yhat_upper\": 9.15728684286937, \"fact\": 8.457620981862641, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:34:00\", \"yhat\": 8.696910307088963, \"yhat_lower\": 8.207119811990882, \"yhat_upper\": 9.12189502436019, \"fact\": 8.612568848026724, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:35:00\", \"yhat\": 8.680293667632633, \"yhat_lower\": 8.189767907151708, \"yhat_upper\": 9.154608159842414, \"fact\": 8.514394842156392, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:36:00\", \"yhat\": 8.686917849022423, \"yhat_lower\": 8.191180540254512, \"yhat_upper\": 9.138291066549998, \"fact\": 8.387880106011288, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:37:00\", \"yhat\": 8.693542030412216, \"yhat_lower\": 8.220767328010469, \"yhat_upper\": 9.177256788945986, \"fact\": 8.223871883913581, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:51:00\", \"yhat\": 8.437524250662507, \"yhat_lower\": 7.872875295054652, \"yhat_upper\": 9.008375635903983, \"fact\": 7.977593528807279, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:53:00\", \"yhat\": 8.443290243472266, \"yhat_lower\": 7.910092859766831, \"yhat_upper\": 8.964656002789654, \"fact\": 8.014169824247498, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:54:00\", \"yhat\": 8.446173239877146, \"yhat_lower\": 7.905867501140967, \"yhat_upper\": 8.994434738508456, \"fact\": 8.002420669187153, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:55:00\", \"yhat\": 8.345446374687723, \"yhat_lower\": 7.803361060039244, \"yhat_upper\": 8.8898510670618, \"fact\": 8.151076376650083, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:56:00\", \"yhat\": 8.346893088725626, \"yhat_lower\": 7.7868708763573435, \"yhat_upper\": 8.877763621936666, \"fact\": 7.979406800773713, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:57:00\", \"yhat\": 8.348339802763528, \"yhat_lower\": 7.751697224434376, \"yhat_upper\": 8.895544754431729, \"fact\": 7.92353421269369, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:58:00\", \"yhat\": 8.349786516801428, \"yhat_lower\": 7.815654872862193, \"yhat_upper\": 8.878487303403098, \"fact\": 8.068779742758723, \"anomaly\": 0}, {\"ds\": \"2021-08-23T12:59:00\", \"yhat\": 8.35123323083933, \"yhat_lower\": 7.817491549129765, \"yhat_upper\": 8.829042990625453, \"fact\": 8.078786779675173, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:00:00\", \"yhat\": 8.29067985310056, \"yhat_lower\": 7.705907071935438, \"yhat_upper\": 8.88512128912387, \"fact\": 8.191788462425002, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:01:00\", \"yhat\": 8.291267339342003, \"yhat_lower\": 7.697983613229138, \"yhat_upper\": 8.799054283511861, \"fact\": 8.000415544530842, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:02:00\", \"yhat\": 8.291854825583444, \"yhat_lower\": 7.682388907155187, \"yhat_upper\": 8.864215057854478, \"fact\": 8.071115630032562, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:03:00\", \"yhat\": 8.292442311824887, \"yhat_lower\": 7.794804959087799, \"yhat_upper\": 8.85953054846824, \"fact\": 8.081479750948631, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:04:00\", \"yhat\": 8.293029798066328, \"yhat_lower\": 7.728310944759558, \"yhat_upper\": 8.895065108822825, \"fact\": 8.098170821285184, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:05:00\", \"yhat\": 8.243101944344636, \"yhat_lower\": 7.691924661657023, \"yhat_upper\": 8.797990341403109, \"fact\": 8.267139845953881, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:06:00\", \"yhat\": 8.242885711720225, \"yhat_lower\": 7.7167409625311105, \"yhat_upper\": 8.71614864496976, \"fact\": 8.212596119789714, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:07:00\", \"yhat\": 8.242669479095817, \"yhat_lower\": 7.70301787439335, \"yhat_upper\": 8.778925781227725, \"fact\": 8.230590163089623, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:08:00\", \"yhat\": 8.242453246471406, \"yhat_lower\": 7.694694614843176, \"yhat_upper\": 8.69692712771857, \"fact\": 8.318860440882997, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:09:00\", \"yhat\": 8.242237013846996, \"yhat_lower\": 7.757158292830677, \"yhat_upper\": 8.770291002039562, \"fact\": 8.392351095262217, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:10:00\", \"yhat\": 8.242738501051726, \"yhat_lower\": 7.718938882054202, \"yhat_upper\": 8.749614434693205, \"fact\": 8.398247511408044, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:11:00\", \"yhat\": 8.242447127981558, \"yhat_lower\": 7.68448043823853, \"yhat_upper\": 8.772991490684559, \"fact\": 8.545377931691302, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:12:00\", \"yhat\": 8.24215575491139, \"yhat_lower\": 7.663947188153545, \"yhat_upper\": 8.76810914577026, \"fact\": 8.553662460728718, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:13:00\", \"yhat\": 8.241864381841221, \"yhat_lower\": 7.713610077019909, \"yhat_upper\": 8.758558027956473, \"fact\": 8.539053365383428, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:14:00\", \"yhat\": 8.241573008771052, \"yhat_lower\": 7.69803499591047, \"yhat_upper\": 8.797748389975812, \"fact\": 8.738610081903111, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:15:00\", \"yhat\": 8.286722986533421, \"yhat_lower\": 7.770313487784731, \"yhat_upper\": 8.928294231482933, \"fact\": 8.789728699261456, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:16:00\", \"yhat\": 8.286908882659382, \"yhat_lower\": 7.770699844440091, \"yhat_upper\": 8.86380531534944, \"fact\": 8.672292432735887, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:17:00\", \"yhat\": 8.287094778785342, \"yhat_lower\": 7.679833657085695, \"yhat_upper\": 8.91191390320141, \"fact\": 8.583695199589734, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:18:00\", \"yhat\": 8.287280674911301, \"yhat_lower\": 7.7884770028163555, \"yhat_upper\": 8.79922017952833, \"fact\": 8.545572696616933, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:19:00\", \"yhat\": 8.287466571037262, \"yhat_lower\": 7.703817336948908, \"yhat_upper\": 8.836782770711565, \"fact\": 8.53469919243193, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:20:00\", \"yhat\": 8.332481616197516, \"yhat_lower\": 7.786614256800465, \"yhat_upper\": 8.830225362559847, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:21:00\", \"yhat\": 8.333120174492123, \"yhat_lower\": 7.77978275440406, \"yhat_upper\": 8.898963986442402, \"fact\": 8.619454458907168, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:22:00\", \"yhat\": 8.33375873278673, \"yhat_lower\": 7.822862493083819, \"yhat_upper\": 8.878314581379694, \"fact\": 8.64014873041566, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:23:00\", \"yhat\": 8.334397291081338, \"yhat_lower\": 7.828995642331184, \"yhat_upper\": 8.85679531498394, \"fact\": 8.773110778116337, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:24:00\", \"yhat\": 8.335035849375945, \"yhat_lower\": 7.773977734230417, \"yhat_upper\": 8.887308709043065, \"fact\": 8.842045243191007, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:25:00\", \"yhat\": 8.385781944480973, \"yhat_lower\": 7.891048661064227, \"yhat_upper\": 8.875808659204061, \"fact\": 8.779304562733579, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:26:00\", \"yhat\": 8.387008956691918, \"yhat_lower\": 7.883982507431046, \"yhat_upper\": 8.999719914587137, \"fact\": 8.715667021210756, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:30:00\", \"yhat\": 8.449019834839346, \"yhat_lower\": 7.814189095174318, \"yhat_upper\": 9.030376573126935, \"fact\": 9.026194022516984, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:31:00\", \"yhat\": 8.450593617164495, \"yhat_lower\": 7.89674109239741, \"yhat_upper\": 9.039659610504945, \"fact\": 8.996799590069418, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:32:00\", \"yhat\": 8.452167399489642, \"yhat_lower\": 7.9055219393125675, \"yhat_upper\": 9.055296107323132, \"fact\": 8.89038427307193, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:33:00\", \"yhat\": 8.453741181814793, \"yhat_lower\": 7.84026726691657, \"yhat_upper\": 9.054505195583921, \"fact\": 8.845887105325563, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:34:00\", \"yhat\": 8.455314964139943, \"yhat_lower\": 7.893305532347313, \"yhat_upper\": 9.070494895393587, \"fact\": 8.940727418078595, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:35:00\", \"yhat\": 8.525062210586926, \"yhat_lower\": 7.950133467186771, \"yhat_upper\": 9.11051206894914, \"fact\": 8.890937823525107, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:36:00\", \"yhat\": 8.527329508283794, \"yhat_lower\": 7.904165251517417, \"yhat_upper\": 9.151475774821444, \"fact\": 8.689691616597951, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:37:00\", \"yhat\": 8.529596805980662, \"yhat_lower\": 7.905919769826134, \"yhat_upper\": 9.191632812498272, \"fact\": 8.859131071315861, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:38:00\", \"yhat\": 8.53186410367753, \"yhat_lower\": 7.935240840191039, \"yhat_upper\": 9.065360291016463, \"fact\": 8.75225132967224, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:39:00\", \"yhat\": 8.534131401374397, \"yhat_lower\": 7.972974989363307, \"yhat_upper\": 9.16096761603271, \"fact\": 8.745441955414979, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:40:00\", \"yhat\": 8.557515011744819, \"yhat_lower\": 7.9558866737891405, \"yhat_upper\": 9.136097795286533, \"fact\": 8.792889390472723, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:41:00\", \"yhat\": 8.559882186265671, \"yhat_lower\": 7.972715084023855, \"yhat_upper\": 9.158438155332782, \"fact\": 8.787700796349098, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:42:00\", \"yhat\": 8.562249360786526, \"yhat_lower\": 8.030510645715724, \"yhat_upper\": 9.16087627806521, \"fact\": 8.865140236693664, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:43:00\", \"yhat\": 8.564616535307378, \"yhat_lower\": 8.005329396352305, \"yhat_upper\": 9.16527942977412, \"fact\": 8.873378150594053, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:44:00\", \"yhat\": 8.56698370982823, \"yhat_lower\": 7.926100057993873, \"yhat_upper\": 9.193926328991262, \"fact\": 9.0222393846978, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:45:00\", \"yhat\": 8.61082940911773, \"yhat_lower\": 8.027406056537847, \"yhat_upper\": 9.131076585153783, \"fact\": 9.065340509014483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:46:00\", \"yhat\": 8.613618652291747, \"yhat_lower\": 8.085253232502163, \"yhat_upper\": 9.190650594279116, \"fact\": 9.08761005037332, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:47:00\", \"yhat\": 8.616407895465763, \"yhat_lower\": 8.027920896783609, \"yhat_upper\": 9.257082486799034, \"fact\": 9.21261808729404, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:50:00\", \"yhat\": 8.705436371993072, \"yhat_lower\": 8.096219663679909, \"yhat_upper\": 9.380690824748367, \"fact\": 9.306666947502116, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:51:00\", \"yhat\": 8.709080119988137, \"yhat_lower\": 8.09246788169226, \"yhat_upper\": 9.362363982926475, \"fact\": 9.262624362293195, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:52:00\", \"yhat\": 8.7127238679832, \"yhat_lower\": 8.107628044095778, \"yhat_upper\": 9.329100813757629, \"fact\": 9.242218868074156, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:54:00\", \"yhat\": 8.720011363973331, \"yhat_lower\": 8.140335785355026, \"yhat_upper\": 9.431625028416123, \"fact\": 9.323311197520256, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:55:00\", \"yhat\": 8.78855475159562, \"yhat_lower\": 8.204676623164586, \"yhat_upper\": 9.414655558914447, \"fact\": 9.224541361617664, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:56:00\", \"yhat\": 8.792753362551911, \"yhat_lower\": 8.1886260698496, \"yhat_upper\": 9.371425053982046, \"fact\": 9.235951852873002, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:57:00\", \"yhat\": 8.796951973508204, \"yhat_lower\": 8.153898192396808, \"yhat_upper\": 9.428170159802889, \"fact\": 9.183230028411051, \"anomaly\": 0}, {\"ds\": \"2021-08-23T13:58:00\", \"yhat\": 8.801150584464494, \"yhat_lower\": 8.14039292663244, \"yhat_upper\": 9.355634646481324, \"fact\": 9.303308572775062, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:00:00\", \"yhat\": 8.881193752715498, \"yhat_lower\": 8.270527601659392, \"yhat_upper\": 9.50190500492678, \"fact\": 9.344349304080247, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:01:00\", \"yhat\": 8.886200953153784, \"yhat_lower\": 8.254651501752253, \"yhat_upper\": 9.533824568843496, \"fact\": 9.418666704403686, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:02:00\", \"yhat\": 8.89120815359207, \"yhat_lower\": 8.276011062474012, \"yhat_upper\": 9.491431860754748, \"fact\": 9.318795523294629, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:03:00\", \"yhat\": 8.896215354030355, \"yhat_lower\": 8.229843577532272, \"yhat_upper\": 9.502367386171422, \"fact\": 9.361514185397724, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:04:00\", \"yhat\": 8.90122255446864, \"yhat_lower\": 8.341133149232896, \"yhat_upper\": 9.556967643662002, \"fact\": 9.455447864087226, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:05:00\", \"yhat\": 8.99349529189196, \"yhat_lower\": 8.349813497924895, \"yhat_upper\": 9.581649206866109, \"fact\": 9.401919535507847, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:06:00\", \"yhat\": 8.9995490180599, \"yhat_lower\": 8.376847380216361, \"yhat_upper\": 9.580938985744762, \"fact\": 9.38713489217632, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:07:00\", \"yhat\": 9.005602744227842, \"yhat_lower\": 8.42060608229472, \"yhat_upper\": 9.66864045017753, \"fact\": 9.455945295107508, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:08:00\", \"yhat\": 9.011656470395783, \"yhat_lower\": 8.378709016514144, \"yhat_upper\": 9.62722329787564, \"fact\": 9.609159720517681, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:09:00\", \"yhat\": 9.017710196563723, \"yhat_lower\": 8.368637388978673, \"yhat_upper\": 9.678075442346184, \"fact\": 9.614996053596242, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:10:00\", \"yhat\": 9.110282384292743, \"yhat_lower\": 8.488069130242215, \"yhat_upper\": 9.703375523765528, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:11:00\", \"yhat\": 9.11743999930366, \"yhat_lower\": 8.48125817725393, \"yhat_upper\": 9.719653312534952, \"fact\": 9.556691781795077, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:12:00\", \"yhat\": 9.124597614314576, \"yhat_lower\": 8.572489150717423, \"yhat_upper\": 9.748986138048533, \"fact\": 9.643000959964645, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:13:00\", \"yhat\": 9.131755229325492, \"yhat_lower\": 8.421953739137237, \"yhat_upper\": 9.767320178590891, \"fact\": 9.718788895128835, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:14:00\", \"yhat\": 9.138912844336408, \"yhat_lower\": 8.551224754584851, \"yhat_upper\": 9.727348007761105, \"fact\": 9.638302318559198, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:15:00\", \"yhat\": 9.232172233559378, \"yhat_lower\": 8.62856298588939, \"yhat_upper\": 9.88042149584469, \"fact\": 9.86400121471953, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:16:00\", \"yhat\": 9.240507844078527, \"yhat_lower\": 8.59442080053327, \"yhat_upper\": 9.911798992894873, \"fact\": 9.832149494497711, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:17:00\", \"yhat\": 9.248843454597676, \"yhat_lower\": 8.592343388939527, \"yhat_upper\": 9.858677433410008, \"fact\": 9.8378481484009, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:19:00\", \"yhat\": 9.265514675635973, \"yhat_lower\": 8.667285166565609, \"yhat_upper\": 9.928473304179048, \"fact\": 9.892267601353337, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:20:00\", \"yhat\": 9.407000191959385, \"yhat_lower\": 8.765441662814544, \"yhat_upper\": 10.057665020619627, \"fact\": 9.931774604936024, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:21:00\", \"yhat\": 9.41722621832168, \"yhat_lower\": 8.709573779918038, \"yhat_upper\": 9.982405304218409, \"fact\": 9.954188808547201, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:22:00\", \"yhat\": 9.427452244683977, \"yhat_lower\": 8.742680753603636, \"yhat_upper\": 10.05739067796284, \"fact\": 9.817695310369409, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:23:00\", \"yhat\": 9.437678271046273, \"yhat_lower\": 8.795176106888594, \"yhat_upper\": 10.085051631309948, \"fact\": 9.84172254699343, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:24:00\", \"yhat\": 9.44790429740857, \"yhat_lower\": 8.818903303370229, \"yhat_upper\": 10.040696661982423, \"fact\": 9.80607724404463, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:25:00\", \"yhat\": 9.57426852185799, \"yhat_lower\": 8.921554751829612, \"yhat_upper\": 10.178327800839291, \"fact\": 9.634992469023846, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:26:00\", \"yhat\": 9.586283079601872, \"yhat_lower\": 8.859765310657572, \"yhat_upper\": 10.191063993369855, \"fact\": 9.719664071742129, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:27:00\", \"yhat\": 9.598297637345752, \"yhat_lower\": 8.973163002637401, \"yhat_upper\": 10.183294028307412, \"fact\": 9.803939082783222, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:28:00\", \"yhat\": 9.610312195089634, \"yhat_lower\": 8.96580365850592, \"yhat_upper\": 10.282700324776728, \"fact\": 9.800414529471565, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:29:00\", \"yhat\": 9.622326752833514, \"yhat_lower\": 9.071840245683727, \"yhat_upper\": 10.215470896404934, \"fact\": 9.82701899851565, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:30:00\", \"yhat\": 9.7176654746229, \"yhat_lower\": 9.139774652262322, \"yhat_upper\": 10.361790370593859, \"fact\": 9.77933964253321, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:31:00\", \"yhat\": 9.731229279042253, \"yhat_lower\": 9.179897882851835, \"yhat_upper\": 10.323277139941291, \"fact\": 9.756520180732126, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:32:00\", \"yhat\": 9.744793083461605, \"yhat_lower\": 9.135464503294576, \"yhat_upper\": 10.384712452029145, \"fact\": 9.850925560836, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:33:00\", \"yhat\": 9.758356887880959, \"yhat_lower\": 9.168271344928662, \"yhat_upper\": 10.350709600175241, \"fact\": 9.804925591815215, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:34:00\", \"yhat\": 9.771920692300313, \"yhat_lower\": 9.207868567343407, \"yhat_upper\": 10.390684669792295, \"fact\": 9.619049334366524, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:35:00\", \"yhat\": 9.867632481505684, \"yhat_lower\": 9.303409790342073, \"yhat_upper\": 10.377361996676305, \"fact\": 9.600139673643671, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:36:00\", \"yhat\": 9.88297361009737, \"yhat_lower\": 9.31210936211504, \"yhat_upper\": 10.405740779755504, \"fact\": 9.654070612123258, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:37:00\", \"yhat\": 9.898314738689056, \"yhat_lower\": 9.291843387479904, \"yhat_upper\": 10.44653936237984, \"fact\": 9.81409008687884, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:38:00\", \"yhat\": 9.913655867280744, \"yhat_lower\": 9.398799801812617, \"yhat_upper\": 10.446337652158377, \"fact\": 9.86346342581928, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:39:00\", \"yhat\": 9.928996995872428, \"yhat_lower\": 9.408706893305212, \"yhat_upper\": 10.476172779234753, \"fact\": 9.857124185840512, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:40:00\", \"yhat\": 10.001688979928876, \"yhat_lower\": 9.550306202508931, \"yhat_upper\": 10.519555576424631, \"fact\": 9.983032579376141, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:41:00\", \"yhat\": 10.018562359492545, \"yhat_lower\": 9.58549178588031, \"yhat_upper\": 10.529445194842529, \"fact\": 10.037199180536911, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:42:00\", \"yhat\": 10.035435739056215, \"yhat_lower\": 9.552631372318823, \"yhat_upper\": 10.45641825111819, \"fact\": 9.993484385678066, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:43:00\", \"yhat\": 10.052309118619885, \"yhat_lower\": 9.593794285907855, \"yhat_upper\": 10.519020583891301, \"fact\": 10.0400027689603, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:44:00\", \"yhat\": 10.069182498183553, \"yhat_lower\": 9.62339047032551, \"yhat_upper\": 10.554357797476072, \"fact\": 10.034298117029037, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:45:00\", \"yhat\": 10.132556796881342, \"yhat_lower\": 9.62502895524723, \"yhat_upper\": 10.580591128943476, \"fact\": 10.076049094922666, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:46:00\", \"yhat\": 10.150509488731247, \"yhat_lower\": 9.675361917694502, \"yhat_upper\": 10.597490527666022, \"fact\": 10.0988034535548, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:47:00\", \"yhat\": 10.16846218058115, \"yhat_lower\": 9.672667198971007, \"yhat_upper\": 10.612162794856541, \"fact\": 10.03315333035482, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:48:00\", \"yhat\": 10.186414872431056, \"yhat_lower\": 9.744198680201933, \"yhat_upper\": 10.680755737992193, \"fact\": 9.989417587885512, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:49:00\", \"yhat\": 10.20436756428096, \"yhat_lower\": 9.72399835011808, \"yhat_upper\": 10.684451205494337, \"fact\": 10.142657199531792, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:50:00\", \"yhat\": 10.224309740321996, \"yhat_lower\": 9.77862157087947, \"yhat_upper\": 10.697877531487704, \"fact\": 10.255063743963055, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:51:00\", \"yhat\": 10.242505012938048, \"yhat_lower\": 9.769203005058069, \"yhat_upper\": 10.674046446640716, \"fact\": 10.289207345135177, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:52:00\", \"yhat\": 10.260700285554103, \"yhat_lower\": 9.788209002567164, \"yhat_upper\": 10.722389770732043, \"fact\": 10.290051522452643, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:53:00\", \"yhat\": 10.278895558170156, \"yhat_lower\": 9.768119753515483, \"yhat_upper\": 10.74224757407709, \"fact\": 10.208202234151164, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:54:00\", \"yhat\": 10.297090830786209, \"yhat_lower\": 9.856288726176551, \"yhat_upper\": 10.797147068912752, \"fact\": 10.20744863055363, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:55:00\", \"yhat\": 10.32711395890904, \"yhat_lower\": 9.848017852787736, \"yhat_upper\": 10.767709937418932, \"fact\": 10.102381099087888, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:56:00\", \"yhat\": 10.34563524080256, \"yhat_lower\": 9.880786140240026, \"yhat_upper\": 10.841555227787882, \"fact\": 10.187155935748017, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:57:00\", \"yhat\": 10.364156522696081, \"yhat_lower\": 9.906184618185872, \"yhat_upper\": 10.831432452806352, \"fact\": 10.126046394947553, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:58:00\", \"yhat\": 10.382677804589603, \"yhat_lower\": 9.8969856474249, \"yhat_upper\": 10.826194898347019, \"fact\": 10.077830439271654, \"anomaly\": 0}, {\"ds\": \"2021-08-23T14:59:00\", \"yhat\": 10.401199086483123, \"yhat_lower\": 9.911250041506838, \"yhat_upper\": 10.881003805716844, \"fact\": 10.112502220252225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:00:00\", \"yhat\": 10.377943356318609, \"yhat_lower\": 9.933290454004004, \"yhat_upper\": 10.828554199466932, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:01:00\", \"yhat\": 10.395957728135327, \"yhat_lower\": 9.874520317880618, \"yhat_upper\": 10.855407206362445, \"fact\": 10.2942943861814, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:02:00\", \"yhat\": 10.413972099952046, \"yhat_lower\": 9.96501589585462, \"yhat_upper\": 10.861202897290626, \"fact\": 10.205446118651967, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:03:00\", \"yhat\": 10.431986471768765, \"yhat_lower\": 9.94617438160715, \"yhat_upper\": 10.90993552139573, \"fact\": 10.271409386655742, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:04:00\", \"yhat\": 10.450000843585489, \"yhat_lower\": 10.007979018111447, \"yhat_upper\": 10.904328741331977, \"fact\": 10.256522349950478, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:05:00\", \"yhat\": 10.428529223526523, \"yhat_lower\": 9.993695954461923, \"yhat_upper\": 10.869102298290752, \"fact\": 10.17902731704118, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:06:00\", \"yhat\": 10.445882604263392, \"yhat_lower\": 9.987505376170304, \"yhat_upper\": 10.847928284785086, \"fact\": 10.223078359670582, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:07:00\", \"yhat\": 10.463235985000262, \"yhat_lower\": 10.007876966324854, \"yhat_upper\": 10.921637754730124, \"fact\": 10.289101894089889, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:08:00\", \"yhat\": 10.48058936573713, \"yhat_lower\": 10.059532447907438, \"yhat_upper\": 10.953042164595862, \"fact\": 10.452816223055665, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:09:00\", \"yhat\": 10.497942746474001, \"yhat_lower\": 10.072072403485501, \"yhat_upper\": 10.959666045691181, \"fact\": 10.530367461184968, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:10:00\", \"yhat\": 10.510072268977254, \"yhat_lower\": 10.083493617757018, \"yhat_upper\": 11.01479187179078, \"fact\": 10.515200566630206, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:11:00\", \"yhat\": 10.527486846728745, \"yhat_lower\": 10.042607018939425, \"yhat_upper\": 10.988842385107398, \"fact\": 10.462488799078955, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:12:00\", \"yhat\": 10.544901424480237, \"yhat_lower\": 10.087678005060598, \"yhat_upper\": 11.025707118901718, \"fact\": 10.536617371571872, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:13:00\", \"yhat\": 10.562316002231729, \"yhat_lower\": 10.12003537563061, \"yhat_upper\": 11.00027719214921, \"fact\": 10.582085913026225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:14:00\", \"yhat\": 10.579730579983218, \"yhat_lower\": 10.10682509245261, \"yhat_upper\": 11.083099783679245, \"fact\": 10.453705254361472, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:15:00\", \"yhat\": 10.570682555673146, \"yhat_lower\": 10.088015285624504, \"yhat_upper\": 10.988730357906137, \"fact\": 10.481826344423022, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:16:00\", \"yhat\": 10.587580957709477, \"yhat_lower\": 10.136320347874035, \"yhat_upper\": 11.05396028106262, \"fact\": 10.353428837573519, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:17:00\", \"yhat\": 10.604479359745811, \"yhat_lower\": 10.145691745519027, \"yhat_upper\": 11.046973614861926, \"fact\": 10.342528897524867, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:18:00\", \"yhat\": 10.621377761782142, \"yhat_lower\": 10.15717729240886, \"yhat_upper\": 11.095357074367888, \"fact\": 10.289505252298003, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:19:00\", \"yhat\": 10.638276163818475, \"yhat_lower\": 10.223221388676569, \"yhat_upper\": 11.07985595963978, \"fact\": 10.233404516009793, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:20:00\", \"yhat\": 10.594443001543334, \"yhat_lower\": 10.181240923270012, \"yhat_upper\": 11.050553459126789, \"fact\": 10.398350843814256, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:21:00\", \"yhat\": 10.610435683854364, \"yhat_lower\": 10.208814982353612, \"yhat_upper\": 11.04845973228696, \"fact\": 10.413367861232464, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:22:00\", \"yhat\": 10.626428366165392, \"yhat_lower\": 10.16390328808611, \"yhat_upper\": 11.039773949960308, \"fact\": 10.465737097515472, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:23:00\", \"yhat\": 10.64242104847642, \"yhat_lower\": 10.209699622617043, \"yhat_upper\": 11.062964924992137, \"fact\": 10.540956107018431, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:24:00\", \"yhat\": 10.65841373078745, \"yhat_lower\": 10.19833495785173, \"yhat_upper\": 11.114855847022596, \"fact\": 10.419642110204657, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:25:00\", \"yhat\": 10.637007022482484, \"yhat_lower\": 10.164302513610142, \"yhat_upper\": 11.054951261696251, \"fact\": 10.38830467957498, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:26:00\", \"yhat\": 10.652487817731192, \"yhat_lower\": 10.194059849280922, \"yhat_upper\": 11.098730923865281, \"fact\": 10.337534746596601, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:27:00\", \"yhat\": 10.667968612979898, \"yhat_lower\": 10.187333712345199, \"yhat_upper\": 11.082997291907654, \"fact\": 10.446651275126646, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:28:00\", \"yhat\": 10.683449408228606, \"yhat_lower\": 10.253330738667334, \"yhat_upper\": 11.163169396742308, \"fact\": 10.514004036753205, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:29:00\", \"yhat\": 10.698930203477314, \"yhat_lower\": 10.235849392851287, \"yhat_upper\": 11.130428142337887, \"fact\": 10.507311180202013, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:30:00\", \"yhat\": 10.671510735494264, \"yhat_lower\": 10.24521830584141, \"yhat_upper\": 11.137399069928593, \"fact\": 10.600130615972407, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:31:00\", \"yhat\": 10.686409637126719, \"yhat_lower\": 10.208060794683833, \"yhat_upper\": 11.170139979971937, \"fact\": 10.608687106522943, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:32:00\", \"yhat\": 10.701308538759173, \"yhat_lower\": 10.243283057188256, \"yhat_upper\": 11.167952707855255, \"fact\": 10.484335112185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:33:00\", \"yhat\": 10.716207440391628, \"yhat_lower\": 10.277441300573575, \"yhat_upper\": 11.153055318161332, \"fact\": 10.621271569245923, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:34:00\", \"yhat\": 10.731106342024082, \"yhat_lower\": 10.249620169702437, \"yhat_upper\": 11.179247207354106, \"fact\": 10.639575926010757, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:35:00\", \"yhat\": 10.711208340951238, \"yhat_lower\": 10.274575296736609, \"yhat_upper\": 11.140670094056363, \"fact\": 10.596954129260547, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:36:00\", \"yhat\": 10.725503541949355, \"yhat_lower\": 10.320537179771513, \"yhat_upper\": 11.20265975386291, \"fact\": 10.62736816641365, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:37:00\", \"yhat\": 10.739798742947473, \"yhat_lower\": 10.262298537741882, \"yhat_upper\": 11.14894309839503, \"fact\": 10.668971329410926, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:38:00\", \"yhat\": 10.754093943945593, \"yhat_lower\": 10.34832224081996, \"yhat_upper\": 11.191705176420301, \"fact\": 10.960130410890418, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:39:00\", \"yhat\": 10.768389144943711, \"yhat_lower\": 10.346882401905082, \"yhat_upper\": 11.230875802374193, \"fact\": 11.0, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:40:00\", \"yhat\": 10.784416166486261, \"yhat_lower\": 10.352175665075363, \"yhat_upper\": 11.188066484588113, \"fact\": 10.944748604963694, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:41:00\", \"yhat\": 10.798680241645886, \"yhat_lower\": 10.373149984287366, \"yhat_upper\": 11.256959534944956, \"fact\": 10.762400197925471, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:42:00\", \"yhat\": 10.81294431680551, \"yhat_lower\": 10.399697129988397, \"yhat_upper\": 11.279332357495898, \"fact\": 10.633397214168852, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:43:00\", \"yhat\": 10.827208391965133, \"yhat_lower\": 10.35817629574591, \"yhat_upper\": 11.274290085413991, \"fact\": 10.508366912453496, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:44:00\", \"yhat\": 10.841472467124758, \"yhat_lower\": 10.396582041637654, \"yhat_upper\": 11.292136292211614, \"fact\": 10.747813043137848, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:45:00\", \"yhat\": 10.83561976979995, \"yhat_lower\": 10.403821985847355, \"yhat_upper\": 11.294733614464985, \"fact\": 10.616517623097478, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:46:00\", \"yhat\": 10.849605721051214, \"yhat_lower\": 10.429172275727177, \"yhat_upper\": 11.264506628451295, \"fact\": 10.519134892650595, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:47:00\", \"yhat\": 10.863591672302478, \"yhat_lower\": 10.42276846185639, \"yhat_upper\": 11.335984130462148, \"fact\": 10.505485347067411, \"anomaly\": 0}, {\"ds\": \"2021-08-23T15:50:00\", \"yhat\": 10.832762856228467, \"yhat_lower\": 10.366899405916355, \"yhat_upper\": 11.3418305461835, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:25:00\", \"yhat\": 10.104342153758534, \"yhat_lower\": 9.469181633384663, \"yhat_upper\": 10.777229435585237, \"fact\": 9.592600239141852, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:38:00\", \"yhat\": 9.714603558792167, \"yhat_lower\": 9.037755968947904, \"yhat_upper\": 10.361439187708715, \"fact\": 9.039800746733981, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:40:00\", \"yhat\": 9.536296933553931, \"yhat_lower\": 8.866172936745173, \"yhat_upper\": 10.302073891299463, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:45:00\", \"yhat\": 9.366646199970733, \"yhat_lower\": 8.607558392562751, \"yhat_upper\": 10.075991135262667, \"fact\": 8.782616489057622, \"anomaly\": 0}, {\"ds\": \"2021-08-23T16:50:00\", \"yhat\": 9.124603463423679, \"yhat_lower\": 8.403112257239563, \"yhat_upper\": 9.78784074383796, \"fact\": 8.530052782649555, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:10:00\", \"yhat\": 8.016204123329612, \"yhat_lower\": 7.456478489419429, \"yhat_upper\": 8.60484670472872, \"fact\": 7.457128971331552, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:11:00\", \"yhat\": 7.992657209653554, \"yhat_lower\": 7.379445867378461, \"yhat_upper\": 8.613508153444533, \"fact\": 7.49124494359832, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:12:00\", \"yhat\": 7.969110295977499, \"yhat_lower\": 7.33730891826001, \"yhat_upper\": 8.596489937273272, \"fact\": 7.746174323894706, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:13:00\", \"yhat\": 7.945563382301443, \"yhat_lower\": 7.330088458641419, \"yhat_upper\": 8.586817801914153, \"fact\": 7.728164560761447, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:14:00\", \"yhat\": 7.9220164686253876, \"yhat_lower\": 7.2928357440027884, \"yhat_upper\": 8.626722064420779, \"fact\": 7.57497190780261, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:15:00\", \"yhat\": 7.768477303332562, \"yhat_lower\": 7.0872502622613975, \"yhat_upper\": 8.302808572199314, \"fact\": 7.629350721280201, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:16:00\", \"yhat\": 7.742636916015501, \"yhat_lower\": 7.134193529738729, \"yhat_upper\": 8.35663041102185, \"fact\": 7.670839399995044, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:17:00\", \"yhat\": 7.7167965286984375, \"yhat_lower\": 7.144608474912343, \"yhat_upper\": 8.296734537586406, \"fact\": 7.8020911978599985, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:18:00\", \"yhat\": 7.690956141381374, \"yhat_lower\": 7.076764576098388, \"yhat_upper\": 8.272281113431289, \"fact\": 7.688201610108968, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:19:00\", \"yhat\": 7.665115754064313, \"yhat_lower\": 7.059379449033429, \"yhat_upper\": 8.366249565268514, \"fact\": 7.491134163279598, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:20:00\", \"yhat\": 7.563337328501627, \"yhat_lower\": 7.014869632937802, \"yhat_upper\": 8.114978327545412, \"fact\": 7.541546760013012, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:21:00\", \"yhat\": 7.535885558366894, \"yhat_lower\": 6.928962420684344, \"yhat_upper\": 8.084080266357521, \"fact\": 7.322022918010769, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:22:00\", \"yhat\": 7.50843378823216, \"yhat_lower\": 6.985663305723257, \"yhat_upper\": 8.075801261185855, \"fact\": 7.235580785625353, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:23:00\", \"yhat\": 7.480982018097427, \"yhat_lower\": 6.862226225607545, \"yhat_upper\": 8.04879652176825, \"fact\": 7.270589900870376, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:24:00\", \"yhat\": 7.453530247962691, \"yhat_lower\": 6.900055050587304, \"yhat_upper\": 8.078388014673807, \"fact\": 7.166069908720111, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:25:00\", \"yhat\": 7.341017299196498, \"yhat_lower\": 6.816223900665392, \"yhat_upper\": 7.904981147993691, \"fact\": 7.084649033319625, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:26:00\", \"yhat\": 7.311990409361209, \"yhat_lower\": 6.7911221691770685, \"yhat_upper\": 7.862852600624656, \"fact\": 6.953837567532185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:27:00\", \"yhat\": 7.2829635195259215, \"yhat_lower\": 6.759646442385876, \"yhat_upper\": 7.822096523601909, \"fact\": 6.9788882663663205, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:28:00\", \"yhat\": 7.253936629690635, \"yhat_lower\": 6.703778166787607, \"yhat_upper\": 7.809413009811246, \"fact\": 7.166048798085546, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:29:00\", \"yhat\": 7.224909739855346, \"yhat_lower\": 6.696820450825303, \"yhat_upper\": 7.76485200357573, \"fact\": 7.397644550791485, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:30:00\", \"yhat\": 7.111046612206254, \"yhat_lower\": 6.623004646897468, \"yhat_upper\": 7.584998755709978, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:31:00\", \"yhat\": 7.0803946269283555, \"yhat_lower\": 6.608217268391012, \"yhat_upper\": 7.603231168711064, \"fact\": 7.244896929081159, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:32:00\", \"yhat\": 7.04974264165045, \"yhat_lower\": 6.55328865091066, \"yhat_upper\": 7.610602454321058, \"fact\": 7.163683211087717, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:33:00\", \"yhat\": 7.01909065637255, \"yhat_lower\": 6.556612674182462, \"yhat_upper\": 7.523413045373181, \"fact\": 6.997342471102844, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:34:00\", \"yhat\": 6.988438671094648, \"yhat_lower\": 6.4860269502342565, \"yhat_upper\": 7.4734004438777815, \"fact\": 6.910312134996908, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:35:00\", \"yhat\": 6.91761028625125, \"yhat_lower\": 6.44129447581451, \"yhat_upper\": 7.393743527977997, \"fact\": 6.920281767120731, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:36:00\", \"yhat\": 6.886009254251673, \"yhat_lower\": 6.4113484263359855, \"yhat_upper\": 7.332645257306482, \"fact\": 7.005098218639339, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:37:00\", \"yhat\": 6.8544082222520935, \"yhat_lower\": 6.416287371297286, \"yhat_upper\": 7.314359724610084, \"fact\": 7.073528376327899, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:38:00\", \"yhat\": 6.822807190252517, \"yhat_lower\": 6.3631630730874305, \"yhat_upper\": 7.33553022194231, \"fact\": 7.092071643143026, \"anomaly\": 0}, {\"ds\": \"2021-08-23T17:39:00\", \"yhat\": 6.791206158252938, \"yhat_lower\": 6.330088550434519, \"yhat_upper\": 7.250938874117, \"fact\": 7.2003894873370955, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:01:00\", \"yhat\": 6.490043370587163, \"yhat_lower\": 5.905858315707741, \"yhat_upper\": 7.086134146046709, \"fact\": 7.017751526939817, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:05:00\", \"yhat\": 6.488767446775505, \"yhat_lower\": 5.92017434614851, \"yhat_upper\": 7.118918046548412, \"fact\": 7.039528369282021, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:06:00\", \"yhat\": 6.461993219164632, \"yhat_lower\": 5.846629335046613, \"yhat_upper\": 7.100302981966062, \"fact\": 7.033655777722624, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:10:00\", \"yhat\": 6.458592220787118, \"yhat_lower\": 5.81141780301464, \"yhat_upper\": 7.052380949993447, \"fact\": 6.8390032876923215, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:11:00\", \"yhat\": 6.433119916054208, \"yhat_lower\": 5.873171970929596, \"yhat_upper\": 7.078012847797866, \"fact\": 6.691998504671839, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:12:00\", \"yhat\": 6.407647611321295, \"yhat_lower\": 5.808308927952229, \"yhat_upper\": 7.006752916985074, \"fact\": 6.752681942577438, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:13:00\", \"yhat\": 6.382175306588385, \"yhat_lower\": 5.800335207614485, \"yhat_upper\": 7.035526860088057, \"fact\": 6.73868451382265, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:14:00\", \"yhat\": 6.356703001855473, \"yhat_lower\": 5.726310096178405, \"yhat_upper\": 6.938533935927566, \"fact\": 6.680331145067498, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:15:00\", \"yhat\": 6.405434880668331, \"yhat_lower\": 5.8344007570339596, \"yhat_upper\": 6.991768148775121, \"fact\": 6.6180921787104054, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:16:00\", \"yhat\": 6.381043952568925, \"yhat_lower\": 5.784482255801548, \"yhat_upper\": 6.974904555497599, \"fact\": 6.6895657202333645, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:17:00\", \"yhat\": 6.356653024469517, \"yhat_lower\": 5.800129791767797, \"yhat_upper\": 6.998323638177441, \"fact\": 6.72316112495938, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:18:00\", \"yhat\": 6.332262096370111, \"yhat_lower\": 5.7940512741871055, \"yhat_upper\": 6.9159632600761185, \"fact\": 6.738952790095521, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:19:00\", \"yhat\": 6.307871168270705, \"yhat_lower\": 5.676210683853358, \"yhat_upper\": 6.927952096018118, \"fact\": 6.664365358351624, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:20:00\", \"yhat\": 6.369075860623301, \"yhat_lower\": 5.837616921141535, \"yhat_upper\": 6.965969747561376, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:21:00\", \"yhat\": 6.346025816376657, \"yhat_lower\": 5.736789886219477, \"yhat_upper\": 6.922504988240872, \"fact\": 6.724600878108458, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:22:00\", \"yhat\": 6.322975772130011, \"yhat_lower\": 5.705574516983221, \"yhat_upper\": 6.85571896469738, \"fact\": 6.580937541938436, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:23:00\", \"yhat\": 6.299925727883366, \"yhat_lower\": 5.723294877977075, \"yhat_upper\": 6.910919505396513, \"fact\": 6.555562177433832, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:24:00\", \"yhat\": 6.27687568363672, \"yhat_lower\": 5.669579212508893, \"yhat_upper\": 6.864048345163709, \"fact\": 6.659379361607502, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:25:00\", \"yhat\": 6.318371726321388, \"yhat_lower\": 5.728181975035238, \"yhat_upper\": 6.802511527723158, \"fact\": 6.375346888821504, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:26:00\", \"yhat\": 6.296312630989526, \"yhat_lower\": 5.684121513190032, \"yhat_upper\": 6.832592786657831, \"fact\": 6.228907112687021, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:27:00\", \"yhat\": 6.2742535356576665, \"yhat_lower\": 5.696057371346161, \"yhat_upper\": 6.826121399118396, \"fact\": 6.35302739173681, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:28:00\", \"yhat\": 6.252194440325807, \"yhat_lower\": 5.743320292590617, \"yhat_upper\": 6.77229644106809, \"fact\": 6.189166144427423, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:29:00\", \"yhat\": 6.230135344993947, \"yhat_lower\": 5.646325783268235, \"yhat_upper\": 6.769193467444064, \"fact\": 6.260671502798964, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:30:00\", \"yhat\": 6.238910271322805, \"yhat_lower\": 5.609144264190328, \"yhat_upper\": 6.824202081087175, \"fact\": 6.171678268702035, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:31:00\", \"yhat\": 6.217504491025063, \"yhat_lower\": 5.735527801656249, \"yhat_upper\": 6.71973847636509, \"fact\": 6.186759614812712, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:32:00\", \"yhat\": 6.19609871072732, \"yhat_lower\": 5.679283267102276, \"yhat_upper\": 6.743496814226547, \"fact\": 6.140920120718393, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:33:00\", \"yhat\": 6.174692930429579, \"yhat_lower\": 5.611414598905765, \"yhat_upper\": 6.76668178715042, \"fact\": 6.2395658921642525, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:34:00\", \"yhat\": 6.153287150131836, \"yhat_lower\": 5.57534324760784, \"yhat_upper\": 6.746112119489736, \"fact\": 6.243797647964152, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:35:00\", \"yhat\": 6.165676598817967, \"yhat_lower\": 5.629421749213169, \"yhat_upper\": 6.6921755677464505, \"fact\": 6.470077371588114, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:36:00\", \"yhat\": 6.144999160830499, \"yhat_lower\": 5.5911187426424265, \"yhat_upper\": 6.689802155251396, \"fact\": 6.60046767084194, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:50:00\", \"yhat\": 6.277515612553597, \"yhat_lower\": 5.732103303367954, \"yhat_upper\": 6.858839941541504, \"fact\": 6.728335674496716, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:51:00\", \"yhat\": 6.262483184569454, \"yhat_lower\": 5.734030047134737, \"yhat_upper\": 6.7650729210263645, \"fact\": 6.747618665608875, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:52:00\", \"yhat\": 6.247450756585312, \"yhat_lower\": 5.66069432402467, \"yhat_upper\": 6.851727343580302, \"fact\": 6.555395135552946, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:53:00\", \"yhat\": 6.232418328601169, \"yhat_lower\": 5.633396681325324, \"yhat_upper\": 6.829233896388081, \"fact\": 6.593569618569199, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:54:00\", \"yhat\": 6.217385900617026, \"yhat_lower\": 5.706341660942245, \"yhat_upper\": 6.770813359201885, \"fact\": 6.537512510098631, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:55:00\", \"yhat\": 6.310722064778587, \"yhat_lower\": 5.772672417802252, \"yhat_upper\": 6.844727617864523, \"fact\": 6.511672421125268, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:56:00\", \"yhat\": 6.297457920595258, \"yhat_lower\": 5.752831022853284, \"yhat_upper\": 6.880091673668895, \"fact\": 6.631520179746892, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:57:00\", \"yhat\": 6.284193776411929, \"yhat_lower\": 5.761597511900887, \"yhat_upper\": 6.820761719281001, \"fact\": 6.75546745691182, \"anomaly\": 0}, {\"ds\": \"2021-08-23T18:59:00\", \"yhat\": 6.257665488045271, \"yhat_lower\": 5.765545096836638, \"yhat_upper\": 6.810068271720524, \"fact\": 6.798885033129787, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:00:00\", \"yhat\": 6.348616519518929, \"yhat_lower\": 5.79987090427162, \"yhat_upper\": 6.8734345694426535, \"fact\": 6.74534060560366, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:01:00\", \"yhat\": 6.336999064165523, \"yhat_lower\": 5.828868077770514, \"yhat_upper\": 6.886415808437503, \"fact\": 6.872906486758738, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:10:00\", \"yhat\": 6.490125754204046, \"yhat_lower\": 5.935918485726143, \"yhat_upper\": 6.9971637790041274, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:12:00\", \"yhat\": 6.473941070061912, \"yhat_lower\": 5.913432210088747, \"yhat_upper\": 7.00569434298764, \"fact\": 6.966991581251915, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:25:00\", \"yhat\": 6.771964021445936, \"yhat_lower\": 6.227183986626315, \"yhat_upper\": 7.346424237172875, \"fact\": 7.123867211441125, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:26:00\", \"yhat\": 6.769069000173238, \"yhat_lower\": 6.207747340274179, \"yhat_upper\": 7.317840898375763, \"fact\": 7.120132713051596, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:27:00\", \"yhat\": 6.7661739789005395, \"yhat_lower\": 6.231850746308391, \"yhat_upper\": 7.426089303502437, \"fact\": 7.0565544845028185, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:28:00\", \"yhat\": 6.763278957627842, \"yhat_lower\": 6.2336630803870445, \"yhat_upper\": 7.305835866026459, \"fact\": 7.139838404300698, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:29:00\", \"yhat\": 6.760383936355144, \"yhat_lower\": 6.192677748795659, \"yhat_upper\": 7.356576341170348, \"fact\": 7.20277666346131, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:30:00\", \"yhat\": 6.843311540192162, \"yhat_lower\": 6.25539491852788, \"yhat_upper\": 7.423275209755657, \"fact\": 7.040986511007052, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:31:00\", \"yhat\": 6.841746922933681, \"yhat_lower\": 6.2211606999391975, \"yhat_upper\": 7.455683426140256, \"fact\": 7.006594977513499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:32:00\", \"yhat\": 6.840182305675199, \"yhat_lower\": 6.2982971504262055, \"yhat_upper\": 7.3747318365395955, \"fact\": 7.105131073775493, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:33:00\", \"yhat\": 6.8386176884167185, \"yhat_lower\": 6.276437105712251, \"yhat_upper\": 7.407325729320813, \"fact\": 6.966567283612587, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:34:00\", \"yhat\": 6.837053071158237, \"yhat_lower\": 6.2851351183305155, \"yhat_upper\": 7.510323127862269, \"fact\": 7.067989237821224, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:35:00\", \"yhat\": 6.891893326327778, \"yhat_lower\": 6.333709629602724, \"yhat_upper\": 7.448100788342722, \"fact\": 7.134185474168518, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:36:00\", \"yhat\": 6.891278024364434, \"yhat_lower\": 6.38293198996686, \"yhat_upper\": 7.4532464752417775, \"fact\": 7.0416050260755325, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:37:00\", \"yhat\": 6.89066272240109, \"yhat_lower\": 6.336100258777909, \"yhat_upper\": 7.421572943965253, \"fact\": 6.980618485802484, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:38:00\", \"yhat\": 6.890047420437747, \"yhat_lower\": 6.308480766760866, \"yhat_upper\": 7.436368994018163, \"fact\": 7.066809141768836, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:39:00\", \"yhat\": 6.889432118474404, \"yhat_lower\": 6.310245794433997, \"yhat_upper\": 7.405089560731449, \"fact\": 7.191769766968483, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:40:00\", \"yhat\": 6.929110964399863, \"yhat_lower\": 6.325198507320823, \"yhat_upper\": 7.4445609949673415, \"fact\": 7.352789477352357, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:41:00\", \"yhat\": 6.929094638349788, \"yhat_lower\": 6.365627395945476, \"yhat_upper\": 7.441855545205153, \"fact\": 7.435857234044891, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:42:00\", \"yhat\": 6.929078312299715, \"yhat_lower\": 6.422412956293233, \"yhat_upper\": 7.49457329106929, \"fact\": 7.224490309562595, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:43:00\", \"yhat\": 6.929061986249641, \"yhat_lower\": 6.4026431846224945, \"yhat_upper\": 7.4922607084509165, \"fact\": 7.123376652717213, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:44:00\", \"yhat\": 6.9290456601995665, \"yhat_lower\": 6.4170870797699155, \"yhat_upper\": 7.432068985070978, \"fact\": 7.0722055728658, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:45:00\", \"yhat\": 6.986662788632522, \"yhat_lower\": 6.420459937798061, \"yhat_upper\": 7.509044235880721, \"fact\": 7.0742890656413255, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:46:00\", \"yhat\": 6.987425907646082, \"yhat_lower\": 6.428609945196617, \"yhat_upper\": 7.6311293480356674, \"fact\": 7.242089094524295, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:47:00\", \"yhat\": 6.988189026659642, \"yhat_lower\": 6.440385539863452, \"yhat_upper\": 7.57105592164751, \"fact\": 7.124376062669945, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:48:00\", \"yhat\": 6.988952145673201, \"yhat_lower\": 6.476225374738309, \"yhat_upper\": 7.617787587612526, \"fact\": 7.211386630870367, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:49:00\", \"yhat\": 6.98971526468676, \"yhat_lower\": 6.402335000229427, \"yhat_upper\": 7.526116211460091, \"fact\": 7.327778305274825, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:50:00\", \"yhat\": 7.040327953538057, \"yhat_lower\": 6.506998340715512, \"yhat_upper\": 7.5570783792342695, \"fact\": 7.114185757892747, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:51:00\", \"yhat\": 7.041848293258926, \"yhat_lower\": 6.522651200979712, \"yhat_upper\": 7.584156508445419, \"fact\": 7.13394669208722, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:52:00\", \"yhat\": 7.043368632979794, \"yhat_lower\": 6.520281718043915, \"yhat_upper\": 7.567573738130294, \"fact\": 6.998725732620053, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:53:00\", \"yhat\": 7.044888972700662, \"yhat_lower\": 6.503225031943927, \"yhat_upper\": 7.5557592260925235, \"fact\": 6.999429650181499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:54:00\", \"yhat\": 7.04640931242153, \"yhat_lower\": 6.533422979261311, \"yhat_upper\": 7.525636865384239, \"fact\": 6.88988017320615, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:55:00\", \"yhat\": 7.068151304632034, \"yhat_lower\": 6.51631147742541, \"yhat_upper\": 7.676119168990066, \"fact\": 7.011925284409866, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:56:00\", \"yhat\": 7.070156396900664, \"yhat_lower\": 6.541183311819202, \"yhat_upper\": 7.575843907717882, \"fact\": 7.0993986854425275, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:57:00\", \"yhat\": 7.072161489169293, \"yhat_lower\": 6.552001098871787, \"yhat_upper\": 7.658977665442215, \"fact\": 7.271220399150457, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:58:00\", \"yhat\": 7.074166581437923, \"yhat_lower\": 6.521260453729821, \"yhat_upper\": 7.606775022462101, \"fact\": 7.264494897726525, \"anomaly\": 0}, {\"ds\": \"2021-08-23T19:59:00\", \"yhat\": 7.076171673706552, \"yhat_lower\": 6.5223117587183035, \"yhat_upper\": 7.652861637209306, \"fact\": 7.044423132287613, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:00:00\", \"yhat\": 7.11832187312819, \"yhat_lower\": 6.560945404388113, \"yhat_upper\": 7.667708029776471, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:01:00\", \"yhat\": 7.121103111882368, \"yhat_lower\": 6.627582824579409, \"yhat_upper\": 7.651294181959099, \"fact\": 7.021339661711941, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:02:00\", \"yhat\": 7.123884350636546, \"yhat_lower\": 6.603093209251146, \"yhat_upper\": 7.673561173530908, \"fact\": 7.317534903185268, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:03:00\", \"yhat\": 7.126665589390724, \"yhat_lower\": 6.578549159011809, \"yhat_upper\": 7.668073474482719, \"fact\": 7.10716948495657, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:04:00\", \"yhat\": 7.129446828144903, \"yhat_lower\": 6.6214583882986275, \"yhat_upper\": 7.633661783394348, \"fact\": 7.215310153650435, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:05:00\", \"yhat\": 7.161984072179014, \"yhat_lower\": 6.643744756265082, \"yhat_upper\": 7.732835133867433, \"fact\": 7.220570452422764, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:06:00\", \"yhat\": 7.165342312888633, \"yhat_lower\": 6.617096922464014, \"yhat_upper\": 7.711520597336798, \"fact\": 7.103080980776757, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:07:00\", \"yhat\": 7.16870055359825, \"yhat_lower\": 6.658779685546905, \"yhat_upper\": 7.653939423686793, \"fact\": 7.050846940115519, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:08:00\", \"yhat\": 7.172058794307867, \"yhat_lower\": 6.671271698247327, \"yhat_upper\": 7.728816611592979, \"fact\": 6.939961443394882, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:09:00\", \"yhat\": 7.175417035017484, \"yhat_lower\": 6.6000596871554675, \"yhat_upper\": 7.699997246739782, \"fact\": 6.998102784901203, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:10:00\", \"yhat\": 7.194843411667347, \"yhat_lower\": 6.635870126882315, \"yhat_upper\": 7.750177112763163, \"fact\": 7.099749789012837, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:11:00\", \"yhat\": 7.198721064139031, \"yhat_lower\": 6.665701053921604, \"yhat_upper\": 7.724274564194186, \"fact\": 7.235330438059645, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:12:00\", \"yhat\": 7.202598716610716, \"yhat_lower\": 6.628763262107656, \"yhat_upper\": 7.67348399885847, \"fact\": 7.338052774675268, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:13:00\", \"yhat\": 7.2064763690824, \"yhat_lower\": 6.658351663863388, \"yhat_upper\": 7.691735412612723, \"fact\": 7.288772432558911, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:14:00\", \"yhat\": 7.210354021554085, \"yhat_lower\": 6.684425479957183, \"yhat_upper\": 7.7370263307869145, \"fact\": 7.324544402704568, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:15:00\", \"yhat\": 7.266513797055888, \"yhat_lower\": 6.808054784494294, \"yhat_upper\": 7.791733459834732, \"fact\": 7.121821576872811, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:16:00\", \"yhat\": 7.271434291513951, \"yhat_lower\": 6.787498275102295, \"yhat_upper\": 7.76851365004242, \"fact\": 7.287459513397984, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:17:00\", \"yhat\": 7.276354785972014, \"yhat_lower\": 6.784946429418977, \"yhat_upper\": 7.749520693710653, \"fact\": 7.314871558542801, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:18:00\", \"yhat\": 7.281275280430078, \"yhat_lower\": 6.809427622026922, \"yhat_upper\": 7.819224303497808, \"fact\": 7.415176143796352, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:19:00\", \"yhat\": 7.286195774888141, \"yhat_lower\": 6.786815068841011, \"yhat_upper\": 7.736914398193088, \"fact\": 7.516025127146469, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:20:00\", \"yhat\": 7.333154796597951, \"yhat_lower\": 6.8507843210210995, \"yhat_upper\": 7.79052758142366, \"fact\": 7.6050364669125985, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:21:00\", \"yhat\": 7.338913339014317, \"yhat_lower\": 6.810629516662267, \"yhat_upper\": 7.835059042582909, \"fact\": 7.566205083257227, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:22:00\", \"yhat\": 7.344671881430684, \"yhat_lower\": 6.893967695611882, \"yhat_upper\": 7.841694676841951, \"fact\": 7.729722886759445, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:23:00\", \"yhat\": 7.350430423847049, \"yhat_lower\": 6.890253041103809, \"yhat_upper\": 7.814418672647727, \"fact\": 7.763741051140791, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:24:00\", \"yhat\": 7.356188966263416, \"yhat_lower\": 6.923221989822984, \"yhat_upper\": 7.933897481516081, \"fact\": 7.791223704044699, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:26:00\", \"yhat\": 7.448542524592189, \"yhat_lower\": 6.995449514110212, \"yhat_upper\": 7.9043720433563935, \"fact\": 7.849663097795245, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:27:00\", \"yhat\": 7.455484795281505, \"yhat_lower\": 7.010506158809517, \"yhat_upper\": 7.953224353593796, \"fact\": 7.787666292025311, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:28:00\", \"yhat\": 7.46242706597082, \"yhat_lower\": 6.99736529118707, \"yhat_upper\": 7.972579448923942, \"fact\": 7.948607630624028, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:30:00\", \"yhat\": 7.562262913334783, \"yhat_lower\": 7.072805103237986, \"yhat_upper\": 8.029561908055324, \"fact\": 7.939931606789101, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:31:00\", \"yhat\": 7.570334466602441, \"yhat_lower\": 7.0604643245640455, \"yhat_upper\": 8.066583165325037, \"fact\": 8.01138413900431, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:32:00\", \"yhat\": 7.5784060198700995, \"yhat_lower\": 7.094935904491729, \"yhat_upper\": 8.121823874316341, \"fact\": 8.024263331132907, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:33:00\", \"yhat\": 7.586477573137756, \"yhat_lower\": 7.103644463503989, \"yhat_upper\": 8.076668168177017, \"fact\": 8.02728778518364, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:42:00\", \"yhat\": 7.856462959296011, \"yhat_lower\": 7.326829943773933, \"yhat_upper\": 8.433110603051192, \"fact\": 8.331208792762425, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:43:00\", \"yhat\": 7.866779956976112, \"yhat_lower\": 7.360029895328991, \"yhat_upper\": 8.421081304009354, \"fact\": 8.236846240515225, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:44:00\", \"yhat\": 7.877096954656212, \"yhat_lower\": 7.322644605915213, \"yhat_upper\": 8.413904953284623, \"fact\": 8.256041617140585, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:45:00\", \"yhat\": 7.953556208194658, \"yhat_lower\": 7.388421428488658, \"yhat_upper\": 8.472466092037724, \"fact\": 8.380900569385801, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:46:00\", \"yhat\": 7.964524704606791, \"yhat_lower\": 7.408898604299068, \"yhat_upper\": 8.576995979638907, \"fact\": 8.283185908846015, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:47:00\", \"yhat\": 7.975493201018925, \"yhat_lower\": 7.445983157925619, \"yhat_upper\": 8.549521528846652, \"fact\": 8.19681328000246, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:48:00\", \"yhat\": 7.98646169743106, \"yhat_lower\": 7.440099292150773, \"yhat_upper\": 8.491368746532885, \"fact\": 8.268775956135276, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:49:00\", \"yhat\": 7.997430193843193, \"yhat_lower\": 7.4485034713293325, \"yhat_upper\": 8.52627345283565, \"fact\": 8.42869425982205, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:50:00\", \"yhat\": 8.055576873600153, \"yhat_lower\": 7.5505931539661555, \"yhat_upper\": 8.559969408768378, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:51:00\", \"yhat\": 8.067092195709584, \"yhat_lower\": 7.5571753845390175, \"yhat_upper\": 8.579337522603865, \"fact\": 8.475701630597108, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:57:00\", \"yhat\": 8.213835380882355, \"yhat_lower\": 7.6700127792320325, \"yhat_upper\": 8.757749984637162, \"fact\": 8.7413195426343, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:58:00\", \"yhat\": 8.226218466734295, \"yhat_lower\": 7.6984281950199325, \"yhat_upper\": 8.788914770537321, \"fact\": 8.735522823807608, \"anomaly\": 0}, {\"ds\": \"2021-08-23T20:59:00\", \"yhat\": 8.238601552586234, \"yhat_lower\": 7.681374963463389, \"yhat_upper\": 8.772181495001483, \"fact\": 8.755033678541, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:00:00\", \"yhat\": 8.347086848218272, \"yhat_lower\": 7.822433697027137, \"yhat_upper\": 8.935566691392399, \"fact\": 8.697623905237386, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:01:00\", \"yhat\": 8.360723004335664, \"yhat_lower\": 7.81546474470819, \"yhat_upper\": 8.923337822232378, \"fact\": 8.732542420245244, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:02:00\", \"yhat\": 8.374359160453057, \"yhat_lower\": 7.761425055549967, \"yhat_upper\": 8.939358357284874, \"fact\": 8.667663294380052, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:03:00\", \"yhat\": 8.38799531657045, \"yhat_lower\": 7.840476634961649, \"yhat_upper\": 8.961077435837518, \"fact\": 8.74224875192919, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:04:00\", \"yhat\": 8.401631472687843, \"yhat_lower\": 7.866307438739334, \"yhat_upper\": 8.953026681188705, \"fact\": 8.813368356071924, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:05:00\", \"yhat\": 8.476246389376694, \"yhat_lower\": 7.919578408460325, \"yhat_upper\": 9.035123614072837, \"fact\": 8.763653819520787, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:06:00\", \"yhat\": 8.490660489607272, \"yhat_lower\": 7.998328860389467, \"yhat_upper\": 9.090334186115374, \"fact\": 8.727719225687869, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:07:00\", \"yhat\": 8.50507458983785, \"yhat_lower\": 7.971555621695731, \"yhat_upper\": 9.02267908729101, \"fact\": 8.757287262181396, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:08:00\", \"yhat\": 8.519488690068428, \"yhat_lower\": 7.925185386494896, \"yhat_upper\": 9.078181529164482, \"fact\": 8.58461198633341, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:09:00\", \"yhat\": 8.533902790299006, \"yhat_lower\": 7.935340377290877, \"yhat_upper\": 9.062923964764959, \"fact\": 8.580523889099103, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:10:00\", \"yhat\": 8.583689707525437, \"yhat_lower\": 8.02919913449831, \"yhat_upper\": 9.110786340606383, \"fact\": 8.729985918072733, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:11:00\", \"yhat\": 8.598556114836583, \"yhat_lower\": 8.026714788574232, \"yhat_upper\": 9.12982030992444, \"fact\": 8.715254942693004, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:12:00\", \"yhat\": 8.613422522147728, \"yhat_lower\": 8.013776623050099, \"yhat_upper\": 9.185813078116317, \"fact\": 8.657186335028134, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:13:00\", \"yhat\": 8.62828892945887, \"yhat_lower\": 8.085555598602387, \"yhat_upper\": 9.185941573444074, \"fact\": 8.715123818586068, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:14:00\", \"yhat\": 8.643155336770016, \"yhat_lower\": 8.148965821104174, \"yhat_upper\": 9.21998573411787, \"fact\": 8.803699468934434, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:15:00\", \"yhat\": 8.69210355785946, \"yhat_lower\": 8.086418285202368, \"yhat_upper\": 9.24378058753363, \"fact\": 8.770428664936265, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:16:00\", \"yhat\": 8.707516938617939, \"yhat_lower\": 8.172616397305655, \"yhat_upper\": 9.298639262838387, \"fact\": 8.68461158678178, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:17:00\", \"yhat\": 8.72293031937642, \"yhat_lower\": 8.230705498621617, \"yhat_upper\": 9.257798423531758, \"fact\": 8.571580251558387, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:18:00\", \"yhat\": 8.7383437001349, \"yhat_lower\": 8.160292134499093, \"yhat_upper\": 9.265225984969174, \"fact\": 8.629115838099489, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:19:00\", \"yhat\": 8.75375708089338, \"yhat_lower\": 8.164504998212019, \"yhat_upper\": 9.304374574904452, \"fact\": 8.680104200208032, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:20:00\", \"yhat\": 8.783402526488135, \"yhat_lower\": 8.314866024717917, \"yhat_upper\": 9.292906829209526, \"fact\": 8.720381281982103, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:21:00\", \"yhat\": 8.799230984437786, \"yhat_lower\": 8.23642791635267, \"yhat_upper\": 9.356485036641976, \"fact\": 8.674145386553628, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:22:00\", \"yhat\": 8.815059442387437, \"yhat_lower\": 8.267002675691955, \"yhat_upper\": 9.333661060603411, \"fact\": 8.645195557966613, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:23:00\", \"yhat\": 8.830887900337087, \"yhat_lower\": 8.338459367849916, \"yhat_upper\": 9.403359639499993, \"fact\": 8.542567468006013, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:24:00\", \"yhat\": 8.846716358286738, \"yhat_lower\": 8.286360851500296, \"yhat_upper\": 9.38026192954718, \"fact\": 8.614450952639153, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:25:00\", \"yhat\": 8.859510573246947, \"yhat_lower\": 8.366551199181913, \"yhat_upper\": 9.381115873338366, \"fact\": 8.600759594883009, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:26:00\", \"yhat\": 8.875527796912952, \"yhat_lower\": 8.315183018669083, \"yhat_upper\": 9.424050932401085, \"fact\": 8.344461174673786, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:40:00\", \"yhat\": 8.860186472999196, \"yhat_lower\": 8.246907562511405, \"yhat_upper\": 9.472134153006735, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:55:00\", \"yhat\": 8.728328882974537, \"yhat_lower\": 8.09320232026054, \"yhat_upper\": 9.395505684744627, \"fact\": 8.107336569826192, \"anomaly\": 0}, {\"ds\": \"2021-08-23T21:56:00\", \"yhat\": 8.739066573487724, \"yhat_lower\": 8.052565010963995, \"yhat_upper\": 9.378879141497357, \"fact\": 8.118646844437311, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:00:00\", \"yhat\": 8.708070526410403, \"yhat_lower\": 8.050071967430679, \"yhat_upper\": 9.379216506335705, \"fact\": 8.062133599963992, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:10:00\", \"yhat\": 8.451056946076758, \"yhat_lower\": 7.802957495479487, \"yhat_upper\": 9.152669595480148, \"fact\": 7.819711007934736, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:11:00\", \"yhat\": 8.456879859701154, \"yhat_lower\": 7.8023485335973914, \"yhat_upper\": 9.123403135505475, \"fact\": 7.983399267364478, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:12:00\", \"yhat\": 8.462702773325551, \"yhat_lower\": 7.758411782037537, \"yhat_upper\": 9.20749246477543, \"fact\": 7.958116508233395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:13:00\", \"yhat\": 8.468525686949949, \"yhat_lower\": 7.697949609905448, \"yhat_upper\": 9.161630421808495, \"fact\": 7.968943931383387, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:14:00\", \"yhat\": 8.474348600574347, \"yhat_lower\": 7.755732733672537, \"yhat_upper\": 9.217059046268856, \"fact\": 8.088943997843543, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:15:00\", \"yhat\": 8.346218764451846, \"yhat_lower\": 7.6629389311597045, \"yhat_upper\": 9.032946257328117, \"fact\": 7.94868555720843, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:16:00\", \"yhat\": 8.349922325992406, \"yhat_lower\": 7.657003986056391, \"yhat_upper\": 8.989569507659512, \"fact\": 8.031676300784632, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:17:00\", \"yhat\": 8.353625887532965, \"yhat_lower\": 7.673277231758184, \"yhat_upper\": 9.025504978803564, \"fact\": 7.919155930994936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:18:00\", \"yhat\": 8.357329449073525, \"yhat_lower\": 7.682900971894503, \"yhat_upper\": 9.027669121943939, \"fact\": 7.860433362299011, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:19:00\", \"yhat\": 8.361033010614085, \"yhat_lower\": 7.637103996323685, \"yhat_upper\": 9.046910707365022, \"fact\": 7.887708781348885, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:20:00\", \"yhat\": 8.2212083108917, \"yhat_lower\": 7.531288840629488, \"yhat_upper\": 8.893349168061839, \"fact\": 7.95518511616727, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:21:00\", \"yhat\": 8.222452007359095, \"yhat_lower\": 7.618183307310904, \"yhat_upper\": 8.929450639316652, \"fact\": 8.031980714285634, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:22:00\", \"yhat\": 8.22369570382649, \"yhat_lower\": 7.515341854333403, \"yhat_upper\": 8.899236598445272, \"fact\": 7.986336725108602, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:23:00\", \"yhat\": 8.224939400293884, \"yhat_lower\": 7.566477834688715, \"yhat_upper\": 8.950762363295482, \"fact\": 7.9750917218656125, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:24:00\", \"yhat\": 8.22618309676128, \"yhat_lower\": 7.611807036245853, \"yhat_upper\": 8.898333220087881, \"fact\": 7.88889753640553, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:25:00\", \"yhat\": 8.06674401078142, \"yhat_lower\": 7.505273505911564, \"yhat_upper\": 8.642747157868035, \"fact\": 7.99517540935556, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:26:00\", \"yhat\": 8.064801754136132, \"yhat_lower\": 7.541849113167768, \"yhat_upper\": 8.658120942732484, \"fact\": 8.048314544065995, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:27:00\", \"yhat\": 8.062859497490845, \"yhat_lower\": 7.519278223778483, \"yhat_upper\": 8.59759282012534, \"fact\": 7.831803761276401, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:28:00\", \"yhat\": 8.060917240845555, \"yhat_lower\": 7.504786832147551, \"yhat_upper\": 8.658515481441151, \"fact\": 7.813286153136449, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:29:00\", \"yhat\": 8.058974984200267, \"yhat_lower\": 7.507540470531026, \"yhat_upper\": 8.593592077867326, \"fact\": 7.800293226728714, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:30:00\", \"yhat\": 7.95282909228629, \"yhat_lower\": 7.437466966680409, \"yhat_upper\": 8.517129780236267, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:31:00\", \"yhat\": 7.948803913440249, \"yhat_lower\": 7.411687000834916, \"yhat_upper\": 8.531342483573125, \"fact\": 7.568500650268759, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:32:00\", \"yhat\": 7.944778734594205, \"yhat_lower\": 7.3882865829195286, \"yhat_upper\": 8.492387282102019, \"fact\": 7.485083521432123, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:33:00\", \"yhat\": 7.940753555748163, \"yhat_lower\": 7.357213410287356, \"yhat_upper\": 8.44402973557609, \"fact\": 7.562902259069609, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:34:00\", \"yhat\": 7.936728376902121, \"yhat_lower\": 7.43736433222985, \"yhat_upper\": 8.500382214941341, \"fact\": 7.774237559343768, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:35:00\", \"yhat\": 7.8267962781462685, \"yhat_lower\": 7.326673649522851, \"yhat_upper\": 8.2911803059356, \"fact\": 7.84399038958902, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:36:00\", \"yhat\": 7.820862060490238, \"yhat_lower\": 7.34987726235113, \"yhat_upper\": 8.34109173664065, \"fact\": 7.703560195883743, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:37:00\", \"yhat\": 7.814927842834207, \"yhat_lower\": 7.372230050175148, \"yhat_upper\": 8.28435696859054, \"fact\": 7.580990260422031, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:38:00\", \"yhat\": 7.808993625178177, \"yhat_lower\": 7.355171184506618, \"yhat_upper\": 8.36248133299969, \"fact\": 7.536262826528088, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:39:00\", \"yhat\": 7.803059407522146, \"yhat_lower\": 7.300984482578756, \"yhat_upper\": 8.260903730558324, \"fact\": 7.479715123694341, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:40:00\", \"yhat\": 7.701991230539838, \"yhat_lower\": 7.252363939852985, \"yhat_upper\": 8.202450017512144, \"fact\": 7.547983789043043, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:41:00\", \"yhat\": 7.6942285216789195, \"yhat_lower\": 7.24434839615693, \"yhat_upper\": 8.150098397332702, \"fact\": 7.661272545133261, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:42:00\", \"yhat\": 7.686465812818, \"yhat_lower\": 7.288793512655571, \"yhat_upper\": 8.104968952336588, \"fact\": 7.799921735142088, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:43:00\", \"yhat\": 7.678703103957082, \"yhat_lower\": 7.252006635094755, \"yhat_upper\": 8.111991420223939, \"fact\": 7.90744271501311, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:44:00\", \"yhat\": 7.670940395096163, \"yhat_lower\": 7.245753074950463, \"yhat_upper\": 8.107392387692645, \"fact\": 7.9914944717499, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:46:00\", \"yhat\": 7.633260559616948, \"yhat_lower\": 7.2587927813857345, \"yhat_upper\": 8.051367596940684, \"fact\": 7.887233092209016, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:47:00\", \"yhat\": 7.62484414114539, \"yhat_lower\": 7.209991313003486, \"yhat_upper\": 8.028465456164547, \"fact\": 7.727544853299987, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:48:00\", \"yhat\": 7.616427722673833, \"yhat_lower\": 7.176361659692317, \"yhat_upper\": 7.99000187682177, \"fact\": 7.797725220766124, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:49:00\", \"yhat\": 7.608011304202275, \"yhat_lower\": 7.216217073282192, \"yhat_upper\": 8.05152394239227, \"fact\": 7.873085248908442, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:50:00\", \"yhat\": 7.591456337013657, \"yhat_lower\": 7.114469097408339, \"yhat_upper\": 8.001471275570383, \"fact\": 7.980822066822155, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:51:00\", \"yhat\": 7.582412760718312, \"yhat_lower\": 7.157214055146166, \"yhat_upper\": 8.044323650059408, \"fact\": 7.734172080818521, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:52:00\", \"yhat\": 7.573369184422969, \"yhat_lower\": 7.115197184388591, \"yhat_upper\": 8.006468855945513, \"fact\": 7.599489257353818, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:53:00\", \"yhat\": 7.564325608127627, \"yhat_lower\": 7.113589884751439, \"yhat_upper\": 7.976972138010895, \"fact\": 7.722687896015395, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:54:00\", \"yhat\": 7.555282031832282, \"yhat_lower\": 7.1414856486976905, \"yhat_upper\": 7.9585657980004845, \"fact\": 7.77275116820956, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:55:00\", \"yhat\": 7.535593920336, \"yhat_lower\": 7.154221071933848, \"yhat_upper\": 7.956234992541242, \"fact\": 7.558314501085786, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:56:00\", \"yhat\": 7.525961449498143, \"yhat_lower\": 7.079805559711838, \"yhat_upper\": 7.943102130779332, \"fact\": 7.60533623053003, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:57:00\", \"yhat\": 7.516328978660286, \"yhat_lower\": 7.102444682049894, \"yhat_upper\": 7.953940868114787, \"fact\": 7.564962022147053, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:58:00\", \"yhat\": 7.506696507822428, \"yhat_lower\": 7.0716965118860555, \"yhat_upper\": 7.913255069402451, \"fact\": 7.507104599166352, \"anomaly\": 0}, {\"ds\": \"2021-08-23T22:59:00\", \"yhat\": 7.497064036984572, \"yhat_lower\": 7.073802855095473, \"yhat_upper\": 7.920162246901812, \"fact\": 7.394733417407842, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:00:00\", \"yhat\": 7.483937072065472, \"yhat_lower\": 7.072061714345916, \"yhat_upper\": 7.884284546170553, \"fact\": 7.209009286177776, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:01:00\", \"yhat\": 7.474182830013936, \"yhat_lower\": 7.067385108195935, \"yhat_upper\": 7.910837547967137, \"fact\": 7.296538174554642, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:02:00\", \"yhat\": 7.464428587962398, \"yhat_lower\": 7.000862604578435, \"yhat_upper\": 7.86224007580215, \"fact\": 7.206584493381573, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:03:00\", \"yhat\": 7.4546743459108615, \"yhat_lower\": 7.012624585980753, \"yhat_upper\": 7.852234119082169, \"fact\": 7.160033858921166, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:04:00\", \"yhat\": 7.4449201038593245, \"yhat_lower\": 7.051419290013115, \"yhat_upper\": 7.860952834122202, \"fact\": 7.254636375974447, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:05:00\", \"yhat\": 7.391231460865729, \"yhat_lower\": 7.020166924353547, \"yhat_upper\": 7.837819286091707, \"fact\": 7.383418162205393, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:06:00\", \"yhat\": 7.380875573380851, \"yhat_lower\": 7.001778774335239, \"yhat_upper\": 7.814084841072749, \"fact\": 7.412786701811927, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:07:00\", \"yhat\": 7.370519685895973, \"yhat_lower\": 6.916059235398335, \"yhat_upper\": 7.790380653341992, \"fact\": 7.410993240415173, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:08:00\", \"yhat\": 7.360163798411095, \"yhat_lower\": 6.96652022728731, \"yhat_upper\": 7.763039502695845, \"fact\": 7.311113765840335, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:09:00\", \"yhat\": 7.349807910926216, \"yhat_lower\": 6.9370218357745115, \"yhat_upper\": 7.7935990875890955, \"fact\": 7.3759026127290195, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:10:00\", \"yhat\": 7.347071499499177, \"yhat_lower\": 6.900309763432042, \"yhat_upper\": 7.747896465446665, \"fact\": 7.429606304723798, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:11:00\", \"yhat\": 7.336865755955575, \"yhat_lower\": 6.898205776447531, \"yhat_upper\": 7.764396659896175, \"fact\": 7.49942313491552, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:12:00\", \"yhat\": 7.326660012411971, \"yhat_lower\": 6.9384552617205335, \"yhat_upper\": 7.725758469217823, \"fact\": 7.391456931311621, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:13:00\", \"yhat\": 7.316454268868368, \"yhat_lower\": 6.891663462208613, \"yhat_upper\": 7.770047460499212, \"fact\": 7.285664791754202, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:14:00\", \"yhat\": 7.306248525324766, \"yhat_lower\": 6.889443940017604, \"yhat_upper\": 7.747376387201753, \"fact\": 7.115643401562619, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:15:00\", \"yhat\": 7.3091287747251314, \"yhat_lower\": 6.864151975967688, \"yhat_upper\": 7.6873468840089, \"fact\": 7.054269618633998, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:16:00\", \"yhat\": 7.2991900880711045, \"yhat_lower\": 6.882019585363145, \"yhat_upper\": 7.747241895668053, \"fact\": 7.060118316641897, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:17:00\", \"yhat\": 7.289251401417076, \"yhat_lower\": 6.8365474265570985, \"yhat_upper\": 7.6931759999372495, \"fact\": 7.161535062516319, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:18:00\", \"yhat\": 7.279312714763048, \"yhat_lower\": 6.858044210869725, \"yhat_upper\": 7.710388391747924, \"fact\": 7.255915033132671, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:19:00\", \"yhat\": 7.269374028109019, \"yhat_lower\": 6.860733945145891, \"yhat_upper\": 7.716262970112493, \"fact\": 7.426012747469036, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:20:00\", \"yhat\": 7.233010125456862, \"yhat_lower\": 6.7843276658920315, \"yhat_upper\": 7.662842167854171, \"fact\": null, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:21:00\", \"yhat\": 7.222666999564133, \"yhat_lower\": 6.843881517410623, \"yhat_upper\": 7.602182724464214, \"fact\": 7.317126681220951, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:22:00\", \"yhat\": 7.2123238736714015, \"yhat_lower\": 6.759578879564706, \"yhat_upper\": 7.584540951052361, \"fact\": 7.437457589321834, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:23:00\", \"yhat\": 7.201980747778673, \"yhat_lower\": 6.815960885173228, \"yhat_upper\": 7.619627954845317, \"fact\": 7.411908464884772, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:24:00\", \"yhat\": 7.191637621885942, \"yhat_lower\": 6.737571611192854, \"yhat_upper\": 7.668319668688082, \"fact\": 7.524143393749286, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:25:00\", \"yhat\": 7.226905370486768, \"yhat_lower\": 6.7966188951487485, \"yhat_upper\": 7.660259241932242, \"fact\": 7.496314903881952, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:26:00\", \"yhat\": 7.217272560126105, \"yhat_lower\": 6.86475897928047, \"yhat_upper\": 7.639595965576988, \"fact\": 7.573752510226136, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:27:00\", \"yhat\": 7.207639749765441, \"yhat_lower\": 6.804391695255277, \"yhat_upper\": 7.570816685637186, \"fact\": 7.541365430808015, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:28:00\", \"yhat\": 7.198006939404778, \"yhat_lower\": 6.761491337163976, \"yhat_upper\": 7.60917976025573, \"fact\": 7.502722693475748, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:29:00\", \"yhat\": 7.188374129044114, \"yhat_lower\": 6.7846916276273745, \"yhat_upper\": 7.556971153943332, \"fact\": 7.432187339829274, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:30:00\", \"yhat\": 7.244370301405081, \"yhat_lower\": 6.843163377518276, \"yhat_upper\": 7.634695847003431, \"fact\": 7.367743829771953, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:31:00\", \"yhat\": 7.235683410762667, \"yhat_lower\": 6.809806419489486, \"yhat_upper\": 7.659242432431903, \"fact\": 7.2855991505679105, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:32:00\", \"yhat\": 7.226996520120252, \"yhat_lower\": 6.815810457299184, \"yhat_upper\": 7.649326676276867, \"fact\": 7.3253574361749, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:34:00\", \"yhat\": 7.2096227388354235, \"yhat_lower\": 6.792697206917347, \"yhat_upper\": 7.627051162752228, \"fact\": 7.591724855148331, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:35:00\", \"yhat\": 7.256145692995185, \"yhat_lower\": 6.8590239143007015, \"yhat_upper\": 7.6532787258843475, \"fact\": 7.518090746071456, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:38:00\", \"yhat\": 7.232674207262087, \"yhat_lower\": 6.813894730427177, \"yhat_upper\": 7.7086557661759825, \"fact\": 7.662263279799936, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:40:00\", \"yhat\": 7.297126456587372, \"yhat_lower\": 6.882776823300513, \"yhat_upper\": 7.681794157424193, \"fact\": 7.535410761101995, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:41:00\", \"yhat\": 7.290382717114853, \"yhat_lower\": 6.9068836818954855, \"yhat_upper\": 7.6794543920360985, \"fact\": 7.555415160113135, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:50:00\", \"yhat\": 7.397604169217175, \"yhat_lower\": 6.993884082760659, \"yhat_upper\": 7.841011737592532, \"fact\": 7.749417906852305, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:52:00\", \"yhat\": 7.38837600925168, \"yhat_lower\": 6.9380370710094965, \"yhat_upper\": 7.825166932455365, \"fact\": 7.682725698948679, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:53:00\", \"yhat\": 7.383761929268934, \"yhat_lower\": 6.945820820988156, \"yhat_upper\": 7.831267150686056, \"fact\": 7.663473876690589, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:54:00\", \"yhat\": 7.379147849286186, \"yhat_lower\": 6.949794929913077, \"yhat_upper\": 7.817440138669109, \"fact\": 7.650759642073896, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:55:00\", \"yhat\": 8.030384508793544, \"yhat_lower\": 7.149390083150819, \"yhat_upper\": 8.946872954858689, \"fact\": 7.643660841766507, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:56:00\", \"yhat\": 8.032690590934862, \"yhat_lower\": 7.124038535440943, \"yhat_upper\": 8.892773521544104, \"fact\": 7.740792599980338, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:57:00\", \"yhat\": 8.034996673076183, \"yhat_lower\": 7.206697504705297, \"yhat_upper\": 8.924578326179715, \"fact\": 7.729485101072052, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:58:00\", \"yhat\": 8.0373027552175, \"yhat_lower\": 7.161532080680552, \"yhat_upper\": 8.912983354533928, \"fact\": 7.809879193660448, \"anomaly\": 0}, {\"ds\": \"2021-08-23T23:59:00\", \"yhat\": 8.039608837358818, \"yhat_lower\": 7.134411735818428, \"yhat_upper\": 8.867921420995563, \"fact\": 7.870193732739887, \"anomaly\": 0}], \"data-a55b879d3e1aa08d4d2d2e85b669ba70\": [{\"ds\": \"2021-08-23T01:47:00\", \"yhat\": 3.425408598493483, \"yhat_lower\": 3.132391799776443, \"yhat_upper\": 3.696729556021589, \"fact\": 3.0901049942288012, \"anomaly\": 1}, {\"ds\": \"2021-08-23T01:48:00\", \"yhat\": 3.4721701432926544, \"yhat_lower\": 3.1992621515409265, \"yhat_upper\": 3.7631691372904323, \"fact\": 3.008162397059522, \"anomaly\": 1}, {\"ds\": \"2021-08-23T01:49:00\", \"yhat\": 3.518931688091824, \"yhat_lower\": 3.257116838160305, \"yhat_upper\": 3.7892305689426706, \"fact\": 3.0342427632947664, \"anomaly\": 1}, {\"ds\": \"2021-08-23T01:50:00\", \"yhat\": 3.392093895234215, \"yhat_lower\": 3.086854118405039, \"yhat_upper\": 3.689968213478047, \"fact\": 2.9627319946168917, \"anomaly\": 1}, {\"ds\": \"2021-08-23T01:51:00\", \"yhat\": 3.432548403456777, \"yhat_lower\": 3.0856781311569135, \"yhat_upper\": 3.736018074589602, \"fact\": 2.9569461503037706, \"anomaly\": 1}, {\"ds\": \"2021-08-23T01:52:00\", \"yhat\": 3.4730029116793397, \"yhat_lower\": 3.1371896071706606, \"yhat_upper\": 3.7992035296719537, \"fact\": 3.0267749492582157, \"anomaly\": 1}, {\"ds\": \"2021-08-23T01:53:00\", \"yhat\": 3.513457419901903, \"yhat_lower\": 3.2056552665636904, \"yhat_upper\": 3.8386345203755807, \"fact\": 3.07180359176354, \"anomaly\": 1}, {\"ds\": \"2021-08-23T01:54:00\", \"yhat\": 3.553911928124465, \"yhat_lower\": 3.206579091713092, \"yhat_upper\": 3.8862454627927074, \"fact\": 3.1560782394784286, \"anomaly\": 1}, {\"ds\": \"2021-08-23T01:56:00\", \"yhat\": 3.354736992523734, \"yhat_lower\": 3.0265083673572555, \"yhat_upper\": 3.719540653273529, \"fact\": 3.009950987266252, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:06:00\", \"yhat\": 3.069390703955379, \"yhat_lower\": 2.8213835386948674, \"yhat_upper\": 3.2966205971181943, \"fact\": 2.817236951076069, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:07:00\", \"yhat\": 3.070030300476838, \"yhat_lower\": 2.8059860155734873, \"yhat_upper\": 3.340368071603505, \"fact\": 2.7591756473744242, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:08:00\", \"yhat\": 3.0706698969982975, \"yhat_lower\": 2.8373395353674185, \"yhat_upper\": 3.337804704812789, \"fact\": 2.7415743889488313, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:09:00\", \"yhat\": 3.0713094935197565, \"yhat_lower\": 2.8243268784133555, \"yhat_upper\": 3.305439324044288, \"fact\": 2.634959930239999, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:22:00\", \"yhat\": 2.6479499628564613, \"yhat_lower\": 2.3908510643751435, \"yhat_upper\": 2.8943733367636364, \"fact\": 2.3347403540561436, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:23:00\", \"yhat\": 2.634040255298826, \"yhat_lower\": 2.3732339208653763, \"yhat_upper\": 2.9191594455580927, \"fact\": 2.262071173411276, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:24:00\", \"yhat\": 2.62013054774119, \"yhat_lower\": 2.3846283823373704, \"yhat_upper\": 2.870851825527081, \"fact\": 2.298347870588908, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:27:00\", \"yhat\": 2.4180537700917673, \"yhat_lower\": 2.1299791146054243, \"yhat_upper\": 2.6991839924807235, \"fact\": 2.1239990673356894, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:28:00\", \"yhat\": 2.397642730140371, \"yhat_lower\": 2.0917444228250126, \"yhat_upper\": 2.6640108617393885, \"fact\": 2.0556779001073835, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:29:00\", \"yhat\": 2.3772316901889745, \"yhat_lower\": 2.069641588236509, \"yhat_upper\": 2.7032519022447916, \"fact\": 2.0694340149175385, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:34:00\", \"yhat\": 2.0675085926879313, \"yhat_lower\": 1.7957534465269196, \"yhat_upper\": 2.3331662725999536, \"fact\": 2.3569619929709806, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:35:00\", \"yhat\": 2.1103111573431925, \"yhat_lower\": 1.8205148031004585, \"yhat_upper\": 2.407173260655713, \"fact\": 2.410609579163354, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:37:00\", \"yhat\": 2.058193575490955, \"yhat_lower\": 1.791193465278028, \"yhat_upper\": 2.355704333464961, \"fact\": 2.4445136543567934, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:38:00\", \"yhat\": 2.0321347845648368, \"yhat_lower\": 1.746145442101424, \"yhat_upper\": 2.324336279336982, \"fact\": 2.465681531052395, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:39:00\", \"yhat\": 2.006075993638717, \"yhat_lower\": 1.7148366914792954, \"yhat_upper\": 2.2834432458968137, \"fact\": 2.534376307983406, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:40:00\", \"yhat\": 2.159879255242714, \"yhat_lower\": 1.8315765354301885, \"yhat_upper\": 2.4873264400546877, \"fact\": 2.6272076036465988, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:41:00\", \"yhat\": 2.139922120467743, \"yhat_lower\": 1.8135199963828947, \"yhat_upper\": 2.475209942999132, \"fact\": 2.5816446195896057, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:42:00\", \"yhat\": 2.1199649856927723, \"yhat_lower\": 1.7829911830155571, \"yhat_upper\": 2.4493357402480678, \"fact\": 2.6662380206684615, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:43:00\", \"yhat\": 2.1000078509178013, \"yhat_lower\": 1.7622906318579834, \"yhat_upper\": 2.4381431559151143, \"fact\": 2.7168521403799497, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:44:00\", \"yhat\": 2.0800507161428303, \"yhat_lower\": 1.745373640411029, \"yhat_upper\": 2.425299067412107, \"fact\": 2.8538032872934025, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:45:00\", \"yhat\": 2.271309143852126, \"yhat_lower\": 1.8578218106621547, \"yhat_upper\": 2.6735358447828137, \"fact\": 2.854838809029115, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:46:00\", \"yhat\": 2.2569091566255888, \"yhat_lower\": 1.8471941923572044, \"yhat_upper\": 2.660966261182707, \"fact\": 2.8618450419844574, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:47:00\", \"yhat\": 2.2425091693990518, \"yhat_lower\": 1.85605622944757, \"yhat_upper\": 2.6431103117132837, \"fact\": 2.9749993982224634, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:48:00\", \"yhat\": 2.228109182172514, \"yhat_lower\": 1.8188301058611593, \"yhat_upper\": 2.656676866320554, \"fact\": 2.9242167077789762, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:49:00\", \"yhat\": 2.2137091949459773, \"yhat_lower\": 1.8138875012736324, \"yhat_upper\": 2.5909245685496614, \"fact\": 3.046298158099033, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:50:00\", \"yhat\": 2.472548443619745, \"yhat_lower\": 1.9998059237293389, \"yhat_upper\": 2.9334898514926038, \"fact\": 3.2619941973050857, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:51:00\", \"yhat\": 2.4663863369459005, \"yhat_lower\": 1.9284025315281805, \"yhat_upper\": 2.9282148048205876, \"fact\": 3.2881410304426844, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:52:00\", \"yhat\": 2.4602242302720563, \"yhat_lower\": 2.0029489955966726, \"yhat_upper\": 2.929972502043231, \"fact\": 3.17823623114512, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:53:00\", \"yhat\": 2.4540621235982116, \"yhat_lower\": 1.9550751693593924, \"yhat_upper\": 2.9231924306192525, \"fact\": 3.2035656084512185, \"anomaly\": 1}, {\"ds\": \"2021-08-23T02:54:00\", \"yhat\": 2.447900016924367, \"yhat_lower\": 1.9298852025717417, \"yhat_upper\": 3.0029122158163326, \"fact\": 3.2670646744239535, \"anomaly\": 1}, {\"ds\": \"2021-08-23T03:42:00\", \"yhat\": 3.3413580178934748, \"yhat_lower\": 3.0354100850539494, \"yhat_upper\": 3.6580814601322684, \"fact\": 3.692430901451204, \"anomaly\": 1}, {\"ds\": \"2021-08-23T03:43:00\", \"yhat\": 3.3467536668360927, \"yhat_lower\": 3.027052838779149, \"yhat_upper\": 3.664374895878244, \"fact\": 3.7236669409703915, \"anomaly\": 1}, {\"ds\": \"2021-08-23T03:44:00\", \"yhat\": 3.352149315778712, \"yhat_lower\": 3.038127110240192, \"yhat_upper\": 3.685501955798585, \"fact\": 3.8603194598248907, \"anomaly\": 1}, {\"ds\": \"2021-08-23T03:45:00\", \"yhat\": 3.4967131273264203, \"yhat_lower\": 3.1443722214477288, \"yhat_upper\": 3.8274754190087275, \"fact\": 3.9691359848159276, \"anomaly\": 1}, {\"ds\": \"2021-08-23T03:46:00\", \"yhat\": 3.5060574480757136, \"yhat_lower\": 3.1286472799275127, \"yhat_upper\": 3.8739242540450163, \"fact\": 3.962226709383252, \"anomaly\": 1}, {\"ds\": \"2021-08-23T03:47:00\", \"yhat\": 3.515401768825006, \"yhat_lower\": 3.1463075349687193, \"yhat_upper\": 3.8834755075052363, \"fact\": 3.9138960369194913, \"anomaly\": 1}, {\"ds\": \"2021-08-23T03:48:00\", \"yhat\": 3.5247460895742986, \"yhat_lower\": 3.1636349754927613, \"yhat_upper\": 3.8623763766636983, \"fact\": 3.866906827861522, \"anomaly\": 1}, {\"ds\": \"2021-08-23T03:49:00\", \"yhat\": 3.5340904103235915, \"yhat_lower\": 3.1860157461206438, \"yhat_upper\": 3.8829982895013972, \"fact\": 3.8996568831849046, \"anomaly\": 1}, {\"ds\": \"2021-08-23T04:18:00\", \"yhat\": 4.413473662199807, \"yhat_lower\": 4.071347677849834, \"yhat_upper\": 4.762242553201748, \"fact\": 3.963354168012908, \"anomaly\": 1}, {\"ds\": \"2021-08-23T04:19:00\", \"yhat\": 4.434405486716498, \"yhat_lower\": 4.075565914305938, \"yhat_upper\": 4.771860967664088, \"fact\": 4.013776178380292, \"anomaly\": 1}, {\"ds\": \"2021-08-23T04:20:00\", \"yhat\": 4.352324160272001, \"yhat_lower\": 3.9806755869893253, \"yhat_upper\": 4.752044939988422, \"fact\": 3.8392000488227365, \"anomaly\": 1}, {\"ds\": \"2021-08-23T04:21:00\", \"yhat\": 4.370861752224022, \"yhat_lower\": 4.0119134248847335, \"yhat_upper\": 4.764197085934688, \"fact\": 3.9196928506772672, \"anomaly\": 1}, {\"ds\": \"2021-08-23T04:22:00\", \"yhat\": 4.389399344176042, \"yhat_lower\": 4.026553790725365, \"yhat_upper\": 4.774731578975649, \"fact\": 4.026390515550767, \"anomaly\": 1}, {\"ds\": \"2021-08-23T04:56:00\", \"yhat\": 4.346688536855592, \"yhat_lower\": 3.9753465843849205, \"yhat_upper\": 4.708330382462337, \"fact\": 4.840059501436562, \"anomaly\": 1}, {\"ds\": \"2021-08-23T04:57:00\", \"yhat\": 4.352615294362694, \"yhat_lower\": 4.019225276112996, \"yhat_upper\": 4.693749246346788, \"fact\": 4.799561104428719, \"anomaly\": 1}, {\"ds\": \"2021-08-23T04:58:00\", \"yhat\": 4.358542051869798, \"yhat_lower\": 3.9992077506329, \"yhat_upper\": 4.718019119859398, \"fact\": 4.795506399361607, \"anomaly\": 1}, {\"ds\": \"2021-08-23T05:06:00\", \"yhat\": 4.6154607291222485, \"yhat_lower\": 4.176094460747009, \"yhat_upper\": 5.013705228370765, \"fact\": 5.17809129022616, \"anomaly\": 1}, {\"ds\": \"2021-08-23T05:07:00\", \"yhat\": 4.6252760399985275, \"yhat_lower\": 4.1751966173012685, \"yhat_upper\": 5.083359379189993, \"fact\": 5.2277973565851275, \"anomaly\": 1}, {\"ds\": \"2021-08-23T05:09:00\", \"yhat\": 4.644906661751087, \"yhat_lower\": 4.242429175454004, \"yhat_upper\": 5.040101244392638, \"fact\": 5.1297403620303, \"anomaly\": 1}, {\"ds\": \"2021-08-23T05:11:00\", \"yhat\": 4.7939070203906455, \"yhat_lower\": 4.328847874683812, \"yhat_upper\": 5.273063377018562, \"fact\": 5.300808308865612, \"anomaly\": 1}, {\"ds\": \"2021-08-23T05:12:00\", \"yhat\": 4.806237492717013, \"yhat_lower\": 4.334157400345976, \"yhat_upper\": 5.207763631788368, \"fact\": 5.26705268243037, \"anomaly\": 1}, {\"ds\": \"2021-08-23T05:16:00\", \"yhat\": 4.953816947396386, \"yhat_lower\": 4.446860734085777, \"yhat_upper\": 5.39545693642832, \"fact\": 5.426325324638567, \"anomaly\": 1}, {\"ds\": \"2021-08-23T05:18:00\", \"yhat\": 4.981688638064775, \"yhat_lower\": 4.5425424312933895, \"yhat_upper\": 5.469092222492535, \"fact\": 5.538297490098523, \"anomaly\": 1}, {\"ds\": \"2021-08-23T05:19:00\", \"yhat\": 4.99562448339897, \"yhat_lower\": 4.515998184645834, \"yhat_upper\": 5.51513469775087, \"fact\": 5.653105045264966, \"anomaly\": 1}, {\"ds\": \"2021-08-23T05:20:00\", \"yhat\": 5.142240208130522, \"yhat_lower\": 4.657569724547791, \"yhat_upper\": 5.653384006886456, \"fact\": 5.765696569733555, \"anomaly\": 1}, {\"ds\": \"2021-08-23T05:24:00\", \"yhat\": 5.208717622700772, \"yhat_lower\": 4.705550487049551, \"yhat_upper\": 5.708481516431225, \"fact\": 5.952771138793346, \"anomaly\": 1}, {\"ds\": \"2021-08-23T05:26:00\", \"yhat\": 5.448631395930975, \"yhat_lower\": 4.957343001295265, \"yhat_upper\": 5.95090422881013, \"fact\": 5.956312217973574, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:23:00\", \"yhat\": 7.398905486046514, \"yhat_lower\": 7.09613847711129, \"yhat_upper\": 7.740928034771321, \"fact\": 7.84596167034078, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:24:00\", \"yhat\": 7.430099283487114, \"yhat_lower\": 7.084513306392738, \"yhat_upper\": 7.779680487167167, \"fact\": 7.810708032610894, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:25:00\", \"yhat\": 7.503068449359887, \"yhat_lower\": 7.132077455430907, \"yhat_upper\": 7.856225987832262, \"fact\": 7.869544211046324, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:28:00\", \"yhat\": 7.598284205344119, \"yhat_lower\": 7.2467733443308155, \"yhat_upper\": 7.969593148464202, \"fact\": 7.22636705323483, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:29:00\", \"yhat\": 7.630022790672195, \"yhat_lower\": 7.301578652824, \"yhat_upper\": 8.000935990240233, \"fact\": 7.215400231065601, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:30:00\", \"yhat\": 7.629562987118985, \"yhat_lower\": 7.261415125287637, \"yhat_upper\": 8.005739476634869, \"fact\": 7.212214491649582, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:32:00\", \"yhat\": 7.69166258270783, \"yhat_lower\": 7.383849137425606, \"yhat_upper\": 8.046448160176297, \"fact\": 7.376476250774716, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:33:00\", \"yhat\": 7.722712380502252, \"yhat_lower\": 7.398064306637721, \"yhat_upper\": 8.075810251913788, \"fact\": 7.335800040585095, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:37:00\", \"yhat\": 7.763209808887485, \"yhat_lower\": 7.388728097617574, \"yhat_upper\": 8.118224160394597, \"fact\": 7.334626120276795, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:38:00\", \"yhat\": 7.792832130817345, \"yhat_lower\": 7.417666619837894, \"yhat_upper\": 8.141570574359186, \"fact\": 7.3049778908374945, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:39:00\", \"yhat\": 7.822454452747199, \"yhat_lower\": 7.469484917189898, \"yhat_upper\": 8.205196512252298, \"fact\": 7.278459085454509, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:41:00\", \"yhat\": 7.792207987581591, \"yhat_lower\": 7.429556916184169, \"yhat_upper\": 8.214119403165839, \"fact\": 7.413871916691975, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:42:00\", \"yhat\": 7.820386336657026, \"yhat_lower\": 7.404719473608865, \"yhat_upper\": 8.242390861519052, \"fact\": 7.306328534468085, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:43:00\", \"yhat\": 7.848564685732459, \"yhat_lower\": 7.420736522635234, \"yhat_upper\": 8.213372212623964, \"fact\": 7.135863705449194, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:44:00\", \"yhat\": 7.876743034807889, \"yhat_lower\": 7.467616511941547, \"yhat_upper\": 8.287214680730298, \"fact\": 7.296605351643508, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:47:00\", \"yhat\": 7.856847718098372, \"yhat_lower\": 7.402322121416356, \"yhat_upper\": 8.27653302450488, \"fact\": 7.278183825443562, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:48:00\", \"yhat\": 7.883389354990358, \"yhat_lower\": 7.473397927870447, \"yhat_upper\": 8.300350204809368, \"fact\": 7.250066035906667, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:49:00\", \"yhat\": 7.90993099188234, \"yhat_lower\": 7.484630620408147, \"yhat_upper\": 8.33448537232224, \"fact\": 7.282209302585056, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:50:00\", \"yhat\": 7.820125167986293, \"yhat_lower\": 7.372249090014914, \"yhat_upper\": 8.272038076589293, \"fact\": 7.2156324032840775, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:51:00\", \"yhat\": 7.8447492265443355, \"yhat_lower\": 7.384347518218982, \"yhat_upper\": 8.293036971019557, \"fact\": 7.196476313520412, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:52:00\", \"yhat\": 7.869373285102379, \"yhat_lower\": 7.421341055626196, \"yhat_upper\": 8.34531003396715, \"fact\": 7.113119567118843, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:53:00\", \"yhat\": 7.893997343660421, \"yhat_lower\": 7.425386391532291, \"yhat_upper\": 8.334904538797568, \"fact\": 7.162704804924952, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:54:00\", \"yhat\": 7.918621402218465, \"yhat_lower\": 7.463041169508518, \"yhat_upper\": 8.410168450495187, \"fact\": 7.221109884038875, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:55:00\", \"yhat\": 7.792377703855139, \"yhat_lower\": 7.376037184518288, \"yhat_upper\": 8.270816272926876, \"fact\": 7.28587585791872, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:56:00\", \"yhat\": 7.814536149936089, \"yhat_lower\": 7.349443330119734, \"yhat_upper\": 8.320825439606706, \"fact\": 7.33450767010157, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:57:00\", \"yhat\": 7.836694596017037, \"yhat_lower\": 7.319075852028994, \"yhat_upper\": 8.331981688054398, \"fact\": 7.2076185280683, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:58:00\", \"yhat\": 7.858853042097987, \"yhat_lower\": 7.388710758090654, \"yhat_upper\": 8.352935339122777, \"fact\": 7.200436641971628, \"anomaly\": 1}, {\"ds\": \"2021-08-23T06:59:00\", \"yhat\": 7.881011488178935, \"yhat_lower\": 7.42388586300723, \"yhat_upper\": 8.402974127198641, \"fact\": 7.174060851045539, \"anomaly\": 1}, {\"ds\": \"2021-08-23T07:17:00\", \"yhat\": 7.794608204603816, \"yhat_lower\": 7.3043617719127925, \"yhat_upper\": 8.350017784963253, \"fact\": 7.2610336329398955, \"anomaly\": 1}, {\"ds\": \"2021-08-23T07:19:00\", \"yhat\": 7.824258476190491, \"yhat_lower\": 7.299785886144246, \"yhat_upper\": 8.313205226122603, \"fact\": 7.175585543122942, \"anomaly\": 1}, {\"ds\": \"2021-08-23T07:20:00\", \"yhat\": 7.705203307174814, \"yhat_lower\": 7.179796205071708, \"yhat_upper\": 8.29508889715433, \"fact\": 7.132322801642127, \"anomaly\": 1}, {\"ds\": \"2021-08-23T07:21:00\", \"yhat\": 7.717498375607754, \"yhat_lower\": 7.1750889003409695, \"yhat_upper\": 8.2189327036714, \"fact\": 7.1510859667762, \"anomaly\": 1}, {\"ds\": \"2021-08-23T07:22:00\", \"yhat\": 7.729793444040696, \"yhat_lower\": 7.259635948786028, \"yhat_upper\": 8.246837631570852, \"fact\": 7.086966133877971, \"anomaly\": 1}, {\"ds\": \"2021-08-23T07:23:00\", \"yhat\": 7.742088512473638, \"yhat_lower\": 7.216099345041247, \"yhat_upper\": 8.242590621402277, \"fact\": 7.091083736255178, \"anomaly\": 1}, {\"ds\": \"2021-08-23T07:24:00\", \"yhat\": 7.754383580906579, \"yhat_lower\": 7.241410745110697, \"yhat_upper\": 8.28917597788792, \"fact\": 7.047475782418074, \"anomaly\": 1}, {\"ds\": \"2021-08-23T07:25:00\", \"yhat\": 7.613096301645659, \"yhat_lower\": 7.083790123017878, \"yhat_upper\": 8.177426160061719, \"fact\": 7.009527254558687, \"anomaly\": 1}, {\"ds\": \"2021-08-23T07:52:00\", \"yhat\": 7.39402646661652, \"yhat_lower\": 7.0020937753496675, \"yhat_upper\": 7.744473547051534, \"fact\": 7.7908900897128355, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:11:00\", \"yhat\": 7.384969201976114, \"yhat_lower\": 6.887588201034092, \"yhat_upper\": 7.823147099420789, \"fact\": 6.8317439585381985, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:12:00\", \"yhat\": 7.385379172486829, \"yhat_lower\": 6.921078090322933, \"yhat_upper\": 7.868204744816045, \"fact\": 6.846925861641189, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:13:00\", \"yhat\": 7.385789142997543, \"yhat_lower\": 6.976642646636571, \"yhat_upper\": 7.8265610129005365, \"fact\": 6.8792347865250285, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:14:00\", \"yhat\": 7.386199113508257, \"yhat_lower\": 6.930498371046004, \"yhat_upper\": 7.834882004509557, \"fact\": 6.918101973663316, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:17:00\", \"yhat\": 7.310000408853259, \"yhat_lower\": 6.853268291454035, \"yhat_upper\": 7.773576676566642, \"fact\": 6.792759709575465, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:18:00\", \"yhat\": 7.309589857003124, \"yhat_lower\": 6.881540187568575, \"yhat_upper\": 7.7658349968381675, \"fact\": 6.781526290147463, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:19:00\", \"yhat\": 7.309179305152988, \"yhat_lower\": 6.864750482532545, \"yhat_upper\": 7.723343422628803, \"fact\": 6.527562112720121, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:21:00\", \"yhat\": 7.208157059778378, \"yhat_lower\": 6.772249277709288, \"yhat_upper\": 7.6153295236104475, \"fact\": 6.342845929573227, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:22:00\", \"yhat\": 7.206358192956609, \"yhat_lower\": 6.74672273570825, \"yhat_upper\": 7.655409083526367, \"fact\": 6.295282891714099, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:23:00\", \"yhat\": 7.204559326134838, \"yhat_lower\": 6.725149994064496, \"yhat_upper\": 7.636262907008109, \"fact\": 6.416976346172642, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:24:00\", \"yhat\": 7.202760459313068, \"yhat_lower\": 6.767415981346756, \"yhat_upper\": 7.632301619229257, \"fact\": 6.474370432036268, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:26:00\", \"yhat\": 7.078438936831481, \"yhat_lower\": 6.602551286692136, \"yhat_upper\": 7.658625911752115, \"fact\": 6.565698424868521, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:27:00\", \"yhat\": 7.075027110419166, \"yhat_lower\": 6.62205831349603, \"yhat_upper\": 7.524160609177972, \"fact\": 6.58040116897878, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:28:00\", \"yhat\": 7.0716152840068505, \"yhat_lower\": 6.610655996486932, \"yhat_upper\": 7.5800510269113985, \"fact\": 6.482049789735297, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:29:00\", \"yhat\": 7.068203457594537, \"yhat_lower\": 6.52604184411481, \"yhat_upper\": 7.542549542272263, \"fact\": 6.390248110625829, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:30:00\", \"yhat\": 6.955693739121696, \"yhat_lower\": 6.464919645821934, \"yhat_upper\": 7.426739375059167, \"fact\": 6.32894900581122, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:31:00\", \"yhat\": 6.95072437919594, \"yhat_lower\": 6.420679816492657, \"yhat_upper\": 7.475264250259787, \"fact\": 6.342132763662364, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:32:00\", \"yhat\": 6.945755019270181, \"yhat_lower\": 6.471973054849666, \"yhat_upper\": 7.481771954926537, \"fact\": 6.431054046458639, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:33:00\", \"yhat\": 6.940785659344423, \"yhat_lower\": 6.413067702863305, \"yhat_upper\": 7.448188573730318, \"fact\": 6.373515189094005, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:34:00\", \"yhat\": 6.935816299418664, \"yhat_lower\": 6.431211144255794, \"yhat_upper\": 7.43040174764512, \"fact\": 6.205522054823765, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:56:00\", \"yhat\": 6.570941728557626, \"yhat_lower\": 6.011040130865521, \"yhat_upper\": 7.088828858973016, \"fact\": 7.097472113550277, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:57:00\", \"yhat\": 6.562498296387626, \"yhat_lower\": 6.044144440236699, \"yhat_upper\": 7.09848640932999, \"fact\": 7.192623177672057, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:58:00\", \"yhat\": 6.554054864217625, \"yhat_lower\": 6.047161465020219, \"yhat_upper\": 7.051623202555208, \"fact\": 7.258527915260533, \"anomaly\": 1}, {\"ds\": \"2021-08-23T08:59:00\", \"yhat\": 6.545611432047625, \"yhat_lower\": 6.053415375738495, \"yhat_upper\": 7.080182792218997, \"fact\": 7.282872270839376, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:01:00\", \"yhat\": 6.620519091270794, \"yhat_lower\": 6.114832561470911, \"yhat_upper\": 7.1861612186874, \"fact\": 7.261334072336341, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:02:00\", \"yhat\": 6.613013641528794, \"yhat_lower\": 6.081248803795237, \"yhat_upper\": 7.138236163482431, \"fact\": 7.264136729062933, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:03:00\", \"yhat\": 6.605508191786794, \"yhat_lower\": 5.99314182658148, \"yhat_upper\": 7.135596027109164, \"fact\": 7.286273159581655, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:04:00\", \"yhat\": 6.598002742044794, \"yhat_lower\": 6.03325596921655, \"yhat_upper\": 7.178870889543485, \"fact\": 7.357895750482174, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:05:00\", \"yhat\": 6.693912584577759, \"yhat_lower\": 6.11676796451608, \"yhat_upper\": 7.287618523634463, \"fact\": 7.330285522164443, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:06:00\", \"yhat\": 6.687626546711165, \"yhat_lower\": 6.0932735712789885, \"yhat_upper\": 7.2569077094979235, \"fact\": 7.421393852719808, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:07:00\", \"yhat\": 6.681340508844571, \"yhat_lower\": 6.0700848770731115, \"yhat_upper\": 7.262329427769223, \"fact\": 7.5620596009564744, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:08:00\", \"yhat\": 6.675054470977977, \"yhat_lower\": 6.017319891450547, \"yhat_upper\": 7.264344563435307, \"fact\": 7.565735575531843, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:09:00\", \"yhat\": 6.668768433111383, \"yhat_lower\": 6.126128104185291, \"yhat_upper\": 7.2765566661024, \"fact\": 7.58361194350413, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:11:00\", \"yhat\": 6.785905612619279, \"yhat_lower\": 6.129696847984307, \"yhat_upper\": 7.39782069029602, \"fact\": 7.610778235091248, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:12:00\", \"yhat\": 6.781069957102472, \"yhat_lower\": 6.13836945520072, \"yhat_upper\": 7.418970421260921, \"fact\": 7.521885308219655, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:13:00\", \"yhat\": 6.776234301585666, \"yhat_lower\": 6.200831660603755, \"yhat_upper\": 7.396832435815853, \"fact\": 7.716909631502675, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:14:00\", \"yhat\": 6.77139864606886, \"yhat_lower\": 6.149146992739965, \"yhat_upper\": 7.449934293993054, \"fact\": 7.747519051979066, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:15:00\", \"yhat\": 6.880367151078534, \"yhat_lower\": 6.254174056573473, \"yhat_upper\": 7.472648092124163, \"fact\": 7.785511706436309, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:16:00\", \"yhat\": 6.876878790714677, \"yhat_lower\": 6.225134253127474, \"yhat_upper\": 7.509176537642664, \"fact\": 7.930365226719392, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:17:00\", \"yhat\": 6.873390430350821, \"yhat_lower\": 6.178417285664864, \"yhat_upper\": 7.557568270149349, \"fact\": 7.967473463214496, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:18:00\", \"yhat\": 6.869902069986965, \"yhat_lower\": 6.217304042785024, \"yhat_upper\": 7.546628875382699, \"fact\": 7.999580916809377, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:19:00\", \"yhat\": 6.866413709623108, \"yhat_lower\": 6.186338830996752, \"yhat_upper\": 7.588657362282398, \"fact\": 7.92745812562292, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:20:00\", \"yhat\": 7.00302652264842, \"yhat_lower\": 6.298998606784435, \"yhat_upper\": 7.661574461783752, \"fact\": 8.055342945626094, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:21:00\", \"yhat\": 7.000874251638397, \"yhat_lower\": 6.264926274018221, \"yhat_upper\": 7.680171650560609, \"fact\": 8.069067375478213, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:22:00\", \"yhat\": 6.998721980628374, \"yhat_lower\": 6.253143768910448, \"yhat_upper\": 7.7085189372527765, \"fact\": 8.155734179368574, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:23:00\", \"yhat\": 6.996569709618351, \"yhat_lower\": 6.330389016301272, \"yhat_upper\": 7.704162497349425, \"fact\": 8.011806921777461, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:24:00\", \"yhat\": 6.994417438608328, \"yhat_lower\": 6.311948624162204, \"yhat_upper\": 7.687352137584781, \"fact\": 8.092111510811511, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:25:00\", \"yhat\": 7.131029050513527, \"yhat_lower\": 6.384100621637634, \"yhat_upper\": 7.894534479397975, \"fact\": 8.220078277501383, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:26:00\", \"yhat\": 7.130278443943234, \"yhat_lower\": 6.378717707515412, \"yhat_upper\": 7.9352598995014025, \"fact\": 8.267900885640357, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:27:00\", \"yhat\": 7.1295278373729385, \"yhat_lower\": 6.326141696513547, \"yhat_upper\": 7.826462236198117, \"fact\": 8.340179387722713, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:28:00\", \"yhat\": 7.128777230802644, \"yhat_lower\": 6.382021536165217, \"yhat_upper\": 7.94305033486737, \"fact\": 8.360308596655782, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:29:00\", \"yhat\": 7.12802662423235, \"yhat_lower\": 6.39378107218271, \"yhat_upper\": 7.814559385200954, \"fact\": 8.356915788188523, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:30:00\", \"yhat\": 7.3035367384566054, \"yhat_lower\": 6.514677633155262, \"yhat_upper\": 8.103345597144344, \"fact\": 8.288188793887379, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:31:00\", \"yhat\": 7.30473289081005, \"yhat_lower\": 6.506649251007318, \"yhat_upper\": 8.089088751985285, \"fact\": 8.371033308450802, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:32:00\", \"yhat\": 7.305929043163493, \"yhat_lower\": 6.504231989126135, \"yhat_upper\": 8.11960879816224, \"fact\": 8.296495018073724, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:33:00\", \"yhat\": 7.307125195516936, \"yhat_lower\": 6.466493859341004, \"yhat_upper\": 8.15868603505896, \"fact\": 8.267777641850003, \"anomaly\": 1}, {\"ds\": \"2021-08-23T09:34:00\", \"yhat\": 7.308321347870381, \"yhat_lower\": 6.550370623563716, \"yhat_upper\": 8.130118489074738, \"fact\": 8.144346886350423, \"anomaly\": 1}, {\"ds\": \"2021-08-23T10:26:00\", \"yhat\": 8.160389804486723, \"yhat_lower\": 7.5001439930559, \"yhat_upper\": 8.853153152413451, \"fact\": 7.45312553026062, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:38:00\", \"yhat\": 8.700166211802006, \"yhat_lower\": 8.225244475155694, \"yhat_upper\": 9.176062005549236, \"fact\": 8.098826371466577, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:39:00\", \"yhat\": 8.706790393191799, \"yhat_lower\": 8.255054506734641, \"yhat_upper\": 9.188267998347873, \"fact\": 8.05572889460056, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:40:00\", \"yhat\": 8.661109523746958, \"yhat_lower\": 8.184440202539015, \"yhat_upper\": 9.148540557976316, \"fact\": 7.956979270891584, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:41:00\", \"yhat\": 8.667286355567727, \"yhat_lower\": 8.164404869596712, \"yhat_upper\": 9.194275264701021, \"fact\": 7.811500666817628, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:42:00\", \"yhat\": 8.673463187388498, \"yhat_lower\": 8.224273460689343, \"yhat_upper\": 9.188713581595733, \"fact\": 7.690415462062634, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:43:00\", \"yhat\": 8.679640019209266, \"yhat_lower\": 8.185427701812879, \"yhat_upper\": 9.22515182459256, \"fact\": 7.717134221024015, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:44:00\", \"yhat\": 8.685816851030035, \"yhat_lower\": 8.235081269625013, \"yhat_upper\": 9.180386245492839, \"fact\": 7.835378833401439, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:45:00\", \"yhat\": 8.550187207709826, \"yhat_lower\": 8.070662275017789, \"yhat_upper\": 9.066935743542079, \"fact\": 7.711894191123989, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:46:00\", \"yhat\": 8.554695449985976, \"yhat_lower\": 8.031305185087305, \"yhat_upper\": 9.062844409884526, \"fact\": 7.7229591895282015, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:47:00\", \"yhat\": 8.559203692262129, \"yhat_lower\": 8.019299291137859, \"yhat_upper\": 9.031548686459688, \"fact\": 7.669836539613878, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:48:00\", \"yhat\": 8.563711934538278, \"yhat_lower\": 8.09644705625358, \"yhat_upper\": 9.098011884893127, \"fact\": 7.717692584250162, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:49:00\", \"yhat\": 8.56822017681443, \"yhat_lower\": 8.02695221382311, \"yhat_upper\": 9.065868239009239, \"fact\": 7.761794676176121, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:50:00\", \"yhat\": 8.434641254257627, \"yhat_lower\": 7.941520340731242, \"yhat_upper\": 8.949197115935734, \"fact\": 7.780476902942309, \"anomaly\": 1}, {\"ds\": \"2021-08-23T12:52:00\", \"yhat\": 8.440407247067387, \"yhat_lower\": 7.935298651467496, \"yhat_upper\": 9.025623520969638, \"fact\": 7.918981702230322, \"anomaly\": 1}, {\"ds\": \"2021-08-23T13:27:00\", \"yhat\": 8.388235968902864, \"yhat_lower\": 7.841676014734966, \"yhat_upper\": 8.943183605970667, \"fact\": 8.95869877998149, \"anomaly\": 1}, {\"ds\": \"2021-08-23T13:28:00\", \"yhat\": 8.389462981113807, \"yhat_lower\": 7.8725745274821035, \"yhat_upper\": 8.918451257476587, \"fact\": 9.131002557332641, \"anomaly\": 1}, {\"ds\": \"2021-08-23T13:29:00\", \"yhat\": 8.390689993324752, \"yhat_lower\": 7.8244051825899215, \"yhat_upper\": 8.893450757688052, \"fact\": 9.110278629189814, \"anomaly\": 1}, {\"ds\": \"2021-08-23T13:48:00\", \"yhat\": 8.61919713863978, \"yhat_lower\": 8.065608866869098, \"yhat_upper\": 9.168493198482807, \"fact\": 9.171105600168334, \"anomaly\": 1}, {\"ds\": \"2021-08-23T13:49:00\", \"yhat\": 8.621986381813796, \"yhat_lower\": 8.055914921852574, \"yhat_upper\": 9.220226242093116, \"fact\": 9.2291796823891, \"anomaly\": 1}, {\"ds\": \"2021-08-23T13:53:00\", \"yhat\": 8.716367615978266, \"yhat_lower\": 8.107224807940304, \"yhat_upper\": 9.3333155551609, \"fact\": 9.33795232275775, \"anomaly\": 1}, {\"ds\": \"2021-08-23T13:59:00\", \"yhat\": 8.805349195420785, \"yhat_lower\": 8.18510708491174, \"yhat_upper\": 9.394330684803636, \"fact\": 9.41516862839868, \"anomaly\": 1}, {\"ds\": \"2021-08-23T14:18:00\", \"yhat\": 9.257179065116825, \"yhat_lower\": 8.625816486831873, \"yhat_upper\": 9.855761373553337, \"fact\": 9.86632383278163, \"anomaly\": 1}, {\"ds\": \"2021-08-23T15:48:00\", \"yhat\": 10.87757762355374, \"yhat_lower\": 10.386860375453077, \"yhat_upper\": 11.319055978910544, \"fact\": 10.370020036709334, \"anomaly\": 1}, {\"ds\": \"2021-08-23T15:49:00\", \"yhat\": 10.891563574805005, \"yhat_lower\": 10.441541522797108, \"yhat_upper\": 11.390525171235838, \"fact\": 10.252602215750233, \"anomaly\": 1}, {\"ds\": \"2021-08-23T15:51:00\", \"yhat\": 10.84580573619485, \"yhat_lower\": 10.357629242364006, \"yhat_upper\": 11.282443929644463, \"fact\": 10.239477262630865, \"anomaly\": 1}, {\"ds\": \"2021-08-23T15:52:00\", \"yhat\": 10.858848616161232, \"yhat_lower\": 10.412728470794644, \"yhat_upper\": 11.310842948076557, \"fact\": 10.27736285358397, \"anomaly\": 1}, {\"ds\": \"2021-08-23T15:53:00\", \"yhat\": 10.871891496127612, \"yhat_lower\": 10.43108236087461, \"yhat_upper\": 11.298774649483146, \"fact\": 10.253281566040584, \"anomaly\": 1}, {\"ds\": \"2021-08-23T15:54:00\", \"yhat\": 10.884934376093993, \"yhat_lower\": 10.366338888958797, \"yhat_upper\": 11.40875173669462, \"fact\": 10.045963893343206, \"anomaly\": 1}, {\"ds\": \"2021-08-23T15:55:00\", \"yhat\": 10.806553488098153, \"yhat_lower\": 10.30471500208687, \"yhat_upper\": 11.26542326028414, \"fact\": 9.974512039077938, \"anomaly\": 1}, {\"ds\": \"2021-08-23T15:56:00\", \"yhat\": 10.81845720321221, \"yhat_lower\": 10.26238890054902, \"yhat_upper\": 11.328021321368503, \"fact\": 10.041043064809825, \"anomaly\": 1}, {\"ds\": \"2021-08-23T15:57:00\", \"yhat\": 10.830360918326265, \"yhat_lower\": 10.297485939599564, \"yhat_upper\": 11.310433023002384, \"fact\": 10.047700947811453, \"anomaly\": 1}, {\"ds\": \"2021-08-23T15:58:00\", \"yhat\": 10.842264633440323, \"yhat_lower\": 10.360976379526239, \"yhat_upper\": 11.322271367268906, \"fact\": 10.004137092919867, \"anomaly\": 1}, {\"ds\": \"2021-08-23T15:59:00\", \"yhat\": 10.854168348554378, \"yhat_lower\": 10.306231350408726, \"yhat_upper\": 11.31308782000769, \"fact\": 9.966989635494258, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:00:00\", \"yhat\": 10.727546407892202, \"yhat_lower\": 10.214686828101975, \"yhat_upper\": 11.19506076647489, \"fact\": 9.988342774645961, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:01:00\", \"yhat\": 10.737780509810392, \"yhat_lower\": 10.206463407758527, \"yhat_upper\": 11.23235214628739, \"fact\": 9.964268279658732, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:02:00\", \"yhat\": 10.748014611728582, \"yhat_lower\": 10.25620180809148, \"yhat_upper\": 11.239398936938837, \"fact\": 9.838689442516403, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:03:00\", \"yhat\": 10.758248713646774, \"yhat_lower\": 10.224051498020215, \"yhat_upper\": 11.269984296872675, \"fact\": 9.773522635065854, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:04:00\", \"yhat\": 10.768482815564964, \"yhat_lower\": 10.238227197592655, \"yhat_upper\": 11.28987423193651, \"fact\": 9.868386927448714, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:05:00\", \"yhat\": 10.639862185313838, \"yhat_lower\": 10.097139975653352, \"yhat_upper\": 11.236741682282082, \"fact\": 9.830469543424808, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:06:00\", \"yhat\": 10.648461523136131, \"yhat_lower\": 10.109029732115753, \"yhat_upper\": 11.24378049469269, \"fact\": 9.788865576129703, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:07:00\", \"yhat\": 10.657060860958426, \"yhat_lower\": 10.130494583258729, \"yhat_upper\": 11.221014292883632, \"fact\": 9.914847367291713, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:08:00\", \"yhat\": 10.665660198780719, \"yhat_lower\": 10.133820352474322, \"yhat_upper\": 11.287525630842095, \"fact\": 9.807562371531388, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:09:00\", \"yhat\": 10.674259536603012, \"yhat_lower\": 10.063949287382982, \"yhat_upper\": 11.26092874033183, \"fact\": 9.670822674017861, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:10:00\", \"yhat\": 10.537486964672853, \"yhat_lower\": 9.93630312059115, \"yhat_upper\": 11.138900105224167, \"fact\": 9.616577898394782, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:11:00\", \"yhat\": 10.544310469116622, \"yhat_lower\": 10.002508331951496, \"yhat_upper\": 11.118286375486054, \"fact\": 9.573703532341133, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:12:00\", \"yhat\": 10.551133973560392, \"yhat_lower\": 9.959203414153173, \"yhat_upper\": 11.12860341023074, \"fact\": 9.467645765284308, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:13:00\", \"yhat\": 10.557957478004163, \"yhat_lower\": 10.002605830508621, \"yhat_upper\": 11.1814231749571, \"fact\": 9.486973369882458, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:14:00\", \"yhat\": 10.564780982447932, \"yhat_lower\": 9.99035998138688, \"yhat_upper\": 11.12949373625888, \"fact\": 9.442311708770832, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:15:00\", \"yhat\": 10.381873533828978, \"yhat_lower\": 9.832408836432972, \"yhat_upper\": 10.994681029707703, \"fact\": 9.395669890818453, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:16:00\", \"yhat\": 10.386235133965277, \"yhat_lower\": 9.7919711607351, \"yhat_upper\": 11.010273627263254, \"fact\": 9.456601403941736, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:17:00\", \"yhat\": 10.390596734101578, \"yhat_lower\": 9.76245087608497, \"yhat_upper\": 10.968684343562138, \"fact\": 9.564992092172044, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:18:00\", \"yhat\": 10.394958334237877, \"yhat_lower\": 9.781721034832145, \"yhat_upper\": 11.000566047808823, \"fact\": 9.63165317584744, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:19:00\", \"yhat\": 10.399319934374176, \"yhat_lower\": 9.787340257811973, \"yhat_upper\": 10.997379436220326, \"fact\": 9.578406412111097, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:20:00\", \"yhat\": 10.245782089410863, \"yhat_lower\": 9.628566648093436, \"yhat_upper\": 10.841340089020287, \"fact\": 9.46403283204649, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:21:00\", \"yhat\": 10.248098500052112, \"yhat_lower\": 9.70907689324114, \"yhat_upper\": 10.902283685592193, \"fact\": 9.216432465535892, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:22:00\", \"yhat\": 10.250414910693364, \"yhat_lower\": 9.64844200586852, \"yhat_upper\": 10.850596066945412, \"fact\": 9.323236419089412, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:23:00\", \"yhat\": 10.252731321334611, \"yhat_lower\": 9.597499157002808, \"yhat_upper\": 10.866292057888014, \"fact\": 9.391465325298743, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:24:00\", \"yhat\": 10.255047731975862, \"yhat_lower\": 9.650310755545087, \"yhat_upper\": 10.869741718803855, \"fact\": 9.50366014614707, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:26:00\", \"yhat\": 10.104680505809045, \"yhat_lower\": 9.463205552164665, \"yhat_upper\": 10.790731948507142, \"fact\": 9.355788749450348, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:27:00\", \"yhat\": 10.105018857859555, \"yhat_lower\": 9.46327482409483, \"yhat_upper\": 10.787522123843322, \"fact\": 9.222799348520082, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:28:00\", \"yhat\": 10.105357209910066, \"yhat_lower\": 9.505918189792963, \"yhat_upper\": 10.750531654813361, \"fact\": 9.034232188045483, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:29:00\", \"yhat\": 10.105695561960575, \"yhat_lower\": 9.447258469645945, \"yhat_upper\": 10.728404395400494, \"fact\": 8.988900736784247, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:30:00\", \"yhat\": 9.940448152634987, \"yhat_lower\": 9.289028730787864, \"yhat_upper\": 10.611894733933827, \"fact\": 8.940239461563786, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:31:00\", \"yhat\": 9.938594478473371, \"yhat_lower\": 9.295021841128888, \"yhat_upper\": 10.66246311742404, \"fact\": 8.867726672403123, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:32:00\", \"yhat\": 9.936740804311754, \"yhat_lower\": 9.323496387573872, \"yhat_upper\": 10.576237748377562, \"fact\": 8.750332311139447, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:33:00\", \"yhat\": 9.934887130150138, \"yhat_lower\": 9.279748455982551, \"yhat_upper\": 10.575437989714926, \"fact\": 8.749543232452918, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:34:00\", \"yhat\": 9.933033455988522, \"yhat_lower\": 9.311475066583245, \"yhat_upper\": 10.655191447047962, \"fact\": 8.714350103767188, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:35:00\", \"yhat\": 9.72813327825672, \"yhat_lower\": 9.076197171733748, \"yhat_upper\": 10.422744893952851, \"fact\": 8.70989589254306, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:36:00\", \"yhat\": 9.723623371768536, \"yhat_lower\": 9.02977687890321, \"yhat_upper\": 10.420241840364467, \"fact\": 8.93646758528286, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:37:00\", \"yhat\": 9.719113465280351, \"yhat_lower\": 9.073224522769861, \"yhat_upper\": 10.425603568344398, \"fact\": 9.012239346556045, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:39:00\", \"yhat\": 9.71009365230398, \"yhat_lower\": 9.04311183279496, \"yhat_upper\": 10.35182835350896, \"fact\": 8.977564792960163, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:41:00\", \"yhat\": 9.529384710848138, \"yhat_lower\": 8.889563591518273, \"yhat_upper\": 10.232246329663601, \"fact\": 8.798698884079773, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:42:00\", \"yhat\": 9.522472488142345, \"yhat_lower\": 8.773727183614735, \"yhat_upper\": 10.275779225205548, \"fact\": 8.757817163308653, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:43:00\", \"yhat\": 9.515560265436552, \"yhat_lower\": 8.787882790813812, \"yhat_upper\": 10.195324300067606, \"fact\": 8.739247557388522, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:44:00\", \"yhat\": 9.508648042730757, \"yhat_lower\": 8.802622162437133, \"yhat_upper\": 10.218601133734975, \"fact\": 8.70356646824997, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:46:00\", \"yhat\": 9.35777135227005, \"yhat_lower\": 8.630784665740293, \"yhat_upper\": 10.021725706915213, \"fact\": 8.479925780652454, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:47:00\", \"yhat\": 9.348896504569366, \"yhat_lower\": 8.63648585634246, \"yhat_upper\": 9.988462050167813, \"fact\": 8.273358954380925, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:48:00\", \"yhat\": 9.340021656868682, \"yhat_lower\": 8.68433612117799, \"yhat_upper\": 10.01048805969932, \"fact\": 8.447199865827617, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:49:00\", \"yhat\": 9.331146809167997, \"yhat_lower\": 8.650842321599223, \"yhat_upper\": 9.973294395323588, \"fact\": 8.523194953304365, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:51:00\", \"yhat\": 9.112817148627423, \"yhat_lower\": 8.419242598469587, \"yhat_upper\": 9.74168392244127, \"fact\": 8.396411307804495, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:52:00\", \"yhat\": 9.101030833831171, \"yhat_lower\": 8.414299874094182, \"yhat_upper\": 9.800222189420403, \"fact\": 8.314908428588723, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:53:00\", \"yhat\": 9.089244519034917, \"yhat_lower\": 8.404888553765515, \"yhat_upper\": 9.731667629466008, \"fact\": 8.244009975240218, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:54:00\", \"yhat\": 9.077458204238663, \"yhat_lower\": 8.395928269273515, \"yhat_upper\": 9.793862365249588, \"fact\": 8.180232114481395, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:55:00\", \"yhat\": 8.88302353417909, \"yhat_lower\": 8.166155427767468, \"yhat_upper\": 9.570169156293238, \"fact\": 7.997073407217911, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:56:00\", \"yhat\": 8.868484826394587, \"yhat_lower\": 8.175483192939092, \"yhat_upper\": 9.490141322546995, \"fact\": 7.997788244170042, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:57:00\", \"yhat\": 8.853946118610086, \"yhat_lower\": 8.227635409978951, \"yhat_upper\": 9.538615954489238, \"fact\": 8.027379343471765, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:58:00\", \"yhat\": 8.839407410825583, \"yhat_lower\": 8.174251156048873, \"yhat_upper\": 9.566077427620714, \"fact\": 7.891617442415619, \"anomaly\": 1}, {\"ds\": \"2021-08-23T16:59:00\", \"yhat\": 8.824868703041082, \"yhat_lower\": 8.160324288505546, \"yhat_upper\": 9.496412361947021, \"fact\": 7.993391171167953, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:00:00\", \"yhat\": 8.625091614476457, \"yhat_lower\": 7.917109144103121, \"yhat_upper\": 9.289310080602506, \"fact\": 7.839794824705354, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:01:00\", \"yhat\": 8.607909900958305, \"yhat_lower\": 7.946664354672064, \"yhat_upper\": 9.308565286900068, \"fact\": 7.730599469753859, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:02:00\", \"yhat\": 8.590728187440154, \"yhat_lower\": 7.9480933391506285, \"yhat_upper\": 9.34564451458235, \"fact\": 7.6509477022655386, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:03:00\", \"yhat\": 8.573546473922002, \"yhat_lower\": 7.942169187477774, \"yhat_upper\": 9.22918014323943, \"fact\": 7.6005718066277375, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:04:00\", \"yhat\": 8.556364760403852, \"yhat_lower\": 7.918915538433692, \"yhat_upper\": 9.254916859584227, \"fact\": 7.616974853712176, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:05:00\", \"yhat\": 8.316710754578912, \"yhat_lower\": 7.678323994499728, \"yhat_upper\": 8.98409391867112, \"fact\": 7.452726173004684, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:06:00\", \"yhat\": 8.296125971651247, \"yhat_lower\": 7.670714930761088, \"yhat_upper\": 8.86251618108461, \"fact\": 7.4873100141103475, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:07:00\", \"yhat\": 8.275541188723583, \"yhat_lower\": 7.605220251959977, \"yhat_upper\": 8.955113037786706, \"fact\": 7.355716834977905, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:08:00\", \"yhat\": 8.254956405795916, \"yhat_lower\": 7.669508089663922, \"yhat_upper\": 8.91277763297565, \"fact\": 7.304617707670855, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:09:00\", \"yhat\": 8.23437162286825, \"yhat_lower\": 7.655681275786132, \"yhat_upper\": 8.925925378742216, \"fact\": 7.489866921022014, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:40:00\", \"yhat\": 6.738995543446881, \"yhat_lower\": 6.302904652969011, \"yhat_upper\": 7.232607551516974, \"fact\": 7.29287665449782, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:41:00\", \"yhat\": 6.706531865831485, \"yhat_lower\": 6.232571322392912, \"yhat_upper\": 7.16235934178656, \"fact\": 7.219469085171615, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:42:00\", \"yhat\": 6.674068188216088, \"yhat_lower\": 6.258265270485607, \"yhat_upper\": 7.1376436786627036, \"fact\": 7.191066675166035, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:43:00\", \"yhat\": 6.641604510600692, \"yhat_lower\": 6.189512914777615, \"yhat_upper\": 7.147385244400855, \"fact\": 7.150610552736501, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:44:00\", \"yhat\": 6.609140832985297, \"yhat_lower\": 6.16759671091267, \"yhat_upper\": 7.062710325171424, \"fact\": 7.173786787560158, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:45:00\", \"yhat\": 6.638676242147621, \"yhat_lower\": 6.157991075990711, \"yhat_upper\": 7.148937675582384, \"fact\": 7.165902938765192, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:46:00\", \"yhat\": 6.606655902574046, \"yhat_lower\": 6.139342338515938, \"yhat_upper\": 7.092612801547553, \"fact\": 7.184761105184088, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:47:00\", \"yhat\": 6.574635563000468, \"yhat_lower\": 6.0932996537552935, \"yhat_upper\": 7.070029953775914, \"fact\": 7.095968849846142, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:48:00\", \"yhat\": 6.542615223426893, \"yhat_lower\": 6.051914886313319, \"yhat_upper\": 7.043128567248866, \"fact\": 7.189463215776056, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:49:00\", \"yhat\": 6.510594883853314, \"yhat_lower\": 6.0068489856690945, \"yhat_upper\": 6.998501028353124, \"fact\": 7.2416172252622815, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:50:00\", \"yhat\": 6.573898036193053, \"yhat_lower\": 6.1313262539196725, \"yhat_upper\": 7.04826770319371, \"fact\": 7.289594697210025, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:51:00\", \"yhat\": 6.542963123323405, \"yhat_lower\": 6.074735589755639, \"yhat_upper\": 7.008523156825859, \"fact\": 7.287819788227195, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:52:00\", \"yhat\": 6.512028210453761, \"yhat_lower\": 6.058525557990556, \"yhat_upper\": 6.97148214064932, \"fact\": 7.252759139403707, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:53:00\", \"yhat\": 6.481093297584116, \"yhat_lower\": 6.02541807348493, \"yhat_upper\": 6.948921590429072, \"fact\": 7.312186655332198, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:54:00\", \"yhat\": 6.450158384714471, \"yhat_lower\": 5.943199455998045, \"yhat_upper\": 6.919253662812838, \"fact\": 7.417825510401695, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:55:00\", \"yhat\": 6.561496312373901, \"yhat_lower\": 6.008569105505864, \"yhat_upper\": 7.073155233512346, \"fact\": 7.537862680510393, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:56:00\", \"yhat\": 6.53239269330437, \"yhat_lower\": 5.9955051968543644, \"yhat_upper\": 7.014895833185693, \"fact\": 7.474088346812236, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:57:00\", \"yhat\": 6.5032890742348375, \"yhat_lower\": 5.962721196522892, \"yhat_upper\": 6.993138033518682, \"fact\": 7.353827173698256, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:58:00\", \"yhat\": 6.474185455165305, \"yhat_lower\": 5.901191555263871, \"yhat_upper\": 6.974741020358067, \"fact\": 7.203553863120317, \"anomaly\": 1}, {\"ds\": \"2021-08-23T17:59:00\", \"yhat\": 6.445081836095772, \"yhat_lower\": 5.8449466588201355, \"yhat_upper\": 6.976377723172193, \"fact\": 7.1667714268010965, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:00:00\", \"yhat\": 6.518236750732726, \"yhat_lower\": 5.946018147423554, \"yhat_upper\": 7.159878210943049, \"fact\": 7.199926729249083, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:02:00\", \"yhat\": 6.4618499904416, \"yhat_lower\": 5.90295522931356, \"yhat_upper\": 7.032666072203013, \"fact\": 7.082192901082215, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:03:00\", \"yhat\": 6.433656610296037, \"yhat_lower\": 5.886008213159699, \"yhat_upper\": 6.956656908586401, \"fact\": 7.060415319852113, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:04:00\", \"yhat\": 6.405463230150473, \"yhat_lower\": 5.8407232264352364, \"yhat_upper\": 7.005558343719051, \"fact\": 7.068729453386899, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:07:00\", \"yhat\": 6.435218991553755, \"yhat_lower\": 5.87982041828483, \"yhat_upper\": 7.001392359530289, \"fact\": 7.062204617401134, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:08:00\", \"yhat\": 6.4084447639428825, \"yhat_lower\": 5.817132152405417, \"yhat_upper\": 6.904923445587536, \"fact\": 6.993569720043028, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:09:00\", \"yhat\": 6.38167053633201, \"yhat_lower\": 5.856306141038915, \"yhat_upper\": 6.946368251606744, \"fact\": 6.9882948401110525, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:37:00\", \"yhat\": 6.124321722843027, \"yhat_lower\": 5.593501325260556, \"yhat_upper\": 6.611653096685884, \"fact\": 6.625989069250561, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:38:00\", \"yhat\": 6.103644284855556, \"yhat_lower\": 5.571752724051457, \"yhat_upper\": 6.662085147900715, \"fact\": 6.7475051661190895, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:39:00\", \"yhat\": 6.082966846868085, \"yhat_lower\": 5.547760029753542, \"yhat_upper\": 6.618425401375162, \"fact\": 6.844731750554106, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:40:00\", \"yhat\": 6.1733693815476895, \"yhat_lower\": 5.6002934308763965, \"yhat_upper\": 6.6733064346010575, \"fact\": 6.859763545701101, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:41:00\", \"yhat\": 6.154238700568382, \"yhat_lower\": 5.63127893977024, \"yhat_upper\": 6.661685855453814, \"fact\": 6.807310091228302, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:42:00\", \"yhat\": 6.135108019589075, \"yhat_lower\": 5.63889182750065, \"yhat_upper\": 6.65765303537158, \"fact\": 6.841886616435936, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:43:00\", \"yhat\": 6.115977338609768, \"yhat_lower\": 5.544826813501997, \"yhat_upper\": 6.637442737355108, \"fact\": 6.85893746778489, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:44:00\", \"yhat\": 6.0968466576304605, \"yhat_lower\": 5.52654776213331, \"yhat_upper\": 6.602790816968387, \"fact\": 6.846026479115778, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:45:00\", \"yhat\": 6.230247883402445, \"yhat_lower\": 5.6508875701623635, \"yhat_upper\": 6.75174652515251, \"fact\": 6.883238199122709, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:46:00\", \"yhat\": 6.213308316530373, \"yhat_lower\": 5.712704901759539, \"yhat_upper\": 6.7597952756968365, \"fact\": 6.809841352593101, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:47:00\", \"yhat\": 6.196368749658301, \"yhat_lower\": 5.651747989412673, \"yhat_upper\": 6.697031505584067, \"fact\": 6.751200710300513, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:48:00\", \"yhat\": 6.1794291827862295, \"yhat_lower\": 5.626152121304647, \"yhat_upper\": 6.709355990832785, \"fact\": 6.805567687218024, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:49:00\", \"yhat\": 6.162489615914158, \"yhat_lower\": 5.6587421251591286, \"yhat_upper\": 6.703564951115963, \"fact\": 6.772889900582233, \"anomaly\": 1}, {\"ds\": \"2021-08-23T18:58:00\", \"yhat\": 6.2709296322286, \"yhat_lower\": 5.688629265291276, \"yhat_upper\": 6.745107842358461, \"fact\": 6.765024078734705, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:02:00\", \"yhat\": 6.325381608812116, \"yhat_lower\": 5.7024460169982385, \"yhat_upper\": 6.885183417192731, \"fact\": 6.914632913487516, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:03:00\", \"yhat\": 6.31376415345871, \"yhat_lower\": 5.788463507847222, \"yhat_upper\": 6.835369767135219, \"fact\": 7.086807423198176, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:04:00\", \"yhat\": 6.302146698105304, \"yhat_lower\": 5.7538906954525375, \"yhat_upper\": 6.802332973203898, \"fact\": 7.073886368734035, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:05:00\", \"yhat\": 6.416873727018654, \"yhat_lower\": 5.923104979891344, \"yhat_upper\": 6.955591870086756, \"fact\": 7.020129069863576, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:06:00\", \"yhat\": 6.407063020226271, \"yhat_lower\": 5.883257250171081, \"yhat_upper\": 6.921490386558398, \"fact\": 7.101131503472381, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:07:00\", \"yhat\": 6.3972523134338894, \"yhat_lower\": 5.846559255483309, \"yhat_upper\": 6.8906393025475845, \"fact\": 7.010405102545185, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:08:00\", \"yhat\": 6.387441606641507, \"yhat_lower\": 5.835242424211177, \"yhat_upper\": 6.87582838997653, \"fact\": 6.951266834994014, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:09:00\", \"yhat\": 6.377630899849125, \"yhat_lower\": 5.882141373860259, \"yhat_upper\": 6.936696538775057, \"fact\": 6.963550333967537, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:11:00\", \"yhat\": 6.48203341213298, \"yhat_lower\": 5.960900742965638, \"yhat_upper\": 7.012953259005188, \"fact\": 7.031916357257972, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:13:00\", \"yhat\": 6.4658487279908465, \"yhat_lower\": 5.866597683652364, \"yhat_upper\": 6.960085693185832, \"fact\": 7.1046647071880225, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:14:00\", \"yhat\": 6.457756385919779, \"yhat_lower\": 5.928570163063725, \"yhat_upper\": 7.009419944771202, \"fact\": 7.040671190034965, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:15:00\", \"yhat\": 6.543452948233109, \"yhat_lower\": 6.039523380505979, \"yhat_upper\": 7.0584662086067, \"fact\": 7.190168047613055, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:16:00\", \"yhat\": 6.5366976210245635, \"yhat_lower\": 6.000407971544045, \"yhat_upper\": 7.09380787529094, \"fact\": 7.253047411598573, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:17:00\", \"yhat\": 6.529942293816019, \"yhat_lower\": 5.946472416155883, \"yhat_upper\": 7.033258039563559, \"fact\": 7.2720044758545415, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:18:00\", \"yhat\": 6.523186966607473, \"yhat_lower\": 6.00366379226002, \"yhat_upper\": 7.03291926487234, \"fact\": 7.381451693947673, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:19:00\", \"yhat\": 6.516431639398928, \"yhat_lower\": 5.997121788196181, \"yhat_upper\": 7.0576380250879165, \"fact\": 7.473923616291, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:20:00\", \"yhat\": 6.656732644607852, \"yhat_lower\": 6.168667916750992, \"yhat_upper\": 7.175356140260079, \"fact\": 7.377898618253228, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:21:00\", \"yhat\": 6.651944241402797, \"yhat_lower\": 6.1495591490426715, \"yhat_upper\": 7.187317076729155, \"fact\": 7.4365645152964674, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:22:00\", \"yhat\": 6.647155838197742, \"yhat_lower\": 6.09397924945614, \"yhat_upper\": 7.183046556161606, \"fact\": 7.424375555436707, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:23:00\", \"yhat\": 6.6423674349926864, \"yhat_lower\": 6.067486346188204, \"yhat_upper\": 7.206929779975967, \"fact\": 7.322828741550124, \"anomaly\": 1}, {\"ds\": \"2021-08-23T19:24:00\", \"yhat\": 6.637579031787631, \"yhat_lower\": 6.0706270673031035, \"yhat_upper\": 7.1763147068128434, \"fact\": 7.259170692504289, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:25:00\", \"yhat\": 7.441600253902873, \"yhat_lower\": 6.9665411529242425, \"yhat_upper\": 7.891014525109182, \"fact\": 8.00363971231057, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:29:00\", \"yhat\": 7.469369336660136, \"yhat_lower\": 7.001776110878833, \"yhat_upper\": 7.997542605701324, \"fact\": 8.10370677263385, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:34:00\", \"yhat\": 7.594549126405413, \"yhat_lower\": 7.1129191480053136, \"yhat_upper\": 8.070040619099538, \"fact\": 8.145123103951551, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:35:00\", \"yhat\": 7.681658782793313, \"yhat_lower\": 7.213221537798087, \"yhat_upper\": 8.140104839873622, \"fact\": 8.346190638990999, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:36:00\", \"yhat\": 7.690770633510965, \"yhat_lower\": 7.152445207293392, \"yhat_upper\": 8.168362903788191, \"fact\": 8.422543666781964, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:37:00\", \"yhat\": 7.699882484228617, \"yhat_lower\": 7.1587163314658175, \"yhat_upper\": 8.207881911797879, \"fact\": 8.459908928046268, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:38:00\", \"yhat\": 7.70899433494627, \"yhat_lower\": 7.245776368423086, \"yhat_upper\": 8.237724083165327, \"fact\": 8.455258423436057, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:39:00\", \"yhat\": 7.71810618566392, \"yhat_lower\": 7.18985044213105, \"yhat_upper\": 8.162824034215868, \"fact\": 8.556138297516846, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:40:00\", \"yhat\": 7.8358289639358105, \"yhat_lower\": 7.258101196378829, \"yhat_upper\": 8.40555792461566, \"fact\": 8.519475678661328, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:41:00\", \"yhat\": 7.846145961615911, \"yhat_lower\": 7.313907369109539, \"yhat_upper\": 8.394911681679416, \"fact\": 8.41012741828165, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:52:00\", \"yhat\": 8.078607517819016, \"yhat_lower\": 7.4503841722878645, \"yhat_upper\": 8.628498314699392, \"fact\": 8.648756666874846, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:53:00\", \"yhat\": 8.090122839928448, \"yhat_lower\": 7.596539291262366, \"yhat_upper\": 8.645970004088397, \"fact\": 8.687765792214106, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:54:00\", \"yhat\": 8.101638162037883, \"yhat_lower\": 7.524931501623367, \"yhat_upper\": 8.610120334279765, \"fact\": 8.748978959879818, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:55:00\", \"yhat\": 8.189069209178475, \"yhat_lower\": 7.680639686972964, \"yhat_upper\": 8.746702477261046, \"fact\": 8.799798123977336, \"anomaly\": 1}, {\"ds\": \"2021-08-23T20:56:00\", \"yhat\": 8.201452295030416, \"yhat_lower\": 7.597889355342116, \"yhat_upper\": 8.699039497924014, \"fact\": 8.712653545197707, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:27:00\", \"yhat\": 8.891545020578958, \"yhat_lower\": 8.399276300708067, \"yhat_upper\": 9.423284548034756, \"fact\": 8.345833211443853, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:28:00\", \"yhat\": 8.907562244244962, \"yhat_lower\": 8.37111057385977, \"yhat_upper\": 9.422307079282845, \"fact\": 8.308939856017505, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:29:00\", \"yhat\": 8.923579467910967, \"yhat_lower\": 8.406767588772396, \"yhat_upper\": 9.458028997612596, \"fact\": 8.288296800857225, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:30:00\", \"yhat\": 8.885104681947984, \"yhat_lower\": 8.348123176265172, \"yhat_upper\": 9.362688586382857, \"fact\": 8.200204061185255, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:31:00\", \"yhat\": 8.90072860141659, \"yhat_lower\": 8.400359446480206, \"yhat_upper\": 9.393457073727841, \"fact\": 8.316763381802183, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:32:00\", \"yhat\": 8.916352520885196, \"yhat_lower\": 8.3387233943113, \"yhat_upper\": 9.411965955598866, \"fact\": 8.213260542060581, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:33:00\", \"yhat\": 8.9319764403538, \"yhat_lower\": 8.417882878004404, \"yhat_upper\": 9.450644102489388, \"fact\": 8.100444362690379, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:34:00\", \"yhat\": 8.947600359822406, \"yhat_lower\": 8.403533839897207, \"yhat_upper\": 9.475451339159823, \"fact\": 8.166018118282045, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:35:00\", \"yhat\": 8.878005283126727, \"yhat_lower\": 8.338655477761147, \"yhat_upper\": 9.424311423748733, \"fact\": 8.133296418077531, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:36:00\", \"yhat\": 8.892899912045017, \"yhat_lower\": 8.35379147741493, \"yhat_upper\": 9.41421195218914, \"fact\": 8.2170409947153, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:37:00\", \"yhat\": 8.907794540963307, \"yhat_lower\": 8.338645755201, \"yhat_upper\": 9.42928583513676, \"fact\": 8.174451684276958, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:38:00\", \"yhat\": 8.922689169881599, \"yhat_lower\": 8.361914069431117, \"yhat_upper\": 9.50017527292884, \"fact\": 8.145406367187972, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:39:00\", \"yhat\": 8.937583798799889, \"yhat_lower\": 8.435212480535018, \"yhat_upper\": 9.547162823159443, \"fact\": 8.179618234404483, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:41:00\", \"yhat\": 8.874262963560916, \"yhat_lower\": 8.304710365200487, \"yhat_upper\": 9.457509338995377, \"fact\": 8.079524030680783, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:42:00\", \"yhat\": 8.88833945412264, \"yhat_lower\": 8.276024129931786, \"yhat_upper\": 9.488996019324667, \"fact\": 8.044864923024296, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:43:00\", \"yhat\": 8.902415944684362, \"yhat_lower\": 8.300770007141038, \"yhat_upper\": 9.492226774072448, \"fact\": 7.985665500760242, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:44:00\", \"yhat\": 8.916492435246086, \"yhat_lower\": 8.316634529758382, \"yhat_upper\": 9.493249072365597, \"fact\": 8.046488503559157, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:45:00\", \"yhat\": 8.839186488581527, \"yhat_lower\": 8.25825644394283, \"yhat_upper\": 9.426561642130395, \"fact\": 7.987912077062759, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:46:00\", \"yhat\": 8.852372983907157, \"yhat_lower\": 8.21269367250712, \"yhat_upper\": 9.472124622543557, \"fact\": 7.950148874417816, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:47:00\", \"yhat\": 8.86555947923279, \"yhat_lower\": 8.256477336237364, \"yhat_upper\": 9.45711814763116, \"fact\": 8.068015846901767, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:48:00\", \"yhat\": 8.87874597455842, \"yhat_lower\": 8.356274939150252, \"yhat_upper\": 9.510387770749686, \"fact\": 8.09246969731638, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:49:00\", \"yhat\": 8.891932469884049, \"yhat_lower\": 8.321843439790046, \"yhat_upper\": 9.497059844961603, \"fact\": 8.019705123658905, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:50:00\", \"yhat\": 8.776673260843316, \"yhat_lower\": 8.166502305051383, \"yhat_upper\": 9.399452625934941, \"fact\": 8.06028447175568, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:51:00\", \"yhat\": 8.788458559041583, \"yhat_lower\": 8.180986091712086, \"yhat_upper\": 9.505778759518698, \"fact\": 8.006729199085527, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:52:00\", \"yhat\": 8.80024385723985, \"yhat_lower\": 8.157531777717914, \"yhat_upper\": 9.495394850039432, \"fact\": 7.884033492434073, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:53:00\", \"yhat\": 8.812029155438118, \"yhat_lower\": 8.187839805734223, \"yhat_upper\": 9.419939677547662, \"fact\": 8.046823619428089, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:54:00\", \"yhat\": 8.823814453636386, \"yhat_lower\": 8.11727143456582, \"yhat_upper\": 9.512571913086923, \"fact\": 7.942622275786526, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:57:00\", \"yhat\": 8.74980426400091, \"yhat_lower\": 8.122368107300325, \"yhat_upper\": 9.374928825709377, \"fact\": 8.101259000219994, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:58:00\", \"yhat\": 8.760541954514096, \"yhat_lower\": 8.135595390144667, \"yhat_upper\": 9.39320621354414, \"fact\": 7.975741033032815, \"anomaly\": 1}, {\"ds\": \"2021-08-23T21:59:00\", \"yhat\": 8.771279645027281, \"yhat_lower\": 8.03227140632031, \"yhat_upper\": 9.45857013951157, \"fact\": 7.988226254020678, \"anomaly\": 1}, {\"ds\": \"2021-08-23T22:01:00\", \"yhat\": 8.718219789655274, \"yhat_lower\": 8.059950588696648, \"yhat_upper\": 9.400786519855092, \"fact\": 8.023293650410814, \"anomaly\": 1}, {\"ds\": \"2021-08-23T22:02:00\", \"yhat\": 8.728369052900145, \"yhat_lower\": 8.091888710068515, \"yhat_upper\": 9.477491463550109, \"fact\": 7.840974331834362, \"anomaly\": 1}, {\"ds\": \"2021-08-23T22:03:00\", \"yhat\": 8.738518316145015, \"yhat_lower\": 8.001409781733233, \"yhat_upper\": 9.430405302138702, \"fact\": 7.651628623492227, \"anomaly\": 1}, {\"ds\": \"2021-08-23T22:04:00\", \"yhat\": 8.748667579389886, \"yhat_lower\": 8.093246486762494, \"yhat_upper\": 9.371177976080025, \"fact\": 7.656945468320031, \"anomaly\": 1}, {\"ds\": \"2021-08-23T22:05:00\", \"yhat\": 8.610851545371188, \"yhat_lower\": 7.9373407858654055, \"yhat_upper\": 9.282000143907794, \"fact\": 7.567227283798734, \"anomaly\": 1}, {\"ds\": \"2021-08-23T22:06:00\", \"yhat\": 8.619308802404564, \"yhat_lower\": 7.898160837067203, \"yhat_upper\": 9.264237086431503, \"fact\": 7.485420053891467, \"anomaly\": 1}, {\"ds\": \"2021-08-23T22:07:00\", \"yhat\": 8.62776605943794, \"yhat_lower\": 7.894938090051737, \"yhat_upper\": 9.338629380811405, \"fact\": 7.453326960684346, \"anomaly\": 1}, {\"ds\": \"2021-08-23T22:08:00\", \"yhat\": 8.636223316471318, \"yhat_lower\": 7.935645579055604, \"yhat_upper\": 9.312749934385678, \"fact\": 7.5675711212537005, \"anomaly\": 1}, {\"ds\": \"2021-08-23T22:09:00\", \"yhat\": 8.644680573504692, \"yhat_lower\": 7.945108519790623, \"yhat_upper\": 9.402990507510104, \"fact\": 7.59136442192483, \"anomaly\": 1}, {\"ds\": \"2021-08-23T22:45:00\", \"yhat\": 7.641676978088506, \"yhat_lower\": 7.244558977745912, \"yhat_upper\": 8.015796273285913, \"fact\": 8.078038554719182, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:33:00\", \"yhat\": 7.218309629477838, \"yhat_lower\": 6.769297658803058, \"yhat_upper\": 7.606213328092621, \"fact\": 7.612270582135634, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:36:00\", \"yhat\": 7.248321864417486, \"yhat_lower\": 6.863260804024741, \"yhat_upper\": 7.657863410372234, \"fact\": 7.676593906453708, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:37:00\", \"yhat\": 7.240498035839787, \"yhat_lower\": 6.822547718370596, \"yhat_upper\": 7.654306354036949, \"fact\": 7.676014289757855, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:39:00\", \"yhat\": 7.224850378684389, \"yhat_lower\": 6.84384456435657, \"yhat_upper\": 7.66346982136988, \"fact\": 7.744231691853355, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:42:00\", \"yhat\": 7.283638977642333, \"yhat_lower\": 6.860754381580501, \"yhat_upper\": 7.681196021040207, \"fact\": 7.735896999116704, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:43:00\", \"yhat\": 7.276895238169813, \"yhat_lower\": 6.866484131488323, \"yhat_upper\": 7.691354189159965, \"fact\": 7.847623077982126, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:44:00\", \"yhat\": 7.270151498697294, \"yhat_lower\": 6.858233981743198, \"yhat_upper\": 7.649427988636571, \"fact\": 7.7968137342359105, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:45:00\", \"yhat\": 7.3388000929182695, \"yhat_lower\": 6.917029752053279, \"yhat_upper\": 7.78155126909891, \"fact\": 7.784207158858803, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:46:00\", \"yhat\": 7.333048985645888, \"yhat_lower\": 6.880325852959037, \"yhat_upper\": 7.7159287555518175, \"fact\": 7.853358920798734, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:47:00\", \"yhat\": 7.327297878373508, \"yhat_lower\": 6.916551357848126, \"yhat_upper\": 7.74678672945157, \"fact\": 7.9176391649767295, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:48:00\", \"yhat\": 7.321546771101126, \"yhat_lower\": 6.934123143319656, \"yhat_upper\": 7.713855038288237, \"fact\": 7.831808587137508, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:49:00\", \"yhat\": 7.315795663828746, \"yhat_lower\": 6.9120259855767445, \"yhat_upper\": 7.7246261038277595, \"fact\": 7.74727118708158, \"anomaly\": 1}, {\"ds\": \"2021-08-23T23:51:00\", \"yhat\": 7.392990089234428, \"yhat_lower\": 6.937723951366438, \"yhat_upper\": 7.7564989253349905, \"fact\": 7.788491835544637, \"anomaly\": 1}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## plot results\n",
    "detected_anomalies = detect_anomalies(total_forecast)\n",
    "plot_anomalies(detected_anomalies, mytitle=\"fbprophet Anomaly Detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aee0fe9-a6fc-43fc-903d-f8387bbb1d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb01406-efa3-420e-bcc4-a0031513e5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
