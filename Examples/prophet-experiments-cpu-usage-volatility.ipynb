{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is exploring using Facebook Prophet while also trying to determine when to retrain the model using the volatility measurement inspired by the DRAIN service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import altair as alt\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit_predict_model is a function which will take in a dataframe, fit the Prophet model to it and then give the forecasted results back for the next N minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_model(dataframe,periods=15,changepoint_prior_scale=0.10,daily_seasonality=False, weekly_seasonality=False, yearly_seasonality=False):\n",
    "    prophet_model = Prophet(growth=\"logistic\",changepoint_prior_scale=changepoint_prior_scale,daily_seasonality=daily_seasonality, weekly_seasonality=weekly_seasonality, yearly_seasonality=yearly_seasonality)\n",
    "    prophet_model.fit(dataframe)\n",
    "    future = prophet_model.make_future_dataframe(periods=periods,freq=\"1MIN\",include_history=False,)\n",
    "    future[\"cap\"] = 1.0\n",
    "    future_forecast = prophet_model.predict(future)\n",
    "    future_forecast[\"timestamp\"] = future_forecast[\"ds\"]\n",
    "    future_forecast = future_forecast.set_index(\"timestamp\")\n",
    "    return future_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detect_anomalies determines if each of the actual values is within the lower and upper bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies(forecast):\n",
    "    forecasted = forecast[['ds','trend', 'yhat', 'yhat_lower', 'yhat_upper', 'fact', 'upper_std', 'lower_std']].copy()\n",
    "    #forecast['fact'] = df['y']\n",
    "    forecasted.loc[forecasted['fact'] > forecasted['upper_std'], 'anomaly'] = 1\n",
    "    forecasted.loc[forecasted['fact'] < forecasted['lower_std'], 'anomaly'] = 1\n",
    "\n",
    "    #anomaly importances\n",
    "    forecasted['importance'] = 0\n",
    "    forecasted.loc[forecasted['anomaly'] ==1, 'importance'] = \\\n",
    "        (forecasted['fact'] - forecasted['yhat_upper'])/forecast['fact']\n",
    "    forecasted.loc[forecasted['anomaly'] ==-1, 'importance'] = \\\n",
    "        (forecasted['yhat_lower'] - forecasted['fact'])/forecast['fact']\n",
    "    \n",
    "    return forecasted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot_anomalies is a function that will plot the lower and upper bounds for each data point in addition to the actual value. Anomalies are marked by red meaning the data point is outside of the lower and upper bound range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_anomalies(forecasted):\n",
    "    interval = alt.Chart(forecasted).mark_area(interpolate=\"basis\", color = '#7FC97F').encode(\n",
    "    x=alt.X('ds:T', axis=alt.Axis(format='%H:%M'), title ='date'),\n",
    "    y='upper_std',\n",
    "    y2='lower_std',\n",
    "    tooltip=['ds', 'fact', 'lower_std', 'upper_std']\n",
    "    ).interactive().properties(\n",
    "        title='Anomaly Detection'\n",
    "    )\n",
    "\n",
    "    fact = alt.Chart(forecasted[forecasted.anomaly==0]).mark_circle(size=15, opacity=0.7, color = 'Black').encode(\n",
    "        x='ds:T',\n",
    "        y=alt.Y('fact', title='CPU Utilization Percentage'),    \n",
    "        tooltip=['ds', 'fact', 'lower_std', 'upper_std']\n",
    "    ).interactive()\n",
    "\n",
    "    anomalies = alt.Chart(forecasted[forecasted.anomaly!=0]).mark_circle(size=30, color = 'Red').encode(\n",
    "        x='ds:T',\n",
    "        y=alt.Y('fact', title='CPU Utilization Percentage'),    \n",
    "        tooltip=['ds', 'fact', 'lower_std', 'upper_std']\n",
    "    ).interactive()\n",
    "\n",
    "    return alt.layer(interval, fact, anomalies)\\\n",
    "              .properties(width=870, height=450)\\\n",
    "              .configure_title(fontSize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in 600 data points from clusterwide_cpu_usage_percentage.txt which contains 600 minutes worth of CPU usage within a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_values = []\n",
    "date_time_vals = []\n",
    "with open('clusterwide_cpu_usage_percentage.txt','r') as cmd:\n",
    "    for line in cmd:\n",
    "        line = line.rstrip().split(\",\")\n",
    "        date_time = datetime.fromtimestamp(float(line[0]))\n",
    "        date_time_vals.append(float(line[0]))\n",
    "        metric_dict = {\"ds\": date_time.strftime(\"%Y-%m-%d %H:%M:%S\"), \"y\": float(line[1]) / 100.0}\n",
    "        dataset_values.append(metric_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inject some outlier data at the end of this dataset to see whether or not these data points are marked as an anomaly or if model can adjust its forecasts over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_one = date_time_vals[-1] + 60\n",
    "icr = 0.70\n",
    "for i in range(500):\n",
    "    if i % 50 == 0:\n",
    "        icr += 0.01\n",
    "    new_dict = {\"ds\": (datetime.fromtimestamp(last_one)).strftime(\"%Y-%m-%d %H:%M:%S\"), \"y\": icr}\n",
    "    last_one += 60\n",
    "    dataset_values.append(new_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define data_range to determine how much of the dataset you would want to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_range = 1200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define time_interval for how often FB Prophet model will be retrained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_interval = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the maximum amount of training data which the FB prophet model will be trained on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metric_limit = 1440"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the changepoint_range for the Prophet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "changepoint_prior_scale = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the first data_range values of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_values = dataset_values[:data_range]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the initial training of the FB Prophet model, retrieve the first time_interval data points from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = data_values[:time_interval]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn the training_dataset list into a Pandas dataframe so it can be taken as input into Prophet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_df = pd.DataFrame(training_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weighted_avg_and_std function which computes the weighted mean and standard deviation of a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_avg_and_std(values, weights):\n",
    "    average = np.average(values, weights=weights)\n",
    "    # Fast and numerically precise:\n",
    "    variance = np.average((values - average) ** 2, weights=weights)\n",
    "    return average, math.sqrt(variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial variables declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_data_queue = deque([],training_metric_limit)\n",
    "normal_periods = []\n",
    "num_anomalies = 0\n",
    "metric_data_obtained = dict()\n",
    "column_names =  ['trend', 'yhat', 'yhat_lower', 'yhat_upper']\n",
    "train_on_next_chance = True\n",
    "stable = False\n",
    "training_start_ts_ns = 0\n",
    "very_first_ts_ns = 0\n",
    "forecasting_future = 1000\n",
    "future_forecast = None\n",
    "metrics_db = dict()\n",
    "prediction_results = []\n",
    "weighted_vols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(0,len(data_values)):\n",
    "    metric_data_obtained = dict()\n",
    "    current_metric_datetime = data_values[i][\"ds\"]\n",
    "    element = datetime.strptime(current_metric_datetime,\"%Y-%m-%d %H:%M:%S\")\n",
    "    element_datetime_tuple = element.timetuple()\n",
    "    current_ts = int(time.mktime(element_datetime_tuple))\n",
    "    if training_start_ts_ns == 0:\n",
    "        training_start_ts_ns = current_ts\n",
    "        very_first_ts_ns = current_ts\n",
    "    current_metric_value = data_values[i][\"y\"]\n",
    "    metrics_db[current_ts] = data_values[i]\n",
    "    metrics_data_queue.appendleft(current_metric_value)\n",
    "    cumulative_metrics_data = np.array(metrics_data_queue)\n",
    "    vol = np.std(cumulative_metrics_data) / np.mean(cumulative_metrics_data[:10])\n",
    "    time_steps = cumulative_metrics_data.shape[0]\n",
    "    weights = np.flip(np.true_divide(np.arange(1, time_steps + 1), time_steps))\n",
    "    weighted_mean, weighted_std = weighted_avg_and_std(cumulative_metrics_data, weights)\n",
    "    weighted_vol = weighted_std / np.mean(cumulative_metrics_data[:10])\n",
    "    weighted_vols.append(weighted_vol)\n",
    "    if future_forecast is not None:\n",
    "        nearest_index = future_forecast.index.get_loc(current_metric_datetime, method=\"nearest\")\n",
    "        nearest_index_value = future_forecast.iloc[[nearest_index]]\n",
    "        for c in column_names:\n",
    "            metric_data_obtained[c] = nearest_index_value[c].values[0]\n",
    "        yhat_lower = nearest_index_value['yhat_lower'].values[0]\n",
    "        yhat_upper = nearest_index_value['yhat_upper'].values[0]\n",
    "        yhat_value = nearest_index_value['yhat'].values[0]\n",
    "        yhat_lower = max(0, yhat_lower)\n",
    "        upper_std = abs(yhat_upper - yhat_value)\n",
    "        lower_std = abs(yhat_value - yhat_lower)\n",
    "        metric_data_obtained = {\"fact\": current_metric_value, \"ds\": current_metric_datetime}\n",
    "        metric_data_obtained['lower_std'] = max(0, yhat_lower - 2 * lower_std)\n",
    "        metric_data_obtained['upper_std'] = yhat_upper + (2 * upper_std)\n",
    "        metric_data_obtained['yhat_lower'] = yhat_lower\n",
    "        metric_data_obtained['yhat_upper'] = yhat_upper\n",
    "        metric_data_obtained['anomaly'] = 0\n",
    "        if (current_metric_value < yhat_lower - (2 * lower_std)) or (current_metric_value > yhat_upper + (2 * upper_std)):\n",
    "            metric_data_obtained['anomaly'] = 1\n",
    "            num_anomalies += 1\n",
    "        prediction_results.append(metric_data_obtained)\n",
    "        \n",
    "    if len(metrics_data_queue) > 15:\n",
    "        if weighted_vol >= 0.199:\n",
    "            train_on_next_chance = True\n",
    "\n",
    "        if (weighted_vol < 0.199 and training_start_ts_ns != very_first_ts_ns and train_on_next_chance):\n",
    "            training_start_ts_ns = current_ts\n",
    "\n",
    "        if weighted_vol > 0.155 and not train_on_next_chance and stable:\n",
    "            training_end_ts_ns = current_ts\n",
    "            normal_periods.append({\"start_ts\": training_start_ts_ns, \"end_ts\": training_end_ts_ns})\n",
    "            stable = False\n",
    "            training_start_ts_ns = -1.0\n",
    "\n",
    "        if weighted_vol <= 0.15 and train_on_next_chance:\n",
    "            print(f\"SENDING TRAIN SIGNAL on iteration {i}\")\n",
    "            if training_start_ts_ns != -1.0:\n",
    "                training_end_ts_ns = current_ts\n",
    "                normal_periods.append({\"start_ts\": training_start_ts_ns, \"end_ts\": training_end_ts_ns})\n",
    "            train_on_next_chance = False\n",
    "            stable = True\n",
    "            training_start_ts_ns = current_ts\n",
    "            training_ds = []\n",
    "            for normal in normal_periods:\n",
    "                start_ts, end_ts = normal[\"start_ts\"], normal[\"end_ts\"]\n",
    "                print(start_ts)\n",
    "                print(end_ts)\n",
    "                print(metrics_db)\n",
    "                for ts in range(start_ts,end_ts,60):\n",
    "                    if ts in metrics_db:\n",
    "                        training_ds.append(metrics_db[ts])\n",
    "            training_ds_df = pd.DataFrame(training_ds)\n",
    "            training_ds_df['cap'] = 1.0\n",
    "            print(training_ds_df)\n",
    "            future_forecast = fit_predict_model(training_ds_df,periods=training_metric_limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_vols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the first Prophet model which will be trained on the initial time_interval data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result_df = pd.DataFrame(prediction_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact</th>\n",
       "      <th>ds</th>\n",
       "      <th>lower_std</th>\n",
       "      <th>upper_std</th>\n",
       "      <th>yhat_lower</th>\n",
       "      <th>yhat_upper</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.153004</td>\n",
       "      <td>2021-07-17 03:33:03</td>\n",
       "      <td>0.056939</td>\n",
       "      <td>0.269987</td>\n",
       "      <td>0.119643</td>\n",
       "      <td>0.190659</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.158510</td>\n",
       "      <td>2021-07-17 03:34:03</td>\n",
       "      <td>0.041048</td>\n",
       "      <td>0.291438</td>\n",
       "      <td>0.114415</td>\n",
       "      <td>0.197879</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.155938</td>\n",
       "      <td>2021-07-17 03:35:03</td>\n",
       "      <td>0.029713</td>\n",
       "      <td>0.316456</td>\n",
       "      <td>0.110706</td>\n",
       "      <td>0.206287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.155479</td>\n",
       "      <td>2021-07-17 03:36:03</td>\n",
       "      <td>0.013573</td>\n",
       "      <td>0.346036</td>\n",
       "      <td>0.105395</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.158823</td>\n",
       "      <td>2021-07-17 03:37:03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376967</td>\n",
       "      <td>0.100012</td>\n",
       "      <td>0.226596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.156750</td>\n",
       "      <td>2021-07-17 03:38:03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.412771</td>\n",
       "      <td>0.093799</td>\n",
       "      <td>0.238600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.156813</td>\n",
       "      <td>2021-07-17 03:39:03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.443658</td>\n",
       "      <td>0.091148</td>\n",
       "      <td>0.248965</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.155792</td>\n",
       "      <td>2021-07-17 03:40:03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.477858</td>\n",
       "      <td>0.085799</td>\n",
       "      <td>0.260435</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.154792</td>\n",
       "      <td>2021-07-17 03:41:04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.528832</td>\n",
       "      <td>0.082223</td>\n",
       "      <td>0.277496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.160082</td>\n",
       "      <td>2021-07-17 03:42:04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.568082</td>\n",
       "      <td>0.078082</td>\n",
       "      <td>0.290649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.157231</td>\n",
       "      <td>2021-07-17 03:43:04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.604939</td>\n",
       "      <td>0.073542</td>\n",
       "      <td>0.303004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.164069</td>\n",
       "      <td>2021-07-17 03:44:04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.649472</td>\n",
       "      <td>0.068837</td>\n",
       "      <td>0.317918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.153275</td>\n",
       "      <td>2021-07-17 03:45:04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.713753</td>\n",
       "      <td>0.064995</td>\n",
       "      <td>0.339415</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.158052</td>\n",
       "      <td>2021-07-17 03:46:04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.781890</td>\n",
       "      <td>0.061361</td>\n",
       "      <td>0.362197</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.160448</td>\n",
       "      <td>2021-07-17 03:47:04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833196</td>\n",
       "      <td>0.059487</td>\n",
       "      <td>0.379368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.159010</td>\n",
       "      <td>2021-07-17 03:48:04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.897350</td>\n",
       "      <td>0.052885</td>\n",
       "      <td>0.400823</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.158885</td>\n",
       "      <td>2021-07-17 03:49:04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.951258</td>\n",
       "      <td>0.048838</td>\n",
       "      <td>0.418862</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.144646</td>\n",
       "      <td>2021-07-17 03:50:04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.007250</td>\n",
       "      <td>0.045969</td>\n",
       "      <td>0.437596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.150116</td>\n",
       "      <td>2021-07-17 03:51:04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.064567</td>\n",
       "      <td>0.042364</td>\n",
       "      <td>0.456771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.157702</td>\n",
       "      <td>2021-07-17 03:52:04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.117047</td>\n",
       "      <td>0.039048</td>\n",
       "      <td>0.474335</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.256281</td>\n",
       "      <td>2021-07-17 03:53:04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.185956</td>\n",
       "      <td>0.036363</td>\n",
       "      <td>0.497375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.226529</td>\n",
       "      <td>2021-07-17 03:54:04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.271207</td>\n",
       "      <td>0.033616</td>\n",
       "      <td>0.525861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.216898</td>\n",
       "      <td>2021-07-17 03:55:04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.350566</td>\n",
       "      <td>0.030644</td>\n",
       "      <td>0.552385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.248562</td>\n",
       "      <td>2021-07-17 03:56:04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.424992</td>\n",
       "      <td>0.029090</td>\n",
       "      <td>0.577263</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.226867</td>\n",
       "      <td>2021-07-17 03:57:05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.469417</td>\n",
       "      <td>0.025979</td>\n",
       "      <td>0.592142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.222871</td>\n",
       "      <td>2021-07-17 03:58:05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.546184</td>\n",
       "      <td>0.024484</td>\n",
       "      <td>0.617801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.199354</td>\n",
       "      <td>2021-07-17 03:59:05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.620420</td>\n",
       "      <td>0.020626</td>\n",
       "      <td>0.642617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.161740</td>\n",
       "      <td>2021-07-17 04:00:05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.676574</td>\n",
       "      <td>0.020226</td>\n",
       "      <td>0.661405</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.158740</td>\n",
       "      <td>2021-07-17 04:01:05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.738077</td>\n",
       "      <td>0.018744</td>\n",
       "      <td>0.681976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.165948</td>\n",
       "      <td>2021-07-17 04:02:05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.805398</td>\n",
       "      <td>0.015904</td>\n",
       "      <td>0.704487</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.165917</td>\n",
       "      <td>2021-07-17 04:03:05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.877321</td>\n",
       "      <td>0.015156</td>\n",
       "      <td>0.728532</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.149385</td>\n",
       "      <td>2021-07-17 04:04:05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.943452</td>\n",
       "      <td>0.014466</td>\n",
       "      <td>0.750646</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.158260</td>\n",
       "      <td>2021-07-17 04:05:05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.018508</td>\n",
       "      <td>0.013094</td>\n",
       "      <td>0.775735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.152281</td>\n",
       "      <td>2021-07-17 04:06:05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.070805</td>\n",
       "      <td>0.011456</td>\n",
       "      <td>0.793238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.152500</td>\n",
       "      <td>2021-07-17 04:07:05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.113787</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>0.807636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.154292</td>\n",
       "      <td>2021-07-17 04:08:05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.172606</td>\n",
       "      <td>0.009106</td>\n",
       "      <td>0.827313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.151188</td>\n",
       "      <td>2021-07-17 04:09:05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.212379</td>\n",
       "      <td>0.008601</td>\n",
       "      <td>0.840641</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.156094</td>\n",
       "      <td>2021-07-17 04:10:05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.258606</td>\n",
       "      <td>0.007696</td>\n",
       "      <td>0.856121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.162271</td>\n",
       "      <td>2021-07-17 04:11:05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.298711</td>\n",
       "      <td>0.007255</td>\n",
       "      <td>0.869560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.161969</td>\n",
       "      <td>2021-07-17 04:12:05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.312193</td>\n",
       "      <td>0.005809</td>\n",
       "      <td>0.874124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.166219</td>\n",
       "      <td>2021-07-17 04:13:06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.348679</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>0.886357</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.158139</td>\n",
       "      <td>2021-07-17 04:14:06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.385878</td>\n",
       "      <td>0.004977</td>\n",
       "      <td>0.898828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.156372</td>\n",
       "      <td>2021-07-17 04:15:06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.411229</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>0.907349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.155240</td>\n",
       "      <td>2021-07-17 04:16:06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.448341</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>0.919790</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.157719</td>\n",
       "      <td>2021-07-17 04:17:06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.477428</td>\n",
       "      <td>0.004119</td>\n",
       "      <td>0.929557</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.152104</td>\n",
       "      <td>2021-07-17 04:18:06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.499892</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.937116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.187906</td>\n",
       "      <td>2021-07-17 04:19:06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.522936</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>0.944868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.165156</td>\n",
       "      <td>2021-07-17 04:20:06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.534737</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.948873</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.159229</td>\n",
       "      <td>2021-07-17 04:21:06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.558415</td>\n",
       "      <td>0.003480</td>\n",
       "      <td>0.956837</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.156615</td>\n",
       "      <td>2021-07-17 04:22:06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.569949</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>0.960753</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fact                   ds  lower_std  upper_std  yhat_lower  \\\n",
       "0   0.153004  2021-07-17 03:33:03   0.056939   0.269987    0.119643   \n",
       "1   0.158510  2021-07-17 03:34:03   0.041048   0.291438    0.114415   \n",
       "2   0.155938  2021-07-17 03:35:03   0.029713   0.316456    0.110706   \n",
       "3   0.155479  2021-07-17 03:36:03   0.013573   0.346036    0.105395   \n",
       "4   0.158823  2021-07-17 03:37:03   0.000000   0.376967    0.100012   \n",
       "5   0.156750  2021-07-17 03:38:03   0.000000   0.412771    0.093799   \n",
       "6   0.156813  2021-07-17 03:39:03   0.000000   0.443658    0.091148   \n",
       "7   0.155792  2021-07-17 03:40:03   0.000000   0.477858    0.085799   \n",
       "8   0.154792  2021-07-17 03:41:04   0.000000   0.528832    0.082223   \n",
       "9   0.160082  2021-07-17 03:42:04   0.000000   0.568082    0.078082   \n",
       "10  0.157231  2021-07-17 03:43:04   0.000000   0.604939    0.073542   \n",
       "11  0.164069  2021-07-17 03:44:04   0.000000   0.649472    0.068837   \n",
       "12  0.153275  2021-07-17 03:45:04   0.000000   0.713753    0.064995   \n",
       "13  0.158052  2021-07-17 03:46:04   0.000000   0.781890    0.061361   \n",
       "14  0.160448  2021-07-17 03:47:04   0.000000   0.833196    0.059487   \n",
       "15  0.159010  2021-07-17 03:48:04   0.000000   0.897350    0.052885   \n",
       "16  0.158885  2021-07-17 03:49:04   0.000000   0.951258    0.048838   \n",
       "17  0.144646  2021-07-17 03:50:04   0.000000   1.007250    0.045969   \n",
       "18  0.150116  2021-07-17 03:51:04   0.000000   1.064567    0.042364   \n",
       "19  0.157702  2021-07-17 03:52:04   0.000000   1.117047    0.039048   \n",
       "20  0.256281  2021-07-17 03:53:04   0.000000   1.185956    0.036363   \n",
       "21  0.226529  2021-07-17 03:54:04   0.000000   1.271207    0.033616   \n",
       "22  0.216898  2021-07-17 03:55:04   0.000000   1.350566    0.030644   \n",
       "23  0.248562  2021-07-17 03:56:04   0.000000   1.424992    0.029090   \n",
       "24  0.226867  2021-07-17 03:57:05   0.000000   1.469417    0.025979   \n",
       "25  0.222871  2021-07-17 03:58:05   0.000000   1.546184    0.024484   \n",
       "26  0.199354  2021-07-17 03:59:05   0.000000   1.620420    0.020626   \n",
       "27  0.161740  2021-07-17 04:00:05   0.000000   1.676574    0.020226   \n",
       "28  0.158740  2021-07-17 04:01:05   0.000000   1.738077    0.018744   \n",
       "29  0.165948  2021-07-17 04:02:05   0.000000   1.805398    0.015904   \n",
       "30  0.165917  2021-07-17 04:03:05   0.000000   1.877321    0.015156   \n",
       "31  0.149385  2021-07-17 04:04:05   0.000000   1.943452    0.014466   \n",
       "32  0.158260  2021-07-17 04:05:05   0.000000   2.018508    0.013094   \n",
       "33  0.152281  2021-07-17 04:06:05   0.000000   2.070805    0.011456   \n",
       "34  0.152500  2021-07-17 04:07:05   0.000000   2.113787    0.009686   \n",
       "35  0.154292  2021-07-17 04:08:05   0.000000   2.172606    0.009106   \n",
       "36  0.151188  2021-07-17 04:09:05   0.000000   2.212379    0.008601   \n",
       "37  0.156094  2021-07-17 04:10:05   0.000000   2.258606    0.007696   \n",
       "38  0.162271  2021-07-17 04:11:05   0.000000   2.298711    0.007255   \n",
       "39  0.161969  2021-07-17 04:12:05   0.000000   2.312193    0.005809   \n",
       "40  0.166219  2021-07-17 04:13:06   0.000000   2.348679    0.005644   \n",
       "41  0.158139  2021-07-17 04:14:06   0.000000   2.385878    0.004977   \n",
       "42  0.156372  2021-07-17 04:15:06   0.000000   2.411229    0.005011   \n",
       "43  0.155240  2021-07-17 04:16:06   0.000000   2.448341    0.004367   \n",
       "44  0.157719  2021-07-17 04:17:06   0.000000   2.477428    0.004119   \n",
       "45  0.152104  2021-07-17 04:18:06   0.000000   2.499892    0.004004   \n",
       "46  0.187906  2021-07-17 04:19:06   0.000000   2.522936    0.003102   \n",
       "47  0.165156  2021-07-17 04:20:06   0.000000   2.534737    0.003260   \n",
       "48  0.159229  2021-07-17 04:21:06   0.000000   2.558415    0.003480   \n",
       "49  0.156615  2021-07-17 04:22:06   0.000000   2.569949    0.001865   \n",
       "\n",
       "    yhat_upper  anomaly  \n",
       "0     0.190659        0  \n",
       "1     0.197879        0  \n",
       "2     0.206287        0  \n",
       "3     0.216216        0  \n",
       "4     0.226596        0  \n",
       "5     0.238600        0  \n",
       "6     0.248965        0  \n",
       "7     0.260435        0  \n",
       "8     0.277496        0  \n",
       "9     0.290649        0  \n",
       "10    0.303004        0  \n",
       "11    0.317918        0  \n",
       "12    0.339415        0  \n",
       "13    0.362197        0  \n",
       "14    0.379368        0  \n",
       "15    0.400823        0  \n",
       "16    0.418862        0  \n",
       "17    0.437596        0  \n",
       "18    0.456771        0  \n",
       "19    0.474335        0  \n",
       "20    0.497375        0  \n",
       "21    0.525861        0  \n",
       "22    0.552385        0  \n",
       "23    0.577263        0  \n",
       "24    0.592142        0  \n",
       "25    0.617801        0  \n",
       "26    0.642617        0  \n",
       "27    0.661405        0  \n",
       "28    0.681976        0  \n",
       "29    0.704487        0  \n",
       "30    0.728532        0  \n",
       "31    0.750646        0  \n",
       "32    0.775735        0  \n",
       "33    0.793238        0  \n",
       "34    0.807636        0  \n",
       "35    0.827313        0  \n",
       "36    0.840641        0  \n",
       "37    0.856121        0  \n",
       "38    0.869560        0  \n",
       "39    0.874124        0  \n",
       "40    0.886357        0  \n",
       "41    0.898828        0  \n",
       "42    0.907349        0  \n",
       "43    0.919790        0  \n",
       "44    0.929557        0  \n",
       "45    0.937116        0  \n",
       "46    0.944868        0  \n",
       "47    0.948873        0  \n",
       "48    0.956837        0  \n",
       "49    0.960753        0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the number of anomalies predicted for each time_interval. A cold start is expected initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'anomaly_count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hl/6plb9y193wngh39z1dzl5rvh0000gn/T/ipykernel_2053/2038706916.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manomaly_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'anomaly_count' is not defined"
     ]
    }
   ],
   "source": [
    "print(anomaly_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_anomalies(pred_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plotting_values = []\n",
    "for d in data_values:\n",
    "    plotting_values.append(d['y'])\n",
    "plt.plot(range(len(plotting_values)), plotting_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
